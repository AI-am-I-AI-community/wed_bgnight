#!/usr/bin/env python3
"""
AIDB ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ç®¡ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ç™ºä¿¡æ´»å‹•ã§ã®å‚ç…§æ€§å‘ä¸Šã‚’æ”¯æ´ã™ã‚‹è‡ªå‹•åŒ–ãƒ„ãƒ¼ãƒ«
"""

import os
import re
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple

class AIDBManager:
    """AIDB ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã®ç®¡ç†ãƒ»æ¤œç´¢ãƒ»æ›´æ–°ã‚’è‡ªå‹•åŒ–"""
    
    def __init__(self, aidb_path: str = "04_data/Article/AIDB"):
        self.aidb_path = Path(aidb_path)
        self.categories = {
            "01_æ¨©å¨æ€§ãƒ»ä¿¡é ¼æ§‹ç¯‰": "authority",
            "02_å®Ÿè·µãƒã‚¦ãƒã‚¦ãƒ»æ‰‹æ³•": "practical", 
            "03_å¿œç”¨ã‚¢ã‚¤ãƒ‡ã‚¢ãƒ»äº‹ä¾‹": "application"
        }
        
    def scan_articles(self) -> Dict[str, List[Dict]]:
        """å…¨è¨˜äº‹ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã¦åŸºæœ¬æƒ…å ±ã‚’æŠ½å‡º"""
        articles = {}
        
        for category_dir, category_key in self.categories.items():
            category_path = self.aidb_path / category_dir
            if category_path.exists():
                articles[category_key] = []
                for md_file in category_path.glob("*.md"):
                    if not md_file.name.startswith("00_"):
                        article_info = self._extract_article_info(md_file)
                        articles[category_key].append(article_info)
                        
        return articles
    
    def _extract_article_info(self, md_file: Path) -> Dict:
        """è¨˜äº‹ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰åŸºæœ¬æƒ…å ±ã‚’æŠ½å‡º"""
        with open(md_file, 'r', encoding='utf-8') as f:
            content = f.read()
            
        # åŸºæœ¬æƒ…å ±ã®æŠ½å‡º
        title = md_file.stem
        file_size = md_file.stat().st_size
        word_count = len(content.split())
        
        # æ¨©å¨æ€§ãƒ¬ãƒ™ãƒ«ã®æ¨å®šï¼ˆçµ„ç¹”åã§åˆ¤å®šï¼‰
        authority_level = self._estimate_authority_level(title, content)
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æŠ½å‡º
        keywords = self._extract_keywords(title, content)
        
        return {
            "title": title,
            "file_path": str(md_file),
            "file_size": file_size,
            "word_count": word_count,
            "authority_level": authority_level,
            "keywords": keywords,
            "last_modified": datetime.fromtimestamp(md_file.stat().st_mtime)
        }
    
    def _estimate_authority_level(self, title: str, content: str) -> int:
        """è¨˜äº‹ã®æ¨©å¨æ€§ãƒ¬ãƒ™ãƒ«ã‚’æ¨å®šï¼ˆ1-3ã®æ®µéšï¼‰"""
        # é«˜æ¨©å¨æ©Ÿé–¢ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        high_authority = [
            "OpenAI", "Google DeepMind", "Microsoft", "Meta", 
            "Stanford", "Harvard", "MIT", "è«–æ–‡", "ç ”ç©¶"
        ]
        
        # ä¸­æ¨©å¨æ©Ÿé–¢ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        medium_authority = [
            "Amazon", "Apple", "NVIDIA", "IBM", "å®Ÿè¨¼å®Ÿé¨“", "èª¿æŸ»"
        ]
        
        text = title + " " + content[:1000]  # ã‚¿ã‚¤ãƒˆãƒ«+å†’é ­1000æ–‡å­—ã§åˆ¤å®š
        
        if any(keyword in text for keyword in high_authority):
            return 3
        elif any(keyword in text for keyword in medium_authority):
            return 2
        else:
            return 1
    
    def _extract_keywords(self, title: str, content: str) -> List[str]:
        """è¨˜äº‹ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º"""
        # ã‚ˆãä½¿ã‚ã‚Œã‚‹AIé–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        ai_keywords = [
            "LLM", "GPT", "Claude", "ChatGPT", "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ", "RAG",
            "ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ", "ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«", "ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯", "è©•ä¾¡",
            "ç²¾åº¦", "æ€§èƒ½", "åŠ¹ç‡", "è‡ªå‹•åŒ–", "ç”Ÿç”£æ€§", "ã‚³ã‚¹ãƒˆ"
        ]
        
        text = title + " " + content
        found_keywords = []
        
        for keyword in ai_keywords:
            if keyword in text:
                found_keywords.append(keyword)
                
        return found_keywords
    
    def search_articles(self, query: str, category: str = None) -> List[Dict]:
        """è¨˜äº‹ã‚’æ¤œç´¢ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ï¼‰"""
        articles = self.scan_articles()
        results = []
        
        # æ¤œç´¢å¯¾è±¡ã‚«ãƒ†ã‚´ãƒªã®æ±ºå®š
        search_categories = [category] if category else list(articles.keys())
        
        for cat in search_categories:
            if cat in articles:
                for article in articles[cat]:
                    # ã‚¿ã‚¤ãƒˆãƒ«ã‚„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«æ¤œç´¢èªãŒå«ã¾ã‚Œã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                    if (query.lower() in article["title"].lower() or
                        any(query.lower() in keyword.lower() for keyword in article["keywords"])):
                        article["category"] = cat
                        results.append(article)
        
        # æ¨©å¨æ€§ãƒ¬ãƒ™ãƒ«ã§ã‚½ãƒ¼ãƒˆï¼ˆé«˜ã„é †ï¼‰
        return sorted(results, key=lambda x: x["authority_level"], reverse=True)
    
    def generate_quick_reference(self) -> str:
        """ã‚¯ã‚¤ãƒƒã‚¯ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ç”¨ã®æƒ…å ±ã‚’ç”Ÿæˆ"""
        articles = self.scan_articles()
        
        # é«˜æ¨©å¨è¨˜äº‹ã®æŠ½å‡º
        high_authority_articles = []
        for category, article_list in articles.items():
            for article in article_list:
                if article["authority_level"] == 3:
                    high_authority_articles.append(article)
        
        # æ•°å­—ã‚’å«ã‚€è¨˜äº‹ã®æŠ½å‡º
        number_articles = []
        for category, article_list in articles.items():
            for article in article_list:
                if re.search(r'\d+%|\d+å€|\d+ä»¶', article["title"]):
                    number_articles.append(article)
        
        return {
            "high_authority_count": len(high_authority_articles),
            "number_articles": number_articles[:10],  # ä¸Šä½10ä»¶
            "total_articles": sum(len(articles[cat]) for cat in articles),
            "categories_summary": {cat: len(articles[cat]) for cat in articles}
        }
    
    def update_indexes(self):
        """ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•æ›´æ–°"""
        print("ğŸ“‹ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è‡ªå‹•æ›´æ–°æ©Ÿèƒ½")
        print("æ³¨æ„: ã“ã®æ©Ÿèƒ½ã¯å°†æ¥çš„ãªå®Ÿè£…äºˆå®šã§ã™")
        
        # å°†æ¥çš„ãªå®Ÿè£…ã‚¢ã‚¤ãƒ‡ã‚¢:
        # 1. å„ã‚«ãƒ†ã‚´ãƒªã®è¨˜äº‹æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        # 2. æ–°ç€è¨˜äº‹ã®è‡ªå‹•åˆ†é¡
        # 3. æ¨©å¨æ€§ãƒ¬ãƒ™ãƒ«ã®è‡ªå‹•åˆ¤å®š
        # 4. ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã®è‡ªå‹•ç”Ÿæˆ
        
        articles = self.scan_articles()
        summary = self.generate_quick_reference()
        
        print(f"ç·è¨˜äº‹æ•°: {summary['total_articles']}ä»¶")
        for category, count in summary["categories_summary"].items():
            print(f"  {category}: {count}ä»¶")
        print(f"é«˜æ¨©å¨è¨˜äº‹: {summary['high_authority_count']}ä»¶")
        
    def export_reference_data(self, output_file: str = "aidb_reference.json"):
        """å‚ç…§ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’JSONã§å‡ºåŠ›"""
        articles = self.scan_articles()
        summary = self.generate_quick_reference()
        
        export_data = {
            "metadata": {
                "export_date": datetime.now().isoformat(),
                "total_articles": summary["total_articles"],
                "categories": summary["categories_summary"]
            },
            "articles": articles,
            "quick_reference": summary
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"âœ… å‚ç…§ãƒ‡ãƒ¼ã‚¿ã‚’ {output_file} ã«å‡ºåŠ›ã—ã¾ã—ãŸ")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    manager = AIDBManager()
    
    print("ğŸš€ AIDB ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ç®¡ç†ãƒ„ãƒ¼ãƒ«")
    print("=" * 50)
    
    while True:
        print("\né¸æŠã—ã¦ãã ã•ã„:")
        print("1. è¨˜äº‹æ¤œç´¢")
        print("2. çµ±è¨ˆæƒ…å ±è¡¨ç¤º")
        print("3. ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ›´æ–°")
        print("4. å‚ç…§ãƒ‡ãƒ¼ã‚¿å‡ºåŠ›")
        print("5. çµ‚äº†")
        
        choice = input("\nç•ªå·ã‚’å…¥åŠ›: ").strip()
        
        if choice == "1":
            query = input("æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›: ").strip()
            results = manager.search_articles(query)
            
            print(f"\nğŸ” æ¤œç´¢çµæœ: {len(results)}ä»¶")
            for i, article in enumerate(results[:5], 1):
                print(f"{i}. {article['title']}")
                print(f"   æ¨©å¨æ€§: {'â­' * article['authority_level']}")
                print(f"   ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(article['keywords'][:3])}")
                print()
                
        elif choice == "2":
            summary = manager.generate_quick_reference()
            print(f"\nğŸ“Š çµ±è¨ˆæƒ…å ±")
            print(f"ç·è¨˜äº‹æ•°: {summary['total_articles']}ä»¶")
            print(f"é«˜æ¨©å¨è¨˜äº‹: {summary['high_authority_count']}ä»¶")
            for category, count in summary["categories_summary"].items():
                print(f"  {category}: {count}ä»¶")
                
        elif choice == "3":
            manager.update_indexes()
            
        elif choice == "4":
            filename = input("å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: aidb_reference.json): ").strip()
            if not filename:
                filename = "aidb_reference.json"
            manager.export_reference_data(filename)
            
        elif choice == "5":
            print("ğŸ‘‹ çµ‚äº†ã—ã¾ã™")
            break
            
        else:
            print("âŒ ç„¡åŠ¹ãªé¸æŠã§ã™")

if __name__ == "__main__":
    main() 