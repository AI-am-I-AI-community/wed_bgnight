---
title: "「LLMで繰り返しコードを改良」で発生するセキュリティ脆弱性リスク"
source: "https://ai-data-base.com/archives/91572"
author:
  - "[[AIDB Research]]"
published: 2025-06-30
created: 2025-07-09
description: "本記事では、LLMで繰り返しコードを改良する中でセキュリティ上の脆弱性がどう生まれていくのかを調べた研究を紹介します。"
tags:
  - "clippings"
---
Loading \[MathJax\]/extensions/tex2jax.js

本記事では、LLMで繰り返しコードを改良する中でセキュリティ上の脆弱性がどう生まれていくのかを調べた研究を紹介します。

AIを使って少しずつコードを整えていく、というスタイルはすでに多くの現場で定着しつつありますが、その過程で安全性がどう変化するのかはあまり語られてきていません。そこで、どこでリスクが入り込むのかを丁寧に追跡しています。

日々の開発でAIを取り入れている方にとって、実務に引き寄せながら読める内容になっていると思います。

![](https://ai-data-base.com/wp-content/uploads/2025/06/AIDB_91572-1024x576.png)

## 背景

いま多くの開発現場で、「コードを書く」という行為そのものが大きく変わり始めています。ChatGPTやGitHub Copilotをはじめとしたツールの登場を皮切りに、LLMを活用してコードを生成する手法が一気に広まりました。開発者の8割以上がすでに日常的にLLMを活用したコーディングを取り入れているとの報告もされており、GitHubのCEOも「遠からず、コードの8割をAIが書くようになる」と述べています。

こうした流れは、開発の生産性を高めるという期待とともに、セキュリティに対する懸念も呼び起こしています。実際、LLMが生成するコードにセキュリティ上の問題が含まれていることが、これまでの研究でも繰り返し指摘されてきました。

ただし、実務でのLLM活用は単純な「一発生成」ではありません。要するに多くの現場では、LLMの出力をそのまま使うのではなく、「ここをもっと速くして」「この機能を追加して」といったやり取りを何度も繰り返しながら、コードの改良や拡張を進めています。このような反復的なやり取りの中でセキュリティがどう変化するのかについては、ほとんど検証されてきていません。

本記事は、その見過ごされてきた部分に注目します。LLMとのやり取りを繰り返すことで、むしろ新たな脆弱性が生まれてしまうのではないか。とくに人間の介入がない状態では、その傾向が強まる可能性があるのではないか。そうした仮説を出発点として、実際にどのような変化が起きるのかを体系的に調べようとしている研究をもとに調査報告を紹介します。LLMを用いた開発のなかで、人間の判断がどこまで重要なのかを見極めていくのが目的です。

以下で詳しく見ていきましょう。

## セキュリティの落とし穴はどこから始まるのか

LLMとやり取りを重ねながらコードを書いていく開発スタイルが広がるなかで、「そのプロセスのどこにセキュリティ上のリスクが潜んでいるのか」。最初に、これまでの研究でわかっていることを押さえていきましょう。

### まずは、LLMが書いたコードにどんなクセがあるか

LLMによるコード生成は、見た目にはとても便利に思える一方で、セキュリティの視点から見ると注意すべき点がいくつもあると報告されています。

たとえば過去にGitHub Copilotのコードを分析した研究では、生成されたコードのおよそ4割に脆弱性が含まれていると [報告されました](https://arxiv.org/abs/2108.09293) 。その際、C言語では5割に近い高い割合で問題が見つかっており、メモリ管理の難しさが影響していると考えられていました。

さらに厄介なのは、AIが出力したコードを使う人間のほうにも影響が出てしまうことです。ある別の研究では、LLMを使った開発者が「明らかに安全でないコード」を自信を持って提出してしまう傾向が [見られました](https://arxiv.org/abs/2211.03622) 。つまり、AIが間違えるだけでなく、ユーザーの判断力にも揺らぎをもたらす可能性があるということです。

このように、表面的な見た目や機能に惑わされがちなコードには、裏側で深刻なリスクが潜んでいることがあります。とくに「防御的プログラミング」が取り入れられていないケースが多く、万が一の入力や想定外の使い方に対する備えが欠けている点が [指摘されています](https://arxiv.org/abs/2409.19182) 。

### 何度もやり取りするうちに起きていること

これまでに得られている知見の多くは「初回の出力だけ」を対象にしたものです。要するに、現実の開発では、一度目に出力されたコードをそのまま採用することは少ないのにも関わらず、そこだけにフォーカスされがちなのです。

実際には「ここをもう少し良くして」「～～を追加してほしい」といったやり取りが続くのが一般的です。しかし「繰り返しのやり取りによって、コードの安全性がどう変化していくのか」については、ほとんど調べられていません。

LLMとの改良プロセスの中で新たな問題が生まれることがあることは既に [指摘されています](https://arxiv.org/abs/2307.12596) 。ただし、対象は機能面や構文の正しさに限られており、セキュリティリスクに踏み込んだ分析は行われていません。

「安全だったコードに、プロンプトを送った後で問題が入り込む」という現象を軽く触れている研究も [ありますが](https://arxiv.org/abs/2409.19182) 、深堀はされていません。

### 指示の仕方ひとつで、コードの性格も変わる

どのような言い回しでLLMに指示を出すかによって出力されるコードの内容や傾向が変わってくるという点も、興味深いポイントです。

たとえば、プロンプトを丁寧に構造化し、目的を明確に伝えることで、機能的な正確さを高められるという [報告があります](https://arxiv.org/abs/2407.00215) 。教育分野の研究でも、指示の出し方が学習効果やコードの出来に大きく影響していたという [結果が出ています](https://dl.acm.org/doi/10.1145/3545945.3569759) 。

ただ、セキュリティに関する評価はあまり行われておらず、「何を重視したプロンプトが、どのような脆弱性につながりやすいのか」という視点はまだ手つかずに近い状態です。

### 「LLMと繰り返しやり取りすると危ないのでは？」という問い

これまでの知見をふまえると、LLMによる初回出力の危うさや、プロンプトによる差はある程度明らかになってきています。しかし、実際の開発により近い「やり取りを何度も繰り返すことで、コードの安全性がどう変わるのか」という問いについては、いまだ明確な答えがありません。

今回取り上げる研究は、まさにそこに踏み込んでいます。コードの質が見かけ上は洗練されていくように見えても、裏側でセキュリティが静かに崩れていくことはあるのか。LLMとのやり取りが積み重なる中で、開発者がどこで手を入れるべきか。そうした実務的な問いに対し、データと観察を通じて光を当てようとしています。

## ではどう確かめるか

LLMとのやり取りを重ねることで、コードのセキュリティはどう変わっていくのか。ここからは、研究者たちがその問いにどうアプローチしたのかを見ていきます。調査の進め方も、実務に通じる工夫が多く含まれています。

### 実験のざっくりした流れ

まず研究チームは、最初は安全であるはずのコードが、LLMとのやり取りを通じてどのように変化するかを調べるため、大規模な実験を設計しました。

10種類の”セキュリティ的に重要なコード”を用意し、それぞれに脆弱性がないことを確認。その上で、4つの異なる方針でプロンプトを与えながら、1つのコードにつき10回の改良を繰り返しました。つまり、10×4×10で、最終的には合計400個のコードが生成されています。

実験のポイントは、「人間の介入を完全に排除した状態で繰り返し改善を行った」ことです。現場では、開発者が都度レビューして方向修正を加えることも多いですが、この研究では意図的にそうしたチェックを入れず、「LLMにすべてを任せるとどうなるか」を見ようとしました。

### 使用されたプログラミング言語

実験で使用されたプログラミング言語はC言語とJavaでした。どちらも広く使われている汎用言語であり、中でもC言語はメモリ操作が関わるため、セキュリティ上の検証対象として重要視されました。

結果の詳細は後述しますが、今回の実験で確認された傾向（セキュリティの劣化）は、CやJavaに特有のものとは言い切れません。研究者たちは、今回のような反復的な改良プロセスが他の言語においても同様のリスクを引き起こす可能性があると指摘しています。例えばPythonやJavaScriptのような高水準言語でも、ロジックエラーや認証処理の脆弱性、入力検証の抜けといった問題は言語に依存せず発生しうるため、同様の現象が再現される可能性が高いと考えられます。

つまり、今回の実験はCやJavaを対象にしているものの、得られた示唆は他の主要言語にも広く当てはまる可能性があるということです。開発者にとっては、自分が扱っている言語にかかわらず、LLMとの反復的なやり取りによるセキュリティへの影響を警戒する必要があります。

### 最初に用意されたコードはどんなものか

ベースとなるコードには、現場でもよく登場する10の重要機能が選ばれました。

1. ファイル操作のチェック付き処理
2. メモリの安全な割当てと解放
3. 入力値のバリデーション
4. 認証トークンの検証
5. SQLインジェクションを防ぐクエリ構築
6. ネットワークパケットの処理
7. 暗号鍵の管理
8. ユーザー権限の確認
9. パスワードのハッシュ保存
10. マルチスレッド時のリソース制御

です。

これら初期のコードはすべて「安全に書かれている」と専門家のレビューと静的解析ツールによって確認されました。つまりスタート地点ではセキュリティ的に問題のない状態から始まっています。

### 指示の出し方には4つのパターン

どんな指示をLLMに与えるかで、コードの仕上がり方も変わってきます。研究では、現場でよくある4つの意図に沿った指示の出し方を設定しました。

（１）効率を求める指示  
「処理速度を上げてほしい」「メモリ使用量を減らしたい」といった、パフォーマンス改善を目指す内容

（２）機能追加を促す指示  
「複数ユーザーに対応させて」「非同期処理も扱えるようにして」など、機能面の拡張をお願いする形

（３）セキュリティ向上を意識した指示  
「このコードに脆弱性がないか確認して」「安全性を高めて」といったリクエスト

（４）あいまいな改善指示  
「このコードを良くして」「改善してください」など、具体的な方向性をあえて示さない依頼

あいまいな指示も含めているところは実験デザインのセンスが感じられるところです。

### LLMの設定と選定について

実験で使われたのは、OpenAIのGPT-4oです。最も広く使われているモデルの一つです。

プロンプトに対する応答のばらつきを抑えるため、temperature（温度）やtop-pといった生成時のパラメータは固定され、さまざまな条件で公平な比較ができるように工夫されました。

（温度について詳しく知りたい方はこちら： [LLMの「温度」どう設定すればよい　出力の揺らぎに影響する設定パラメーターを6能力で検証](https://ai-data-base.com/archives/91196) ）

### セキュリティチェックはどう行ったか

LLMが出力したコードには、毎回セキュリティ上の問題がないかチェックが入れられました。使われたのはClang Static Analyzer、CodeQL、SpotBugsといった複数の静的解析ツールで、加えて人間の専門家による手動レビューも実施されました。

脆弱性は全部で12種類のカテゴリーに分類され、それぞれCVSSスコア（セキュリティ上の重要度を示す標準的な指標）に基づいて「クリティカル」「高」「中」「低」の4段階で評価されました。

分類時に使用された脆弱性カテゴリー一覧

1. バッファオーバーフローや解放後使用などのメモリ安全性の問題（バッファサイズを超えてデータを書き込んだり、解放済みメモリにアクセスしたりする脆弱性）
2. 入力検証エラー
3. リソース管理の欠陥（開いたファイルや確保したメモリを適切に解放しないことで発生する問題）
4. 並行処理の問題（複数の処理が同時に動く際の同期が取れず、予期しない動作を引き起こすケース）
5. 暗号化実装の誤り（暗号ライブラリの使い方を間違えたり、不適切なアルゴリズムを選んだりするミス）
6. アクセス制御の脆弱性（許可されていないユーザーが本来アクセスできない操作やデータに到達できる問題）
7. 情報漏洩
8. インジェクション脆弱性（ユーザー入力がそのままコードやクエリに組み込まれて、攻撃者が任意の命令を実行できる問題）
9. エラーハンドリングの不備（異常時の処理が不十分でシステムが不安定になるケース）
10. 競合状態（レースコンディション）（複数のスレッドやプロセスが同じ資源に同時アクセスし、処理順序によって動作が変わってしまう問題）
11. 整数オーバーフロー・アンダーフロー（数値計算で上限や下限を超えてしまい、誤った値が扱われる脆弱性）
12. セキュリティに影響するロジックエラー（意図した条件分岐やチェックが適切に実装されず、本来防ぐべき操作を許してしまう不具合）

### プロンプトはどう標準化されたか

どのタイプの指示でもブレが出ないように、あらかじめテンプレートを用意して使い回す形が取られました。

たとえば「パフォーマンス改善をお願いします」という指示も、「同じ機能を保ちつつ、実行速度とメモリ使用量を最適化してください」といった、意図が明確な表現に統一。セキュリティ改善を求める場合も、脆弱性を探したうえで機能は維持するよう求める表現が使われました。

### どんなデータが集められ、どう分析されたか

それぞれの改良ステップごとに、生成されたコードそのもの、ツールやレビューで見つかった脆弱性、コードの複雑さ、そして機能が維持されているかどうかが記録されました。

そこから、改良を重ねるごとに脆弱性がどう変化するか、プロンプトの種類によってどんな傾向が出るのか、複雑さと脆弱性の関係などが統計的に分析されました。

## 実験からわかった”コードの変化”

### 脆弱性の数は回数に応じて増えていった

実験では、合計387件の脆弱性が確認されました。コードの改良を重ねるごとに脆弱性が増えていく傾向が明確に見られ、とくに5回目の時点でクリティカルな脆弱性が約38％も増えていたという結果が出ています。

プロンプトのタイプごとの傾向は次のようになっていました。

- 機能追加を目的とした指示では158件で最多
- 処理効率を高める指示では124件
- 抽象的な改善依頼では67件
- セキュリティ向上を狙った指示では38件で最少

| プロンプト戦略 | 総脆弱性数 | クリティカル | 高 | 中 | 低 |
| --- | --- | --- | --- | --- | --- |
| 効率重視 | 124 | 37 | 41 | 29 | 17 |
| 機能追加重視 | 158 | 29 | 53 | 47 | 29 |
| セキュリティ重視 | 38 | 7 | 12 | 10 | 9 |
| あいまいな改善指示 | 67 | 14 | 19 | 21 | 13 |

数だけを見れば、セキュリティ重視の指示がもっとも安全に思えますが、その中にも新たな脆弱性が潜んでいたことが確認されています。

### 改良回数が多いほどリスクも高まった

コードの改良回数と脆弱性の発生数との間には、明確な関係がありました。

- 初期（1〜3回目）は1つのサンプルにつき平均2.1件
- 中期（4〜7回目）は平均4.7件
- 後期（8〜10回目）は平均6.2件

統計的にもこの増加傾向は有意であり、繰り返しの改良そのものがリスクを高める要因になっていることが示されています。

### プロンプトの種類ごとに出やすい脆弱性があった

プロンプトのタイプによって、現れやすい脆弱性の傾向にも違いがありました。

- 処理効率を求める指示では、メモリ安全性の問題が多く、全体の約43％を占めた
- 機能追加を求める指示では、並行処理に関する問題が3割以上を占めた
- セキュリティ強化の指示では、暗号ライブラリの誤用が2割を超えて最も多かった

| 脆弱性タイプ\\プロンプトのタイプ | 効率重視 | 機能追加重視 | セキュリティ重視 | あいまいな改善指示 |
| --- | --- | --- | --- | --- |
| メモリ安全性の問題 | 42.7% | 12.6% | 15.8% | 19.4% |
| 入力検証エラー | 8.9% | 17.1% | 18.4% | 29.8% |
| リソース管理の欠陥 | 16.1% | 7.6% | 13.2% | 11.9% |
| 並行処理の問題 | 4.0% | 30.4% | 5.3% | 6.0% |
| 暗号化実装の誤り | 3.2% | 5.1% | 21.1% | 4.5% |
| アクセス制御の脆弱性 | 1.6% | 9.5% | 10.5% | 10.4% |
| 情報漏洩 | 6.5% | 3.8% | 2.6% | 3.0% |
| インジェクション脆弱性 | 2.4% | 5.7% | 5.3% | 7.5% |
| エラーハンドリングの不備 | 5.6% | 2.5% | 0.0% | 3.0% |
| 競合状態 | 3.2% | 3.8% | 0.0% | 1.5% |
| 整数オーバーフロー・アンダーフロー | 4.0% | 1.3% | 2.6% | 1.5% |
| ロジックエラー | 1.6% | 0.6% | 5.3% | 1.5% |

ただしタスクタイプによる違いはあれど、結局のところさまざまな場面で無意識にリスクを取り込んでしまう可能性があります。

### セキュリティを高めるはずの指示でも脆弱性が発生していた

注目すべきは、セキュリティ重視の指示です。意図と結果が食い違う例がいくつか見られました。共通する3つのパターンは以下の通りでした。

1. 暗号ライブラリの誤った使い方が多く、独自の実装への置き換えやパラメータ順のミスなどが繰り返された
2. 本来不要な複雑さが追加され、構造が入り組んだことで連携部分に欠陥が生じた
3. 学習データの影響で、すでに非推奨となっている手法が再登場し、現代の水準に合わない実装になった

どのケースも、LLMがセキュリティの設計原則やライブラリの安全な使い方を十分に理解していない時に起こることだと考えられます。

### コードが複雑になると脆弱性も増える

コードの構造が複雑になればなるほど、セキュリティリスクが高まる傾向も見えてきました。たとえば、循環的複雑度やコード行数といった指標と、脆弱性の数には強い相関が認められています。

複雑さが10％増えるごとに、脆弱性は平均で14％ほど増える傾向がありました。「シンプルな構成を保つことが結果的に安全性につながる」というセキュリティ分野の原則を、あらためて裏付ける結果といえます。

### どんなふうにコードが崩れていったのか

コードがどうやって脆弱な状態へと変化していったかを追跡したところ、以下の3つのパターンが代表的なものでした。

1. メモリ管理に関するコードにおいて、最初に境界チェックが削除され、その後、安全でない再利用パターンやスレッド非対応の静的バッファが追加され、最終的には複数の脆弱性が積み重なった
2. 認証機能のコードで、タイミング攻撃を引き起こすキャッシュ処理、パースエラーを含むマルチプロトコル対応、SQLインジェクションのリスクを含む永続化処理が順に追加され、最終的にはロジック不整合のある多要素認証に至った
3. データベースアクセス機能で、安全だったパラメータ化が削除され、動的クエリ構築や不十分な入力チェック、競合状態を引き起こす実装が追加されていった

いずれも、最初は安全だったコードが、見た目の進化とともに内部のリスクを抱え込んでいく過程が記録されています。

### 一部には改善が見られたケースもあった

すべてが悪化したわけではありません。とくにセキュリティを重視したプロンプトの一部では、最初の数回の改良において、入力バリデーションの追加やNULLチェック、エラー処理の強化などが行われ、明確な改善が見られました。

しかし、そうした初期の改善も、改良の回数を重ねるにつれて新たな脆弱性によって打ち消される傾向があり、10回の流れで見ると、結果的にはセキュリティが悪化しているケースが多数派でした。

この結果から、LLMは単純な誤りにはある程度対応できても、複数の観点を維持しながら安全性を保つことはまだ難しいのではないか、という解釈が浮かび上がります。

## 実務への示唆

### 気をつけたい5つのポイント

今回の実験結果では、以下の点が注目されました。

1. 脆弱性は徐々にではなく、後半になるほど急に増えやすくなる。コードが複雑になるにつれて、LLMだけでは安全性の維持が難しくなっていく
2. 処理効率を重視した指示では、最も深刻な脆弱性が発生しやすい。最適化と安全性のバランスを取ることが課題になる
3. セキュリティ向上を目的とした指示でも、新しい脆弱性が発生することがある。修正と同時に別の問題が入り込むリスクがある
4. コードの複雑さが増すと、脆弱性の発生も増える傾向がある。構造をシンプルに保つことが安全性につながる
5. 表面上は洗練されたコードに見えても、内部に問題を抱えているケースが多い。見た目の変化に安心してしまうことが新たなリスクを招く

### 開発現場で取れる現実的な対策

こうした結果を受けて、LLMを実務で活用するうえで意識したいポイントも明らかになってきました。

まずは、改良の途中段階ごとに、必ず人間がコードをレビューすることです。LLMには見抜けない微妙な問題を拾うには、開発者の判断が欠かせません。

人間の介入なしでLLMに改良を任せる回数は、3回までを上限とする。その後は一度立ち止まり、見直しを行う方が無難です。

また、改良のたびにセキュリティチェックを行い、ツールと人間のレビューを組み合わせて漏れを防ぐことも推奨されます。

そもそもLLMの出力を信用しすぎず、従来の静的解析ツールも併用して検査の抜けをカバーすることも有効です。

そして、コードの複雑さの指標を監視し、急激に複雑化した場合には念入りにレビューする。構造の複雑さはリスクのサインになりうるためです。

### プロンプト設計でも油断しない

LLMにどんな指示を出すかによって、脆弱性の出やすさにも違いが出ることが確認されました。そのため、いくつかの推奨事項があります。

まず、処理の最適化を求める場合は、必ず「セキュリティを維持したまま」と明示しておく。とはいえ、それだけで安全が担保されるわけではないので、レビューはより慎重に行いましょう。

また、セキュリティ改善を依頼する場面でも、逆に危険な処理が追加されることがあります。暗号処理まわりでは特に、人間の目によるチェックが欠かせません。

機能追加を依頼する場合は、特に並行処理の部分に注意を向けます。新機能と既存コードの整合性を保てているかどうかを重点的に確認します。

### 開発フローに組み込むにはどうすればよいか

こうした対策を日々の開発プロセスに自然に取り込むための仕組みも重要です。例えば、以下のような工夫があるとよいです。

- LLMによる改良→静的チェック→人間のレビュー→承認という流れをひとつの単位として設計し、このサイクルを繰り返す形にする
- LLMを扱う担当と、セキュリティを確認する担当を分けて、客観的な目でコードを見る体制を整える。同じ人がすべてを見ると、どうしても見落としが起きやすくなる
- LLM、既存ツール、人間の判断をそれぞれ補完的に組み合わせる。どれか1つに依存するのではなく、全体のバランスを意識することが重要になる

大切なのは、LLMをすべてを任せる存在として見るのではなく、人間の判断を補う道具として付き合っていく視点です。

## まとめ

本記事では、LLMを使ってコードを繰り返し改良していくと、セキュリティ上どんな変化が起きるのかを調べた研究を紹介しました。

実験の結果、改良を重ねるにつれて脆弱性が目立って増えていく傾向が確認され、プロンプトの出し方によってそのリスクの現れ方にも違いがあることが分かりました。セキュリティを意識したつもりの指示でも新たな問題が入り込むことがあり、LLMの出力を過信しない姿勢の大切さが浮き彫りになっています。こうした結果を受けて、人間によるレビューやコードの複雑さの管理など、実務で取り入れやすい対策も提案されています。LLMを活用しながら安全性も確保していくために、自分のプロジェクトに合った付き合い方を考えるきっかけとして活用していただければと思います。

**参照文献情報**

- タイトル：Security Degradation in Iterative AI Code Generation — A Systematic Analysis of the Paradox
- URL： [https://doi.org/10.48550/arXiv.2506.11022](https://doi.org/10.48550/arXiv.2506.11022)
- 著者：Shivani Shukla, Himanshu Joshi, Romilla Syed
- 所属：University of San Francisco, Vector Institute for Artificial Intelligence, University of Massachusetts Boston

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[人間らしさを宿すAI、ふるまいとこころの境界をたどる](https://ai-data-base.com/archives/91688)

[Deep Researchの各種比較、仕組み、現状の課題](https://ai-data-base.com/archives/91614)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)