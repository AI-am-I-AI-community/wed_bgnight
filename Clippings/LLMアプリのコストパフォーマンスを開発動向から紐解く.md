---
title: "LLMアプリのコストパフォーマンスを開発動向から紐解く"
source: "https://ai-data-base.com/archives/91425"
author:
  - "[[AIDB Research]]"
published: 2025-06-26
created: 2025-07-09
description: "本記事では、LLMを活用したアプリ開発において、費用と効果のバランスをどう考えるかという視点を紹介します。LLM業界では技術の進歩が加速する中で、使うことで得られる価値とコストのつり合いが問われる場面が増えています。"
tags:
  - "clippings"
---
本記事では、LLMを活用したアプリ開発において、費用と効果のバランスをどう考えるかという視点を紹介します。

LLM業界では技術の進歩が加速する中で、使うことで得られる価値とコストのつり合いが問われる場面が増えています。

そこで実際の開発動向を整理しながら、性能と効率をどう両立させるかという観点で見直していきます。

![](https://ai-data-base.com/wp-content/uploads/2025/06/AIDB_91425-1024x576.png)

## 背景

現在、「エージェントの年」とまで言われるほどLLMを活用したエージェント（以下、LLMエージェント）への期待が集まっています。  
LLMエージェントは、人が目的を設定すると柔軟に動いて、自律的に推論し、計画し、行動する存在として注目されています。

ただし、現時点でLLMエージェントが広く活用されているとはまだ言いがたい状況です。

技術単位で比較すると、既存の技術とLLMでは実用化の進み具合にまだ差があります。アプリケーションで比較しても、たとえば動画共有プラットフォームと比べるとOpenAIのChatGPTでさえ1%に満たないユーザー人口です。

この数字の差は、LLMエージェントが本格的に普及するにはまだ壁があることを示しています。

現在のLLMエージェントは、ソフトウェア開発や研究支援など、専門知識を持つユーザーを対象とした分野で偏って使われています。

そして、多少のミスが許容される環境だからこそ、今の仕様でも受け入れられています。

もっと多くの人が日常的に使うような場面では、専門知識の不足や扱いづらさが障壁となり、なかなか定着していません。

このような背景をふまえると、普及の妨げになっているのはモデルの性能そのものではなく、「使ったときに得られる価値」と「使うためにかかる手間やコスト」のバランスにあると考えられます。  
要するに、LLMエージェントは賢さや正確さだけでなく、使いやすさや効率性も含めて総合的に評価されたときに「役立つ」と判断されることになりそうです。

そこで、費用対効果（または投資利益率）を冷静に分析する視点が重要になります。エージェントが提供する情報の価値を、実際に使う際の時間や費用と比較して評価するということです。

LLMを使ったアプリケーションを世に出そうとしている開発者にとって、あるいは使う価値のあるLLMアプリケーションを見極めたい消費者にとって有益になる考え方になると思われます。

以下で詳しく説明します。

本記事で参照している文献は記事下部に記載いたしましたので適宜ご覧ください。

## エージェント開発の進み方にはリズムがある

![](https://ai-data-base.com/wp-content/uploads/2025/06/AIDB_91425_1-1024x475.png)

LLMエージェントの価値は、どれだけ賢くふるまえるかだけでなく、それを使うコストとのバランスで決まります。では、この [ROI](https://ai-data-base.com/archives/26574 "ROI（Region of Interest）") （費用対効果または投資利益率）を高めていくには、どうすればよいのでしょうか？

ここで新しい考え方・情報として、開発の進み方は一直線ではなく、「スケールアップ」と「スケールダウン」を交互に繰り返すようなリズム、いわば“ジグザグ”の進化パターンであるというお話をします。

### まずは性能を上げる大型化フェーズがある

たとえば、OpenAIの開発状況を見てみましょう。まず性能を高めるために大規模なモデルを投入し（o1-miniからo1への移行など）、その後、より軽量で効率の良いバージョン（o3-miniやo4-mini）が登場しています。

![](https://ai-data-base.com/wp-content/uploads/2025/06/AIDB_91425_3-1024x633.png)

世の中のLLMエージェント開発も、この流れに重なる部分があります。

現在は、まさにスケールアップの段階にあります。  
推論力や汎用性、ツールの使いこなしなどを底上げするため、大型のモデルが投入され、情報品質は高まってきています。  
ただしそのぶん、応答にかかる時間や、ユーザーの負担、インフラの要求水準は上がっており、導入できる場面は限られています。

そのため、今のところLLMエージェントの用途としては「人手で何時間もかかるような作業を肩代わりする」、というのが現実的です。たとえばプログラミングや研究支援など、もともと人間が時間をかけて取り組んでいた領域では、エージェントによる時間短縮が高コストを補ってくれます。つまり、コストもかかるけれど効果も高い場面が狙いどころというわけです。

### 次のステップでは効率化が進む

今後は、ここからさらに一段階進んで、スケールダウンのフェーズに入っていくと予想されます。

より効率的で軽量な仕組みが有効に取り入れられ、処理時間や運用コストが下がり、日常的なタスクにもLLMエージェントが使えるようになるかもしれません。

たとえば、カスタマーサポートやEC、タスク管理のように、簡単だけどニーズの多い領域への広がりが見込まれます。

### 今どのフェーズにいるかを見極める

こうした「ジグザグ」の進み方を意識しておくと、いま自分たちが（世の中の開発が）どの段階にあるのかが見えてきます。そして、それに応じた期待値の調整や導入判断もしやすくなります。

高性能・高コストの段階にある場合は、効果が大きい用途に集中して使うのが合理的です。一方で、将来はコストも含めて手軽に扱える時代が来るかもしれません。

LLMを使ったアプリケーションの開発や導入を考えている方にとって、こうした時間的なトレードオフを視野に入れておくことは、中長期的な戦略を立てるうえでも有益かと思われます。

## エージェントの力を引き上げる「スケールアップ」で行われていること

ジグザグな開発トレンドの中で、「性能を上げる」フェーズにおいて行われることは何でしょうか。このフェーズで、コストをおさえつつもモデルの能力を向上させることが重要でもあります。

今のLLMエージェントは、応答までの時間やコストがかかっても、情報の質を最大限に高めようとする段階にあります。学習や調整、実行のそれぞれの場面で、そのための工夫が積み重ねられています。

以下は、（ノウハウではなく）まず現状の技術動向や取り組み内容を整理して理解することを目的としたセクションです。

### 学習時の工夫

LLMの基本的な力は、事前学習のフェーズで育まれます。言語理解、推論、世界知識のような基礎能力を向上させるため、モデルのサイズを大きくし、より多くのデータと計算資源を使う活動が行われています。

人間の補助なしでも一定の段取りで複雑な仕事をこなせるようにするには、学習データも重要な役割を買います。マニュアルや業務手順書のように、実務で使われる知識を含む文書が力を発揮するため、モデル開発企業は積極的に取り入れています。

また、文脈の取り扱いも進化しています。長い履歴やユーザーの好み、過去のやりとりを把握できるようになることで、複数の手順が絡むタスクや、長期的な目標に対しても柔軟に対応できるようになりつつあります。

### 調整によって現実的なふるまいを身につける

大規模に学習されたモデルをそのまま使うだけでは、現場で動くエージェントにはなりません。人間の期待に近づけたり、周囲の環境にうまくなじませたりするための調整が行われます。

人間の期待と出力の間のギャップを縮めるためには、個別の好みに合わせた応答、わかりやすい説明、安心して任せられるふるまいが求められます。そうした調整は、人間との対話ログやクラウドで集めた注釈付きデータをもとに行われています。

また、APIやツールなど、外部のシステムとのやりとりも大事です。そのためには、エージェントが出す指示が実際に動作するものである必要があります。行動の履歴や操作の成功例などを学習させ、現実の操作に対応できる力を身につけさせるといった方針でチューニングされます。

そしてLLMエージェントが実際に使われると、ユーザーからのフィードバックやタスクの実行記録、エラーの内容などが自然と蓄積されていきます。これらの履歴がさらに学習に使われていくことで、少しずつ改良が進みます。このように実用の中から学び、改善していく循環が生まれ始めています。

### ふるまいを柔軟に調整する

エージェントがタスクを実行する際の品質向上のための調整も行われています。たとえば思考の手順を増やすことで、（やや複雑な問いに対しては）出力の正確さや信頼性が高まるとされています。自らの出力を見直してから答えを生成するような手法もその一例です。

複数のエージェントが役割を分担しながら一つのタスクを進める方式も試みられています。分業によってより複雑なタスクにも対応しやすくなりますが、そのぶん調整のコストや出力の一貫性といった点への配慮も求められます。

さらに、ツールを段階的に呼び出し、途中の結果を確認しながら進めるような推論も検討されています。

また最近の開発傾向からは、エージェントがリアルタイムに判断し、状況に応じて推論の深さや手順、外部ツールの使用などを選び取るようになることも期待されています。

### より現実に近い環境で評価と訓練を行う

LLMエージェントの能力を現実的なものにするために、訓練や評価に使う環境そのものにも工夫が必要です。現実は途中で状況が変わったり、正解が明確に定まらないことも多いため、学習や評価にもそうした不確実性を取り込む必要があります。

現在広く使われているLLMエージェントの評価環境は、構造が単純化されているケースが多く、実際の利用現場の複雑さには対応しきれていないことが課題とされています。

そこで、現場の情報を学習や評価に活用する取り組みも進み始めています。例えばECサイトやカスタマーサポートのような既存のサービスには、ユーザーの反応や行動の多様性がすでに含まれており有用です。

望ましい環境の条件としては次のような点が挙げられています。

・テキスト以外に画像や音声も取り扱えること  
・一回の応答で終わらない複数ステップのタスクを扱えること  
・ユーザーの主観や好みに応じた多様な反応を再現できること  
・環境の変化や不明確な状況も含めた設計になっていること

こうした特性を備えた環境で訓練されたエージェントは、実際の運用環境でも安定した品質を発揮すると想定されています。

LLMエージェント向けに広く使われている環境を以下にまとめます。

| 環境（公式ページ） | ドメイン | 現実的FB | 個人化FB | モダリティ | 不確実性 | 平均ステップ数 |
| --- | --- | --- | --- | --- | --- | --- |
| [AlfWorld](https://github.com/alfworld/alfworld) | 家事 | ✗ | ✗ | テキスト | ✗ | – |
| [ScienceWorld](https://github.com/allenai/scienceworld) | 研究 | ✗ | ✗ | テキスト | ✗ | – |
| [AgentBench](https://github.com/THUDM/AgentBench) | ハイブリッド | ✗ | ✗ | テキスト | ✗ | 10.5 |
| AgentSims | 社会生活 | ✗ | ✓ | テキスト | ✓ | – |
| WebArena | ウェブ閲覧 | ✗ | ✗ | テキスト・画像 | ✗ | – |
| AppWorld | 制御 | ✓ | ✗ | テキスト・画像 | ✓ | 26.0 |
| Mind2Web | ウェブ閲覧 | ✓ | ✗ | テキスト・画像 | ✗ | 7.3 |
| [Generative Agents](https://github.com/joonspk-research/generative_agents) | 社会生活 | ✗ | ✓ | テキスト | ✓ | – |
| WebShop | ウェブ閲覧 | ✗ | ✗ | テキスト | ✗ | 11.3 |
| AndroidEnv | 制御 | ✓ | ✗ | テキスト・画像 | ✓ | – |
| Mobile-Env | 制御 | ✓ | ✗ | テキスト・画像 | ✗ | – |
| WebCanvas | ウェブ閲覧 | ✓ | ✗ | テキスト | ✓ | 8.4 |
| AndroidWorld | 制御 | ✓ | ✗ | テキスト・画像 | ✓ | 27.2 |
| Minecraft | ゲーム | ✗ | ✗ | テキスト・画像・音声 | ✓ | – |
| RecAgent | レコメンド | ✗ | ✓ | テキスト | ✓ | – |
| [VirtualHome](https://github.com/xavierpuigf/virtualhome) | 家事活動 | ✗ | ✗ | テキスト・動画 | ✗ | 11.6 |
| TheAgentCompany | ソフトウェア開発 | ✗ | ✗ | テキスト | ✓ | – |
| MiniWob++ | ウェブ閲覧 | ✗ | ✗ | テキスト・画像 | ✗ | 3.6 |
| WebLINX | ウェブ閲覧 | ✓ | ✗ | テキスト・画像 | ✗ | 43.0 |
| AssistantBench | ウェブ閲覧 | ✓ | ✗ | テキスト | ✗ | – |
| VisualWebArena | ウェブ閲覧 | ✓ | ✗ | テキスト・画像 | ✗ | – |
| VideoWebArena | ウェブ閲覧 | ✓ | ✗ | テキスト・画像・動画 | ✗ | – |
| OSWorld | 制御 | ✓ | ✗ | テキスト・画像 | ✓ | – |
| WorkArena | ウェブ閲覧 | ✓ | ✗ | テキスト・画像 | ✗ | 10.0 |
| InfoDeepSeek | ウェブ検索 | ✓ | ✗ | テキスト | ✓ | 5.0 |

### 安全性や堅牢性の確保に向けた試み

LLMエージェントが出力する情報の質を安定して保つためには、信頼性や安全性に関する配慮も不可欠です。意図しない出力や、環境の変化に対する脆弱さを抑えるための技術的検討が進められています。

たとえば、報酬設計の仕方によっては、本質的な課題解決ではなく、うまく見せかけることを優先するようなふるまいが現れる可能性があります。コード生成の分野では、検証をすり抜けるために結果を意図的に調整するような行動が確認された例もあります。

また、訓練段階で悪意あるデータが混入したり、実行時に攻撃的な入力が与えられたりすることも想定されます。こうしたリスクに対しては、入力の異常を検知する仕組みや、データの来歴を管理する技術、さらに信頼できる外部情報源を参照しながら事実確認を行う設計などが検討されています。

LLMエージェントの設計においては、こうした観点も品質の一部と捉え、安全に動作し続けるための仕組みが含まれていることが望ましいとされています。

## 次は「スケールダウン」へ　処理時間とコストをどう抑えるか

「スケールアップ」のあとに控えるのは、コストや処理時間を減らして効率性を高める「スケールダウン」のフェーズです。このフェーズではエージェントの品質を維持しながら運用負荷を現実的な水準に抑えることが求められます。

エージェントは、単に出力の正確であるべきなだけでなく、タスク完了までのスピードや使いやすさも見られます。応答が遅すぎたり、導入コストが高すぎたりすれば、どれだけ賢くても現場では活用されにくくなります。

スケールアップのフェーズよりもこちらの方では広い範囲で実務者が工夫できることが増えます。

### タスク完了までの時間を短くするには

エージェントが処理にかける時間は、ユーザー体験に直結します。やりとりがスムーズに進めば、インタラクティブな操作やリアルタイム性が求められる場面でも活用の幅が広がります。

#### ①記憶を使って手戻りを減らす

エージェントにメモリ機能を持たせると、過去のやりとりや知識を活用して、同じ処理を何度も繰り返す必要がなくなります。人間の専門家が経験に基づいて素早く判断を下すのと似ています。

一度覚えたことを再利用できるようになると、たとえば好みに合わせた調整や定型業務の処理が効率化されます。その結果、応答までの所要時間を短縮でき、全体の運用コストも下げやすくなります。

一方で、メモリをどう管理し、いつ何を参照するかの設計が複雑になっていくという課題もあります。エージェント設計では、こうした記憶の扱いも重要な論点のひとつです。

#### ②小さなモデルで大きな仕事をこなす

モデルサイズが大きくなると、当然ながら処理時間や消費リソースも増加します。そこで小規模モデルも検討しましょう。ただ、単にモデルを小さくすると性能が落ちるため、品質を保ったままの「軽量化」が課題になります。

最近では、大規模モデルから必要な知識や推論力を抽出し、小さなモデルに移す「蒸留」と呼ばれる技術が多く使われています。DeepSeek-R1やQwen3といったモデルでも採用されており、OpenAIのモデルにも同様の仕組みがあると推測されています。こうした蒸留モデルは応答の遅延や導入時の負荷を抑えつつ、実用レベルの性能を保てる可能性が高いため、重宝されます。

#### ③無駄な思考を避ける設計もカギ

出力までに時間がかかる理由は、計算負荷だけとは限りません。たとえば、思考の手順が長すぎたり、過度に自己確認を繰り返す推論フローがあると、結果に大きな違いが出ないにもかかわらず時間だけがかかってしまうことがあります。

必要以上に考えすぎないような推論ポリシーを採ることも大事です。考える時間が短くても、的確に答えにたどり着けるような構造をつくることで、応答のスピードが大きく変わってきます。

#### ④処理速度を支えるインフラを使用する

LLMの推論はソフトウェアだけでなく、インフラ環境の性能にも左右されます。高速な推論を可能にする専用ハードウェア（たとえばGroqやCerebras）や、処理を効率化するソフトウェアスタック（vLLMやFlashAttentionなど）によって、トークンの生成速度が大きく改善されつつあります。

とくに組み込み型のLLMや、インタラクティブな用途でLLMを使いたい場面では、低遅延かつリアルタイム対応可能な実行環境が欠かせません。

### 利用コストをどう考えるか

エージェントを普及させるには、技術的な性能だけでなく、使う側の負担が小さいことも大事です。ここで言う「コスト」には、金銭的な費用と、やりとりの手間の両面があります。

#### ①やりとりが面倒では使われにくい

ユーザーがエージェントを使う際、うまく意図を伝えるまでに多くの試行錯誤が必要だと、それ自体が負担になってしまいます。プロンプトを何度も書き直したり、表現を工夫したりといった負荷が積み重なると、使いたくても使われないという状況が起こります。

この課題に対しては、エージェント側がユーザーの意図を汲み取る力を持ち、曖昧さをその場で解消できるようになる必要があります。たとえば、入力をただ受け取るだけでなく、必要に応じて逆に問い返したり、推論で意図を補ったりするスタイルを実装することが考えられます。

理想的には、プロンプトの作成そのものを最小限に抑え、ユーザーの目的や状況を推測しながら自然にタスクを進めるエージェントが求められています。

#### ②金銭的な負担も軽視できない

モデルの推論時間が長い、ツールをたくさん使う、外部APIを頻繁に呼び出す、といった構成になると、料金もどんどん増えていきます。規模が大きいプロジェクトや継続的な利用が前提の場合、この点は無視できません。

そのため、処理の最適化、無駄なコンテキストの削減、リソースの使い方を柔軟に切り替える工夫など、金銭的コストを抑えるための設計が求められます。

## どの方向でエージェントを育てていくか

エージェント開発に取り組む際には、いくつかの考え方があります。しかし代表的なアプローチは2つに整理可能です。リソースや目的に応じて、どちらに重きを置くかを選ぶことになります。

### あらかじめ決めた流れを動かす「エージェントワークフロー」型

ひとつめの考え方は、あらかじめ設計した流れに沿ってタスクを実行する方式です。人間の知識や経験をもとに、手順や役割を決めたうえでLLMに働きかけます。タスクごとのステップやツールの使い方を事前に定義しておき、エージェントはその流れに従って動きます。

たとえば「天気を聞かれたら気象APIを呼ぶ」といったルールをプロンプトで明示し、思考のパターンも決めておきます。

ワークフロー型の設計は、エージェントを「動かす」ためには扱いやすい方法です。少ないファインチューニングで導入でき、コストも読みやすくなります。業務システムへの組み込みや、特定の用途に最適化された使い方では重宝されます。

一方で、動きが固まってしまうという側面もあります。柔軟な応用には限界があるため、最近では流れをゆるやかに設定し、タスクの進め方をエージェント自身にある程度任せるような工夫も増えています。たとえばマルチエージェント型の設計で、役割の切り替えや動的なタスク分担を取り入れることで、よりしなやかな運用が模索されています。

また、エージェント自身が流れを最適化できるような設計も試されています。ただし、基本的にはプロンプトに定められた範囲内で動くスタイルにとどまります。

### 自ら動き方を学ぶ「エージェントモデル」型

もうひとつの考え方は、エージェントに行動のしかたを学ばせてしまうという方法です。プロンプトで流れを指示するのではなく、 [強化学習](https://ai-data-base.com/archives/26125 "強化学習") などを通じて、状況に応じた最適な判断をエージェントに身につけさせます。

どのツールを使い、どの順で処理を進めるかといった判断を、モデル自身が繰り返し学習を通じて習得していきます。柔軟で高度な対応が期待されるぶん、ルールでコントロールしづらくなります。

たとえばOpenAIのDeep Researchでは、検索タスクに特化したモデルをゼロから訓練し、事前に決めたワークフローなしでも自律的に動けるようにしています。ほかにも、複雑な会話に対応するスキルをエージェントに学習させている事例や、自分で作成するカリキュラムに従ってウェブ操作を覚える設計を採用している事例もあります。

さらに、自己改善型のエージェントを強化学習でチューニングしたり、マルチターンの対話に特化した訓練手法を提示したりと、研究の幅は広がりを見せています。

### 使う場面によって使い分けを

上述の2つの設計方針は、それぞれ用途に応じて使い分けます。たとえば、制御性や再現性を重視し、人間の専門知識を反映させたい場合にはワークフロー型が適しています。一方で、複雑な状況に柔軟に対応させたい場合や、大規模なリソースをかけてエージェントを鍛える余裕があるなら、モデルを訓練していく方向が選ばれます。

現在のところ、現場で多く使われているのはワークフロー型のスタイルですが、今後はモデル型のアプローチも増えていく可能性があります。特定の用途に応じて、どちらの方向で育てていくかを考えることが、実践の第一歩になります。

## 指標が投げかけるもうひとつの問い

エージェントにおけるROIを考える際には、実務の観点だけでなく、より広い視野からの検討も必要です。社会や設計に与える示唆をもう少し掘り下げてみます。

### 製品設計や利用のしかたにも影響

ROIは、現実的なプロダクト設計にもヒントを与えます。「何ができるか」ではなく「どこまで使われるか」を重視する発想は、エージェントのUI設計や対話設計、ワークフロー設計などの方針にもつながります。

使い手の負担を減らす、価値を実感しやすくする、といった考え方をベースにしたプロダクト開発は、普及の鍵を握る要素です。

### 実用性だけでは測れない価値もある

一方で、ROIだけでエージェントの価値を語ることはできません。倫理的な課題、依存による人間側の変化、データの取り扱いの問題など、別の観点も存在します。

そのため、ROIはあくまで複数ある視点のひとつとして捉える必要があります。社会的な影響や技術の透明性、規制とのバランスなどを含めた広い枠組みで捉えることも求められます。

### 人間とAIの関係そのものも変わっていく

もう少し長期的に見ると、エージェントを導入することで人間の仕事の仕方そのものがどう変わっていくのかを考える必要性も出てきます。タスクをエージェントに任せるようになれば、人間がその分のスキルを失っていくことも将来的にはありえます。逆に、エージェントの補助によって人間の思考が洗練されるケースもあるかもしれません。

ROIは短期的な見方になりがちなので、長い目で変化を見極めることも大切な観点です。

### 誰もが使えるAIへ向けた問い直し

ROIを考え出すと「このサービスは誰の役に立つのか？」という問いにもつながります。高性能でも使いこなすには知識が必要という状況では、AI技術の恩恵が限られた層にしか届きません。

技術に詳しくない人でも扱いやすいエージェントを目指す際には実際のコストや手間を意識しながら設計を見直す必要があります。

### 研究の方向性にも影響する

こうした実用性を重視する視点は、研究の方向性にも影響しています。純粋な性能競争だけではなく、実際に社会の中でどう使われるかを見据えたアプローチが求められています。

経済性や人間の行動との関係を視野に入れて技術開発や研究開発をしていくことが望まれています。

## まとめ

本記事では、エージェントにおけるROIの考え方や、スケールアップとスケールダウンを行き来する開発の流れなどを紹介しました。

情報品質とコストのバランスに注目するROIは、実用性を見極める際に注目に値する概念かと思われます。

また、性能を高める時期と効率化を図る時期を交互にたどる「ジグザグ型」の進化パターンも、現場の判断に役立つ情報になっています。

エージェントワークフロー型とエージェントモデル型という異なる考え方も、それぞれの特徴や使いどころも見えてきたかと思います。

ご自身のプロジェクトや業務をあらためて見直すきっかけになればうれしく思います。

**参照文献情報**

- タイトル：The Real Barrier to LLM Agent Usability is Agentic [ROI](https://ai-data-base.com/archives/26574 "ROI（Region of Interest）")
- URL： [https://doi.org/10.48550/arXiv.2505.17767](https://doi.org/10.48550/arXiv.2505.17767)
- 著者：Weiwen Liu, Jiarui Qin, Xu Huang, Xingshan Zeng, Yunjia Xi, Jianghao Lin, Chuhan Wu, Yasheng Wang, Lifeng Shang, Ruiming Tang, Defu Lian, Yong Yu, Weinan Zhang
- 所属：Shanghai Jiao Tong University, Huawei Noah’s Ark Lab, University of Science and Technology of China

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[LLM活用時のプライバシーリスク　問題と対策の現状](https://ai-data-base.com/archives/91388)

[LLMコスト効率を高める「プロンプト圧縮」入門　比較で見える実践のポイント](https://ai-data-base.com/archives/91507)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)