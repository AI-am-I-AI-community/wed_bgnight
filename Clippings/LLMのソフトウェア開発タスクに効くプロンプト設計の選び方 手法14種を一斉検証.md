---
title: "LLMのソフトウェア開発タスクに効くプロンプト設計の選び方 手法14種を一斉検証"
source: "https://ai-data-base.com/archives/90975"
author:
  - "[[AIDB Research]]"
published: 2025-06-16
created: 2025-07-09
description: "本記事では、LLMに対するプロンプト設計手法をソフトウェア開発タスクに適用して検証した研究を紹介します。"
tags:
  - "clippings"
---
本記事では、LLMに対するプロンプト設計手法をソフトウェア開発タスクに適用して検証した研究を紹介します。  
「どんな書き方をすれば精度が上がるのか」「どの手法がタスクに合っているのか」といった問いに、実験結果をもとに一定の方向性が示されています。  
コード生成やバグ修正など、実務で頻出する10種類のタスクを対象に、代表的な14のプロンプト設計手法が一斉に比較されています。  
LLMを使った開発支援に関心のある方にとって、設計の工夫がどこまで効果を左右するのかを見極めるうえで参考になる内容です。

![](https://ai-data-base.com/wp-content/uploads/2025/06/AIDB_90975-1024x576.png)

## 背景

ソフトウェア開発の現場では、言わずもがなLLMの活用が進んでいます。

たとえば、コードの生成や翻訳、バグ修正、コミットメッセージの生成などが作業の代表例です。プロンプトを与えるだけでこうした処理が半自動的に可能になることから、実装の省力化や品質向上の手段として関心を集めています。

ただし、おそらくほとんどの人が意外な壁に直面します。どのようにプロンプトを構築するかによって、出力の質が大きく変わることがあるという壁です。言い回しの違いが、生成されるコードの正確性や可読性、修正提案の有効性にまで影響するのです。

そこで注目されているのが、こうしたソフトウェアタスクに特化したプロンプトの設計手法そのものの見直しです。

これまで、広範なタスクにおいては、LLMの出力をより良く導くための工夫は数多く提案されてきました。しかし実際のところ、どの手法がどのタスクに有効なのか、網羅的には整理されていません。そのため、エンジニアが現場でLLMを使う際に一般的なプロンプト手法を勉強しても「どれが自分の目的に合っているのか」見えづらい状況です。

さらに言えば、LLMの実行には相応のリソースがかかります。商用APIを使う場合、推論のたびにコストが発生します。プロンプトを少し工夫しただけなのに、トークン数が増えて料金が跳ね上がる、といった事態も起こりかねません。性能を上げることと、計算資源を抑えることのバランスは、多くの実務者にとって悩ましいテーマです。

こうした状況をふまえて、本記事では論文をもとにソフトウェアエンジニアリングにおけるプロンプト設計について体系的な実験結果をお伝えします。プロンプト設計の手法を10種類のソフトウェア開発タスクに適用し、その効果を横断的に評価するという取り組みが行われています。これをもとに、目の前のソフトウェアタスクに対してどのようなプロンプトが適当なのか検討する材料にしていただければ幸いです。

## ソフトウェアタスクにおけるLLMの使われ方と工夫の歴史

ソフトウェア開発の現場でLLMの導入が進むにつれ、「どう活用すれば成果が出るのか」「どんな工夫が必要なのか」を見極めようとする動きが加速しています。

### ソフトウェア開発とLLMの関係はどう変わってきたか

LLMは、自然言語とソースコードの両方を大量に学習しており、数十億ものパラメータを備えています。人間のようにコードを読み取り、適切な形式で出力を返せる力があるため、さまざまな応用が試みられてきました。

たとえば、コードの翻訳や修復、コミットメッセージの生成、コードレビュー支援など、もともとは開発者が手作業で行っていた工程をLLMに任せる試みが数多く報告されています。

こうした流れは実務にも広がっています。いくつものコード支援ツールが登場し、テストコードの自動生成やドキュメントのたたき台作成といった場面で、LLMが実際に開発フローに組み込まれるケースも増えてきました。

### モデルの能力を強くするには何が有効か

LLMを開発業務に活かすにあたって、「どうすればもっと性能を引き出せるのか」という課題にも注目が集まっています。ここで大きく分かれるのが、学習ベースのアプローチと、プロンプト設計によるアプローチです。

#### 再学習アプローチにおける課題点

LLMにソフトウェア関連のデータを追加で学習させるという方法は以前からよく取り組まれてきました。特定領域に特化した知識を身につけさせることで、汎用モデルよりも高い精度を目指すという考え方です。

ただし、この方法には大きな課題があります。高精度な結果を得るには、大量の高品質な学習データと長時間の学習処理が必要になります。そのぶん、コストも高くなりがちです。

#### プロンプトの工夫も選択肢

一方で、モデル自体は変更せず、プロンプトの設計を工夫するだけで性能が変わることもわかっています。

たとえば、単体テストを自動生成する研究では、慎重に設計されたプロンプトが追加学習なしでも十分な性能を出せるという結果が示されています。分類体系の構築といったタスクでも、学習を伴わないプロンプトベースの手法のほうが安定して良い結果を出すことがあると報告されています。

また、プロンプトの違いによって出力がどれほど変化するかを58通りの手法で比較した過去の調査でも、プロンプト設計そのものが性能の鍵を握る要素として述べられています。

### 見落とされていた視点

これまでの比較研究の多くは「モデルが持つ性能そのもの」に注目しており、「どんなプロンプトを与えるか」といった入力設計の観点までは十分に踏み込んでいません。

出力の質は、モデルだけでなく入力側の設計に大きく左右されます。たとえ優れたモデルであっても、プロンプトの構成次第では本来の力を発揮できないという事例も少なくありません。タスクの性質に応じて、どのようにプロンプトを調整するのが効果的なのか。この視点が、これまで十分に評価されてこなかったのです。

## ソフトウェアタスクでのプロンプト設計手法の有効性検証

そこで今回、プロンプトの設計手法が実際にどの程度の効果を持つのか大規模な実験が実施されました。14種類のプロンプト手法を、10種類のソフトウェア開発タスクに適用し、4つの異なるLLMで性能を比較するといった実験内容です。

### 対象となったソフトウェア開発タスク

実験対象としては開発現場でもよく扱われる10のタスクが選ばれました。大きくは「コードを理解するタスク」と「コードを生成するタスク」の2種類に分類されます。

#### コードを理解するタスク

- コードにバグが含まれているかを判定する「欠陥検出」
- 類似した機能を持つコードの断片を見つけ出す「クローン検出」
- 処理中に発生しうる例外の種類を推定する「例外タイプ予測」
- プログラムの動作や意図についての質問に答える「コードに関する質問応答」

#### コードを生成するタスク

- ある言語で書かれたコードを別の言語に書き換える「コード翻訳」
- 不具合のあるコードに対して修正版を提案する「バグ修正」
- テストの多様性を確保するために変化を加えたコードを生成する「ミュータント生成」
- テストコードに含める検証文を自動で作成する「アサート生成」
- コードの内容を自然言語で短く説明する「コード要約」
- 自然言語の仕様をもとにコードを組み立てる「コード生成」

いずれのタスクも、現場での実用性を重視した構成です。各タスクに対しては、95％の信頼度と5％の誤差範囲でサンプルが抽出され、およそ2000件のプロンプトが作成されました。

| タスク (略称) | カテゴリ | データセット | 評価指標 | サンプル数 |
| --- | --- | --- | --- | --- |
| 欠陥検出 (DD) | コード理解 | Devign | [正解率](https://ai-data-base.com/archives/25930 "正解率") (Accuracy) | 391 |
| クローン検出 (CD) | コード理解 | BigCloneBench | [F1スコア](https://ai-data-base.com/archives/26112 "F1スコア（F値）") | 390 |
| 例外タイプ予測 (ET) | コード理解 | Kanade et al. | 正解率 (Accuracy) | 380 |
| コード質問応答 (QA) | コード理解 | CoSQA / CodeSearchNet | 正解率 (Accuracy) | 382 |
| コード翻訳 (CT) | コード生成 | CodeTrans | CodeBLEU | 378 |
| バグ修正 (BF) | コード生成 | BFP | CodeBLEU | 390 |
| ミュータント生成 (MG) | コード生成 | GM | BLEU | 390 |
| アサート生成 (AG) | コード生成 | ATLAS | BLEU | 390 |
| コード要約 (SM) | コード生成 | DeepCom | BLEU | 390 |
| コード生成 (CG) | コード生成 | CONCODE | CodeBLEU | 391 |

### 比較対象となったプロンプト設計手法

事前に収集された46種類のプロンプト手法の中から、ソフトウェア開発タスクへの適用が可能な14種類が選ばれています。（外部ツールに依存する手法は対象外とされています。）

#### Exemplar Selection KNN（事例選択KNN）

過去のコード事例を埋め込みで自動抽出し、現在のタスクに最も近い例をプロンプトに含めることで文脈を補強し、出力精度を高める

#### Few-Shot Contrastive CoT（少数ショット対照CoT）

正解例と誤答例を組み合わせてChain-of-Thoughtを示すことで思考過程を対照的に学習させ、論理展開の正確さを上げる

#### Tree Of Thought（思考樹形探索）

複数の解決経路を枝分かれのように同時探索させる指示で、多様なアプローチを試しながら複雑問題への対応力を引き出す

#### Self Ask（自己問いかけ）

まずモデル自身に追加の問いを生成させて問題を細分化し、段階的に回答を導くことで複雑なタスクを解きほぐす

#### Universal Self Consistency（普遍的自己一貫性）

モデルに複数の回答を出力させ、その中から最も一貫性の高いものを選ばせるプロセスで応答の信頼性を確保する

#### Self Refine（自己改善）

初回の回答を自己評価させ、そのフィードバックをもとに繰り返し修正させることで最終出力を洗練させる

#### Self-Generated In-Context Learning（自己生成コンテキスト学習）

少数ショットの例示をモデル自身に自動生成させ、手動で用意する手間を省きつつ学習効果を維持する

#### Thread Of Thought（思考スレッド）

問題を小さなステップに分解し、各ステップで要点をまとめさせる構成で思考の透明性と整理を促す

#### Step Back Prompting（ステップバックプロンプト）

全体を俯瞰して主要なポイントを考えさせたうえで詳細回答を構築させる指示で、計画的な推論を引き出す（参考： [LLMにまず前提から尋ることで出力精度を向上させる『ステップバック・プロンプティング』と実行プロンプト](https://ai-data-base.com/archives/56671) ）

#### Emotional Prompting（感情誘導プロンプト）

「この修正は重要です」など感情的な語句を含めることで、応答に丁寧さや配慮のニュアンスを加える（参考： [「自分を信じて限界を超えてください」など感情を込めたプロンプト『EmotionPrompt』が添えられると、ChatGPTなどLLMのパフォーマンスは向上する](https://ai-data-base.com/archives/58158) ）

#### Style Prompting（文体指定プロンプト）

「簡潔にまとめて」「フォーマルな文体で」といった文体や形式の指示を与え、出力スタイルを統一する

#### Rephrase and Respond（言い換えて応答）

最初に問いをモデル自身に言い換えさせたうえで回答をさせ、意図理解を深めたうえで正確な応答を得る（参考： [ユーザープロンプトをLLMが言い換えて、LLM自身が理解しやすくする手法『RaR』](https://ai-data-base.com/archives/51160) ）

#### Role Prompting（役割指定プロンプト）

「開発者として」「コードレビュアーとして」などの視点を与え、タスクに応じた観点での出力を誘導する

#### Analogical Prompting（類推誘導プロンプト）

具体例や類推を用いるよう指示し、抽象的な概念やアルゴリズムを直感的に理解しやすい形で生成させる

### プロンプト表現のバリエーションと品質管理

プロンプトの書き方が性能に与える影響を抑えるため、各手法について10通りの異なる言い回しが準備されました（意味の一貫性は検証されています）。

### 使用された4つのLLM

検証に用いられたモデルは、いずれもコード生成において実績のあるLLMです。性能だけでなく、オープンソースか商用かといった観点でも多様性が確保されています。

- DeepSeek-V3（コード生成に強みを持つ）
- Qwen2.5-Coder-32B-Instruct（多言語に対応したコード特化モデル）
- Llama-3.3-70B-Instruct（汎用的な大規模モデル）
- OpenAI o3-mini（商用サービスでも広く使われている軽量モデル）

### 評価方法と結果の収集

各手法は10のタスク全てに適用され、4つのモデルそれぞれで出力結果が収集されました。

評価には、タスクに応じた複数の指標が使われました。分類タスクでは正解率やF1スコア、生成タスクではBLEUやCodeBLEUといった自動評価指標が採用されています。

また、比較の出発点として、シンプルな指示だけを与えたベースライン構成も用意され、各プロンプト手法によって性能がどの程度向上したかが測定されました。

## 実験で見えてきたプロンプト手法の有効性

実験の結果、大枠の結論としては、すべてのタスクに万能な手法があるわけではなく、それぞれのタスクの性質に応じて最適な設計が異なることがわかりました。

### タスクごとに異なる「うまくいく」手法

まずは、各タスクで最も効果的だったプロンプト手法をまとめた表を示します。

| タスク | 総合 | Qwen2.5 | DeepSeek-V3 | Llama-3.3 | o3-mini |
| --- | --- | --- | --- | --- | --- |
| 欠陥検出 | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 役割指定プロンプト |
| クローン検出 | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") |
| 例外タイプ予測 | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 言い換えて応答 |
| コードQA | 普遍的自己一貫性 | 自己生成コンテキスト学習 | 普遍的自己一貫性 | 普遍的自己一貫性 | 役割指定プロンプト |
| コード翻訳 | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") |
| バグ修正 | ベースライン | 自己生成コンテキスト学習 | 自己生成コンテキスト学習 | 自己生成コンテキスト学習 | ベースライン |
| ミュータント生成 | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 役割指定プロンプト | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 役割指定プロンプト |
| アサート生成 | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") |
| コード要約 | ベースライン | 自己生成コンテキスト学習 | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | ベースライン | 自己生成コンテキスト学習 |
| コード生成 | 普遍的自己一貫性 | 普遍的自己一貫性 | 自己生成コンテキスト学習 | 普遍的自己一貫性 | 普遍的自己一貫性 |

いくつかの興味深い傾向が明らかになっています。

たとえば、似たような処理をしているコードを見つけ出すタスク（「クローン検出」）や、コード実行時にどんな例外が発生しうるかを予測するタスク（「例外タイプ予測」）では、過去の類似コード例を埋め込みベースで抽出してプロンプトに組み込む手法（「事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") 」）が最も高い性能を示しました。全4モデルで共通して効果が出ており、具体的なコード例に基づいた文脈補強が、こうしたパターン認識タスクに有効だったと考えられます。

また、コードにバグが含まれているかを検出するタスク（「欠陥検出」）では、複数の解決ルートを枝分かれ形式で探索させる手法（「思考樹形探索」）が有効でした。コードを部分ごとに分解し、複数の視点から検討させる構成が、バグの兆候を拾いやすくしたと考えられます。

コードの動作や目的について自然言語の質問に答えるタスク（「コードQA」）では、複数の出力を生成させ、その中から一貫性の高いものを選ばせる手法（「普遍的自己一貫性」）が高い効果を示しました。モデル自身が整合性を評価する構造が、質問に対する正確な回答に結びついたと考えられます。

一方、コードを別の言語に変換するタスク（「コード翻訳」）、テストコードの検証文を作成するタスク（「アサート生成」）、意図的にバリエーションを持たせたコードを作るタスク（「ミュータント生成」）でも、事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") が好成績を収めました。文脈に適した具体例を与えるアプローチは、出力形式の学習にも効果的だったようです。

バグを修正するタスクや、コードの内容を要約するタスクでは、モデル自身に少数ショットのプロンプト例を自動生成させる手法（「自己生成コンテキスト学習」）や、もっとも基本的な指示のみを与える構成（ベースライン）が高い性能を示す場面もありました。複雑な誘導が必ずしも必要ではないことを示唆する結果です。

自然言語の仕様をもとにコードを一から生成するタスクでは、再び普遍的自己一貫性が有効でした。複数案を出力させ、その中から一貫性のあるコードを選ばせる構成が、全体の整合性を高めたと推測されます。

### モデルごとの違いも見られた

商用の軽量モデル「o3-mini」は、他のモデルとは異なる傾向が出ました。多くのタスクで、モデルに「開発者として」や「コードレビュアーとして」といった役割を明示する手法（「役割指定プロンプト」）が最も高い性能を示しています。視点や立場を与えることで、出力内容がブレにくくなるという効果があったと考えられます。

知識を問うタスクではなく推論の方向性がものを言うタスクでは、このように役割の設定も意味を持つようです。

一方で、DeepSeek-V3、Qwen2.5-Coder、Llama-3.3といった大規模モデルでは、事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") が全体を通じて安定した成果を上げており、コード文脈への対応力に強みがあることが確認されました。

### 成果が出なかった手法もある

すべての手法が効果的だったわけではありません。中には、単純なベースライン構成よりも性能が下がった手法も報告されています。

各タスクで最も効果が低かったプロンプト手法は以下の通りです。

| タスク | 総合 | Qwen2.5 | DeepSeek-V3 | Llama-3.3 | o3-mini |
| --- | --- | --- | --- | --- | --- |
| 欠陥検出 | 自己改善 | 言い換えて応答 | 思考樹形探索 | 思考樹形探索 | ステップバックプロンプト |
| クローン検出 | 自己改善 | 自己生成コンテキスト学習 | 自己生成コンテキスト学習 | 普遍的自己一貫性 | 自己改善 |
| 例外タイプ予測 | 言い換えて応答 | 自己改善 | 思考樹形探索 | 自己改善 | 自己改善 |
| コードQA | 思考樹形探索 | 思考樹形探索 | 思考樹形探索 | ベースライン | 自己生成コンテキスト学習 |
| コード翻訳 | 自己生成コンテキスト学習 | 自己生成コンテキスト学習 | 普遍的自己一貫性 | 思考樹形探索 | 自己生成コンテキスト学習 |
| バグ修正 | 言い換えて応答 | 思考樹形探索 | 言い換えて応答 | 自己改善 | 感情誘導プロンプト |
| ミュータント生成 | 思考樹形探索 | 思考樹形探索 | 自己生成コンテキスト学習 | 普遍的自己一貫性 | 自己改善 |
| アサート生成 | 自己改善 | 思考樹形探索 | 自己生成コンテキスト学習 | 自己改善 | 自己改善 |
| コード要約 | 言い換えて応答 | 言い換えて応答 | 思考樹形探索 | 自己改善 | 言い換えて応答 |
| コード生成 | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 思考樹形探索 | 思考樹形探索 | 思考樹形探索 | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") |

たとえば、初回の出力をモデル自身に評価させて改善を繰り返す手法（「自己改善」）は、欠陥検出やコードQAなどの理解系タスクで逆効果となることが多く見られました。自己修正のプロセスがかえって出力を混乱させたと考えられます。

「この作業は重要です」といった感情的な文を含める手法（「感情誘導プロンプト」）も、欠陥検出では精度が低下しました。技術的な判断を要する場面で、過剰なトーンがノイズになった可能性があります。

また、複数の思考経路を同時に試す手法（「思考樹形探索」）は、生成系のタスクでは安定性を欠きやすく、結果的に性能が下がる傾向が見られました。例示を自動生成する「自己生成コンテキスト学習」も、コード翻訳などのタスクでは逆効果になる場面があり、生成される例の質にばらつきがあることが影響していると見られます。

### プロンプト表現の特徴と出力精度の関係

プロンプトの”書き方”自体が性能にどう影響するかも分析されました。

その結果、語彙の多様さ（MATTR）は、すべてのタスクで高い正の相関、つまり効果があることを示しました。語彙が豊かで多様な表現を含むプロンプトほど、モデルの出力精度が高まる傾向があります。生成タスクではとくに強い相関が見られました。

一方で、プロンプトの長さ（トークン数）は全体的に負の相関を示しました。長く書けばよいというわけではなく、必要な情報が過剰に含まれることでかえってモデルの判断が鈍るケースもあるようです。

読みやすさに関しては、理解系タスクでは平易な文体の方が効果的であり、複雑な文は精度を下げる要因となる傾向が見られました。反対に、生成系タスクでは多少構造が複雑なプロンプトの方が良い結果を出す場面もあり、読みやすさの最適水準はタスクに依存すると考えられます。

### LLMに聞いてみた成功要因

研究では、LLM自身に「なぜこの手法がうまくいったのか」を説明させるメタ分析も行われました。

その結果をまとめると以下の通りでした。

| 要因 | 割合（％） |
| --- | --- |
| 構造化されたガイダンス | 32.05 |
| 文脈内の事例提示 | 21.80 |
| 効率性 | 17.95 |
| 曖昧さの削減 | 15.38 |
| 堅牢性・包括性 | 7.70 |
| 推論の明示 | 2.56 |
| 正確性と精密性 | 2.56 |

最も多く挙げられた理由は、出力構造や目的を明確に伝えることです。どんな形式でどんな情報を出せばよいかが明確になっているほど、迷いのない出力が得られやすいと考えられます。

次に多かったのは、タスクに関連する具体例が含まれていることです。モデルが状況を正しく捉える助けとなり、出力の妥当性が向上するという指摘がありました。

そのほか、曖昧さの排除、効率的な誘導、推論の明示、精度重視の設計なども成功した手法の要因として言及されています。

### 性能とリソースのトレードオフ

実務でプロンプト設計を検討する際には、性能だけでなく、トークン消費や応答時間といったリソース面のコストも無視できません。

以下の２つの表はプロンプトごとのトークン節約量（平均）および時間節約量（平均）です。

| タスク | 総合 | Qwen2.5 | DeepSeek-V3 | Llama-3.3 | o3-mini |
| --- | --- | --- | --- | --- | --- |
| 欠陥検出 | 2361.47 | 2195.55 | 3079.72 | 4867.86 | 2559.22 |
| クローン検出 | 3588.50 | 3518.13 | 3777.58 | 3498.83 | 3634.21 |
| 例外タイプ予測 | 1985.42 | 1957.17 | 2070.51 | 1913.72 | 2583.11 |
| コードQA | 2143.98 | 2812.42 | 3984.25 | 19485.09 | 1696.93 |
| コード翻訳 | 3021.62 | 3094.46 | 3265.77 | 3471.79 | 551.83 |
| バグ修正 | 8306.71 | 7698.30 | 8744.93 | 7621.01 | 360.08 |
| ミュータント生成 | 2945.01 | 92.55 | 2679.70 | 4458.38 | 362.61 |
| アサート生成 | 250.75 | 427.77 | 3886.71 | 5269.65 | 643.66 |
| コード要約 | 3129.23 | 3408.88 | 4586.85 | 2648.01 | 1004.58 |
| コード生成 | 10733.42 | 9278.82 | 8502.98 | 8837.50 | 791.71 |

| タスク | 総合 | Qwen2.5 | DeepSeek-V3 | Llama-3.3 | o3-mini |
| --- | --- | --- | --- | --- | --- |
| 欠陥検出 | 107.60秒 | 220.09秒 | 103.48秒 | 56.87秒 | 66.87秒 |
| クローン検出 | 80.31秒 | 191.34秒 | 83.02秒 | 30.81秒 | 32.45秒 |
| 例外タイプ予測 | 66.68秒 | 186.78秒 | 22.89秒 | 19.91秒 | 54.61秒 |
| コードQA | 85.73秒 | 207.76秒 | 68.15秒 | 39.70秒 | 43.34秒 |
| コード翻訳 | 111.33秒 | 101.74秒 | 107.54秒 | 39.80秒 | 4.41秒 |
| バグ修正 | 211.72秒 | 363.59秒 | 262.24秒 | 72.23秒 | 2.80秒 |
| ミュータント生成 | 114.80秒 | 17.89秒 | 91.95秒 | 48.83秒 | 2.54秒 |
| アサート生成 | 139.91秒 | 91.82秒 | 129.99秒 | 55.94秒 | 5.06秒 |
| コード要約 | 121.34秒 | 269.99秒 | 143.31秒 | 32.81秒 | 56.34秒 |
| コード生成 | 231.05秒 | 384.03秒 | 240.96秒 | 78.14秒 | 7.55秒 |

たとえば、事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") は多くのタスクで最適な結果を出しましたが、参照事例の追加によってプロンプトが長くなり、トークンコストが増えるという側面があります。

一方で、役割指定プロンプトのようなコンパクトな手法は、性能を保ちつつトークン効率も良好でした。モデルの立場や視点を明示するだけでも効果があることは、コストパフォーマンスの観点から重要な発見です。

さらに、複数回の出力やフィードバックが必要な手法（たとえば普遍的自己一貫性や自己改善）は、応答までにかかる時間も長くなります。リアルタイム性が求められる場面では、自己問いかけや事例選択のような比較的軽量な手法の方が適していると言えるでしょう。

こうしたトレードオフの知見は、LLMの活用を現場で定着させるうえで不可欠です。どの手法が「よい」かを判断する際には、性能だけでなく、リソース条件とのバランスをどうとるかという観点が欠かせません。

## 現場で役立つ設計のヒント

実験で得られた知見は、実際にLLMを開発業務へ組み込む際の判断材料としても意味を持ちます。プロンプト設計をどう考えるべきか。実務の視点で整理してみましょう。

### モデルとタスクの組み合わせで考える

まず押さえておきたいのは、プロンプト設計において「万能なやり方」は存在しないという点です。ある手法がうまくいくかどうかは、モデルの特性とタスクの性質がどう組み合わさるかに強く依存します。

たとえば、軽量モデルのo3-miniでは「開発者として答えてください」のように視点を与える手法（役割指定プロンプト）が多くのタスクで良い結果を出していました。一方、DeepSeekやLlamaといった大規模モデルでは、コード事例を文脈に加える構成（事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") ）の方が安定した成果につながっていました。

こうした違いは、APIだけを差し替えてモデルを入れ替える運用では見落とされがちです。モデルを切り替える際には、プロンプトも含めて設計を見直す必要があることが示されています。

### タスクの性質に応じたアプローチの違い

取り組むタスクの種類によっても、有効なプロンプトの作り方は変わります。理解系のタスクと生成系のタスクでは、LLMに求められる能力がそもそも異なっているからです。

#### コードを「理解」するタスクでは、明快な指示が大事

たとえば、欠陥検出やクローン検出のような分類型のタスクでは、「このコードはバグか？」「この2つの処理は似ているか？」といった判断を正確に行わせる必要があります。複雑な誘導よりも、判断の軸となる具体例を明示する方が効果的であり、プロンプトの言い回しも平易な方が成果につながる傾向がありました。

#### コードを「生成」するタスクでは、構造の誘導が効いてくる

一方で、コード翻訳やアサート生成といった出力型のタスクでは、段階的な思考を促したり、複数の候補を出させて比較させるような構成が効果を発揮していました。「どう作るか」をガイドするプロンプト構造が、出力の安定性を高める鍵になります。

### モデルごとの違いも押さえておく

モデルの規模や性質によっても、向いている設計が変わってきます。

#### 軽量モデルには、視点の明示が効く

計算資源の限られた軽量モデルでは、「あなたは開発者です」といった指示がとくに有効でした。出力の方向性が定まりやすくなるため、余計なブレを抑えることができたと考えられます。

#### 大規模モデルには、文脈の厚みを活かす

大規模モデルでは、コード事例などの補足情報をプロンプトに含めても性能が下がらず、むしろ精度が上がる場面が多くありました。文脈を読み解く能力に余裕があるぶん、情報量の多い設計のほうが力を引き出しやすいようです。

### 自動設計の可能性も見える

こうした知見は、プロンプトの最適化を自動で行うようなツールの実現可能性にもつながります。

モデルの種類とタスクの内容に応じて、テンプレートや構造を自動で切り替える仕組みがあれば、開発者の試行錯誤を減らせます。とくに、今回の分析で明らかになった「構造の明示」と「具体例の提示」という2つの成功要因は、アルゴリズム化しやすい特徴でもあります。

### コストや速度をどう考えるか

プロンプト設計を実務で使うには、性能だけでなくトークン消費量や応答時間といったコスト面のバランスも重要になってきます。

#### トークンを抑えたい場合

商用APIでは、トークン数がそのまま課金に直結します。事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") は高性能ですが、参照事例のぶんだけトークンも増えるため、コストを重視する場面では選びにくくなります。役割指定のような短いプロンプトでも効果が出るなら、その方が適しているケースもあります。

#### 応答速度を優先したい場合

リアルタイム性が求められる用途では、複数の出力を生成して比較する手法（たとえば普遍的自己一貫性）や、フィードバックを繰り返す手法（自己改善）は向きません。すばやく反応することを優先するなら、構成がシンプルなプロンプトの方が実用的です。

### トークン効率に与える影響もタスク次第

トークン数の削減がどれだけ効くかも、タスクによって違いがあります。

たとえば、コード生成やバグ修正のようにプロンプトが長くなりがちなタスクでは、設計を見直すことで大きな節約効果が得られます。一方、クローン検出や例外予測のように短めのプロンプトが適しているタスクでは、圧縮してもあまり効果はなく、むしろ過度な削減で精度が落ちるリスクがあります。

なお、以下の表は最適手法のリソースコスト傾向（デフォルト／トークン効率／時間効率）です。

| タスク | 総合 | Qwen2.5 | DeepSeek-V3 | Llama-3.3 | o3-mini |
| --- | --- | --- | --- | --- | --- |
| 欠陥検出 | 思考樹形探索／ベースライン／事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 思考樹形探索／ベースライン／ベースライン | 思考樹形探索／ベースライン／自己問いかけ | 思考樹形探索／役割指定／思考樹形探索 | 役割指定／ベースライン／ベースライン |
| クローン検出 | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") ／文体指定／事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") ／役割指定／ベースライン | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") ／感情誘導／思考樹形探索 | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") ／感情誘導／事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") ／ベースライン／ベースライン |
| 例外タイプ予測 | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") ／ベースライン／事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") ／ベースライン／事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") ／役割指定／思考樹形探索 | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") ／ベースライン／事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 言い換えて応答／ベースライン／ベースライン |
| コードQA | 普遍的自己一貫性／ベースライン／事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 自己生成コンテキスト／ベースライン／事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 普遍的自己一貫性／ベースライン／事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 普遍的自己一貫性／役割指定／事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 役割指定／ベースライン／ベースライン |
| コード翻訳 | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") ／ベースライン／事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") ／ベースライン／事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") ／文体指定／自己問いかけ | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") ／ベースライン／事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") ／ベースライン／ベースライン |
| バグ修正 | ベースライン／ベースライン／事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 自己生成コンテキスト／ベースライン／ベースライン | 自己生成コンテキスト／役割指定／思考樹形探索 | 自己生成コンテキスト／ベースライン／事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | ベースライン／ベースライン／ベースライン |
| ミュータント生成 | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") ／ベースライン／事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 役割指定／ベースライン／事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") ／役割指定／自己問いかけ | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") ／ベースライン／事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 役割指定／ベースライン／ベースライン |
| アサート生成 | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") ／ベースライン／事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") ／ベースライン／事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") ／ベースライン／事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") ／ベースライン／事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") ／ベースライン／ベースライン |
| コード要約 | ベースライン／ベースライン／ベースライン | 自己生成コンテキスト／ベースライン／ベースライン | 事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") ／ベースライン／事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | ベースライン／ベースライン／ベースライン | 自己生成コンテキスト／ベースライン／ベースライン |
| コード生成 | 普遍的自己一貫性／ベースライン／事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 普遍的自己一貫性／ベースライン／事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 自己生成コンテキスト／自己問いかけ／事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 普遍的自己一貫性／ベースライン／事例選択 [KNN](https://ai-data-base.com/archives/26147 "k近傍法（KNN）") | 普遍的自己一貫性／ベースライン／ベースライン |

### 現場で導入するなら段階的に

今回得られた知見をそのまま現場に適用するには、いくつかのステップを踏むのが現実的です。

まずは、使用するモデルと主要なタスクの組み合わせをもとに、小規模な検証を行ってみましょう。その結果を踏まえて、応答速度やトークン数といった制約を加味しながら、導入時の最適バランスを探ることが重要です。

さらに、モデルのアップデートやタスク内容の変更があったときには、プロンプト設計も定期的に見直していくことが求められます。今回の実験結果は出発点であり、導入後の改善ループこそが成果を支える基盤になります。

## 注意

今回の実験結果は、実務における参考になりますが、いくつか踏まえておくべき注意点があります。

（１）手法の選定やプロンプトの設計には主観が入り得ます。ただし複数研究者による合意形成や一貫性の検証などを通じて、評価の公平性が保たれています。また各モデルでは温度設定が固定され、全タスクで同一のサンプルが用いられるなど、条件もできる限り統一されています。

（２）対象となったモデルやタスクは実務での活用が想定されるものですが、必ずしもすべての状況に当てはまるとは限りません。モデルやタスクが変わる場合には、再度の検証が推奨されます。

（３）評価指標にはBLEUやCodeBLEUといった自動評価が用いられましたが、実際の開発では人手による品質確認も重要です。また、トークン数や応答時間といった指標はAPIやネットワーク環境に依存するため、運用時には差が出ることも考えられます。

（４）導入を検討する際には、自社での小規模な検証から始め、モデルやタスクの変化に応じてプロンプト設計を見直す体制を整えておくと安心です。自動評価だけに頼らず、開発者視点での実用性も併せて見ていくことが大切です。

## まとめ

本記事では、LLMにおけるプロンプト設計の効果をソフトウェア開発タスクで広く検証した研究を紹介しました。

14種類の手法を10のタスクに適用した結果、手法の良し悪しはモデルやタスクの特性によって大きく左右されることがわかりました。同時に、明確な構造や具体的な文脈を与える設計は、多くの場面で高い効果を発揮しています。一方で、自己改善や感情誘導といった手法は、使い方を誤ると性能を落とすケースもありました。

性能だけでなくトークンコストや応答速度といった条件も踏まえ、自分のタスクに最も合った設計を選ぶことが重要になりそうです。

**参照文献情報**

- タイトル：Which Prompting Technique Should I Use? An Empirical Investigation of Prompting Techniques for Software Engineering Tasks
- URL： [https://doi.org/10.48550/arXiv.2506.05614](https://doi.org/10.48550/arXiv.2506.05614)
- 著者：E. G. Santana Jr, Gabriel Benjamin, Melissa Araujo, Harrison Santos, David Freitas, Eduardo Almeida, Paulo Anselmo da M. S. Neto, Jiawei Li, Jina Chun, Iftekhar Ahmed
- 所属：Federal University of Bahia, Federal Rural University of Pernambuco, University of California Irvine

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[性格と自信、内省と交渉から見えてくるAIのふるまいと未来](https://ai-data-base.com/archives/90848)

[あなたのLLM依存度はどのくらいか 仕事面と感情面の12項目テストで傾向をチェック](https://ai-data-base.com/archives/91020)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)