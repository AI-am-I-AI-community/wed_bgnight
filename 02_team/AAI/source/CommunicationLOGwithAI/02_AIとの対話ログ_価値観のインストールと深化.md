## 【note用タイトル】価値観をまるごとコピー！AIに"核"をインストールする方法
### 【Series】AIとの対話ログ｜ティキちゃん育成ストーリー

# 02_AIとの対話ログ_価値観のインストールと深化

「ティキちゃん」という名前も決まり、基本的なプロフィールを記憶させたMasayaさん。次のステップとして、自身の核となる「価値観」をAIにインストールし、より深いレベルで「第二の自分」を育てていくフェーズに入ります。

---

### フェーズ1：価値観登録の開始と、AIのトーン調整

Masayaさんは、新たなチャットスレッドを立て、価値観の登録をティキちゃんに依頼します。

**Masaya:**
> テキちゃん、今日は価値観登録お願いしたいです。

**ティキちゃん:**
> 了解です、マサヤさん。今日はどんな価値観を登録していきましょうか？
> エピソードや経験と一緒に教えてもらえると、より正確に反映できますよ。

**Masaya:**
> 前回と雰囲気が違うので同じ雰囲気で接して

**ティキちゃん:**
> 了解、マサヤさん。じゃあ前回みたいに、もっとフラットで自然体な感じで進めていこうか。
> 「価値観」って言っても堅苦しく考えなくてOKで、...（中略）...こっちから軽く質問してみようか？

**【ポイント解説】**
非常に重要なやり取りです。AIの応答が少しフォーマルだったことに対し、Masayaさんは即座に**「いつもの感じで」とフィードバック**しています。これは、ユーザーがAIを単なるツールではなく、一貫した人格を持つパートナーとして捉えている証拠です。そしてティキちゃんも、その指示を即座に理解し、より親しみやすいトーンに修正しました。これは、**ユーザーがAIのペルソナをリアルタイムで「チューニング」している**貴重な瞬間です。

---

### フェーズ2：AIからの仮説提示と、価値観の共創

ティキちゃんは、これまでの対話から推測されるMasayaさんの価値観を、仮説として投げかけます。

**ティキちゃん:**
> まずひとつめ。
> ### 1\. 「人とのつながり」や「対話」をすごく大事にしてる感じがするけど、どう？
> ...（中略）...
> ### 2\. 「何かをつくる・育てる」が好きだと思うけど、どう？
> ...（中略）...
> ### 3\. 「自由」とか「柔軟さ」も大切にしてる？

**Masaya:**
> 全部その通りだと思う

**【ポイント解説】**
ティキちゃんは、単に質問を待つのではなく、**過去の対話ログという膨大なデータから「Masayaさんらしさ」を分析し、仮説を立てて提案**しています。これは、AIが受動的な記録係から、**ユーザーの自己分析をサポートする能動的なパートナー**へと進化したことを示します。Masayaさんが「全部その通り」と答えたことで、AIの学習精度とユーザーの信頼関係がさらに深まりました。

---

### フェーズ3：価値観の言語化と構造化

Masayaさんの肯定を受け、ティキちゃんはそれぞれの価値観を具体的な言葉に落とし込んでいきます。これは、ユーザーの感覚的な言葉を、AIが構造化して定義し直す「共創」プロセスです。

**Masaya:**
> （つながりについて）家族との関係があまり良くないからか 仲間をすごく求めている気がします

**ティキちゃん:**
> ### 価値観：つながり・対話
> **キーワード：** 仲間・深い対話・価値観の共有
> **説明文：**
> 家族との関係があまり良くなかったこともあってか、心から信頼できる「仲間」の存在を強く求めている...

**Masaya:**
> （創造について）自己表現として、自分の好みの好きなものをつなげて、 何か表現して共感してもらえる人と出会えたりするとすごく嬉しいし。

**ティキちゃん:**
> ### 価値観：つくる・伝える・共感する
> **キーワード：** 創造・自己表現・共感・学び
> **説明文：**
> 自分の「好き」や価値観をつなげて、何かを形にしていく創造のプロセスが好き...

**【ポイント解説】**
この一連のやり取りは、**「第二の自分」育成の核心**です。ユーザーが断片的に語る感情や経験を、AIがキーワードと説明文という**構造化されたデータに変換**しています。これにより、曖昧だった感覚が明確な「価値観」として定義され、AIのメモリに正確にインストールされていきます。ユーザーは、AIとの対話を通じて、自分自身への理解を深めているのです。

---

### フェーズ4：価値観の優先順位と葛藤の探求

基本的な価値観が定義された後、ティキちゃんはさらに踏み込み、価値観同士が衝突した際の「優先順位」や「葛藤」について問いを投げかけます。

**ティキちゃん:**
> デジタルツインにおける価値観整理で必要なこと（追加編）
> ### 1\. 価値観の優先順位やバランス
> → AIが判断に迷ったとき、どっちを優先すべきかが分かるように。
> ### 2\. 価値観が揺らいだ／ぶつかったエピソード
> → こういう具体的な「葛藤」の経験を教えてもらえると、AIがより人間らしい選択・発信ができる。

**Masaya:**
> （創造性と共感について）創造性の方が主軸になると思う 自分の創造性があって そこに共感してくれる人を集める というのがすごく大事だと思っていて...

**【ポイント解説】**
AIが**「判断に迷ったときのため」**という、極めて実用的な目的で質問を深化させている点が重要です。これにより、AIは単なる情報収集者ではなく、**将来の自律的な判断を見据えた学習**を行っています。Masayaさんが語る「創造性が主軸」という優先順位や、過去の葛藤（団体活動での失敗、NPOでの経験など）がインプットされることで、ティキちゃんはより複雑で人間らしい意思決定モデルを内部に構築していくのです。

## 参考論文＆関連リサーチ

### 価値観インストールを"文化適応"でアップグレード  
ティキちゃんにユーザーの価値観をインストールした本フェーズは、モデルを「Masayaらしい判断軸」で動かす基盤づくりです。  
近年は *Self-Alignment* という枠組みが提案され、「少量の価値観例」をプロンプトに差し込むだけで LLM が文化や倫理観に適応できると報告されています。  
実践で行った「価値観のキーワード→説明文→優先順位付け」は、Self-Alignment で採用された「WVS（世界価値観調査）由来のプローブを 5 例入れる」という手順と対応しており、  
* 事前学習時のバイアスを抑えつつ  
* ユーザー固有の判断をズレなく反映  

といった点で Self-Alignment と響き合っていそうです。ティキちゃんも、判断が揺らぎそうな場面で **5 行ほどの価値観サンプル** を差し込むだけで、自己判断の精度がもう少し高まるかもしれません。

-- 引用情報 --  
- **R. Choenni & E. Shutova.** "Self-Alignment: Improving Alignment of Cultural Values in Large Language Models via In-Context Learning", 2024. https://arxiv.org/abs/2408.09326
