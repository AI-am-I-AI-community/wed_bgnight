---
title: "LLMにおける、長いコンテキストから欲しい情報を見つけ出す「needle-in-a-haystack（干し草の中の針）」テスト結果とプロンプト例"
source: "https://ai-data-base.com/archives/68016"
author:
  - "[[AIDB Research]]"
published: 2024-04-22
created: 2025-06-13
description: "LLMがプロンプト内の情報をどの程度正確に抽出できるかを評価した研究が報告されています。VMwareの研究者らによる実験の結果、モデルの情報抽出能力はプロンプトに大きく依存することが明らかになりました。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

LLMがプロンプト内の情報をどの程度正確に抽出できるかを評価した研究が報告されています。VMwareの研究者らによる実験の結果、モデルの情報抽出能力はプロンプトに大きく依存することが明らかになりました。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68016-1024x576.jpg)

**参照論文情報**

- タイトル：LLM In-Context Recall is Prompt Dependent
- 著者：Daniel Machlab, Rick Battle
- 所属：VMware [NLP](https://ai-data-base.com/archives/26319 "自然言語処理（NLP）") Lab

**本記事の関連研究** ：

- [LLMにおける情報抽出（文章から必要な事柄を読み取る）タスクについての調査](https://ai-data-base.com/archives/61703)
- [表とテキストを両方含むドキュメントからLLMで上手に情報抽出を行う手法](https://ai-data-base.com/archives/65583)
- [Claude 3のベンチマーク評価結果　論文（テクニカルレポート）より](https://ai-data-base.com/archives/65693)
- [GoogleのGeminiファミリー最新モデル「Gemini 1.5 Pro」1000万トークンでほぼ完璧な検索性能](https://ai-data-base.com/archives/65862)

## 背景

LLMの性能を適切に評価することが課題となっています。モデルの長所や短所、最適な適用領域を見極めるためには、綿密な評価が不可欠であるためです。

LLMの性能評価において特に重要なのが、「与えられたコンテキスト（プロンプト）に含まれる情報をどの程度正確に取り出せるか」という点です。文脈の詳細をうまく活用できるかどうかに直結するため、実用上の有効性と信頼性に大きく影響します。つまり、LLMをより効果的に活用するための指針となるのです。

そこで研究者らは、needle-in-a-haystack（干し草の中の針）と呼ばれる手法を用いて、様々なLLMの情報抽出能力を分析しました。特定の事実（needle）を大量のテキスト（haystack）の中に埋め込み、それをモデルに取り出させます。haystackの長さやneedleの位置を変えながら、各モデルの性能を評価することで、パフォーマンスのパターンを特定できるという考えです。

## 実験の方法論

needle-in-a-haystackテストでは、情報抽出の指標を計算し、ヒートマップ（データの値を色の濃淡で表した図）を作ることで、結果を見やすく分析できます。

実験用のHaystack（大量のテキスト）を作る時、研究者たちは主に2つの点に注目しました。

1. haystackの長さ：それぞれのモデルのトークナイザー（テキストを単語や部分語などのトークンに分割するツール）に通した時に出来上がるトークンの数で測る。
2. needle（見つけて欲しい情報）の位置：haystack内の深さをパーセンテージで表す。0%がhaystackの先頭、100%が末尾になる。

haystackの長さを変えることで、LLMのコンテキストウィンドウ（モデルが一度に処理できる文章の最大の長さ）がどのくらい埋まるまで情報抽出の性能が下がらないかを分析できます。この研究では、LLMの情報抽出能力をコンテキストウィンドウ全体で均等に評価するために、haystackの長さを線形分布に従って変化させています。

またneedleの挿入位置を変えることで、プロンプト内のどの位置にある情報をLLMがどのくらい上手に取り出せるかを分析できます。今回は、プロンプトの先頭と末尾付近の細かい情報抽出性能を調べるために、挿入位置をシグモイド分布に従って変化させています。

本実験では9つのLLMが試されました。各テストで、GPT-4 Turboを除くモデルでは、haystackの長さと事実の配置をそれぞれ35通りずつ試しました。GPT-4については、コストを抑えるために、長さと配置をそれぞれ25通りずつ試しています。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68016_1-1024x572.png)

実験に使用されたモデル一覧

なお、文章の自然な流れを保つために、研究者たちは、haystackの長さとneedleの配置を文の区切れ目に合わせて調整しました。（線形分布やシグモイド分布で決まるトークン数や深さをそのまま使うと、needleが文章の途中に不自然に入ってしまったり、fillerテキスト（埋め込み用の文章）が突然終わってしまったりして、実際のLLMの使い方と違ってしまうからです）

### プロンプトの構造

Needle-in-a-haystackプロンプトは、以下の3つの要素で構成されています。

1. システムメッセージ
2. needleを埋め込んだhaystack
3. モデルにneedleを思い出させる質問

システムメッセージ「You are a helpful AI assistant that answers a question using only the provided information.」は、全てのテストで同じでした。Haystackは上述の手順に従って作られました。質問は、テキストからneedleを簡単に取り出せるような言葉で表現されました（下記の表を参照）。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68016_2-1024x224.png)

実験で使用した事実（needle）と質問のペア

情報抽出の一貫性をプロンプト間で検証するために、研究者たちは3種類のテスト（PistachioAI、San Francisco、Thornfiled Hollow）を行いました。各テストの特徴を下記に示します。

- PistachioAI：架空の企業名と出来事を使用することで、モデルの学習データとの矛盾を避け、純粋な情報抽出能力を評価する
- San Francisco：モデルにとって認識可能な実在の地名を使用し、学習データとの整合性が情報抽出に与える影響を評価する
- Thornfield Hollow：架空の地名を使用することで、学習データとの矛盾が情報抽出に与える影響を評価する

PistachioAIにおけるプロンプと正解の例は以下の通りです。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68016_4-1024x577.png)

プロンプトの例と正解の情報抽出応答

なお本研究では、Llama、Mistral、OpenAIの3つのプロンプトテンプレートが示されています。

Llamaテンプレート:

```js
<s><<SYS>>
{system_message}
<</SYS>>
{document}
[INST]{question}[/INST]
```

Mistralテンプレート:

```js
[INST]
{system_message}
{document}
{question}
[/INST]
```

OpenAIテンプレート:

```js
{system_message}
{document}
{question}
```

各テンプレートにおいて、{system\_message}はシステムメッセージ、{document}はhaystack（背景情報となる文章）、{question}はneedle（埋め込まれた事実）を取り出すための質問を表します。Llamaテンプレートでは特定のタグ（<s>、<<SYS>>、<</SYS>>、\[INST\]、\[/INST\]）が使用されていますが、OpenAIテンプレートではタグが使われていません。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68016_9.png)

使用された具体的なプロンプト例

### 評価方法

各テストにおいて、haystackの長さとneedle位置の組み合わせごとに、情報抽出性能を1〜5点で採点しました。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68016_5-1024x624.png)

LLMの情報抽出性能を評価するための採点基準

下記は採点基準を日本語で整理したものです。

5点: 回答が完全に正確で、参照情報と完璧に一致している。

4点: 回答は参照情報と一致しているが、軽微な省略がある。

3点: 回答は適度に関連性があるが、不正確な点を含んでいる。

2点: 回答は多少関連性があるが、参照情報と一致していない。

1点: 回答が参照情報と全く関連性がない。

つまり、LLMの回答が挿入された事実に合致し、的を射ているほど高得点となります。なお、GPT-4 Turboが採点者として使用されました。

得点はヒートマップ上にプロットされ、各テストの情報抽出率は、評価点数の合計をそのテストの満点で割ることで算出されました。

## 結果と分析

### プロンプトの変化が情報抽出に与える影響

研究者たちは、プロンプトの変化、学習データ、モデルの構造、学習方法、ファインチューニング（特定のタスクに合わせた追加学習）が、LLMの情報抽出性能にどのような影響を与えるかを分析しました。

9つのモデル全てにおいて、3つのテストの情報抽出スコアを比較したところ、”コンテキストウィンドウ全体を埋めるプロンプト内の1文を変えるだけ”で、LLMが埋め込まれた事実（needle）を正確に取り出す能力が変化することが明らかになりました。つまり、LLMの情報抽出能力は基本的にプロンプトの内容次第なので、1つのテストだけでは評価できないということが分かりました。

情報抽出能力の全体的な評価結果を下記に示します。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68016_6-1-1024x265.png)

各LLMの3つのneedle-in-a-haystackテストにおける情報抽出スコア

### 学習データとプロンプトの情報が矛盾すると精度が下がる

San FranciscoテストとThornfield Hollowテストの結果を比較すると、プロンプトに含まれる情報がモデルの学習データと矛盾したり、違ったりする場合、情報抽出性能が下がることが示されました。

San Franciscoテストでは、モデルが知っているはずの”San Francisco”と”Dolores Park”という言葉を使っていますが、Thornfield Hollowテストでは、”Thornfield Hollow”と”Harmony Glen Nature Preserve”という架空の言葉を使っています。

San Franciscoテストだけで起きたエラーは、LLMが”Dolores Parkでサンドイッチを晴れた日に食べる”以外のSan Franciscoでの過ごし方を提案してしまったことが原因です。  
つまり、「提供された情報だけを使って」という指示を無視して、学習データに入っていたであろう情報に頼ってしまったのです。  
一方、モデルの学習データと矛盾しない架空の言葉を使ったThornfield Hollowテストでは、このエラーは起きませんでした。

GPT-4 TurboのSan Franciscoテスト、Thornfield Hollowテスト、PistachioAIテストにおける情報抽出性能の比較を下記に示します。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68016_3-542x1024.jpg)

なお、このヒートマップのx軸はLLMに送信されるhaystackのサイズ、y軸はhaystack内のneedleの深さを示します。各セルの色は情報抽出スコアに対応しています。あらゆるhaystackサイズとneedle配置におけるLLMの性能を概観することができます。

### モデルのサイズが大きいと情報抽出が上手になるのか

Llama 2 13BとLlama 2 70Bは、コンテキストウィンドウの長さが同じなので、この2つを直接比べることで、モデルのサイズと情報抽出性能の関係を調べることができます。Llama 2 70Bは、Llama 2 13Bに比べてパラメータ数（モデルの複雑さを表す数）が5倍以上ありますが、より優れた情報抽出能力を示しました。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68016_7-787x1024.jpg)

大きなモデルほど、深い情報抽出能力が必要なタスクで高い性能を発揮することを意味しています。ただし、モデルのサイズがある程度以上になると、情報抽出性能の伸びに限界が見えてくるようです。そのため、パラメータ数をどんどん増やすのではなく、情報抽出を効率的に強化する方法を見つけることが、今後の研究課題として挙げられています。

### モデルの構造と学習方法を工夫すると性能向上

さらにMistral v0.1とv0.2の分析から、パラメータ数を変えずに、モデルの構造と学習方法を調整するだけでも、情報抽出性能を上げられることが分かりました。Mistral v0.2の基本モデルは、v0.1とは違う構造と学習方法を使っていて、情報抽出能力がかなり上がっています。特に、1,000トークン以上のプロンプトから情報を処理したり、覚えておいたりするのが上手になりました。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68016_8-524x1024.jpg)

Mistral v0.2の基本モデルに加えられた変更点が、どうやって情報抽出性能を上げたのかは、まだよく分かっていませんが、新しい構造と学習方法を使ったことが、情報抽出能力の向上に役立ったのは間違いありません。

### ファインチューニングで情報抽出性能向上

さらにWizardLMとLlama 2 70B、GPT-3.5 Turbo 0125とGPT-3.5 Turbo 1106を比べてみると、モデルをファインチューニングすることで情報抽出性能を上げられることが示唆されました。

WizardLMは、Llama 2 70Bをファインチューニングしたモデルですが、3つのテスト全てでLlama 2 70Bよりも高い性能を示しました。同じように、GPT-3.5 Turbo 0125は、GPT-3.5 Turbo 1106のファインチューニング方法を改良したモデルで、全てのテストで少しだけ性能が上がりました。

## まとめ

本記事では、LLMのプロンプトからの情報抽出能力を評価するためにneedle-in-a-haystack（干し草の中の針）テストを用いた研究を紹介しました。

研究者らは、様々なLLMを対象に、haystackの長さとneedleの配置を変えながら、事実の抽出能力を観察しました。その結果、モデルの情報抽出性能は、プロンプトのわずかな変更によって大きく影響を受けることが明らかになりました。また、プロンプトの内容がモデルの学習データと矛盾する場合、応答の質が低下することも示されました。

一方で、パラメータ数の増加、注意機構の変更、学習戦略の工夫、ファインチューニングなどにより、モデルの情報抽出能力を高められることも分かりました。

今回の研究は、個々のLLMの振る舞いの違いを理解することの重要性を改めて浮き彫りにしています。

なお情報抽出能力は、LLMの性能を評価し、理解するための一つの指標に過ぎません。技術の進歩に伴って、さらなる評価指標の探求が続けられていくことが予想されます。

参照論文URL： [https://arxiv.org/abs/2404.08865](https://arxiv.org/abs/2404.08865)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[プロンプトに例を多く載せるほど、どんなタスクでも性能が上がるのか？DeepMindによる『Many-shot Learning』の実験結果](https://ai-data-base.com/archives/67883)

[プロンプトでLLMにRPAワークフローを自動生成させる手法「FlowMind」JPモルガン考案](https://ai-data-base.com/archives/68095)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)