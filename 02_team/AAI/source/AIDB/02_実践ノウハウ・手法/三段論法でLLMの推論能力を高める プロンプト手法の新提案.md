---
title: "三段論法でLLMの推論能力を高める プロンプト手法の新提案"
source: "https://ai-data-base.com/archives/82746"
author:
  - "[[AIDB Research]]"
published: 2025-01-27
created: 2025-06-13
description: "本記事では、LLMに三段論法による推論能力を付与する新しいフレームワークを紹介します。LLMは豊富な事前学習により推論能力を持っていますが、その推論過程には厳密性が欠けることがあります。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、LLMに三段論法による推論能力を付与する新しいフレームワークを紹介します。

LLMは豊富な事前学習により推論能力を持っていますが、その推論過程には厳密性が欠けることがあります。

そこで研究者らは人間の三段論法による推論プロセスを参考に、LLMの推論をより厳密にし、複雑な知識ベースの推論タスクでの性能向上を目指しました。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82746-1024x576.png)

**発表者情報**

- 研究者：Wentao Wan et al.
- 研究機関：中山大学, 広東省, 華南師範大学

論文情報詳細は記事の下部に記載されています。

## 背景

人間の重要な能力に「演繹推論」があります。演繹推論とは、既存の知識を基に複雑な問題を解決する思考方法です。最近のLLMは豊富な事前学習によって演繹的な推論能力を身につけ、Chain-of-Thoughtプロンプト（ステップバイステップの思考を促すプロンプト）の導入によってさらにその能力が向上しました。

しかし、LLMによる推論には厳密性が欠けることがあり、正しい推論経路から外れてしまう場合があります。また、形式言語に基づく推論エンジンや自動定理証明は厳密な推論を可能にしますが、日常的な質問応答などの知識ベースの推論タスクには適用が困難です。

そこで、人間が行う三段論法による推論が注目されます。三段論法とは、大前提と小前提から結論を導く厳密な演繹推論の一つです。

今回研究者らは、LLMにこの三段論法による推論を行わせることで、推論の厳密性を高め、錯覚を減らし、複雑なタスクでのパフォーマンスを向上させられると考えました。そして三段論法をLLMに実行させるためのプロンプト手法を考案しました。  
問題の解釈から始まり、大前提の提案、小前提の生成と回答、最終的な三段論法による推論という合計5段階で構成される手法です。各段階で必要な情報のみを参照することで、推論の厳密性を保ちながら、様々な知識ベースの推論タスクに対応することが目指されています。

以下で詳しく紹介します。

## フレームワークの全体像

研究者らが開発したフレームワーク「SR-FoT」は、具体的にどのように三段論法による推論を実現したのでしょうか。

SR-FoTフレームワークは、問題解釈、大前提生成、小前提質問の作成、小前提の生成、三段論法による最終推論という5つの段階で構成されています。各段階では、必要な情報のみが参照されます。

### 三段論法の基本構造

三段論法は、大前提、小前提、結論の3つの部分から構成される推論形式です。例えば「すべての人間は死ぬ（大前提）」「ソクラテスは人間である（小前提）」から「ソクラテスは死ぬ（結論）」が導かれます。大前提は一般的な原則を、小前提は具体的な事例を示します。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82746_1.png)

三段論法の例。主要前提、従属前提、結論の構造。

### 5段階の推論プロセス

#### 1\. 問題解釈

まず問題文が解釈され、必要な情報が特定されます。問題文とコンテキストのみを参照し、適切な解決アプローチが提案されます。

#### 2\. 大前提生成

問題の解釈に基づき、LLMの持つ知識から適切な大前提が生成されます。問題文、コンテキスト、問題解釈の情報が参照されます。

#### 3\. 小前提質問の作成

大前提を適用するために必要な具体的な情報を得るための質問が作成されます。問題文、コンテキスト、大前提の情報が参照されます。

#### 4\. 小前提の生成

作成された質問に対する回答から小前提が生成されます。Chain-of-Thought手法を用いて段階的に回答が導かれます。質問とコンテキストのみが参照されます。

#### 5\. 最終推論

大前提と小前提から、三段論法による推論が行われ、最終的な回答が導出されます。問題文、大前提、小前提の情報のみが参照されます。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82746_2-1024x427.png)

提案されたSR-FoTフレームワークの5段階の手順

### プロンプトテンプレート

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82746_4-1024x566.png)

**explain\_prompt**

```js
「あなたは知識豊富な学者です。以下は対応する文脈とともに提示される質問です。質問を注意深く読み、その意味を説明し、文脈から回答に必要な情報を見つけてください。見つけた情報は文脈から得られたものでなければならず、文脈に現れない情報を仮定してこの質問に直接回答することはできません。」
質問: {質問}
文脈: {文脈}
説明:
```

**major\_prompt**

```js
「三段論法の観点から、文脈と説明に基づいて質問に対する主要前提を提案してください。三段論法では、主要前提は一般的な声明または普遍的な真実です。主要前提は文脈に基づいているか、文脈から支持される必要があり、質問に可能な限り関連している必要があります。」
質問: {質問}
文脈: {文脈}
説明: {説明}
主要前提:
```

**minor\_question\_prompt**

```js
「三段論法の観点から、与えられた質問に対して従属前提の質問をしてください。従属前提の質問は、与えられた質問に可能な限り関連性が高いものにする必要があります。」
質問: {質問}
文脈: {文脈}
主要前提: {主要前提}
従属前提の質問:
```

**minor\_prompt**

```js
「文脈に基づいて考え、段階的に質問に回答してください。文脈に基づいてのみ考え、回答する必要があります。」
質問: {従属前提の質問}
文脈: {文脈}
従属前提:
```

**final\_prompt**

```js
「三段論法の観点から、主要前提と従属前提に基づいて段階的に考え、質問に回答してください。」
主要前提: {主要前提}
従属前提: {従属前提}
質問: {質問}
回答:
```

## 実験設定

研究者らは、実際にこのフレームワークがどの程度効果的なのか、下記のデータセットを用いて検証を行いました。

#### ScienceQA

科学分野の質問応答データセットで、自然科学、言語科学、社会科学の3分野から構成され、21,208問の選択式問題が含まれています。実験では、テキストのみのコンテキストを持つ2,224問が使用されました。

#### StrategyQA

一般常識に関する質問応答データセットで、複数のステップを経て解答する必要がある問題が収録されています。実験では2,290問が使用されました。

#### BoolQ

読解力を問うデータセットで、yes/no形式の回答を求める問題が3,270問含まれています。単純な事実確認ではなく、文脈から推論する必要がある複雑な問題が特徴です。

### 検証用モデル

実験では3種類のLLMが使用されました。

- GPT-3.5-turbo
- DeepSeek-v2：236Bパラメータを持つオープンソースモデル
- Qwen1.5-32B-Chat：32Bパラメータを持つオープンソースモデル

## 実験結果

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82746_3-1024x242.png)

ScienceQA、StrategyQA、BoolQデータセットにおける各手法の性能比較。

#### ScienceQA における結果

GPT-3.5-turboを使用した単一回の推論では、SR-FoTは基本手法より1.5%、CoTより0.5%高い精度を達成しました。多数回の推論を行うSC-SR-FoTでは、さらに1.5%の性能向上が見られました。DeepSeek-V2では、SR-FoTは基本手法より4.8%、CoTより3.2%の改善を示し、多数回推論との組み合わせで93.0%まで精度が向上しました。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82746_5-1024x626.png)

ScienceQAデータセットの質問に対するCoTとSR-FoTの回答比較。正確性と論理の違いが強調されている。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82746_6-1024x363.png)

ScienceQAデータセットでのサブカテゴリ別効果比較。

#### StrategyQAとBoolQにおける結果

StrategyQAでは、GPT-3.5-turboによる単一回推論で、SR-FoTは基本手法から7.3%、CoTから0.8%の改善を示しました。BoolQでも同様の傾向が見られ、三つのモデル全てで最高性能を記録しました。

### 厳密性の評価

各データセットから50事例をランダムに選び、推論過程の厳密性が評価されました。推論の各ステップが論理的に正しく、矛盾なく結論に至る場合を「厳密」と判定しています。SR-FoTはCoTと比較して、ScienceQAで82%（CoT:76%）、StrategyQAで92%（CoT:88%）、BoolQで96%（CoT:80%）と、より高い厳密性を示しました。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82746_7.png)

ScienceQAデータセットでの各段階の有効性を検証するアブレーションスタディの結果

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82746_8.png)

StrategyQAデータセットでの各段階の可視情報の影響を検証するアブレーションスタディ

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82746_9.png)

CoTとSR-FoTの厳密性を評価した結果

### エラー分析の詳細

誤答事例50件の詳細分析から、エラーの発生箇所とその割合が明らかになりました。

#### ScienceQAのエラーパターン

小前提の生成における誤り（48%）が最も多く、次いで大前提の生成（26%）でした。具体的な事実から一般的な法則を見出す過程で課題があることが示唆されています。

#### StrategyQAのエラーパターン

最終推論過程（32%）と大前提の生成（30%）での誤りが主要でした。推論の複雑さが増すにつれて、論理的な飛躍が生じやすくなる傾向が見られました。

#### BoolQのエラーパターン

小前提質問の生成（28%）と最終推論過程（32%）での誤りが目立ちました。Yes/No形式の回答を導く際の論理構築に改善の余地があることが分かりました。

誤り分析から、データセットの性質によって異なるエラーパターンが存在することが明らかになり、今後の改善に向けた具体的な方向性が示されました。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82746_10.png)

SR-FoTによる誤りの原因を分類した結果

## まとめ

本記事では、LLMに三段論法による推論を導入する新しいフレームワーク「SR-FoT」の研究を紹介しました。

5段階からなるフレームワークによって、LLMはより厳密な推論プロセスを実行できるようになり、複数のデータセットでの実験で従来手法を上回る性能を示しました。

LLMによる推論の厳密性と信頼性を向上させる取り組みとして、今後活用されてみてはいかがでしょうか。

**参照文献情報**

- タイトル：SR-FoT: A Syllogistic-Reasoning Framework of Thought for Large Language Models Tackling Knowledge-based Reasoning Tasks
- URL： [https://arxiv.org/abs/2501.11599](https://arxiv.org/abs/2501.11599)
- 著者：Wentao Wan, Zhuojie Yang, Yongcan Chen, Chenglin Luo, Ruilin Wang, Kehao Cai, Nan Kang, Liang Lin, Keze Wang
- 所属：Sun Yat-sen University, Guangdong Key Laboratory of Big Data Analysis and Processing, South China Normal University

## 理解度クイズ（β版）

1\. SR-FoTフレームワークが導入された主な目的は何ですか？

SR-FoTは三段論法を用いてLLMの推論プロセスをより厳密にすることを目指しています。LLMは豊富な事前学習により推論能力を持っていますが、その推論過程には厳密性が欠けることを解決するために開発されました。

解説を見る

2\. SR-FoTフレームワークの推論プロセスは何段階で構成されていますか？

SR-FoTは問題解釈、大前提生成、小前提質問の作成、小前提の生成、三段論法による最終推論という5段階で構成されています。各段階では必要な情報のみを参照し、不要な情報による干渉を防いでいます。

解説を見る

3\. SR-FoTの評価実験で使用されたデータセットの特徴として正しいものはどれですか？

実験では科学分野の質問回答(ScienceQA)、一般常識(StrategyQA)、読解力(BoolQ)という異なる性質を持つ3種類のデータセットが使用されました。多様なデータセットで検証することで、フレームワークの汎用性が確認されました。

解説を見る

4\. SR-FoTのエラー分析で判明したエラーパターンに含まれないものはどれですか？

SR-FoTのエラーパターンは、大前提、小前提質問、小前提、最終推論過程に関する誤りの4つに分類されました。技術的なエラーではなく、推論プロセスの各段階における論理的な誤りが分析されています。

解説を見る

5\. SR-FoTフレームワークの革新的な点は何ですか？

SR-FoTは人間が行う三段論法による推論をLLMに適用することで、推論の厳密性を高めました。形式言語による推論と日常的な質問応答の利点を組み合わせた新しいアプローチです。

解説を見る

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[マルチエージェントによる自動カウンセリングシステム](https://ai-data-base.com/archives/82682)

[マルチエージェントシステムで発生する同調バイアスを緩和する方法](https://ai-data-base.com/archives/82900)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)