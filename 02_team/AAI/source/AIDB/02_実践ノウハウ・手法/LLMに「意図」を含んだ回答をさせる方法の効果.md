---
title: "LLMに「意図」を含んだ回答をさせる方法の効果"
source: "https://ai-data-base.com/archives/87486"
author:
  - "[[AIDB Research]]"
published: 2025-04-04
created: 2025-06-13
description: "LLMに回答させる際に「意図」も含めて出力するよう促すことで、数学・質問応答・長文要約などさまざまな能力が大幅に向上することが示唆されました。さらに、思考プロセスの提示は、回答を見る人の解釈を助けることにもつながります。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

LLMに回答させる際に「意図」も含めて出力するよう促すことで、数学・質問応答・長文要約などさまざまな能力が大幅に向上することが示唆されました。

さらに、思考プロセスの提示は、回答を見る人の解釈を助けることにもつながります。

人間が難しい問題を任されたときに、過程も提示することからこの試みが発想されたようです。

最先端の推論モデルは思考プロセスを提示するような仕組みになっているものの、回答と整合性がとれない場合もあると報告されています。  
そんな中、出力に思考プロセスを明記させるのは有効なアプローチだと言えるかもしれません。

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_87486-1-1024x576.png)

**本記事の関連研究**

- [推論時のトークン数を80%以上削減しながら出力精度を保つプロンプト手法](https://ai-data-base.com/archives/86361)
- [LLMにおける「計画立案能力」を高めるプロンプト手法](https://ai-data-base.com/archives/82983)
- [三段論法でLLMの推論能力を高めるプロンプト手法](https://ai-data-base.com/archives/82746)

## 背景

LLMは問題が複雑になると、回答の精度や正確性が下がることがあります。

そこで、段階的な思考を行わせるChain-of-Thought（思考の連鎖）というプロンプト手法がよく使用されています。

しかし、最も効果を出すためにはユーザーが思考のステップをLLMに教示する必要があります。

そこで、Chain-of-Thoughtが自動的に発動するo1などの推論型モデルも好んで使われています。

推論型モデルにおいては思考のステップは自動探索されます。

ただし、そのプロセスがすべて明らかにされるわけではありません。

また、推論型モデルが示す考え方と実際の回答とがずれている場合もあり、ユーザーがその回答を十分に理解・納得できないことがあります。

このような問題は数学、文章読解、要約、常識的な判断など幅広いタスクに共通しています。

そこで「モデルがどのような意図で答えを導き出すのかを明らかにさせるように徹底すれば、回答の品質も、根拠の透明性も向上するだろう」と考えられました。

このような背景を受けて研究者らは、モデル自身が自らの「意図」を明確に文章で示して回答を導き出すことの効果を入念に検証しました。

以下で詳しく紹介します。

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_87486_1-1024x357.png)

LLMが自分自身の「意図」を言葉で明確に示し、それをもとに問題を解く方法の概要を示した図。 (a) 意図が推論を導く全体の流れ、(b) 実際に意図を示しながら問題を解いた例、(c) 数学問題や選択式質問での性能向上の具体例。

## 「LLMに考えさせる」とはどういうことか

LLMは自然な文章を生成し、さまざまな質問にも答えます。ただ、複雑な問題を解こうとすると、人間のように順序立てて考えることが苦手で、間違えることがあります。そこで、これまでさまざまな研究者たちがLLMに「どのように考えさせれば良いか」を試行錯誤しています。

### 「順序立てて考えさせる」ための工夫

一番よく知られている方法に「Chain-of-Thought（CoT）」があります。CoTはLLMに一気に答えを出させるのではなく、「まずこれを調べ、その結果を使って次にあれを考える」というように、段階を踏んで考えるよう指示を与える方法です。人間が問題を解くときの考え方をLLMに再現させることで、 [正解率](https://ai-data-base.com/archives/25930 "正解率") が高まることがわかっています。

しかし、ユーザーが毎回LLMに「順番に考えなさい」と指示を出すのは手間がかかります。そこで、最近では「Reasoningモデル」と呼ばれる推論能力が高められたLLMを使うことが増えています。これは、モデル自身が最初から順序立てて考える能力を持っているため、ユーザーがその都度指示を出す必要がありません。

### 「質問の意図」を読み取るという方法

もう一つの工夫として、「質問に込められた意図をしっかり読み取る」方法があります。「ARR（Analyzing, Retrieving, and Reasoning）」と呼ばれる手法は、LLMがまず質問の意図を分析し、それに関連する情報を探し出した上で、最終的な答えを出します。質問の「意図」を理解してから考えるため、CoTよりもさらに正確な答えを導けることが多くの研究で示されています。

本研究は、このARRのアイデアをさらに一歩進め、「質問の意図」だけでなく、LLM自身が自分の「意図」を文章で表現してから推論を進めるという新たな方法を提案しているものになっています。

### 自分の「意図」を表明する意味とは？

「意図」という概念は、実は身近なところでもよく使われています。たとえば、私たちが誰かに質問するとき、その質問には必ず「何を知りたいか」という意図があります。この意図を正しく理解することで、相手は適切な答えを返すことができます。

これまでの研究では、こうした意図をあらかじめ決めたカテゴリーに分類する方法が一般的でした。しかし、今回の研究では、LLMが自分の考えていることを「自由な文章」で表明するという、これまでにない柔軟なやり方を試しています。そうするとLLMが問題を解くときの思考過程がより自然になり、人間にとっても理解しやすくなる可能性があります。

## 「意図を言葉にする」方法

人間が何かの問題を解くときは、「まずこの情報を確認しよう」「次にこれを計算しよう」といったように、自分の中で順序立てて考えることが普通です。この「自分自身への語りかけ」に似たものを、LLMにも取り入れられるのではないかと考えられています。LLMが自分の考えていること、つまり「意図」をはっきりと文章で示すことで、回答の流れが明確になり、より正確な答えを導く助けになる可能性があります。

LLMが問題を解くとき、一般的には以下のような流れになっています。

たとえば、数学問題の場合は「問題文」が与えられ、その答えとなる数字などを導きます。選択式の質問ならば、質問と複数の選択肢が示され、正しいものを選びます。また、文章の要約の場合は、長い文章を短くまとめて出力します。

通常、ユーザーがLLMに与えるのは「この問題を解いてください」といったシンプルな指示です。

そうではなく、例えばLLMに対して、「回答を出す際に自分の考えていることをその都度明確に示してください」と指示を加えます。

するとLLMは、「まず○○を計算する」「次に△△について確認する」というように、自分の意図を文章化しながら回答を生成します。

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_87486_2-1024x235.png)

「意図を示さない方法（Baseline）」と「意図を示す方法（Speaking with Intent: SWI）」のプロンプトを比較した図。

## 「意図を示す」場合と「示さない」場合を比べる実験

こうした方法がどれくらい効果的なのかを確かめるため、「意図を示さない方法」と「意図を示す方法」の比較が行われました。

この二つを比べることで、「意図を示すこと」がLLMの回答の正確さや、回答の理解しやすさにどう影響するのかを確認できます。

方法の効果を検証するために、数学問題、選択式の質問、文章要約という推論を必要とする代表的なタスクが用いられました。

評価のポイントは主に次の3点です。

- 正しい回答がより多く出るようになるか
- 出された回答が、ユーザーにとって理解しやすく納得できるものになっているか
- 特に文章要約では、内容が正確で、元の文章の事実を誤解なく伝えているか

## 数学問題を使って「意図を示す方法」を検証した結果

LLMが自分の意図を示しながら推論すると、実際にどのような効果があるのでしょうか。その効果を具体的に確かめるため、まず数学問題を使って実験が行われました。

数学の問題は、論理的に段階を追って考える必要があり、LLMの推論力を評価するのに適しています。たとえば、複数の計算を正しい順序で実施しなければ答えが得られないような問題です。このような場合では、単純に記憶した情報を引き出すだけでは正解できず、モデルがどのように考え、どのような順序で計算しているかがとても重要です。

### 実験で使われたデータセット

今回の実験では、数学的な推論力を評価するためのベンチマークとして広く知られているデータセットが複数使われました。

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_87486_3-1024x215.png)

「意図を示さない方法（Baseline）」と「意図を示す方法（Speaking with Intent: SWI）」のプロンプトを比較した図。

各データセットには、多段階の計算や論理推論が求められる問題が多数含まれており、モデルが論理的に問題を解決できるかを詳細に評価できます。

### 実験での比較方法

評価の基準としては、モデルが正しい回答をどれくらい多く導き出せるかを中心に確認しました。また、各回答について、推論過程が適切であり、論理的に整合性が取れているかという点も評価対象になりました。

さらに、以前に提案されている他の推論方法（例えばChain-of-Thoughtなど）とも比較を行い、「意図を示す方法」が従来の方法と比べてどのような特徴を持っているかも検討しました。

### 実験の結果

実験の結果、「意図を示す方法」を用いた場合、数学問題の正解率が「意図を示さない方法」よりも明確に高くなりました。さらに、回答が論理的で整合性を保っており、推論の過程が理解しやすくなっていることも確認されました。

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_87486_4-1024x190.png)

数学問題で「意図を示す方法（SWI）」と「意図を示さない方法（Baseline）」の性能を比較した結果。

また、Chain-of-Thoughtなどの手法と比較しても、「意図を示す方法」の方が安定して高い精度を示すことが分かりました。このことから、モデルが自分の意図を明確にすることは、特に複雑な推論を必要とする問題において有効であると言えます。

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_87486_5-1024x212.png)

数学問題で、SWIを従来の手法（Chain-of-Thought（CoT）、ARR、Plan-and-Solve（PS）など）と比較した結果。 より難易度の高い問題においても、SWIが既存手法と同等かそれ以上の性能を示すことが示されている。

## 「意図を示す方法」は他のタスクでも有効なのか

数学問題で有効だった「意図を示す方法」が、他のタイプの課題にも同様に効果を発揮するのかを確かめました。ここでは、「多肢選択式の質問」と「文章の要約」という、数学とは異なる種類の課題を対象に検証しています。

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_87486_6-1024x385.png)

多肢選択式質問で使用されたデータセットの一覧表。

### 多肢選択式の質問における効果

多肢選択式の質問とは、質問に対して複数の選択肢が示され、その中から正しい回答を選ぶ形式の問題です。こうした問題では、単に知識を覚えているだけでなく、選択肢の内容を理解して適切なものを選ぶための論理的な推論が求められることがあります。

実験では、「意図を示しながら回答を選ぶ方法」と「意図を示さずに直接回答を選ぶ方法」を比較しました。その結果、モデルが自分の意図を明確にしながら回答を選ぶと、正解率が向上することが確認されました。これは、意図を言葉で明確にすることで、選択肢を選ぶ際の論理的な判断がしやすくなったためと考えられます。

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_87486_7-1024x176.png)

さまざまな選択式質問でSWIとBaselineの正解率を比較した結果。 幅広いタスクにおいて、SWIが正解率を大きく向上させたことが示されている。

### 文章要約における効果

文章要約は、元の長い文章から重要な情報を抽出し、短くまとめる作業です。要約する際には、元の文章の内容を正しく理解し、重要なポイントを論理的に取捨選択する必要があります。また、要約した内容が元の文章の内容とずれないように、事実関係の正確性も求められます。

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_87486_8-1024x336.png)

文章要約タスクで用いられたデータセット一覧表。

このタスクでも、「意図を示しながら要約を行う方法」と「意図を示さずに直接要約を行う方法」を比較しました。結果として、意図を示す方法で生成された要約のほうが、より正確で、元の文章との整合性が高くなることが明らかになりました。意図を明示することで、モデルがどの部分をなぜ重要だと判断したのかが明確になり、要約の質が向上したと考えられます。

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_87486_9-1024x197.png)

文章要約タスクにおけるSWIとBaselineのROUGEスコア（要約品質を測る指標）比較結果。 SWIによる要約が、より正確で質の高いものであることを示している。

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_87486_10-1024x237.png)

文章要約において、生成された内容の「事実の正確性（ファクトチェック）」を評価した結果。 事実と異なる誤情報を生成していないかを、Precision・Recall・ F1スコア で比較した表。

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_87486_11-1024x517.png)

文章要約の具体例を示した図。

以上から「意図を示す方法」は数学問題だけでなく、多肢選択式の質問や文章要約のような多様な課題に対しても汎用的に有効であることが示されました。

## LLMが示した「意図」の質を人間が評価すると

LLMが自分の考えていること（意図）を示すことで、問題への回答が理解しやすく、正確になることが確認されました。しかし、LLMが示した「意図」の質そのものはどうでしょうか客観的に確かめるために、人間による評価が行われました。

評価では、LLMが示した意図について次の3つの観点からチェックしました。

**整合性（Coherence）**

LLMが示した意図が論理的に一貫しているかどうか。

**有効性（Effectiveness）**

示された意図が実際に問題を解くために役立つ内容であるかどうか。

**理解しやすさ（Interpretability）**

LLMの示す意図が人間にとって理解しやすく、わかりやすいものであるかどうか。

評価の結果、LLMが示した意図は一般に高い整合性を持ち、問題を解決するために有効であると認められました。

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_87486_12-1024x317.png)

SWIによって生成された「意図の質」を人間が評価した結果をまとめた表。 意図が論理的か（整合性）、役に立つか（有効性）、理解しやすいか（可読性）という3つの視点で評価。

ただし、ときおりLLMが示す意図がやや冗長であったり、内容が一般的すぎて具体性に欠けるケースがありました。漠然とした説明ではなく、明確に説明するよう強調することが推奨されます。

## まとめ

本記事では、LLMが自分の意図を明示的に文章化しながら推論を進める新しい手法について紹介しました。このような手法を使うと、数学問題や多肢選択式の質問、文章の要約など、さまざまなタスクで回答の正確性や整合性が改善されることが分かりました。

また、モデルが自分の意図を示すことで、利用者にとっても回答の内容が理解しやすくなるというメリットがあります。従来の手法と比較しても、幅広い課題で安定した効果を示しました。

LLMを活用する際には、こうした意図を示す方法を取り入れることで、利用者が自分の目的や課題に合わせて、より安心して効果的にモデルを活用できる可能性があります。

**参照文献情報**

- タイトル：SWI: Speaking with Intent in Large Language Models
- URL： [https://doi.org/10.48550/arXiv.2503.21544](https://doi.org/10.48550/arXiv.2503.21544)
- コード： [https://github.com/YuweiYin/SWI](https://github.com/YuweiYin/SWI)
- 著者：Yuwei Yin, EunJeong Hwang, Giuseppe Carenini
- 所属：University of British Columbia, Vector Institute for AI

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[LLMに対するプロンプトインジェクションを防ぐ4つの工夫](https://ai-data-base.com/archives/87403)

[Metaの最新決算から読み解くAI事業戦略と求められる人材像](https://ai-data-base.com/archives/87816)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)