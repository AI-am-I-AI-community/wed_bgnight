---
title: "「HTMLをそのままLLMに入力してはどうか」という新しいアプローチ"
source: "https://ai-data-base.com/archives/78254"
author:
  - "[[AIDB Research]]"
published: 2024-11-11
created: 2025-06-13
description: "本記事では、LLMの精度向上のために用いられるRAG（検索拡張生成）システムにおける、HTML活用の可能性について紹介します。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、LLMの精度向上のために用いられるRAG（検索拡張生成）システムにおける、HTML活用の可能性について紹介します。

現在のRAGシステムでは、ウェブページから単純にテキストを抽出して利用していますが、この過程で見出しの階層構造や表組みのレイアウトといった重要な情報が失われています。そこで注目されているのが「HTMLをそのまま活用する」という新しいアプローチです。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78254-1024x576.jpg)

**参照論文情報**

- タイトル：HtmlRAG: HTML is Better Than Plain Text for Modeling Retrieved Knowledge in RAG Systems
- 著者：Jiejun Tan, Zhicheng Dou, Wen Wang, Mang Wang, Weipeng Chen, Ji-Rong Wen
- 所属：Renmin University of China, Baichuan Intelligent Technology

## 背景

LLMには、「一般的でない知識を忘れてしまう」「古い情報しか持っていない」「ときおり事実と異なる回答をしてしまう」などの課題があります。

そこでRAGが注目されています。RAGは、外部から必要な情報を検索して取り込むことで、LLMの回答精度を向上させる仕組みです。RAGシステムの中には、ウェブページの情報を活用するものもあります。例えば、ウェブ検索で関連ページを見つけ、HTMLで書かれたウェブページからテキストを抽出し、そのテキストをLLMに入力して回答を生成する、といった流れです。

しかしまだ問題があります。HTMLからテキストを抽出する際に、見出しの階層や表のレイアウト、リンク情報といった、重要な情報が失われてしまうのです。

そこで今回研究者らは、「HTMLをそのままLLMに入力してはどうか」という新しいアプローチを提案しています。  
HTMLをそのまま使うことには多くのメリットがあります。学習済みのLLMはすでにHTMLを理解する能力を持っているため、ウェブページの構造や意味的な情報を保持できます。  
なお、PDFなどの他の形式の文書をHTMLに変換することも可能です。

ただし、HTMLをそのまま使用する際には新たな課題も存在します。例えば、HTMLファイルは非常に長くなりがちであり、JavaScriptやCSSなど、回答生成に不要な情報も多く含まれています。このため、HTMLを効率的に処理する手法の開発が求められています。

以下、今回の取り組みの全体と開発されたアプローチをわかりやすく紹介します。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78254_1.png)

HTMLをプレーンテキストに変換する際の情報損失を示す図。構造情報や意味情報が失われる様子を表現している

## 『HtmlRAG』

本研究で提案された新しい手法は、HtmlRAGと名付けられました。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78254_2-1024x417.jpg)

パイプライン概要。HTMLのクリーニング、ブロックツリー構築、埋め込みベースの枝刈り、生成モデルによる細かい枝刈りの4ステップを示す

先ほど述べた通り、RAGシステムにおいて、単純なテキストの代わりにHTML形式を採用することで、より豊かな意味や構造を保持することを目指したものです。通常のウェブページやドキュメントは、簡単にHTML形式に変換できることから、幅広い活用が期待されます。

HTML形式をそのまま利用すると文脈が長くなりすぎてしまう課題に対しては、HTMLから不必要な部分を取り除く作業と、HTMLの中身を絞り込むことで対処します。

1. ユーザーが入力した質問に関係の深い部分を見つけ出すため、「埋め込みモデル」で重要度を判定し、関係の薄い部分が取り除かれる
2. LLMを使って、さらに細かく内容を見直し、本当に必要な部分だけが残される

例えるなら、大きな本から必要な章を選び、その章の中から特に重要な段落を選ぶような作業に似ています。

### HTMLの整理プロセス

まずは、元のHTMLから不要なコンテンツを取り除き、冗長な構造を圧縮する工程が行われます。ここでは意味的な特徴を考慮せずに [ルールベース](https://ai-data-base.com/archives/26614 "ルールベース") の処理が適用されます。

1. まず、人間には見えない余分なコンテンツ（CSSやJavaScriptなど）が削除されます。ただし、HTMLタグの多くは文書構造の理解に役立つため維持されます。
2. 次に、HTMLの構造が圧縮されます。例えば、単一の入れ子になった複数のタグは統合され、空のタグは除去されます。

### ブロックツリーの構築

HTMLは、もともと入れ子構造になっています。たとえば、「見出し」の中に「段落」があり、その中に「リンク」がある、というような構造です。この構造を図で表すと木のような形になるため「DOMツリー」と呼ばれています。

しかし、このDOMツリーはとても細かく分かれすぎているため、そのまま処理するのは効率が悪いのです。そこで、関連する部分をある程度まとめた「ブロックツリー」という新しい構造が作られます。

ブロックツリーの便利な点は、まとめる大きさを自由に変えられることです。例えば「200単語までなら一つのブロックにまとめてよい」というような上限（maxWords）を設定できます。DOMツリーの細かい要素（例：個々のリンクや文章）を、その上の大きな要素（例：段落や節）にくっつけていく作業が行われます。これにより、扱いやすい大きさの「ブロック」が作られていきます。

細かいパーツがたくさんある積み木（DOMツリー）を、いくつかのパーツをくっつけてより扱いやすい大きさの部品（ブロックツリー）にする、というようなイメージです。

### ブロックツリーによるHTMLの刈り込み

HTMLの刈り込み処理は、2段階のステップで実施されます。いずれもブロックツリー構造に基づいて行われ、最初の段階では埋め込みモデルが、次の段階では生成モデルが活用されます。

#### （１）埋め込みモデルによるブロックの刈り込み

最初の刈り込み処理は、シンプルながら効果的な方法です。まず、各ブロックの中身のテキストが取り出され、そのテキストがユーザーの質問とどれくらい関連があるかが、埋め込みモデルというツールで計算されます。

次に、関連性の低いものから順番に削除していく方法（これを「貪欲法」と呼びます）が使われます。例えるなら、スーツケースに荷物を詰める時に、「必要度が低いものから順に除外していく」というような考え方です。この除外作業は、HTMLの長さが決められた上限におさまるまで続けられます。

ブロックを削除した後は、HTMLの構造を整える作業が行われます。例えば、入れ子になった複数のタグを一つにまとめたり、中身が空になったタグを取り除いたりします。

以上の方法は、処理が軽く効果的です。

しかし二つの大きな問題点が見つかりました。

1. 埋め込みモデルは、一度に見られる範囲が限られています。大きな絵を小さな窓から覗くように、一部分しか見ることができません。そのため、文書全体の中での重要性を正確に判断できないことがあります。
2. とても小さなブロック（例：数単語程度）の場合、その内容の本当の意味を理解するのが難しくなります。文章の一部分だけを切り取って「これは何についての文章か？」と聞かれても、正確に答えるのが難しいのと似ています。

これらは深刻で、質問に答えるために文書全体の文脈を理解する必要がある場合に問題となります。そのため、次の段階でより賢い方法が必要となりました。

#### （２）LLMによる細かな刈り込み

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78254_3-1024x315.png)

ブロックツリーがトークンツリーに変換され、対応するHTMLタグとトークンが同じ色で示されている

先ほどの問題点を解決するため、2段階目の刈り込みでは、高性能なLLMが活用されます。まず、1段階目で大まかに刈り込まれたブロックを、さらに小さな単位に分割します。

LLMは、人間の文章を理解して文章を生成できる優れものです。埋め込みモデルと比べると、より広い範囲の文章を一度に理解でき、複数のブロックの関係性も把握できます。ただし整理済みのHTMLでも平均60,000文字もあり、これを丸ごとLLMに読ませると、処理に時間がかかりすぎてしまいます。

そこで、HTMLの中の位置を「住所」のように表現する「ブロックパス」という方式が考案されました。例えば、「本文の3番目の段落の2番目のリンク」というような位置情報をタグの連なりで表現します。LLMはこの「住所」を手がかりに、各ブロックがどれだけ重要かを判断します。そして1段階目と同じように、重要度の低いものから順に削除していきます。

このように、埋め込みモデルとLLMという2種類の異なる技術を組み合わせることで、HTMLの構造を保ったまま、効率よく重要な情報を選び出すことができるようになりました。まず大まかに選別してから（1段階目）、詳しく中身を確認する（2段階目）という、人間の文書整理に似た方法といえます。

下記はLLMへのプロンプト例です。質問に最も関連するテキスト部分をHTML文書から特定するタスクの指示が含まれています。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78254_4.png)

```js
Input:
**HTML**: "{HTML}"
**Question**: **{Question}**
Your task is to identify the most relevant text piece
to the given question in the HTML document. This text
piece could either be a direct paraphrase to the fact,
or a supporting evidence that can be used to infer the
fact. The overall length of the text piece should be
more than 20 words and less than 300 words. You should
provide the path to the text piece in the HTML document.
An example for the output is: <html1><body><div2><p>Some
key information...

Output:
<html1><body><div2><p>At the historic 2018 Royal Rumble,
Shinsuke Nakamura won the Men's Royal Rumble...
```

日本語訳↓

```js
入力:
**HTML**: "{HTML}"
**質問**: **{質問}**
あなたの課題は、HTML文書の中から与えられた質問に最も関連する
テキスト部分を特定することです。このテキスト部分は、事実を
直接言い換えたものか、その事実を推論するために使える裏付け
となる証拠のいずれかである必要があります。テキスト部分の
全体の長さは20語以上300語以下とします。HTML文書における
そのテキスト部分へのパスを提供してください。
出力例: <html1><body><div2><p>重要な情報...

出力:
<html1><body><div2><p>歴史的な2018年のロイヤルランブルで、
中邑真輔がメンズ・ロイヤルランブルを制し...
```

## 実験内容

HtmlRAGの性能を確認するため、6種類の質問応答データセットを用いた実験が実施されました。実際のウェブ検索エンジンの動作環境を再現するため、実在のウェブページが使用されました。

### 使用されたデータセット

以下の6つの異なる特徴を持つデータセットが選ばれました。

- ASQA
- HotpotQA
- NQ (Natural Questions)
- TriviaQA
- MuSiQue
- ELI5

ASQAは、複数の知識源から異なる答えが導き出せるような曖昧な質問を含むデータセットです。HotpotQAは、複数のステップを経て答えにたどり着く質問が収録されています。NQは、Googleの実際のユーザーから集められた質問で構成されています。Trivia-QAには、ユーザーから集められた一般的な質問が含まれています。MuSiQueは、人工的に作られた複数ステップの質問で構成されています。そしてELI5は、Reddit掲示板から集められた、長い回答を必要とする質問が収録されています。

各データセットから、テスト用もしくは検証用のデータの中から400個の質問がランダムに選ばれました。

### 実験用データの収集方法

一般的な研究では、Wikipediaの文章を検索対象として使うことが多いのですが、今回はHTML形式のデータが必要でした。そこで、Bingの検索APIを使用して、米国の英語圏で実際のウェブページが検索されました。検索結果として得られたURLから、静的なHTMLドキュメントが取得されました。これらのURLとHTMLドキュメントは、実験の再現性を確保するために保存されました。

### 評価方法

システムの性能は、「LLMの回答」を最終的な出力として評価されました。データセットごとに、その特徴に合わせて異なる評価指標が使用されました。

HotpotQAとMuSiQueのように一つの短い答えが正解となる場合は、完全一致（Exact Match）という指標が使われました。  
ASQA、NQ、Trivia-QAのように複数の正解がある場合は、完全一致とHit@1（少なくとも1つの正解が回答に含まれている割合）の両方が測定されました。  
ELI5のような長い回答が必要な場合は、ROUGE-LとBLEUという、文章の類似度を測る指標が使用されました。

### 使用されたモデル

最新のオープンソースLLMであるLlama-3.1-70B-InstructとLlama-3.1-8B-Instructが使用され、コンテキストウィンドウは4,000トークンに設定されました。

HtmlRAGの実装では、まず256単語を上限とする粗いブロックツリーが作られ、埋め込みモデルによる刈り込みが行われました。その後、128単語を上限とするより細かいブロックツリーが構築され、生成モデルによる刈り込みが実施されました。埋め込みモデルにはBGE-Large-ENが、生成モデルには3BパラメータのPhi-3.5-Mini-Instructが採用されました。

訓練データとしては、2,635個の自動生成されたサンプルが使用され、各サンプルの長さは2,000から32,000トークンの範囲で設定されました。

### 比較対象の手法

HtmlRAGは、HTMLを知識の形式として使う初めての試みです。そのため、他の方法との比較では、検索結果を処理する従来の手法が選ばれました。主に普通のテキストやMarkdown形式を扱う手法です。

大きく分けて2種類の比較対象が選ばれました。

#### （１）チャンキング（分割）ベースの手法

まず、LangChainで文書を小さく分割します。その後、3つの異なる方法で重要な部分を選び出します。

1. BM25：単語の出現頻度を使う伝統的な方法
2. BGE：BGE-Large-ENという、エンコーダー型の埋め込みモデルを使う方法
3. E5-Mistral：Mistral-7Bという大きなLLMを使って埋め込みを行う方法

#### （２）要約ベースの手法

文書を要約して重要な部分を抽出する2つの方法も比較対象となりました。

1. LongLLMLingua：Llama7Bという大きなLLMを使って、重要な文脈を選び出す方法
2. JinaAI Reader：1.5Bという比較的小さなLLMを使い、HTMLをMarkdownに変換するように訓練された方法

公平な比較のため、これらの手法はすべて同じような条件で試験されました。また、最終的な質問応答の部分では、すべての手法で同じLLMが使われました。

## 実験結果

主な実験結果が表にまとめられています。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78254_5-1024x495.png)

短いコンテキスト設定でのHtmlRAGとベースラインの比較結果

HtmlRAGは、全ての評価指標において、比較対象となった既存手法と同等かそれ以上の性能を示しました。また、以下のような興味深い発見がありました。

### テキストの分割方法に関する結果

まず、LangChainでは、文書を見出し（h1、h2など）で区切って処理されていますが、この方法でもHTMLの構造を少しは活用できているもののHtmlRAGほど上手く使えていません。さらに、最後にHTMLを普通の文章に変換する際に、見出しや段落などの文書の構造や、リンクの重要性といった意味合いが失われてしまう問題がありました。

また、検索結果の順位付けについては、3つの方法が比較されました。単純に単語の出現回数で判断するBM25という方法は、他の2つの検索方法よりも性能が低いことが分かりました。その二つの中では、BGEという方法がより複雑なe5-mistralよりも良い結果を出しました。

### 文書を要約する方法に関する結果

LongLLMLinguaという方法には弱点がありました。HTML文書を扱うための特別な工夫がされていないため、HTML文書から必要な情報を上手く取り出せませんでした。また、最後に普通の文章に変換してしまうため、文書の構造が分からなくなってしまう問題もありました。

JinaAI-readerという方法は、HTMLをMarkdownという別の形式に変換します。しかし、長い文書を扱う必要があるため、処理に時間と手間がかかってしまいます。また、文章を1単語ずつ生成していく必要があり、システム全体に大きな負担がかかることも問題でした。

これらに比べて、HtmlRAGは文書の構造を保ったまま、効率よく処理できることが確認されました。

### HTMLを整理する効果

まず、HTMLをそのまま使うことの良さを確かめるため、HTMLの整理方法が3つ比較されました。

1. HtmlRAGの整理方法（ただし刈り込みはしない）
2. BeautifulSoupという道具で単純なテキストに変換する方法
3. Markdownifyという道具でMarkdown形式に変換する方法

文字数を数えてみると、HtmlRAGの整理方法では元の94%以上を減らせることが分かりました。単純なテキストへの変換では約97%、Markdown変換では約90%が減りました。

整理後のHTMLはまだ長いため、128,000文字まで読める設定で試験が行われました。その結果、HtmlRAGは刈り込みを使わなくても、他の方法より良い結果を出せました。また、より賢いLLM（70B）は、HTMLの中身をより正確に理解できることも分かりました。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78254_6-1024x386.png)

刈り込みなしのHtmlRAGとベースラインの長いコンテキスト設定での比較結果

### それぞれの部品の重要性

HtmlRAGの3つの重要な部品について調べました。

1. ブロックツリーの作り方
2. 埋め込みモデルによる刈り込み
3. 生成モデルによる刈り込み

それぞれの部品を外してみると、以下のような問題が起きました。

- ブロックツリーを使わないと、文書の構造が細かすぎて処理が難しくなる
- 最初の刈り込みを省くと、文書が長すぎて処理に時間がかかりすぎる
- 2回目の刈り込みを省くと、文書の全体的な関係を見失ってしまった

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78254_7-1024x383.jpg)

HtmlRAGの各コンポーネントを除いた場合の性能比較

### ブロックの大きさの影響

ブロックの大きさを64単語から512単語まで変えて試してみました。すると、生成モデルは小さなブロックでもうまく処理できましたが、埋め込みモデルは少し大きめのブロックの方が良い結果を出せることが分かりました。これは、2段階で刈り込む方法が理にかなっていることを示しています。

### 処理の効率

計算機の負担についても調べられました。3Bという大きな生成モデルを使っているのに、処理時間はあまり増えませんでした。これは、45%以上の部分を飛ばして読めるためです。

文書の長さの変化を見ると、以下の通りでした。

- 最初のHTML：160万文字（20個の文書）
- 整理後：13.5万文字
- 1回目の刈り込み後：8,000文字
- 最後の刈り込み後：4,000文字

通常は、HTMLの処理にかかる時間はLLMの処理時間より少ないので、全ての手順を使うことが推奨されます。ただし、計算機のパワーが限られている場合は、1回目の刈り込みだけでも、従来の方法より良い結果が得られることが分かりました。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78254_8.png)

ELI5データセットにおける推論コストの分析。モデルパラメータ、ストレージ、入出力トークン数を比較

## まとめ

本記事では、RAGシステムにおいてHTMLをそのまま活用する新しいアプローチ「HtmlRAG」の研究を紹介しました。

実験結果から、HTMLを適切に処理して活用することで、従来のプレーンテキストベースの手法を上回る性能が確認されました。RAGシステムにおける情報表現の新たな可能性を示すとともに、HTMLを効果的に処理するための基本的な解決策を提供している方法論と言えます。

研究チームは、今後LLMの性能がさらに向上するにつれて、HTMLはRAGシステムの外部知識フォーマットとしてより適したものになると予測しています。また、本研究で提案された手法は、HTMLを活用したRAGシステムの研究における一つの出発点にすぎないと位置づけられており、より効率的なHTML処理手法の開発が期待されています。

- 参照論文URL： [https://arxiv.org/abs/2411.02959](https://arxiv.org/abs/2411.02959)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[LLMの機能別「領域」はまるで脳のようであるとの仮説](https://ai-data-base.com/archives/78200)

[上司役のLLMが部下LLMたちに的確に仕事を振り分ける『Magentic-One』マイクロソフトが開発](https://ai-data-base.com/archives/77850)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)