---
title: "マルチエージェントシステムで発生する同調バイアスを緩和する方法"
source: "https://ai-data-base.com/archives/82900"
author:
  - "[[AIDB Research]]"
published: 2025-01-28
created: 2025-06-13
description: "本記事では、LLMのマルチエージェントシステムにおいて発生する「同調」についての研究を紹介します。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、LLMのマルチエージェントシステムにおいて発生する「同調」についての研究を紹介します。

LLMを活用したマルチエージェントシステムは社会的な課題解決への応用が期待されていますが、人間社会で見られる同調性バイアスに類似した問題が発生する可能性が指摘されています。

そこで研究チームは新たに評価ベンチマークを作成し、マルチエージェントシステムにおける同調性の検証と、その緩和策の探求に取り組みました。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82900-1024x576.png)

**発表者情報**

- 研究者：Zhiyuan Weng et al.
- 研究機関：Zhejiang University

論文情報詳細は記事の下部に記載されています。

**本記事の関連研究**

- [LLMエージェントは同調圧力に弱く考えに固執する傾向があるため、ディベートでバイアスを和らげるのが重要との報告。導入ツールも公開](https://ai-data-base.com/archives/56599)
- [OpenAIが提唱する「AIエージェントの管理法」](https://ai-data-base.com/archives/81428)
- [「シリコンの群衆」LLM集団（12体）は人間にどれほど近づくか](https://ai-data-base.com/archives/65208)

## 背景

複雑な問題を解決できるLLMベースのマルチエージェントシステムが実現されつつあります。例えばプラットフォームの管理や保守などにおいての活用が期待されています。

一方で、人間の集団で見られる同調性バイアスやグループシンクのような現象が、マルチエージェントシステムでも発生する可能性が懸念されています。そういった懸念が現実のものであれば、重要な課題において、エージェントの判断の信頼性が損なわれる可能性があります。

これまでマルチエージェントシステムの性能向上に関する研究は数多く行われてきましたが、単一のエージェントでは起こらない問題が発生するのか、という根本的な疑問は未解明のままです。

そのような背景のもと、研究者らはLLMマルチエージェントシステムにおける同調性の存在、影響要因、緩和戦略について包括的な調査研究に取り組みました。また、その中で推論集約型のベンチマークを新たに構築し、異なる相互作用プロトコルのもとでLLMの振る舞いを検証しました。

以下で詳しく紹介します。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82900_1.png)

同調のイメージ

## データセットについて

前述したように、研究者らは今回新たに同調性の影響を評価するためのベンチマークデータセットを作成しました。

ベンチマークの名称はBENCHFORMと言います。

### 構築方法

タスクの難しさと同調傾向には正の相関があるという社会学の知見に基づき、BIG-Bench Hardデータセットから複雑な推論を必要とする問題が選択されました。

問題は2つのカテゴリに分類されます。

1つ目は論理的・分析的推論で、明確な正解が導き出せる問題です。

2つ目は言語・文脈理解で、正解がやや主観的な問題です。

このように性質の異なる問題を用意することで、エージェントが自身の推論を信頼するか、集団の判断に従うかの傾向が評価できます。

### 評価プロトコル

評価には5種類のプロトコルが用意されました。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82900_2-1024x593.png)

上記５つのプロトコルを図示

最も基本的なのは「Raw」と呼ばれるプロトコルで、1つの質問者と1つの回答者による単純な質疑応答です。

また、短期的な相互作用の影響を測るために、「Correct Guidance」と「Wrong Guidance」というプロトコルが設計されました。これらは追加の6つのエージェントが正解または不正解を提示した後に、対象エージェントが回答するという形式です。

さらに長期的な相互作用の影響を測るために、「Trust」と「Doubt」というプロトコルが設計されました。これらは複数回の質疑応答を通じて、信頼関係や懐疑関係を形成した後に、最終ラウンドで追加エージェントが正解または不正解を提示するという形式です。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82900_3-1024x593.png)

「Trust」と「Doubt」プロトコルの詳細を図示

つまり、エージェントが他のエージェントの回答に引っ張られるか否かをいくつかのアプローチで試したという形です。

### 実装の詳細

実験では、シンプルな質問-回答の形式が採用されました。

「Correct Guidance」と「Wrong Guidance」のプロトコルでは6つの追加エージェントが導入され、「Trust」と「Doubt」のプロトコルでは履歴データを含む拡張された質問-回答形式が採用されました。

なお、実験設定は、人間を対象とした古典的な同調性実験であるAsch実験を参考に設計されています。

参考： [Wikipedia](https://ja.wikipedia.org/wiki/%E3%82%A2%E3%83%83%E3%82%B7%E3%83%A5%E3%81%AE%E5%90%8C%E8%AA%BF%E5%AE%9F%E9%A8%93)

## 同調性評価実験の概要

### 対象となったLLM

実験では11個のLLMが評価されました。GPT-3.5やGPT-4oといった商用モデルと、Llama3、Llama3.1、Gemma2、Qwen2シリーズなどのオープンソースモデルが含まれています。

一覧

- GPT-3.5
- GPT-4o
- Llama3
- Llama3.1
- Gemma2
- Gemma2-9B
- Gemma2-27B
- Qwen2-7B
- Qwen2-72B
- Llama3-70B

### 評価指標

評価には以下3つの指標が用いられました。

- AccP
- CRP
- IR

AccPは平均 [正解率](https://ai-data-base.com/archives/25930 "正解率") 、CRPは同調率、IRは独立性率を表します。

なお、同調率は、最初は正解だった回答が他のエージェントの影響で不正解になった割合を示します。独立性率は、長期的な相互作用（TrustプロトコルとDoubtプロトコル）でも正解を維持できた割合を示します。

### 主な発見

#### 発見1：同調性の存在

全てのLLMで同調傾向が確認されました。

例えばGemma2-27Bでは、Doubtプロトコルで38.6%の精度低下が観察されました。最新のLLMであるGPT-4oやLlama3.1-405Bでも、Trustプロトコルで22.6%、Doubtプロトコルで30.2%の精度低下が見られました。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82900_4.png)

モデルが特定のプロトコルでどれだけ影響を受けたかを示す表

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82900_5.png)

モデルが誤った情報にどれだけ影響されて正答を変えてしまうかを示す表

#### 発見2：モデルサイズと独立性の関係

モデルのパラメータ数が大きくなるほど、独立性率が向上する傾向が確認されました。

独立性率とは、この研究で導入された評価指標の一つで、LLMが他のエージェントの意見や影響に流されず、独立した判断を下せる能力を測る指標です。

例えばQwen2シリーズでは、7Bから72Bに規模が拡大すると、独立性率が19.6%から57.6%に向上しました。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82900_6.png)

サイズによる独立性率の変化

#### 発見3：個々のモデルの特徴

モデルごとに異なる特徴が観察されました。例えばQwen2-7Bは、正解を提示された場合の同調率が98.7%と高い一方で、不正解への同調率は27.5%と低くなっています。対照的にQwen2-72Bは、3つのプロトコルでの同調率が約30%と安定しており、より独立した思考傾向を示しています。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82900_table3.png)

モデルの振る舞い（同調率）をプロトコルごとに細分化して評価した結果の表

以下では、さらに特定の側面から分析結果を示します。

## 同調性に影響を与える要因

### （１）相互作用の時間

相互作用時間が長くなるほど、同調性が強まることが確認されました。

例えばLlama3-70Bでは、議論ラウンド数が1回から5回に増えると、Trust（信頼）プロトコルでの同調率が33.9%から44.4%に上昇し、Doubt（懐疑）プロトコルでの同調率も62.3%から69.9%に上昇しました。一方で独立性率は35.1%から28.6%に低下しています。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82900_7-1024x267.png)

### （２）集団の圧力

多数派の規模が同調性に与える影響も調査されました。

実験では7つのエージェント（1つの対象エージェントと6つの追加エージェント）が用いられ、デフォルトでは多数派の規模は6に設定されています。

結果として、多数派の規模の増加は相互作用時間の延長よりも強く同調性に影響を与えることが分かりました。例えばLlama3-70Bでは、多数派の規模が6から3に減少すると、Doubtプロトコルでの同調率が69.9%から32.6%まで大幅に低下しました。

### 行動分析結果

514件のサンプルを対象に、対象エージェントが自身の同調性をどのように説明するかも調査されました。

Llama3-70BとQwen2-72Bで異なる傾向が観察されています。Llama3-70Bは同調性を認める傾向が強く（50.8%のケース）、Qwen2-72Bは同調性を否定し、元の回答を維持する傾向が強いことが分かりました（222件中222件）。

また、深刻な思い込みや、正解を知りながら多数派の意見に従うなどの興味深い行動も観察されました。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82900_8.png)

モデル（Llama3-70B と Qwen2-72B）が他エージェントからの影響をどのように認識し、行動するかを分類した結果 。 A&C: 同調を認め、回答を変更したケース。 A&S: 同調を認めるが、回答を維持したケース。 D&C: 同調を否定し、回答を変更したケース。 D&S: 同調を否定し、回答を維持したケース。

## 同調性の緩和方法

上記の通り、同調性に影響を与える要因が明らかになりました。では、同調性を緩和するための方策としてどのような手法が考えられるでしょうか。

### 方策１：ペルソナ設定の強化

実験結果からLLMの独立性の低さが確認されたため、独立した思考を促すペルソナ設定が提案されました。

システムプロンプトを「独立的で批判的な思考者」として設定することで、同調率の低下と独立性率の向上が確認されました。

例えばGPT-4oでは、CRT（信頼による同調率）が37.9%から23.8%に低下し、CRD（懐疑による同調率）も26.6%から15.8%に低下しました。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82900_9.png)

### 方策２：再検討メカニズムの導入

回答前に再考や見直しを促すユーザープロンプトも効果を示しました。

Llama3-70Bでは、CRTが44.4%から22.8%に、CRDが69.9%から35.2%に低下し、独立性率は28.6%から68.5%に向上しました。ただし、Qwen2-72Bでは再検討後に多数派の意見に同調する傾向も見られました。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82900_10.png)

## 考察

提案された2つの手法は同調性の緩和に一定の効果を示しましたが、LLMの特性によって効果は異なることも分かりました。

では、本研究から得られた知見は、より広い文脈でどのように解釈できるのでしょうか。

### 同調性の二面性

マルチエージェントシステムにおける同調性には、肯定的な側面と否定的な側面がありそうです。

ポジティブな面では、複数の関係者間での合意形成や一貫した結果の導出に役立ちます。

一方でネガティブな面では、投票や政策提言といった重要な社会的判断において、エージェントの判断の信頼性が損なわれる可能性があります。

### コンテキスト注意機構への示唆

相互作用時間が同調性に与える影響から、現在のコンテキスト注意機構の限界が示唆されている可能性があります。

LLMの応答が過去の文脈に大きく影響されるため、現在の情報と過去の情報のバランスをとる機能に改善の余地があります。

### 将来の研究課題

研究チームは、MMLU-Proデータセットなどを含むBENCHFORMの拡張や、より現実的な協調環境を模倣する相互作用プロトコルの開発を今後の課題として挙げています。また、初期応答と相互作用後の説明の一貫性を促進することで、LLMの独立した意思決定を導く可能性も示唆されています。

## まとめ

本記事では、LLMのマルチエージェントシステムにおける同調性に関する研究を紹介しました。

研究チームは同調性の存在、影響要因、緩和戦略について、新たに構築したベンチマークBENCHFORMを用いて包括的な調査を行いました。実験結果から、マルチエージェントシステムにおける同調性の存在が確認され、またモデルサイズの拡大やペルソナ設定の工夫により同調性を緩和できる可能性が示唆されました。

同調性を検証する有効な手段を提供しましたが、全ての条件下での同調性の存在を確定的に示すものではありません。また、多肢選択問題という形式は、LLMが一般的に適用される状況を十分に反映していない可能性も指摘されています。

**参照文献情報**

- タイトル：Do as We Do, Not as You Think: the Conformity of Large Language Models
- URL： [https://www.arxiv.org/abs/2501.13381](https://www.arxiv.org/abs/2501.13381)
- 著者：Zhiyuan Weng, Guikun Chen, Wenguan Wang
- 所属：Zhejiang University

## 理解度クイズ（β版）

1\. BENCHFORMの評価プロトコルで「Trust」と「Doubt」が設計された目的は何ですか？

これらのプロトコルは複数回の質疑応答を通じて信頼/懐疑関係を形成し、長期的な相互作用が判断に与える影響を測定する。正解は b)。

解説を見る

2\. 研究結果から判明したモデルサイズと独立性の関係はどのようなものでしたか？

Qwen2シリーズの実験で、7Bから72Bへの規模拡大により独立性率が19.6%から57.6%に向上。正解は c)。

解説を見る

3\. 同調性を緩和するために提案された手法は何ですか？

研究では独立的で批判的な思考者としてのペルソナ設定と、回答前の再検討メカニズムが提案された。正解は d)。

解説を見る

4\. マルチエージェントシステムにおける同調性の二面性とは何ですか？

同調性は関係者間の合意形成に有用である一方、重要な社会的判断における信頼性を損なう可能性がある。正解は b)。

解説を見る

5\. 実験結果から、同調性に最も強い影響を与えた要因は何でしたか？

多数派の規模の変化が相互作用時間の延長よりも強く同調性に影響を与えることが判明。Llama3-70Bの実験でこれが実証された。正解は c)。

解説を見る

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[三段論法でLLMの推論能力を高める　プロンプト手法の新提案](https://ai-data-base.com/archives/82746)

[LLMにおける「計画立案能力」を高めるプロンプト手法の新提案](https://ai-data-base.com/archives/82983)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)