---
title: "人間を討論で言い負かすディベート上手なLLMの実装方法"
source: "https://ai-data-base.com/archives/74886"
author:
  - "[[AIDB Research]]"
published: 2024-08-28
created: 2025-06-13
description: "本記事では、LLMを活用してディベートに強い自動応答システムを開発した研究を紹介します。研究者らは、LLMに対して4つの役割を定め、人間を模倣する仕組みを作りました。また、自動評価システムと人間の審判を用いて性能を評価しました。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、LLMを活用してディベートに強い自動応答システムを開発した研究を紹介します。

研究者らは、LLMに対して4つの役割を定め、人間を模倣する仕組みを作りました。また、自動評価システムと人間の審判を用いて性能を評価しました。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74886-1024x576.jpg)

**参照論文情報**

- タイトル：Can LLMs Beat Humans in Debating? A Dynamic Multi-agent Framework for Competitive Debate
- 著者：Yiqun Zhang, Xiaocui Yang, Shi Feng, Daling Wang, Yifei Zhang, Kaisong Song
- 所属：Northeastern University, Alibaba Group

## 背景

学校や法廷、政治の場など、さまざまな場面で必要になるのが討論する能力です。論理的に考える力、自分の意見をうまく伝える力、相手の意見を素早く分析する力など、多くの能力が必要となります。

LLM登場以前も、コンピューターで人間の議論を再現しようという研究はありましたが、限られた範囲の課題にしか対応できていませんでした。現在、LLMによって再現のクオリティーが一気に向上するという期待が出ています。

しかし、LLMを討論に使うにあたって2つの問題があります。1つは、時々事実ではない情報を作り出してしまうこと。もう1つは、長時間の激しいやりとりを続けることが難しいことです。

そこで研究チームは、Agent for Debate（Agent4Debate）というシステムを開発しました。人間のように、情報を探す役、分析する役、文章を書く役、内容を確認する役の4つの役割を持つLLMが協力して働く仕組みになっています。

さらに、この仕組みの性能を正確に測るため、Competitive Debate Arenaという評価システムも作られました。人間とLLMの討論能力を比べるものです。

以下で取り組みの内容を詳しく紹介します。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74886_1-1024x380.jpg)

## タスクの定義

ディベートは、決まった形式で行われる複数回のやりとりで行われます。各回の発言は、一つのまとまった文章を作り出す作業だと考えることができます。当然ながら回を重ねるごとに内容が進んでいきます。

### 討論の基本構造

討論では通常、賛成側と反対側の2つの立場があります。討論の流れは、誰がどの立場で何を言ったかの記録として表すことができます。各発言の内容は、討論のテーマ、話者の立場、そしてそれまでの討論の経過を踏まえて作られます。

### 流れとルール

一般的なディベートは、次の3つの段階で進められます。

1. 最初の主張（立論）
2. 相手の主張への反論
3. まとめの発言（総括）

公平さを保ち、実際の討論に近づけるため、各段階にはいくつかのルールがあります。

まず立論段階では、両側が別々に準備をします。反対側は賛成側の主張を見ることができないので、お互いの最初の意見に影響されません。

反論と総括の段階では、それまでの全ての発言内容を見ることができます。そのため、相手の主張に的確に応えることができます。

発言の順番は、有利不利が偏らないよう工夫されます。反論では賛成側が先に話し、総括では反対側が先に話します。

## Agent for Debateフレームワーク

LLMがディベートできるようにするためにAgent for Debate（Agent4Debate）というシステムが開発されました。人間が討論の準備をする過程を真似て作られており、4つの異なる役割を持つLLMが協力して働きます。各役割は、人間の討論チームの主要な役割を反映しています。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74886_2-1024x498.jpg)

Agent4Debateのワークフロー図。4つの主要な役割（Searcher, Analyzer, Writer, Reviewer）の相互作用と反復的な作業プロセスを示す

### エージェントの役割

1. Searcher（検索者）は、情報を集める役割です。助手のような働きをします。
2. Analyzer（分析者）は、戦略を立てたり、議論を分析したりする役割です。コーチのような働きをします。
3. Writer（執筆者）は、実際に議論を組み立てて表現する役割です。討論者のような働きをします。
4. Reviewer（レビュアー）は、内容をチェックして改善点を提案する役割です。討論コーチのような働きをします。

各LLMエージェントは、討論の進行に合わせて柔軟に協力し合います。討論の段階や状況に応じて、それぞれの役割や貢献の仕方を変えていきます。すべて人間の討論チームの動きを模倣しています。

### Agent4Debateの特徴

Agent4Debateの中での協力は、単純に順番に仕事をこなすだけではありません。討論の段階や状況に応じて、4つの役割が互いに情報をやり取りしながら柔軟に働きます。それぞれの役割には、討論の各段階に合わせて特別に用意された指示（プロンプト）があります。

### 各エージェントの詳細

#### Searcherエージェント

Searcherは、事実と異なる情報生成の問題や情報の新しさの問題に対処するためのツールとして働きます。主な特徴は以下の通りです。

- 外部の知識データベースから情報を集め、整理します。
- 検索したい内容をより詳細な検索キーワードに分けます。
- 検索エンジンや専門的な知識データベースを使って関連情報を探します。
- 見つけた情報をわかりやすくまとめます。

Searcherがまとめた情報は、討論のテーマに関する固定の知識ベースとなり、全てのエージェントが参照できるようになります。

**プロンプト**

```js
You are a searcher. Your role is to gather information to support the debate process. Act as an assistant by finding relevant data, facts, and references that can be used to strengthen the arguments. Your goal is to provide accurate and useful information to other agents.
```

**日本語訳**

```js
あなたは検索者です。あなたの役割は、ディベートプロセスを支援するために情報を集めることです。関連するデータ、事実、および参考資料を見つけて、議論を強化するために使用してください。正確で役立つ情報を他のエージェントに提供することがあなたの目標です。
```

#### Analyzerエージェント

Analyzerは、討論中のリアルタイムの情報を統合し、次の発言内容のための構造化された指針を提供する中心的なエージェントです。主な機能は以下の通りです。

- 与えられたテーマ、現在の討論段階、これまでの討論の流れに基づいて、討論内容を体系的に分析し、計画を立てます。
- 討論内容を段階的に分解します。
- 詳細な概要を作成します。
- 他のエージェントに的確な戦略アドバイスを提供します。

各討論段階でAnalyzerは異なる役割を果たします。

1. 立論段階では、テーマを要約し、定義、判断基準、主要な議論、および裏付け証拠を自身の視点から作り出します。
2. 反論段階では、両側の意見の違いを分析し、反論の方法を提案します。
3. 総括段階では、引き続き意見の相違点をまとめ、反論方法を提供するとともに、価値観に基づく提案も行います。

**プロンプト**

```js
You are an analyzer. Your task is to develop strategies and analyze the arguments in the debate. Act like a coach, helping to interpret information and providing insights on how to approach the debate effectively. Your goal is to create a coherent and logical line of reasoning.
```

**日本語訳**

```js
あなたは分析者です。あなたの任務は、戦略を立て、ディベートにおける議論を分析することです。コーチのように働き、情報を解釈し、ディベートを効果的に進めるための洞察を提供してください。一貫性があり論理的な議論のラインを構築することがあなたの目標です。
```

#### Writerエージェント

Writerは、分析と計画を実際の討論内容に変換する実行役です。主な機能は以下の通りです。

- Analyzerが提供した指示と概要に基づいて完全な討論原稿を作成します。
- Reviewerからの意見に基づいて原稿を修正し、討論の質と説得力を高めます。
- 現在の知識ベースの情報が、概要と原稿の修正要件を満たしているかを確認します。
- 必要に応じて、Searcherに追加の資料を積極的に要求します。

**プロンプト**

```js
You are a writer. Your role is to construct and articulate the arguments in the debate. Use the information provided by the searcher and the insights from the analyzer to form persuasive and well-structured arguments. Your goal is to clearly express the debate's position.
```

**日本語訳**

```js
あなたは執筆者です。あなたの役割は、ディベートの議論を構築し、表現することです。検索者が提供した情報と分析者の洞察を使用して、説得力があり、構造化された議論を形成してください。ディベートの立場を明確に表現することがあなたの目標です。
```

#### Reviewerエージェント

Reviewerは、Writerが作成した討論原稿をチェックする品質管理役です。主な機能は以下の通りです。

- 現在の討論段階とこれまでの流れに基づいて、的確な修正提案を行います。
- 討論内容の質、論理性、説得力を確保します。

討論の各段階で、Reviewerは異なる側面に注目します。全ての討論段階を通じて、以前に述べた情報との一貫性を常にチェックし、議論の整合性を保ちます。

1. 立論段階では議論構造の完全性、内容の包括性、裏付け証拠の十分さ、表現の分かりやすさをチェックします。
2. 反論段階では反論方法が適切に使われているか、自分の立場と矛盾していないかを確認します。
3. 総括段階では討論内容の深さを評価し、全体の流れを踏まえて判断を下します。

**プロンプト**

```js
You are a reviewer. Your responsibility is to review the content and suggest improvements. Analyze the written arguments for consistency, logical flow, and evidence strength. Act like a debate coach by providing feedback to enhance the overall quality. Your goal is to ensure that the debate arguments are compelling and credible.
```

**日本語訳**

```js
あなたはレビュアーです。あなたの責任は、内容をレビューし、改善点を提案することです。書かれた議論を一貫性、論理の流れ、証拠の強さについて分析してください。ディベートコーチのように働き、全体的な質を向上させるためのフィードバックを提供してください。説得力があり信頼できるディベートの議論を確保することがあなたの目標です。
```

## 実験設定

この研究では、ベースライン（基本となるシステム）、さまざまなLLMを使ったAgent4Debate、そして人間の参加者が実験に必要でした。

### 実験対象

#### ベースライン

AI-Debater 2024という大会で使われた基本的なシステムを使いました。Tavilyという検索エンジンと、討論の段階ごとに特別な指示を使っています。基礎となるモデルには、Claude-3.5-sonnetとDeepseek-Chatを使いました。

#### Agent4Debate

Agent4Debateがさまざまな状況でどれくらい上手く働くかを調べるため、いくつかの先端LLMを基礎モデルとして選びました。例えば、Claude-3.5-sonnet、GPT-4o、Gemini-1.5-Pro/Flashなどです。他のさまざまな評価でも良い結果を出しているモデルたちです。

また、この研究では（中国語での討論に焦点を当てているため、）中国語を特に上手く扱えるLLMも使いました。例えば、Qwen2-72b-Instruct、Deepseek-Chat、GLM-4-Airです。

なお全ての実験において、Searcherエージェントの検索エンジンにはTavilyが使用されました。また全てのモデルで、文章の多様性を調整する設定（温度とTop P）は同じにしました。

#### 人間参加者

Agent4Debateの性能を人間と比べるために、10人の経験豊富な討論者に参加してもらいました。参加者は全員、2〜4年間の討論チームでの訓練経験と、少なくとも1年間の中国語でのディベートの経験があります。

参加者には、LLMと討論することを伝え、各テーマについて2日間の準備時間を与えました。

また情報を正確に伝え合い、人間の討論者が十分に考えて答える時間も確保するように、次の工夫も行われました。

- 人間の発言を文字に変えるために、Whisperというモデルを使いました。
- 人間の討論者は、LLMの出力を直接読むことができます。

### 評価指標

#### Debatrix

Debatrixは、LLMを使って討論を評価する新しい方法です。以下のような特徴があります。

- 討論の流れに沿って、「論証（妥当な論拠を挙げて推論しているか）」「情報源」「言葉遣い」という3つの観点から評価します。
- 各観点の評価は、普通の言葉で説明されます。
- 評価を組み合わせて総合評価を行い、最終的に勝者を決めます。

実際の使用では、各観点の評価結果を「勝ち」「負け」「引き分け」のいずれかに変換します。この方法は、複数回のやりとりがある長文の競争的討論を評価するのに特に適しています。  
実験では、DebatrixのベースとなるモデルにGPT-4o-miniを使いました。評価の信頼性を高めるため、各討論について3回の独立した評価を行い、それらの結果から最終的な点数を出しました。

#### 人間評価

3人の経験豊富なディベートの審判にも参加してもらいました。各審判には以下のような特徴があります。

- 3〜5年間のディベートの経験がある
- 大学の討論チームを指導した経験がある

審判は各討論を独立して評価し、「勝ち」「負け」「引き分け」のいずれかに投票します。最終結果は多数決で決められます。

公平性を保つため、審判には「両サイドが同じだけ自分の主張を証明する責任がある」ということだけを伝え、それ以外の情報は与えませんでした。

なお全ての審判はこの研究の開発過程に関わっておらず、コンピューター科学の専門知識も持っていません（偏った判断が入る可能性が最小限）。

## 実験結果

### Agent4Debate vs. ベースライン

Agent4Debateと基本のシステム（ベースライン）の性能を比べる実験を行いました。各システムは、5つの異なる討論テーマについて20回の討論に参加しました。公平を期すため、各システムが賛成側と反対側を主張する回数を同じにしました。評価には前述したDebatrixを使いました。

Debatrixでは、各討論を3回ずつ評価し、「論証」「言葉遣い」「情報源」「全体的な性能」の4つの観点で点数をつけました。それぞれの観点で勝てば1点、引き分けなら0.5点が与えられます。

実験の結果、Agent4Debateは両方のモデルでディベートの性能を向上させました。

- Claude-3.5-sonnetを使った場合、全体的な点数が0.38から2.62に上がりました。
- Deepseek-Chatを使った場合、全体的な点数が0.23から2.77に上がりました。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74886_3.png)

Agent4DebateとBaselineの比較表。異なるモデルでのAgent4Debateの性能向上を示す

なお、特に「情報源」の観点で大きな改善が見られました。Agent4Debateの情報を探すエージェントと分析するエージェントが、討論テーマを深く分析し、材料を体系的に整理して、外部の知識をより効果的に活用したと評価できます。

「言葉遣い」の改善は比較的小さかったですが、これは言語モデルがもともと文章を生成する能力が高く、さらに改善する余地が少なかったためだと解釈できます。

Claude-3.5-sonnetとDeepseek-Chatの結果を比べると、Agent4Debateはより性能の高いモデルでより大きな改善を示していることが分かります。特に「論証」と「全体的な性能」でこの傾向が顕著でした。より高性能なモデルの方が、推論能力が高く、指示に従う能力も優れているため、複雑なシステムにより上手く対応できることを示唆しています。

### 削減実験

Agent4Debateの中で、それぞれのエージェントがどれくらい役立っているかを調べるため、特定のエージェントを取り除いた状態で性能を測る一連の「削減実験」を行いました。実験の設定は前の比較実験と同じで、5つの討論テーマについて20回の討論を行い、賛成側と反対側を主張する回数を同じにしました。評価方法もDebatrixを使って、前と同じやり方で点数をつけました。

文章を作る役割のWriterエージェントは、全ての段階で必要なので削減実験は行いませんでした。この実験では、基本となるモデルとしてClaude-3.5-sonnetを使いました。

実験の結果、Agent4Debateの中の各エージェントはすべて全体の性能向上に貢献していることが明らかになりました。どのエージェントを取り除いても全体的な点数が下がり、それぞれが必要であることが確認されました。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74886_4.png)

削除実験の結果表。各エージェントの重要性を示す

例えば、Analyzerエージェントを取り除くと、全体的な点数が2.12から1.76に下がりました。特に「情報源」と「論証」の点数が大きく下がり、「情報源」が2.79から1.83に、「論証」が2.01から1.79になりました。分析者が材料の分析、議論の改善、反論の戦略を立てる上で重要な役割を果たしていることを示しています。

Searcherエージェントを取り除くと、「情報源」の点数が2.79から0.21へと大きく下がり、全体的な点数も2.12から0.88に下がりました。外部の知識を適切に探して整理することが、討論の性能を上げるのに重要だということを強調しています。

最後にReviewerエージェントを取り除くことの影響は比較的小さく、全体的な点数は2.12から1.93に下がっただけでした。原稿を確認し、修正を提案し、Agent4Debateの出力の質を高めるというレビュアーの主な役割が、システムの設計意図通りに機能していることを示しています。

### アリーナの結果

今回の実験では、200回の討論記録が集められました。66の討論テーマを扱い、「事実」「価値観」「政策」という3つの分野をカバーしています。参加者には、さまざまな基礎モデルを使ったAgent4Debate、2つの基本システム、そして10人の人間の討論者が含まれ、全てがランダムに組み合わせて競争しました。

各討論は、Debatrixという自動評価システムと人間の審判によって別々に評価されました。特別な計算方法を使って、全200試合の総合点と3つの討論分野ごとの点数を計算しました。結果は、Debatrix-EloとHuman-Eloという2つの独立したランキングシステムで示されました。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74886_5.png)

Debatrix-Eloランキング表。異なるモデルとヒトの競争的ディベート能力を比較

これらの結果から、以下のことがわかりました。

Gemini-1.5-ProやClaude-3.5-sonnetなどの高性能な基礎モデルを使ったAgent4Debateは、Debatrix-EloとHuman-Eloの両方のランキングで、人間の討論者と同等かそれ以上の成績を示しました。最も優秀だったAgent4Debate（Gemini-1.5-Pro使用）は常に1位で、Debatrix-Eloランキングで1044.18点、Human-Eloランキングで1040.64点を獲得しました。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74886_6.png)

Human-Eloランキング表。異なるモデルとヒトの競争的ディベート能力を人間の判断に基づいて比較

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74886_7.png)

人間とAgent4Debateの比較表。DebatrixとHuman評価による両者の性能比較

Debatrix-Eloランキングでは、多くのモデルが事実、政策、価値観の分野ごとに点数の変動を示しました。一方、Human-Eloランキングでは各モデルの点数が分野間でより一貫していました。この違いは、Debatrixが「情報源」「言葉遣い」「論証」という3つの観点で評価しているのに対し、人間の審判は主に論理と反論の技術に注目している可能性があるためと考えられます。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74886_8.png)

DebatrixとHuman評価の一貫性分析表。評価方法間の一致度を示す

Debatrix-Eloランキングでは、特定のモデルが特定の分野で優れた成績を示しました。これは3つの討論テーマの種類による議論の進め方の違いが原因と考えられます。

政策討論では通常、政策の必要性と効果を示すための幅広い証拠が必要です。一方で価値観の討論では、より深い論理的思考と表現力が求められます。そして事実についての討論は、両方の特徴を持ち合わせています。

以上の違いがDebatrixの多面的な評価に反映され、さまざまな結果をもたらしたと考えられます。

## まとめ

本記事では、LLMを用いたディベートフレームワーク「Agent for Debate (Agent4Debate)」の研究を紹介しました。

4つの専門エージェントを活用し、LLMの討論能力向上を目指したこの研究では、Agent4Debateが人間と同等の能力を示し、各エージェントの有効性が確認されました。

研究背景で述べられているように、学校や法廷、政治の場など、さまざまな場面で必要になる討論能力がLLMで再現できるというのは大きな成果です。

- 参照論文URL： [https://arxiv.org/abs/2408.04472](https://arxiv.org/abs/2408.04472)
- コード： [https://github.com/ZhangYiqun018/agent-for-debate](https://github.com/ZhangYiqun018/agent-for-debate)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[プロンプトの影響によるLLMの性能のばらつきを考慮した評価指標「Sharpeスコア」　NAIST研究者ら考案](https://ai-data-base.com/archives/74842)

[RAGで検索文書の要約を活用したクエリ書き換えが検索精度を大幅に向上させる　AWS報告](https://ai-data-base.com/archives/74922)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)