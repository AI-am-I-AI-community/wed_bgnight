---
title: "LLMの「自己対話」により複雑な問題の解決能力を飛躍的に向上させる手法『Iteration of Thought』"
source: "https://ai-data-base.com/archives/76134"
author:
  - "[[AIDB Research]]"
published: 2024-09-25
created: 2025-06-13
description: "本記事では、LLMの推論能力を向上させるためのフレームワーク「Iteration of Thought（IoT）」を紹介します。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、LLMの推論能力を向上させるためのフレームワーク「Iteration of Thought（IoT）」を紹介します。このフレームワークの特徴は、反復的な思考を自動的に行うことで、複雑なタスクにおいてより柔軟な推論が期待されている点です。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_76134-1024x576.jpg)

**参照論文情報**

- タイトル：Iteration of Thought: Leveraging Inner Dialogue for Autonomous Large Language Model Reasoning
- 著者：Santosh Kumar Radha, Yasamin Nouri Jelyani, Ara Ghukasyan, Oktay Goktas
- 研究機関：Agnostiq Inc., University of Toronto

**本記事の関連研究**

- [CoT（思考の連鎖）は数学や論理で劇的に性能を向上させる一方、常識や知識のタスクでほとんど効果がない](https://ai-data-base.com/archives/75942)
- [LLMの推論能力を戦略的に向上させる新しいプロンプト手法『SCoT』](https://ai-data-base.com/archives/75505)
- [LLMにハイレベルな問題の解決アプローチを自分で考えさせるエージェント化手法「SelfGoal」](https://ai-data-base.com/archives/71720)
- [LLMが思考のネットワークを構築し、人間の推論プロセスを模倣する『THOUGHTSCULPT』プロンプティング](https://ai-data-base.com/archives/67755)
- [LLMにタスクに応じた推論プロセスを自ら考えるようにするプロンプト手法『SELF-DISCOVER』Google DeepMindなどが開発](https://ai-data-base.com/archives/64136)
- [CoTの推論ステップ数がLLMの推論能力に及ぼす影響を詳細に検証した結果](https://ai-data-base.com/archives/62364)
- [プロンプトの原則26ヶ条をまとめた報告](https://ai-data-base.com/archives/61417)

## 背景

人間とLLMのやり取りを繰り返すことで、LLMの応答の質が向上する傾向があると言われています。単純なプロンプトではエラーを引き起こす可能性がありますが、より洗練されたプロンプトを用いると、精度と信頼性が大幅に向上することが最近の研究で示されています。適切な文脈を与えることで、LLMが内部知識をより効果的に活用できることを示唆する事実です。

人間によるLLMとのやり取りは通常、以下のような流れで進みます。

1. ユーザーがLLMに質問をする
2. 初期の応答を受け取る
3. 回答が不完全または最適でない場合、ユーザーがLLMに追加の文脈を提供する

最初は簡単な答えしか返ってこないかもしれませんが、さらに質問を重ねることで、より深い理解が得られるというプロセスです。

しかし既存の手法、例えばChain of Thought（CoT）やTree of Thoughts（ToT）などは、進化する文脈に適応することが難しく、LLMの応答品質が改善される度合いには限界があります。

そこで研究者たちは、人間とLLMのやり取りにおけるダイナミックな性質を再現する「Iteration of Thought （IoT）」フレームワークを提案するに至りました。人間のフィードバックなしで自律的、反復的、適応的なアプローチをLLMの推論に導入することを目的としています。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_76134_1-1024x447.jpg)

LLMの推論能力を向上させるための異なるプロンプト戦略（IO、CoT、ToT、IoT）を比較している図。今回の提案手法はIoT。

## フレームワークと実装

### Iteration of Thought（IoT）の基本

IoTは、3つの主要な要素から構成されています。

**内部対話エージェント  
**ユーザーの質問とLLMの前回の回答に基づいて、文脈に応じたプロンプトを生成する

**LLMエージェント  
**プロンプトを処理し、回答を洗練させる

**反復プロンプティングループ  
**内部対話エージェントとLLMエージェントの間で会話が繰り返され、回答が徐々に改善されていく

この反復プロセスを通してLLMの内部知識がより効果的に活用され、正確で洗練された回答が生成されると考えられています。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_76134_2-1024x472.jpg)

IoTフレームワークを使用して簡単な質問を処理する過程を示す図。GIoT変種を使用し、反復回数を2回に設定した例

ただしIoTは基本的な概念であり、実際に使われるのはIoTの変種です。

### IoTの変種

IoTフレームワークは、「自律的思考の反復（Autonomous Iteration of Thought, AIoT）」と「誘導された思考の反復（Guided Iteration of Thought, GIoT）」という2つの主要な変種が考案されました。

#### 自律的思考の反復（AIoT）

こちらの変種は、LLMが自ら回答の十分さを判断する仕組みが目指されています。

各ステップで「回答が完全かどうか」がLLMによって評価され、評価結果が「iteration\_stop」という信号で示されます。「iteration\_stop」がTrueであると、LLMが回答を最終的なものと判断したことを意味します。

AIoTのプロセスは以下のとおりです。

1. 最初の回答生成
2. 回答の十分さの評価
3. 必要に応じた新しいプロンプトの生成と回答の再作成
4. 2〜3を十分な回答が得られるか最大反復回数に達するまで繰り返す

このステップを通してLLMの内部知識がより深く探索され、回答が段階的に改善されると考えられています。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_76134_3-1024x457.png)

#### 誘導された思考の反復（GIoT）

もう一方の変種であるGIoTは、より構造化された反復プロセスです。あらかじめ定められた回数（N-1回）の反復が強制的に行われ、N回目の反復でのみLLMに最終回答の決定が許可されます。

GIoTのプロセスは以下のとおりです。

1. 最初の回答生成
2. N-1回の反復を通じて回答が洗練される
3. 最後の反復で蓄積された情報に基づいて最終的な回答が作られる

LLMがより徹底的に内部知識を探索し、回答を洗練させる仕組みです。ただし、AIoTと比べると計算コストが高くなる可能性があります。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_76134_4-1024x346.png)

### 実装

なおIoTフレームワークは、Pythonライブラリとして実装されました。Pydanticが使用され、LLMからの生の応答に対して出力スキーマが提供されます。

## 結果

各種フレームワークの評価実験が行われました。

### GPQAによるIoTの評価

GPQAとは、高度な推論能力を必要とする質問で構成されているデータセットです。問題は、単純な検索では答えられず、深い理解と複雑な推論を必要とします。最も難しいレベルを意味する「Diamond」が使用されました。

実験では、OpenAIの独自モデルであるGPT-4o miniが使用され、Chain of Thought、Input-Output (IO)、AIoT、GIoTの手法が比較されました。

Input-Output（IO）とは最も基本的なアプローチで、質問（入力）に対して直接答え（出力）を生成する方法です。中間的な推論ステップを明示せず、単純に質問から回答へと直接つなげます。今回のベースラインとして使われました。

結果として、AIoTが最も高い精度（46.3%）を達成し、IOベースラインと比較して14.11%の改善が見られました。GIoTもIOと比較して2.62%の精度向上を示しましたが、CoTはIOとほぼ同等の性能にとどまりました。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_76134_5-1024x303.png)

AIoTが優位性を見せたのは、動的で自律的な反復停止メカニズムによるためだと考えられます。約60%のタスクが1回の反復で、約90%が2回の反復で完了されるなど、効率的に推論空間が探索されました。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_76134_6-1024x659.png)

GPQA評価における異なる手法（IO、CoT、GIoT、AIoT）の精度を比較したグラフ

一方、GIoTは強制的な反復により、一部のケースでは過剰な探索や幻覚（ハルシネーション）のリスクが高まる可能性が示唆されました。

### 探索的問題解決タスクにおけるIoTの評価

Game of 24とMini Crosswordsタスクを用いてIoTの性能が評価されました。

Game of 24タスクは、4つの数字と基本的な算術演算（+、-、×、÷）を使って、結果が24になる式を作る数学パズルです。

またMini Crosswordsタスクは、5×5のグリッドに単語を埋めていく小型のクロスワードパズルです。語彙力と文脈理解が求められます。

GPT-4o miniが使用され、CoT、IO、AIoT、GIoTの手法が比較されました。また、Tree of Thoughts（ToT）の結果とも比較が行われました。

ToTとは、複数の思考経路を同時に探索する推論手法です。問題解決の過程を木構造として表現し、各 [ノード](https://ai-data-base.com/archives/26470 "ノード") で複数の可能性を検討します。「次の問題について考え、可能な解決策をいくつか列挙してください。」「各アプローチの長所と短所を考慮し、次のステップでどのように進むべきかを判断してください。」「最も適切な次の行動を選択し、その理由を説明してください。」…といったプロンプトの連続的な実行により進めることができます。

Mini Crosswordsタスクでは、GIoTがCoTと比較して文字で35.5%、単語で90.6%の成功率向上を示しました。AIoTも文字で28.3%、単語で74.5%の向上が見られました。Game of 24タスクでは、GIoTがCoTと比較して266.4%の改善を示し、AIoTも168.4%の改善が確認されました。

IoTはToTほどの性能向上は示しませんでしたが、計算コストを抑えつつ効果的な探索が実現されました。GIoTはAIoTよりも探索的なアプローチを取り、複雑なタスクで優位性が示されました。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_76134_7-1024x414.jpg)

Mini Crossword: Letters、Mini Crossword: Words、Game of 24タスクにおける異なる手法（GIoT、AIoT、CoT、IO）のパフォーマンス比較を示す

将来的には、外部検証ツールや追加のフィードバックメカニズムの導入により、IoTの性能がさらに向上する可能性があります。

### 多文脈推論と検索タスクにおけるIoTの評価

HotpotQA-Hardデータセットを用いてIoTの性能が評価されました。HotpotQA-Hardデータセットは、複数の文書からの情報統合が必要なマルチホップ質問応答（QA）タスクのために設計されたベンチマークです。

GPT-4o miniが使用され、CoTおよびマルチエージェントフレームワークであるAgentLiteとの比較が行われました。

AgentLiteは、複数のエージェントが協力してタスクを遂行する「階層的なマルチエージェント」フレームワークです。主な役割を持つ「マネージャーエージェント」が各サブエージェント（チームエージェント）を調整します。

評価指標としては、Exact Match（EM）、 [F1スコア](https://ai-data-base.com/archives/26112 "F1スコア（F値）") 、ROUGE-Lスコアが用いられました。

EMは、モデルが生成した応答が正解と完全に一致する割合を測定します。またROUGE-Lスコアは、モデルが生成した応答と正解の間の最長共通部分列（Longest Common Subsequence）を評価する指標です。F1スコアについては一般的に使用されるものですが、精度（Precision）と [再現率](https://ai-data-base.com/archives/26095 "再現率") （Recall）のバランスを取った指標です。

結果として、AIoTは全ての評価指標でCoTを上回る性能を示しました。さらに、AgentLiteと比較してF1スコアで約35%、EMスコアで約44%の改善が確認されました。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_76134_9-1024x129.png)

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_76134_8-1024x380.jpg)

HotPotQA-Hardデータセットにおける AIoTとCoTのパフォーマンス比較を示すグラフ

AIoTの動的な推論パスの適応能力が、複雑な多段階QAタスクで効果を発揮した結果だと考えられます。IoTフレームワークは、静的なエージェントベースのアプローチよりも優れた性能を示すことが明らかになりました。

## IoTの強みと弱み

### IoTの強み4つ

#### 1\. 概念的透明性と説明可能性

IoTの大きなメリットとして、その推論プロセスが明確に追跡可能であることが挙げられます。CoTなどの手法と同様に、IoTも推論過程が段階的に示されます。しかし、IoTでは内部対話エージェントが生成する指示が各ステップの根拠を提供する点が特徴的です。

LLMは内部対話エージェントからの指示を人間ユーザーからのプロンプトと同等に扱います。このため、出力シーケンスを分析することで、モデルの自己修正能力や一般的なLLMとの効率的な対話方法についての洞察が得られる可能性があります。

#### 2\. 他のフレームワークとの組み合わせ可能性

IoTは他の推論フレームワークと組み合わせることができます。例えばCoTとのハイブリッド手法が作成可能です。さらに、エージェントに異なるモデルを使用することで、システムの知識ベースを拡大することができます。

#### 3\. 自律的な推論能力

IoTは人間の介入なしに独立して機能できるため、迅速かつ継続的な意思決定が必要な場面や、人間の監督が難しい状況で特に有用です。

#### 4\. モデル訓練への応用可能性

IoTが生成する思考シーケンスは、既存のモデルの微調整に活用できる可能性があります。

### IoTの弱み（変種別）

#### 1\. AIoTの課題

AIoTでは、回答の完全性が誤って判断され、プロセスが早期に終了してしまう可能性があります。

ただしこの問題に対しては、フィードバックエージェントの導入やMaieuticプロンプティング技術の活用が考えられます。

Maieuticプロンプティングとは、対話型の推論プロセスを通じて、モデルが複雑な問題や推論課題に対して論理的かつ一貫した解答を生成することを促す技法です。「問題を読み、最初に考えられる解決策や仮説を述べてください。その根拠も説明してください。」「今の答えの論理的な根拠を検証してください。どこに矛盾や不確実性がありますか？その点を詳しく説明してください。」…といった流れで進めます。

#### 2\. GIoTの課題

GIoTでは固定反復回数が使用されるため、複雑なタスクでは性能が向上する一方で、幻覚のリスクが高まる可能性があります。幻覚を減らすための適切な技術の導入が必要とされます。

### 将来の展望

内部対話エージェントの拡張として、専門化されたサブエージェントから構成される、より大規模なアンサンブルへの発展が考えられます。研究結果によると、10-15のエージェントで性能向上が飽和するとされています。

参考： [小さなLLMを多数組み合わせることで、単一の巨大モデルに匹敵する可能性](https://ai-data-base.com/archives/64708)

さらに知識ベースの拡大として、特定のドメインに特化したLLMや、追加のツールやデータソースを備えたLLMの使用により、さらなる性能向上が期待されます。

なお、課題への対応としては、GIoTの幻覚リスクを軽減する技術の導入や、AIoTの早期終了問題に対処するための半自律的なフレームワークの導入、外部知識チェックの実装などが検討されています。

## まとめ

本記事では、LLMの推論能力を向上させるための新しいフレームワーク『Iteration of Thought』に関する研究を紹介しました。内部対話エージェントを用いて反復的に推論を行い、複雑なタスクでより高い性能を発揮する手法です。

研究チームは、IoTの2つの変種（AIoTとGIoT）を提案し、多様なデータセットで評価を行いました。結果として、IoTは従来手法を上回る性能を示し、中でもマルチホップ推論を必要とするHotpotQAタスクで顕著な改善が見られました。

IoTの利点として推論プロセスの透明性が挙げられる一方、早期収束やハルシネーションのリスクなど課題も指摘されています。今後は、専門化されたLLMの使用や問題への対策を通じて、さらなる発展が期待されます。

- 参照論文URL： [https://arxiv.org/abs/2409.12618](https://arxiv.org/abs/2409.12618)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[CoT（思考の連鎖）は数学や論理で劇的に性能を向上させる一方、常識や知識のタスクでほとんど効果がない](https://ai-data-base.com/archives/75942)

[OpenAIの新しいモデルo1-preview、従来のLLMと比べて「計画能力」で圧倒的な性能向上](https://ai-data-base.com/archives/76177)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)