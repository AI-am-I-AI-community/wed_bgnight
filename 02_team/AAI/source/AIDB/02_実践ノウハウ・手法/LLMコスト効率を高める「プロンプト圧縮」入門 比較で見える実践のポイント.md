---
title: "LLMコスト効率を高める「プロンプト圧縮」入門 比較で見える実践のポイント"
source: "https://ai-data-base.com/archives/91507"
author:
  - "[[AIDB Research]]"
published: 2025-06-27
created: 2025-06-28
description: "本記事では、プロンプト圧縮の手法を比較した研究を紹介します。プロンプトの長さを抑えながら出力の質やコスト効率をどう維持できるかは、LLMを業務で使ううえで無視できないテーマです。"
tags:
  - "clippings"
---
Loading \[MathJax\]/extensions/tex2jax.js

[![](https://ai-data-base.com/wp-content/uploads/2025/06/aidbmeetuptokyo-scaled.jpg)  
オフラインイベント『AIDB Meetup Tokyo』（2025/7/25（金））参加受付開始しました！](https://connpass.com/event/358069/)  
  
\---以下、記事本文---

本記事では、プロンプト圧縮の手法を比較した研究を紹介します。

プロンプトの長さを抑えながら出力の質やコスト効率をどう維持できるかは、LLMを業務で使ううえで無視できないテーマです。今回の検証では、実用的なタスクを通じて、手法ごとの得意な場面や傾向が整理されています。

導入時の選択肢やプロンプト設計の工夫を考えるうえで、手がかりになる内容です。

![](https://ai-data-base.com/wp-content/uploads/2025/06/AIDB_91507-1024x576.png)

## 背景

LLMを使うとき、ちょっとしたプロンプトの工夫で、その使い勝手が大きく変わることがあります。たとえば、思考の流れを誘導したり、参考情報をそっと添えたりするだけで、かなり賢く振る舞ってくれます。こうした設計の自由さは、実務の現場でもありがたいところです。

とはいえ、プロンプトが長くなるほど、処理のコストは跳ね上がっていきます。商用サービスを通じて使っている場合は、APIの料金も気になってきます。たくさん使えば便利になる一方で、お財布にはそれなりの負担がかかるという現実があります。

そこで関心が高まってくるのが「プロンプト圧縮」です。なるべく短く、でも大事な情報はちゃんと残す。そんなバランスをうまく取れれば、性能を落とさずにコストを抑えられるかもしれません。これまでにも要約や質問応答といったタスクで、圧縮プロンプトの性能が評価されてきました。

ただ、まだ分かっていない部分もあります。たとえば、圧縮によってモデルの汎化能力や幻覚的な誤答がどう変わるのかは、きちんと調べられていません。画像とテキストを組み合わせたマルチモーダルな使い方にも、あまり適用されていないのが現状です。そもそもプロンプトを作るときに、どの情報を削っても大丈夫なのか、という素朴な疑問にも明確な答えは出ていません。

今回の記事は、こうした疑問に正面から向き合った試みを紹介します。いろいろなタスクを使いながら、プロンプト圧縮がモデルの出力にどんな影響を与えるのかを整理します。プロンプトに関心がある方にとってはヒントが見つかる内容になっています。

## 長いプロンプトをどう扱うか

プロンプト圧縮の話に入る前に、そもそもLLMは長い文章をどんなふうに処理しているのかを簡単に見ておきます。こうした前提を踏まえておくと、圧縮という発想の意義や現実的な選択肢としての魅力もつかみやすくなります。

### なぜ長文がつらいのか、LLMの事情

LLMは、長い文章を読み込むときに、計算量がどんどん増えていく性質があります。処理対象が長くなるほど、必要な計算リソースも急増していきます。実際にAPIなどで使っていると、「少しだけ長めのプロンプト」のつもりでも予想外に重くなることがあります。

この課題に対して、これまでさまざまな工夫が試されてきました。モデルの処理上限を伸ばす試み、無駄の多い計算を効率化する工夫、トランスフォーマーとは別の仕組みを模索する動き、モデル自体の軽量化、さらにはハードウェアと相性のよい設計への最適化まで、多岐にわたる努力が行われてきました。

そんな中、比較的手軽で、実務でもすぐに応用しやすい方法のひとつが「プロンプト圧縮」です。モデルの構造や処理方式をいじる必要がなく、テキストとして入力する部分を工夫するだけで効果が出せます。実際にAPIを使う場面でも導入しやすく、コストの節約にもつながります。

### どう短くするのか

プロンプト圧縮では、「どれだけ短くできたか」を測る指標として「圧縮率」という数値が使われます。たとえば、元の長さが100、圧縮後が50であれば圧縮率は0.5（要するに2分の1）になります。単純な式ではありますが、圧縮の効果を定量的に捉えるうえで役立ちます。

これまで、大きく2つの方向で圧縮のやり方が試されてきました。ひとつは、 [強化学習](https://ai-data-base.com/archives/26125 "強化学習") を使って「分かりやすく」「簡潔に」といった目標を達成する方法。もうひとつは、冗長な部分や重要性の低い情報をLLMでうまく見つけて削っていく方法です。

なお、モデルの内部構造やキャッシュにアクセスして最適化するアプローチもありますが、こうした方法は商用APIのようなクローズドな環境では使いづらく、現場での応用は限られます。汎用的に使いたいなら、テキストそのものを工夫する方向が現実的です。プロンプトキャッシュの機能を搭載する作り込まれたプロダクトも登場しつつありますが、ユーザーにとってはそのプロダクトを選ぶという手段に限定されてしまいます。

![](https://ai-data-base.com/wp-content/uploads/2025/06/AIDB_91507_1.png)

プロンプト圧縮の流れのイメージ

## 圧縮にもいろいろある

実際にどんなやり方で圧縮を試みることができるのでしょうか。異なるタイプの6つの手法を取り上げ、それぞれの特徴や動きを比較します。手法ごとに得意な分野や工夫の方向性が異なるのが興味深いところです。

### 圧縮手法のざっくり分類

6つの手法は、大きく分けて3つの系統に分類されます。

まずひとつ目は「強化学習タイプ」。モデルが何度も試行錯誤を繰り返しながら、圧縮の精度や読みやすさを高めていく方法です。あらかじめ正解を用意しなくても、自律的に改善していけるのが特徴です。

次に「LLMのスコアを活用するタイプ」。こちらは、LLMに各単語の「情報の濃さ」を評価させて、スコアの低いところから順に削っていきます。一度で処理が済むため、動作も軽めです。

最後は「LLMに圧縮の例を作らせて（ [アノテーション](https://ai-data-base.com/archives/26297 "アノテーション") させて）学習するタイプ」。まず大きなLLMにたくさんの圧縮例を出してもらい、それをもとに小さなモデルを育てていく流れです。手間はかかりますが、狙った方向に精度を出しやすくなります。

![](https://ai-data-base.com/wp-content/uploads/2025/06/AIDB_91507_2-1024x302.png)

3つの系統それぞれのイメージ

### 6つの手法それぞれの特徴を見てみる

各手法は、どれも異なる視点からプロンプトの「中身の削り方」を考えています。

#### KiS（強化学習タイプ）

読みやすく簡潔にまとめ直すことを目指す手法です。流暢さや内容の保持、簡潔さのバランスを見ながら、いくつかの候補を出して最適なものを選びます。文章全体を書き換えるスタイルなので、それなりに時間がかかりますが、自然な仕上がりになります。

#### SCRL（強化学習タイプ）

文章の各単語に「必要かどうか」のラベルを付けていく方式です。ベースとなるモデルに強化学習で調整を加え、圧縮の質と文章の自然さの両立を目指します。構造はシンプルですが、実用的な精度が出るのが強みです。

#### Selective Context（LLMスコア活用タイプ）

各単語の情報量を計算し、低いものから削っていきます。モデルが「この単語はどれくらい予測しやすいか」を見て、そのスコアをもとに取捨選択する仕組みです。やや理屈っぽいですが、やっていることは直感的です。

#### LLMLingua（LLMアノテーションタイプ）

ざっくり削ってから細かく調整するという二段構えの圧縮スタイルです。無駄を大まかに取り除いたうえで、単語単位での微調整を加えます。出力の整合性を保ちながら圧縮率を高めるための“予算管理”も導入されています。

#### LongLLMLingua（LLMアノテーションタイプ）

LLMLinguaを長文向けに発展させた手法です。質問内容に応じて圧縮の仕方を変えたり、文の順序を入れ替えたりする工夫で、内容の偏りを防ぎます。動的な圧縮率の調整機能も備わっていて、長文でも意味が崩れにくくなっています。

#### LLMLingua-2（LLMアノテーションタイプ）

より幅広いタスクや環境で使えるように汎用性と効率を重視して設計されています。GPT-4から大量の圧縮例を学習し、前後の文脈を両方から読み取れる構造を採用。従来の一方向処理では見逃されがちだった関係性にも対応しています。

次のセクションでは、これらの手法がどのようなタスクで試され、どんなふうに性能を比べられたのかを見ていきます。どの手法が自分のユースケースに合いそうか、想像しながら読み進めてもらえると面白いかもしれません。

## 手法同士を比べる

6つの圧縮手法の特徴を見ただけでは実用のヒントにはなりません。どの手法がどんな場面で力を発揮するのかを知るには、しっかりとした比較が必要です。

### 目的の違う3つのタスクで検証

今回、「要約」「復元」「質問応答」を通じて、それぞれの手法の強みや弱点が引き出すための実験が行われました。

**「要約」**

元のプロンプトと圧縮後のプロンプトから生成される要約を比較し、その内容の近さを測ります。ニュース記事（Gigaword）、学術文書の要約（DUC2004）、イギリスの文書 [コーパス](https://ai-data-base.com/archives/26324 "コーパス") （BNC）、放送原稿（Broadcast）、Google関連の情報などが使用されました。

**「復元」**

圧縮されたプロンプトから元の文章をどこまで再構成できるかを見ています。対象となったのは、数学問題（GSM8K）、BBCニュース記事、論文（Arxiv）、人とAIの対話記録（ShareGPT）など、ジャンルの異なるデータです。

**「質問応答」**

圧縮されたプロンプトを使って質問に答えた際の正確さを評価します。論理力を問う問題集（BBH）、数学の基礎問題（GSM8K）、長文理解を試すベンチマーク（Lon [gB](https://ai-data-base.com/archives/26343 "勾配ブースティング") ench）などが用いられました。  
なお、画像を含むマルチモーダルなケースにも対応しており、視覚情報とテキストの組み合わせによる質問応答（VQA）も検証対象に含まれています。図表ベースの問題（IconQA）や、外部知識が求められる課題（OK-VQA）が使われました。

### 評価に使われた指標

どの手法がどれだけ優れているかを見極めるため、目的に応じた適切な指標も必要とされました。

要約や復元では、出力と正解の類似度を測るBLEU、ROUGE、BERTScoreの3つが使われました。異なる観点から文章の一致度を評価するものです。

質問応答では、答えが明確に決まっている問題には [正解率](https://ai-data-base.com/archives/25930 "正解率") を、やや曖昧なオープンエンドの問いには [F1スコア](https://ai-data-base.com/archives/26112 "F1スコア（F値）") が使われました。

さらに、LLM特有の現象であるハルシネーション（事実でない内容を生成してしまうこと）にも着目し、Micro Hallucination Rate（MiHR）とMacro Hallucination Rate（MaHR）の2つの指標で検出精度が測られました。

### 実験の進め方と比較の仕方

KiSとSCRLは、圧縮率（どれくらいの割合の文章量に削るか）を自動で調整する仕組みがあるため設定をそのままに。それ以外の手法は、圧縮率を0.5、つまりプロンプトの長さをちょうど半分にそろえて比較されました。

また、比較対象として、単語をランダムに選んで削除するベースラインも用意されました。「意味を考えた上での圧縮」がどれほど効果的かを測るためです。

使われたモデルは、GPT-3.5-turbo、GPT-4o-mini、Claude-3-Haikuの3種類でした。異なるモデルを並べて検証することで、圧縮手法そのものの汎用性や、モデルとの相性の傾向も浮かび上がってきます。

## 実験結果から見えてきたこと

6つの圧縮手法を比べた結果を見ていきます。それぞれの手法がどんな場面で強みを発揮するのか、また実用を考えるうえで気になる傾向はあるのか。実験を通じて明らかになったポイントを整理してみます。

### 手法ごとに得意な領域が違う

まず、どの手法が最も優れていたのかが気になるところです。

結論から言うと、すべてのタスクで一貫して強い手法があるわけではなく、内容によって得意不得意が分かれるという結果になりました。

![](https://ai-data-base.com/wp-content/uploads/2025/06/AIDB_91507_3-1024x244.png)

各手法のパフォーマンス全体

要約や復元のように、情報を要点にまとめる系のタスクでは、LLMLingua、LongLLMLingua、LLMLingua-2が安定した性能を見せています。ただし復元タスクに限ってはSelective Contextがやや抜けた性能を発揮しています。

また数学問題（GSM8K）ではLLMLingua系の手法が強く、ニュース系（GigawordやDUC2004）ではLLMLingua-2がやや優位でした。一方で、人間らしい文脈や口調が含まれるデータ（BBC NewsやShareGPT）ではSelective Contextの方が良い結果を出しています。

要約タスク（右５列）と復元タスク（左４列）それぞれのデータセットにおける指標スコア（平均値）を以下の表に示します（BLEUスコア（高いほど良い）です）。

| 手法 | GSM8K | BBC News | ShareGPT | ArXiv | Gigaword | DUC2004 | BNC | Broadcast | Google |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| ランダム選択 | 0.40 | 0.23 | 0.19 | 0.07 | 0.25 | 0.21 | 0.21 | 0.10 | 0.23 |
| KiS | 0.58 | 0.16 | 0.11 | 0.05 | 0.20 | 0.23 | 0.55 | 0.49 | 0.36 |
| SCRL | 0.38 | 0.14 | 0.30 | 0.10 | 0.28 | 0.28 | 0.57 | 0.47 | 0.46 |
| Selective Context | 0.58 | 0.33 | 0.35 | 0.31 | 0.26 | 0.25 | 0.56 | 0.50 | 0.47 |
| (Long) LLMLingua | 0.76 | 0.19 | 0.26 | 0.15 | 0.22 | 0.23 | 0.66 | 0.73 | 0.42 |
| LLMLingua-2 | 0.55 | 0.28 | 0.26 | 0.45 | 0.29 | 0.34 | 0.46 | 0.61 | 0.48 |

質問応答では、長文を扱うケースにおいてはLongLLMLinguaが際立って高い成績を残しました。LongLLMLinguaは、質問の内容に応じて圧縮の方針を柔軟に変えられるため、それが功を奏していると考えられます。短い文章では手法による差が出にくいものの、長くなるほど手法ごとの違いがはっきりしてくる傾向も見られました。

| メソッド | BBHブール式（Acc.） | BBH因果判断（Acc.） | BBH Web of Lies（Acc.） | GSM8K数学（Acc.） | Lon [gB](https://ai-data-base.com/archives/26343 "勾配ブースティング") ench単文書（F1） | Lon [gB](https://ai-data-base.com/archives/26343 "勾配ブースティング") ench複数文書（F1） | Lon [gB](https://ai-data-base.com/archives/26343 "勾配ブースティング") enchFewShot（Acc.） | Lon [gB](https://ai-data-base.com/archives/26343 "勾配ブースティング") ench合成（Acc.） |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| オリジナルプロンプト | 0.516 | 0.648 | 0.556 | 0.337 | 0.149 | 0.095 | 0.334 | 0.174 |
| ランダム選択 | 0.468 | 0.556 | 0.532 | 0.030 | 0.146 | 0.108 | 0.356 | 0.192 |
| KiS | 0.576 | 0.480 | 0.512 | 0.149 | 0.118 | 0.092 | 0.312 | 0.166 |
| SCRL | 0.464 | 0.472 | 0.556 | 0.218 | 0.214 | 0.302 | 0.378 | 0.176 |
| Selective Context | 0.480 | 0.616 | 0.552 | 0.179 | 0.185 | 0.101 | 0.412 | 0.288 |
| LLMLingua | 0.528 | 0.504 | 0.536 | 0.297 | 0.286 | 0.319 | 0.620 | 0.128 |
| LongLLMLingua | 0.524 | 0.536 | 0.492 | 0.218 | 0.301 | 0.334 | 0.640 | 0.582 |
| LLMLingua-2 | 0.484 | 0.584 | 0.520 | 0.220 | 0.223 | 0.312 | 0.632 | 0.210 |

なお処理の軽さという観点では、SCRLが群を抜いて効率的でした。計算時間もメモリ使用量も抑えられるため、実装コストやリソース制約を重視する場面では候補に入ってきそうです。

| 手法 | プロンプトごとの処理時間（ms） | トークンごとの処理時間（ms） | メモリ使用量（MB） |
| --- | --- | --- | --- |
| KiS | 2410 | 5.03 | 1378 |
| SCRL | 67 | 0.15 | 315 |
| Selective Context | 319 | 0.69 | 487 |
| LLMLingua | 180 | 0.39 | 5309 |
| LongLLMLingua | 184 | 0.40 | 5309 |
| LLMLingua-2 | 115 | 0.25 | 2137 |

![](https://ai-data-base.com/wp-content/uploads/2025/06/AIDB_91507_4.png)

さまざまな質問応答タスクにおける各手法のパフォーマンス

### 圧縮率と性能のバランス

どれくらい圧縮できるか、という点も実用では見逃せません。実験では、圧縮率を変えながら性能の変化が調べられました。

短い文章では、圧縮率を上げるほど性能は素直に下がっていきます。情報そのものが限られているため、削るほどロスが増えるのは自然な流れです。

一方で、長い文章では状況が少し変わります。圧縮率が0.3程度までであれば、かえって性能が上がるケースも確認されました。情報が多すぎて焦点がぼやけていたところを整理することで、必要な部分が際立つという効果があるのかもしれません。

高い圧縮率でも崩れにくいのは、LLMLinguaやLLMLingua-2でした。重要度を見極めながら丁寧に圧縮していく設計が、内容の骨格を維持するのに貢献しているようです。

![](https://ai-data-base.com/wp-content/uploads/2025/06/AIDB_91507_5-1-1024x509.png)

圧縮率によるパフォーマンスの推移

| 手法 | GPT-3.5-turbo応答長 (単語) | GPT-4o-mini応答長 (単語) | Claude-3-Haiku応答長 (単語) |
| --- | --- | --- | --- |
| オリジナルプロンプト | 56.8 | 74.9 | 124.6 |
| ランダム選択 | 60.1 (+3.3) | 78.0 (+3.1) | 121.6 (–3.0) |
| KiS | 58.4 (+1.6) | 76.4 (+1.4) | 122.1 (–2.5) |
| SCRL | 57.4 (+0.6) | 75.6 (+0.6) | 121.0 (–3.7) |
| Selective Context | 58.1 (+1.3) | 76.0 (+1.1) | 122.4 (–2.2) |
| LLMLingua | 57.1 (+0.3) | 75.2 (+0.3) | 121.8 (–2.8) |
| LongLLMLingua | 57.7 (+0.9) | 75.8 (+0.9) | 122.2 (–2.4) |
| LLMLingua-2 | 57.2 (+0.4) | 75.4 (+0.5) | 121.5 (–3.1) |
| **平均** | 58.0 (+1.2) | 76.0 (+1.1) | 121.8 (–2.8) |

![](https://ai-data-base.com/wp-content/uploads/2025/06/AIDB_91507_5-1024x509.png)

### 圧縮によって応答内容も変わる

圧縮されたプロンプトを使ったとき、LLMの出力にも変化が生まれるという興味深い結果もありました。

たとえば、（GPT-3.5-turboと）GPT-4o-miniは、圧縮されたプロンプトに対してやや長めの応答を返す傾向があります。削られた情報を補完しようとする動きとも考えられます。

一方で、Claude-3-Haikuは逆に出力が短くなりました。もともと説明の多いモデルが、圧縮されたプロンプトに合わせて簡潔な応答に切り替えたとも受け取れます。

こうした違いは、モデルの訓練方針や応答の設計思想によるものかもしれません。プロンプト圧縮を使う際には、モデルごとの反応の違いにも注意を払っておきたいところです。

### ハルシネーションへの影響

圧縮によって、事実でない内容が出てしまうハルシネーションが増える傾向も見られました。とくに目立ったのは、情報が不足している箇所をLLMが埋めようとして、実際には存在しない情報を補ってしまうパターンです。

![](https://ai-data-base.com/wp-content/uploads/2025/06/AIDB_91507_6.png)

ハルシネーションパターンのイメージ

詳しく見ていくと、意味が変わってしまったことによる誤りよりも、そもそも情報が欠けていたことで生じた誤りの方が多くを占めていました。

ただし、手法によって差があるのも事実です。LLMLingua-2は、復元や要約タスクで比較的ハルシネーションを抑える傾向があり、質問応答ではLongLLMLinguaが安定した出力を示していました。

以下は「プロンプト圧縮がLLMのハルシネーションに与える影響」をまとめた表です（値が低いほど望ましい）。

| 手法 | 再構成 MaHR↓ | 再構成 MiHR↓ | 要約 MaHR↓ | 要約 MiHR↓ | 質問応答（短文）MaHR↓ | 質問応答（短文）MiHR↓ | 質問応答（長文）MaHR↓ | 質問応答（長文）MiHR↓ | 平均 MaHR↓ | 平均 MiHR↓ |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| オリジナルプロンプト | – | – | 0.10 | 0.03 | 0.18 | 0.04 | 0.33 | 0.08 | – | – |
| ランダム選択 | 0.83 | 0.54 | 0.77 | 0.42 | 0.53 | 0.31 | 0.65 | 0.48 | 0.70 | 0.44 |
| KiS | 0.36 | 0.17 | 0.23 | 0.12 | 0.28 | 0.15 | 0.41 | 0.21 | 0.32 | 0.16 |
| SCRL | 0.31 | 0.16 | 0.21 | 0.11 | 0.24 | 0.13 | 0.39 | 0.18 | 0.29 | 0.15 |
| Selective Context | 0.24 | 0.14 | 0.19 | 0.08 | 0.22 | 0.12 | 0.34 | 0.17 | 0.25 | 0.13 |
| LLMLingua | 0.23 | 0.11 | 0.16 | 0.09 | 0.20 | 0.13 | 0.31 | 0.15 | 0.23 | 0.12 |
| LongLLMLingua | 0.21 | 0.11 | 0.13 | 0.09 | 0.23 | 0.13 | 0.24 | 0.12 | 0.20 | 0.11 |
| LLMLingua-2 | 0.19 | 0.10 | 0.13 | 0.08 | 0.24 | 0.14 | 0.27 | 0.14 | 0.21 | 0.12 |

![](https://ai-data-base.com/wp-content/uploads/2025/06/AIDB_91507_7.png)

プロンプト圧縮により起こる各ハルシネーションタイプの様相

### 画像も扱うタスクではどうか

テキストだけでなく、画像とテキストを組み合わせたタスクでも比較が行われました。視覚情報を含む質問応答（VQA）では、圧縮手法による影響がやや複雑になります。

SCRL、Selective Context、LLMLingua-2は、データの種類によって性能にばらつきが見られました。問題の構成や、求められる推論のタイプが変わると、圧縮がどのように効くかも変化するようです。

LLMLinguaとLongLLMLinguaは全体的に安定していましたが、最高成績とまではいきませんでした。もともとテキスト専用に作られた設計であるため、マルチモーダルの環境では最適化がまだ不十分なのかもしれません。

以下の表ではVQAタスクにおける各プロンプト圧縮手法のスコアを示します。

| 手法 | IconQA-txt | IconQA-blank | OK-VQA |
| --- | --- | --- | --- |
| オリジナルプロンプト | 0.705 | 0.232 | 0.758 |
| ランダム選択 | 0.668 | 0.161 | 0.498 |
| KiS | 0.660 | 0.226 | 0.696 |
| SCRL | 0.699 | 0.200 | 0.726 |
| Selective Context | 0.662 | 0.230 | 0.686 |
| LLMLingua | 0.681 | 0.225 | 0.752 |
| LongLLMLingua | 0.684 | 0.228 | 0.754 |
| LLMLingua-2 | 0.683 | 0.229 | 0.620 |

### 削られやすい単語には特徴がある

最後に、どんな単語が実際に削除されやすいのかを調べた結果も興味深いものでした。

頻繁に削られていたのは、基本的なつなぎの語です（英語のため「the」「to」「of」「a」「and」など）。文法的にはあまり目立たない語が、優先的に対象になっていました。

ただし、こうした語を削ることが常に安全とは限りません。とくに長い文章では、つなぎの語が文脈の理解に重要な役割を果たしている場合があり、無闇に削ると性能が下がることも確認されています。

上記は画像処理における現象との共通点もあります。画像認識では、背景のような目立たない領域に配置されたトークンが、内部処理で重要な役割を担っていることがあります。LLMでも、いかにも情報量が少なそうな単語が、内部的には意味の構造を支える重要なパーツとして使われている可能性があります。

プロンプト設計の際には、一見すると削ってよさそうな単語でも慎重に扱う必要がありそうです。性能の観点だけでなく、モデルの内部挙動にも目を向けると、削る・削らないの判断がより深まるかもしれません。

## まとめ

本記事では、プロンプト圧縮がLLMの出力や挙動にどのような影響を与えるのかを多角的に検証した研究を紹介しました。

検証された6つの手法は、用途や状況によって向き不向きが異なり、一概に優劣を決めるのが難しいことが分かります。圧縮によってコストが抑えられる一方で、応答の内容や安定性には変化が生じることも確認されました。とくに長文やマルチモーダルな場面では、手法選びや圧縮率の設定が結果に大きく影響するようです。

目的やリソースに合わせて「どこまで削るか」を丁寧に見極めることが、日々の活用でも重要になってきそうです。

**参照文献情報**

- タイトル：An Empirical Study on Prompt Compression for Large Language Models
- URL： [https://doi.org/10.48550/arXiv.2505.00019](https://doi.org/10.48550/arXiv.2505.00019)
- 著者：Zheng Zhang, Jinyi Li, Yihuai Lan, Xiang Wang, Hao Wang
- 所属：The Hong Kong University of Science and Technology (Guangzhou), South China University of Technology, University of Science and Technology of China

\*ICLR 2025 Workshopに採択

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[LLMアプリのコストパフォーマンスを開発動向から紐解く](https://ai-data-base.com/archives/91425)

[今週の注目AI論文リスト（論文公開日2025/6/23～6/27）](https://ai-data-base.com/archives/91805)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)