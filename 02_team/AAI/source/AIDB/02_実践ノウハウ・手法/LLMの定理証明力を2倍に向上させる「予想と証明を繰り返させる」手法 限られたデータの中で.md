---
title: "LLMの定理証明力を2倍に向上させる「予想と証明を繰り返させる」手法 限られたデータの中で"
source: "https://ai-data-base.com/archives/83548"
author:
  - "[[AIDB Research]]"
published: 2025-02-07
created: 2025-06-13
description: "本記事ではLLMによる定理証明における重要な進展を紹介します。定理証明は、LLMの推論能力を客観的に評価できる重要な指標としても注目されていますが、学習データの不足が大きな課題となっています。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事ではLLMによる定理証明における重要な進展を紹介します。

定理証明は、LLMの推論能力を客観的に評価できる重要な指標としても注目されていますが、学習データの不足が大きな課題となっています。スタンフォード大学の研究チームは、人間の学習プロセスからヒントを得て、予想生成と証明を組み合わせた新しい学習手法を開発しました。

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_83548-1024x576.png)

**発表者情報**

- 研究者：Kefan Dong ほか
- 研究機関：スタンフォード大学

論文情報詳細は記事の下部に記載されています。

## 背景

定理証明の世界に、新たな風が吹き始めています。LLMを用いた形式的定理証明に、研究者たちの注目が集まっているのです。

定理証明の中でも、コンピュータが証明の正しさを厳密に検証できる形式で書かれた証明のことを形式的定理証明と言います。これが、LLMの推論能力を客観的に評価できる重要な指標としても注目されています。

人間がLLMと力を合わせて新たな定理証明を効率的にできるようになれば、さまざまな分野でその恩恵を得る可能性があります。

しかし、形式的定理証明の学習に使えるデータを集めることは、極めて困難な課題となっています。なぜなら、定理や証明は専門家によって作成される必要があり、他の機械学習のデータソースと比べて、利用可能な量が何桁も少ないからです。

これまでの研究では [強化学習](https://ai-data-base.com/archives/26125 "強化学習") や専門家反復（expert iteration）と呼ばれる手法が試されてきました。LLMに証明を生成させ、正しい証明が得られた場合にそれを用いて再学習を行うというアプローチです。  
しかしこの方法では未証明の定理に対して正しい証明を生成するために必要なサンプル数が指数関数的に増加してしまうため、性能はすぐに限界に達してしまいます。  
さらに、強化学習には「訓練データの質による制約」も存在します。たとえば、高校レベルの問題だけで訓練されたモデルが、大学レベルの証明技術を習得することは原理的に困難とされています。つまり、オープンな数学の問題に対して、既存の強化学習手法では十分な訓練データを得ることができないのです。

そこで今回スタンフォード大学の研究者たちは、人間の数学者の学習プロセスに着目しました。数学者は既存の定理を変形したり、拡張したり、組み合わせたりすることで理解を深め、証明スキルを磨いています。また、新しい予想を提案し公表することも、証明と同様に重要な活動とされています。

このような洞察に基づき、研究チームは予想生成と証明を組み合わせた新しい学習手法の開発に着手したのです。

以下で詳しく紹介します。

## 手法

それでは、本研究で提案された手法について詳しく見ていきましょう。

研究チームが開発したSTPと呼ばれる手法は、3つの段階で構成されています。

1. モデルの初期化と教師あり学習から始まり、
2. 自己対戦による訓練を経て、
3. 最後に再訓練が実施されます。

### ①モデルの初期化と教師あり学習

まず、教師あり学習による初期化段階では、予想を生み出す役割と証明を行う役割という2つの異なる機能を持つモデルが作られます。例えばLlamaのような基盤となるLLMに対して、既存の数学ライブラリから作成したデータセットを用いて微調整が行われます。ここでいう数学ライブラリとは、人間が記述した形式的証明を集めたもので、教科書の章のように一つの数学的結果がまとめられています。

#### 証明生成用のデータセット

証明を行う役割のモデルを訓練する際には、3つの要素が一組となったデータが使用されます。

- システムからの指示（数式を形式的な言語で書くよう促すプロンプト）と、
- 定理の内容、
- その証明
- です。

モデルは、与えられた定理に対して、適切な証明を生成できるよう訓練されます。

#### 予想生成用のデータセット

一方、予想を生み出す役割のモデルは、新しい関連する予想を生成することを目指します。

訓練データとして、

- アイデアのきっかけとなる定理、
- その証明、
- 補題（証明中で使用される重要な部分的結果）が与えられます。

モデルはこれらの情報をもとに、新たな予想を生成するよう訓練されます。なお、補題を明示的に与えることの意味は、生成される予想が元の定理と関連性を持つようにするためです。

また、予想生成の柔軟性を高めるため、単純な補題を使用することも許容されています。そうすることで、特定の分野に限定されることなく、幅広い予想を生み出すことが可能となります。訓練用のデータセットは、数学ライブラリから（補題、定理X、定理Y）という3つ組を抽出して作られます。定理XとYは同じファイルに含まれており、両方の証明で同じ補題が使用されているものが選ばれます。実際の訓練では、補題と定理Xを入力として与え、定理Yを出力として扱うという方法が採用されています。

### ②自己対戦による訓練

モデルの性能を向上させるため、自己対戦による訓練が図に示す4つのステップで実施されます。

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_83548_1-1024x429.png)

自己対戦による訓練の全体像

従来の手法である専門家反復と大きく異なる点として、”予想を生成するプロセス”が新たに組み込まれています。

#### 新しい予想を生み出す（ステップ1）

自己対戦は、すでに証明が得られている定理とその証明から始まります。まず証明から重要な部分である補題が取り出され、これを基に予想生成モデルが新たな予想を生み出します。

なお、モデルが特定の証明技法に偏らないよう工夫がなされています。同じ定理と補題の組み合わせは一度しか使用されず、頻繁に現れる補題の一部は無作為に除外されるのです。

#### 証明に挑戦する（ステップ2）

予想が生成されたのち、その数が未証明の定理の数を超えないように、無作為に選ばれます。これは、演算資源を予想と既存の定理に均等に配分するための工夫です。そして、選ばれた予想と未証明の定理それぞれについて、32回ずつ独立に証明の生成が試みられます。

#### 証明の正しさを確かめる（ステップ3）

生成された証明は、LeanやIsabelleといった形式的検証システムによって自動的に検証されます。証明が正しいかどうかを判定するだけでなく、その証明の中でどのような補題が使われているかという情報も取り出されます。この情報は、次のステップで予想の質を評価する際に活用されます。

#### 学習に使うデータを選び出す（ステップ4）

予想生成モデルを訓練する上で最も難しい技術的課題は、適切な評価基準（報酬関数）の設計です。良い予想とは、多様性があり、元の定理と関連性があり、さらに適度に挑戦的なものである必要があります。

生成された全ての予想と証明のデータは、以下5つの要素でまとめられます。

- 元の定理
- その証明
- 補題
- 生成された予想
- 予想に対する証明）

そして予想の難しさは、32回の独立した証明生成の試行における成功率で評価されます。成功率が0より大きく25%以下の予想が、「適度に挑戦的」と判断されます。

また、予想の美しさも重要な要素として考慮されています。予想の長さに対する最短の正しい証明の長さの比率が下位20%に入る予想は除外されます。こうすることで、不自然に複雑な目標を持つ人工的な予想が抑制されるのです。

さらに、予想の多様性を保つための工夫も施されます。選ばれた予想の分布が、未証明の定理の分布に近づくよう重み付けが行われます。この際、現在のモデルが計算した埋め込み表現間のコサイン類似度が、判断の基準として使用されます。

ちなみに、証明生成モデルの訓練データとしては、経験的成功率が50%未満の定理や予想に対する正しい証明のみが選ばれます。重複は取り除かれ、直近3回の反復で得られた証明が、リプレイバッファとして活用されるのです。

### 学習の仕上げとなる再訓練

自己対戦による訓練では、学習に使うデータの性質が刻々と変化していきます。そのため、モデルの安定性を確保するには工夫が必要です。研究チームは最終段階として、初期モデル（教師あり学習を行う前の状態）に立ち返り、再度訓練を実施することにしました。

この最終訓練では、2種類のデータが使われます。

- 1つは教師あり学習で使用した元々のデータセット、
- もう1つは自己対戦によって生み出された正しい証明です。

ただし、自己対戦で得られた証明については、慎重な選別が行われました。対応する定理や予想の経験的成功率が25%以下のものだけが、訓練データとして採用されたのです。さらに、計算の効率性を考慮して、各定理や予想につき最大16個の異なる証明がランダムに選ばれました。

このような再訓練の効果は、実際の評価結果からも明らかになっています。詳細は後述しますが、たとえば、生成された予想を含めて再訓練を行ったモデルは、LeanWorkBookのデータセットで良い成績を収めただけでなく、miniF2F-testやProofNet-testといった外部のベンチマークでも、約1%の性能向上を達成しました。つまり、自己対戦によって生み出された予想には、単に既存の問題を形を変えただけではない、本質的な価値が含まれていたことが示唆されているのです。  
以下で詳しく見ていきましょう。

## 実験による検証

研究チームが提案した手法の有効性を確かめるため、複数の実験が実施されました。ここでは、実装の具体的な内容と、LeanとIsabelleという2つの形式的検証システムでの結果について説明します。また、手法の各要素が実際に効果を発揮しているかを確認するための分析結果も示していきます。

\*Leanは依存型理論に基づく形式的検証システムで、柔軟な戦術や自動化機能を活かし、数学の定理やプログラム検証に利用されています。活発なコミュニティと充実したライブラリが強みです。一方、Isabelleは高階論理を基盤とし、Isabelle/HOLなど複数の論理体系をサポートする成熟したシステムです。ソフトウェアやハードウェア検証、数学の形式化で長い実績があり、使いやすいインターフェースと自動証明機能が評価されています。

### 実装の具体的な方法

#### 学習に使用したデータセット

実験では、 [LeanWorkbook](https://huggingface.co/datasets/internlm/Lean-Workbook) という既存のデータセットが活用されました。このデータセットには、自然言語で書かれた数学の記述を形式的な数学言語に自動的に変換して作られた約89,000個の定理が収められています。なお、同じ自然言語の記述から複数の形式的定理が生成された場合は、重複を避けるため1つだけが選ばれています。

また、Isabelleでの実験のために、DeepSeek-V2.5（LLM）を使って、Leanで書かれたLeanWorkbookの定理をIsabelleの形式に変換する作業が行われました。この変換作業は、少数の具体例を参考にしながら進められました。

#### 初期学習のためのデータ準備

Isabelleでの実験では、AFPと呼ばれるIsabelleの証明アーカイブと、Isabelleに標準で組み込まれているHOLという理論ファイルからデータが集められました。

一方、Leanでの実験では少し異なるアプローチが取られました。ベースとなるDeepseek-Prover-V1.5-SFTというモデルが、すでにLeanWorkbookで訓練されていたためです。そこでまず、各定理について32個の証明を生成し、その中から正しい証明を集めました。そして、これらの証明とMathlib（数学ライブラリ）から取り出した例を組み合わせて、初期学習用のデータセットが作られたのです。

このように、既に確立された数学ライブラリや検証済みの証明を活用することで、モデルに基本的な証明能力を身につけさせてから、自己対戦による訓練が始められました。これは、段階的な学習を実現するための重要な工夫といえるでしょう。

### Leanシステムでの実験成果

研究チームは、ベースとなるモデルとして先述の通りDeepSeek-Prover-V1.5-SFTを選びました。このモデルは、公開データセット（LeanWorkbook、 [miniF2F-valid](https://github.com/openai/miniF2F) 、 [ProofNet-valid](https://mathai2022.github.io/papers/20.pdf) ）と非公開データセットを組み合わせ、専門家反復という手法で訓練されています。

さて、提案された手法による訓練は24回の反復を重ねて行われました。その過程で、200万個の予想、1億2000万個の証明が生み出され、生成されたトークンは198億に達しました。  
訓練の進み具合は、「訓練全体を通じて証明できた定理の割合」という指標で測られています。

#### 評価から見えてきた主な成果

LeanWorkbookデータセットでの成績が下の図に示されています。提案手法は、従来の専門家反復や並列 [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") と比べて、より効率的に学習を進められることが示されました。つまり、同じ計算資源でより多くの定理を証明できたのです。

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_83548_2.png)

LeanWorkbook データセットに対する STP、エキスパート反復法、並列 サンプリング の累積合格率を比較。STP は、証明生成の数に対するスケーリングの面で優れた性能を発揮。

そして、さらなる性能向上を目指し、LeanWorkbook、miniF2F-valid、ProofNet-validのデータを使って8回の追加訓練が実施されました。その成果は、一般的なベンチマークであるminiF2F-testとProofNet-testでの評価結果に表れています。

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_83548_4-1-1024x432.png)

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_83548_5-1024x320.png)

miniF2F-test（高校レベルの数学問題）および ProofNet-test（大学レベルの数学問題）に対して、STP と他の定理証明モデルのパス率を比較。異なる推論時のサンプル数（128, 3200, 25600 など）に対して結果を報告。

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_83548_3.png)

miniF2F-test における STP のパス率と推論時のサンプル数との関係を示すグラフ。STP は Deepseek-Prover-V1.5 シリーズを一貫して上回る成績を示す。

#### ベンチマークでの驚くべき成果

提案手法は、一度の証明生成での成功率（pass@128）で57.2%、より多くの試行を許した場合（pass@3200）で61.1%という成績を収め、従来の手法を上回りました。さらに、より高度な数学を扱うProofNet-testでも、23.1%（pass@3200）という最高記録を達成したのです。

\*「pass@k」とは、「k回 [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") して正解が1つでもあれば合格」の評価指標

また、さきほどの表では探索ベースの手法との比較も示されています。探索ベースとは、LLMが証明の各ステップを生み出し、最良優先探索やモンテカルロ木探索を使って完全な証明を組み立てる手法です。厳密な計算コストの比較は難しいものの、提案手法は同程度の推論時間でより良い成績を残しています。

そして、学部レベルの数学コンテスト問題を集めた [PutnamBench](https://github.com/trishullab/PutnamBench) でも、従来の最高記録である6問を更新し、644問中8問（64サンプル使用時）または9問（3200サンプル使用時）を解くことに成功しました。

これらの結果から、予想を生み出す過程を組み込んだ自己対戦学習が、形式的定理証明の性能を効果的に高められることが明らかになっています。

### Isabelleシステムでの実験成果

数学に特化したLlemma-7bをベースモデルとして採用し、58回の反復訓練が実施されました。訓練の途中、複数の時点でモデルの性能を確認し、そこから従来の専門家反復や並列 [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") に切り替えた場合と比較することで、提案手法の拡張性が検証されたのです。

#### 計算の効率性を比べる

下の図に、LeanWorkbook（Isabelle版）での提案手法と従来手法の累積成功率が示されています。モデルの能力レベルが異なる時点から始めた場合でも、提案手法は一貫して優れた拡張性を見せました。

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_83548_fig4-1.png)

Isabelle の LeanWorkbook における STP、エキスパート反復法、並列 サンプリング の累積合格率を比較。STP はすべてのチェックポイントでスケーリングが良好。

#### 段階的に高まる性能

次に、訓練が進むにつれてminiF2Fでの性能がどのように変化したかが表されています。およそ6800万個の証明生成を1つの区切りとして、性能が徐々に向上していく様子が確認できます。  
なお、この実験ではsosなどの高度な証明テクニックは使われておらず、miniF2F-validでの訓練も行われていないことは、結果を見る上で重要な点です。

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_83548_fig4-2.png)

miniF2F-test における STP のパス率の向上を示す。

#### 予想生成がもたらす効果

さらに累積成功率が11.4%に達した時点での興味深いデータが示されています。生成された予想と、まだ証明されていない定理それぞれについて、証明に成功する確率の分布が比較されています。

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_83548_fig4-3.png)

生成された予想と未証明の定理のパス率のヒストグラム。STP で生成された予想は未証明の定理よりも証明成功率が高く、より密な学習信号を提供。

注目すべきは、生成された予想の方が証明に成功しやすい傾向が明確に表れていることです。グラフのy軸が対数スケールで表示されていることからも、この差が極めて大きいことが分かります。

具体的な数字で見てみましょう。この時点で証明されていない79,000個の定理に対して、250万回もの証明生成を試みたにもかかわらず、正しい証明が得られたのはわずか131個でした。つまり、未証明の定理に対する証明生成は非常に効率が悪く、モデルの再訓練にほとんど役立っていないことが明らかになったのです。

一方で、生成された予想については、少なくとも47%が証明可能でした。これは、予想生成という新しい手法が、より効果的な学習の機会を提供できていることを示す重要な発見といえるでしょう。

### 実験による分析

#### 生成された予想による学習信号の密度

Isabelle実験の一時点（累積成功率11.4%）における、生成された予想と既存の未証明定理の比較は興味深いです。

250万回の証明生成試行のうち、79,000個の未証明定理に対して正しい証明が得られたのはわずか131個でした。結果として、専門家反復による訓練はほとんど効果を持たない状態に陥っています。  
一方、生成された予想については、少なくとも47%が証明可能でした。予想生成モデルが到達可能な難易度の予想を生成するよう訓練されているため、より効率的な学習が可能になっています。これは、提案手法の核心的な利点を示す結果といえます。

#### 生成された予想を用いた再訓練の効果

最終的な再訓練段階で、生成された予想を含めることの効果も検証されました。LeanWorkBookの定理だけを用いた場合と比較して、生成された予想も含めた再訓練では、miniF2F-testとProofNet-testの両方で約1%の性能向上が観察されました（pass@128の設定で）。

この結果は単なる既存問題の変形以上の価値を示唆しています。生成された予想を学習することで、モデルはより汎用的な証明能力を獲得できると考えられます。また、既存のデータセットだけでは捉えきれない、より広範な数学的パターンの学習にも貢献している可能性があります。

### 生成された予想の例

Lean実験の最終段階で生成された予想について、3つの具体例が紹介されています。これらは手作業で選択された例ですが、提案手法によって生成される予想の質と多様性を示すものです。

#### 例1：より一般化された不等式

元の定理は「x ∈ \[0,1\]のとき、1 + x² ≤ (1 + x)²」という不等式でした。これに対して生成された予想は「n ≥ 1なる整数nとx ∈ \[0,1\]に対して、(1 + x)^(2n) ≥ 1 + x^n」というものでした。

生成された予想は元の定理より難しくなっていますが、二項展開とx ≥ 0という条件を使用するという点で、似た証明技法が適用可能です。

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_83548_7-1024x191.png)

#### 例2：代数的な関係の一般化

元の定理「n – 1は n^k – 1を割り切る」に対して、生成された予想は「x, nが整数のとき、(x^n – 1) mod (x – 1) ≤ 1」というものでした。

この予想は、b mod a = 0であることとaがbを割り切ることが同値であるという関係性に着目して生成されています。ただし、不等式の上界が最適ではなく、データセットに含まれにくい種類の予想となっています。

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_83548_8-1024x168.png)

#### 例3：特殊な場合の一般化

元の定理は「Σ(1/4)^k \* (√5/4) = √5/3」という具体的な等式でした。これに対して生成された予想は「0 < a ≤ 1のとき、Σ(1/4)^i \* a = a/(1-1/4)」という、より一般的な形に拡張されています。

√5/4という具体的な値をパラメータaで置き換えることで、元の定理を特殊ケースとして含む、より一般的な定理が生成されています。

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_83548_9-1024x215.png)

これらの例は、提案手法が単なるパターンの模倣を超えて、数学的に意味のある一般化や関連する定理の生成に成功していることを示しています。

## まとめ

本記事では、数学の定理証明における新しい学習アプローチ「Self-play Theorem Prover (STP)」の研究を紹介しました。

STPは、定理を推測する役割と証明する役割の2つを同時に持つことで、限られた訓練データから効率的に学習を進めることを可能にしました。

研究チームの実験では、従来手法の2倍となる26.3%の定理を証明することに成功し、複数のベンチマークテストでも最高性能を達成しています。人間の数学者が新しい定理を提案しながら証明技術を磨いていく過程を模倣した手法が一定の効果を示した形です。

**参照文献情報**

- タイトル：Beyond Limited Data: Self-play LLM Theorem Provers with Iterative Conjecturing and Proving
- URL： [https://doi.org/10.48550/arXiv.2502.00212](https://doi.org/10.48550/arXiv.2502.00212)
- 著者：Kefan Dong, Tengyu Ma
- 所属：Stanford University

## 理解度クイズ

理解度クイズ

1\. LLMを使った形式的定理証明で「学習データの不足」が大きな課題とされる主な理由は何か。

専門家が手作業で形式的証明を用意する必要があるため、他の機械学習データよりはるかに量が少ない。  
既存の強化学習手法では、この少ないデータ量を十分に補えず、高度な証明技術の獲得が難しい。

解説を見る

2\. スタンフォード大学の研究チームが着想を得た「人間の数学者の学習プロセス」とは何か。

数学者は既存の定理を変形・拡張・組み合わせる過程で理解を深め、あわせて新しい予想を提案する。  
新しい結果を生み出しながら証明技術を高める姿勢がモデル設計の鍵になっている。

解説を見る

3\. STP（Self-play Theorem Prover）の手法が、従来の「専門家反復」と最も異なる点は何か。

従来は定理に対して正しい証明を集めて再学習するだけだったが、STPは新しい予想を生み出す段階を加えている。  
生成した予想にも挑戦するため、未知の課題に対応する学習機会が増えている。

解説を見る

4\. STPにおける「新しい予想を生成する」仕組みが学習を促進できる理由は何か。

未知の定理だけを証明しようとしても成功率が低く再学習の材料が乏しくなりやすいが、適度な難易度の予想を生成することで効率的に正解データを増やせる。  
未知の課題を自ら作りつつ解決できるため、モデルが幅広い証明スキルを獲得しやすくなる。

解説を見る

5\. 最終段階の再訓練で、モデルの性能が向上した要因として最も正しいのはどれか。

記事では、自動生成された予想とその正しい証明を選別して再度学習に含める方法が有効とされた。  
新たな知見が含まれた追加データが、より汎用的な証明能力の獲得に貢献している。

解説を見る

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[LLMを活用した「Text to CAD」 テキスト指示から高品質な3Dモデルを作成する](https://ai-data-base.com/archives/83475)

[DeepSeek‑R1の技術【クイズ】](https://ai-data-base.com/archives/84055)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)