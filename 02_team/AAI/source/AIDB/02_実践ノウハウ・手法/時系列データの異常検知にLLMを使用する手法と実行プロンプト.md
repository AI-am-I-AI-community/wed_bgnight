---
title: "時系列データの異常検知にLLMを使用する手法と実行プロンプト"
source: "https://ai-data-base.com/archives/69867"
author:
  - "[[AIDB Research]]"
published: 2024-05-28
created: 2025-06-13
description: "LLMをゼロショットで時系列データの異常検知に利用するプロンプトベースの手法が提案されています。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

LLMをゼロショットで時系列データの異常検知に利用するプロンプトベースの手法が提案されています。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69867-1024x576.jpg)

**参照論文情報**

- タイトル：Large language models can be zero-shot anomaly detectors for time series?
- 著者：Sarah Alnegheimish, Linh Nguyen, Laure Berti-Equille, Kalyan Veeramachaneni
- 所属：MIT, IRD ESPACE-DEV

## 背景

LLMはプログラミングのコードを生成したり、画像や動画を生成したりと、その応用範囲が大きく広がってきました。さらに、LLMには追加の学習なしに新しいタスクに取り組める能力もあるので注目を集めています。

そしてLLMによる時系列データから未来の値を予測する「時系列予測」が注目され、時系列データを文字列としてLLMに入力することが有効と分かってきました。そこで、予測よりも複雑なタスクである異常検知への応用可能性が浮上しました。

時系列データは、産業界の日常業務で頻繁に扱われているため、LLMによる異常検知の実現は大きなインパクトを持つ可能性があります。

今回MITの研究者らは、追加の学習を必要とせず計算コストを大幅に削減できるLLMベースの異常検知手法を考案し、その有効性を実験的に示しています。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69867_2.png)

機械学習モデルが教師なし設定で異常を見つける一般的な原理。本研究ではLLMにより、従来の手法を代替する試みを行っている。

## 時系列データの表現方法

時系列データは様々な形式で表現されますが、本論文では、単変量時系列を X = (x₁, x₂, …, xT) と定義しています。ここで、xt (t = 1, 2, …, T) は時刻 t における値であり、T は時系列の長さを表します。

LLMに時系列データを入力するためには、上記を適切な形式に変換する必要があります。本研究では、単変量時系列 X をトークン化された値のシーケンスに変換するため、スケーリング、量子化、ローリングウィンドウによる [セグメンテーション](https://ai-data-base.com/archives/26353 "セグメンテーション") 、トークン化の4つのステップで行われます。以下、各ステップについて詳しく説明します。

1. **スケーリング  
	**時系列データには、値の大きさが異なるものや、正の値と負の値が混在するものがあります。データ表現を標準化し、計算効率を最適化するために、最小値を時系列から引いて、新しい時系列 Xₛ = (xₛ₁, xₛ₂, …, xₛT) を作ります（xₛₜ は、xₜ から最小値を引いた値です）。これで負の値を扱う必要がなくなります。
2. **量子化  
	**LLMは、有限のボキャブラリーセットを用いて学習されています。一方、スケーリングされた時系列の値 xₛₜ は無限に存在し得るため、そのままではLLMで処理できません。そこで、量子化と呼ばれる処理を行います。  
	各値を所定の小数点以下の桁数で四捨五入し、その後、整数形式にスケーリングします。すると小数点以下の桁数に無駄なトークンを使わずに済みます。量子化された時系列を Xq = (xq₁, xq₂, …, xqT) とすると、xqₜ は非負の整数値になります。
3. **ローリングウィンドウ  
	**LLMへの入力には、コンテキスト長の上限があります。また、 [GPU](https://ai-data-base.com/archives/26570 "GPU") メモリにも制約があります。これらの制約を踏まえ、ローリングウィンドウと呼ばれる手法を用います。  
	時系列を所定の長さとステップサイズのウィンドウに分割します。つまり、処理された時系列 Xq を、{xᵢ₁…w} (i = 1, 2, …, N) という形式のセグメントに分割します。ここで、w はウィンドウサイズ、N はウィンドウの数を表します。  
	要するに時系列データを小さな範囲（ウィンドウ）に区切って、少しずつずらしながら処理するということです。
4. **トークン化  
	**トークン化の方法は、数値の扱い方によって異なります。今回は、数値を個別の桁に分割して桁間にスペースを挿入し、各桁が個別にエンコードされるようにしています。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69867_3-1024x726.jpg)

変換プロセスの異なるバリエーションの下でのLLMの出力の可視化

今回の研究では、上記の変換方法が、LLMの出力にどのように影響するかを調べるために、いくつかの実験が行われています。

その結果、スケーリングを行うことで、トークン化される桁数を減らすことができ、よりよい結果が得られることがわかりました。また、GPTモデルでは、桁間にスペースを追加することが有効である一方、MISTRALモデルではそうではないことも明らかになりました。

## SIGLLMフレームワークの概要

LLMで時系列データの異常を検出するためのフレームワーク「SIGLLM」について説明します。

単変量時系列 X = (x₁, x₂, …, xT) を入力とし、異常な時間セグメントの集合 A = {(tₛ, tₑ)ᵢ | 1 ≤ tₛ < tₑ ≤ T} (i = 1, 2, …, m) を出力します。ここで、tₛ と tₑ は、それぞれ異常区間の開始時刻と終了時刻を表します。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69867_4.png)

SIGLLMフレームワークにおける異常検知手法

本手法では、異常検知を行うための2つの方法が提案されています。1つ目は「PROMPTER」、2つ目は「DETECTOR」と呼ばれるものです。以下、それぞれの方法について。

### PROMPTER（プロンプトエンジニアリングによる異常検知）

プロンプトを用いて、LLMに時系列データの異常を直接指摘させる方法です。

プロンプトと処理された時系列ウィンドウ uᵢ₁…k を連結した入力をLLMに与えます。ここで、uᵢ₁…k は、プロンプトと xᵢ₁…w (ウィンドウサイズ w の時系列セグメント) を連結したものであり、k は連結後の入力の長さを表します。

LLMは、入力されたテキストに対して、次のトークン uk+1 を生成します。このトークンは、自己回帰的な確率分布 pθ(uk+1|u₁…k) から [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") されます。本研究では、いくつかの実験を行い、最適なプロンプトを決定しました。以下はプロンプトの例です。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69867_5-1024x502.png)

PROMPTERで使用されるプロンプトの例とそれぞれの観測出力

**プロンプトの日本語訳**

**（１）**

```js
プロンプト:
{x_{1..w}}. 上記の時系列の異常を見つけなさい。

出力例:
- numpyのconvolveやsklearnのIsolationForestを使った汎用的な異常検出コードを生成。
- 異常を見つけられなかった。
- 異常を見つけるための一般的なアプローチに関する曖昧な回答を生成。
```

**（２）**

```js
プロンプト:
このシリーズの異常なインデックスの範囲を見つけなさい {x_{1..w}} または このシリーズを与えられた {x_{1..w}}. 異常なインデックスの範囲を見つけなさい。

出力例:
- インデックスのリストを生成。
- 試行#1と似たコードを生成。
- 異常を見つけられなかった。
- 異常を見つけるための一般的なアプローチに関する曖昧な回答を生成。
- ‘基準や特定の方法を持っていますか’と質問。
- 異常は平均から大きく外れた値であることを確認。確認後、話題がそれた。
```

**（３）**

```js
プロンプト:
このシリーズの異常なインデックスを見つけなさい {x_{t_s-100..t_e+100}}. ここでt_sとt_eはそれぞれ異常の始まりと終わりのインデックスです。

出力例:
- インデックスのリストを生成。
- 異常を見つけられなかった。
```

**（４）**

```js
プロンプト:
timeseries_1の異常インデックスは {x_{1..w}}1 : {t{1..k}}_1
timeseries_2の異常インデックスは {x_{1..w}}2 : {t{1..k}}_2
timeseries_3の異常インデックスは {x_{1..w}}_3 :

出力例:
- インデックスのリストを生成。
- timeseries_3の異常が与えられたと主張。
- 異常を見つけられなかった。
- ‘Whoa, かなり長い時系列ですね！このデータについて何を手伝えますか’と出力。
```

**（５）**

```js
プロンプト:
あなたは時系列異常検出を行う有用なアシスタントです。ユーザーはシーケンスを提供し、あなたはシーケンス内の異常なインデックスのリストを提供します。シーケンスはカンマで区切られた10進文字列で表されます。追加のテキストを生成せずに、次のシーケンス内の異常なインデックスのリストを提供してください。シーケンス内の異常なインデックスは’のようなことを言わないでください。単に数字を返してください。シーケンス: {x_{1..w}}

出力例:
GPT-3.5-turbo:
- インデックスのリストを生成。
- 時々、‘Index:’のような言葉が含まれる。
- 時々、出力インデックスがシーケンスの長さを超えた。
MISTRAL:
- 値のリストを生成。
```

PROMPTERでは、時系列をローリングウィンドウに分割し、各ウィンドウに対してLLMを適用します。そして、LLMが異常と判断した値に対応するインデックスを収集します。最終的に、各ウィンドウから得られた異常インデックスのリストを統合し、最終的な異常検知結果を得ます。

### DETECTOR（予測に基づく異常検知）

LLMの時系列予測能力を活用して異常を検出する方法です。通常の機械学習パイプラインでは、モデルの学習に時間がかかりますが、LLMを用いることで、この学習フェーズをスキップできます。

DETECTORの処理の流れは以下のようになります。

**a. 前処理  
**生の時系列データを、LLMが扱える形式に変換します。

**b. 予測  
**LLMを用いて、各ウィンドウに対して未来の値を予測します。

**c. 後処理  
**予測値と実際の値の差を計算し、異常スコアを算出します。

まず各ウィンドウ xᵢ₁…w に対して、LLMを用いて次の h 個の値 (xᵢw+1…w+h) を予測します（h は予測ホライズンを表す）。つぎに予測値と実際の値の差を計算し、異常スコアを算出します。異常スコアが閾値を超えた場合、そのインデックスを異常とみなします。

なお本研究では、予測値と実際の値の差を計算するための様々な手法（絶対差、二乗差など）を比較しています。また、異常スコアの閾値を決定するために、 [スライディングウィンドウ](https://ai-data-base.com/archives/26349 "スライディングウィンドウ") を用いた手法も提案されています。

## 評価実験の結果

SIGLLMの有効性を検証するための様々な評価実験が行われました。以下3つが検証テーマでした。

1. LLMは単変量時系列データの異常検知に有効か？
2. 既存手法と比べてどの程度の性能を示すか？
3. 提案手法の成功例と失敗例は何か？その理由は？

実験には11のデータセットが用いられました。NASAの衛星テレメトリデータ、Yahoo S5ベンチマーク、NAB(Numenta Anomaly Benchmark)など、様々なドメインから収集されたものです。合計で492の時系列と2,349の異常が含まれています。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69867_6.png)

データセットの要約: 492シグナルと2349異常

フレームワークとしてはPROMPTERとDETECTORの2つのアプローチが比較されました。

また、LLMとしてGPT-3.5-turboとMISTRAL-7B-Instruct-v0.2が使用されています。

さらに、提案手法と既存手法との性能比較も行っています。比較対象の既存手法は、ARIMA、Matrix Profile、 [LSTM](https://ai-data-base.com/archives/26165 "LSTM") 、 [オートエンコーダ](https://ai-data-base.com/archives/26329 "オートエンコーダ") 、 [GAN](https://ai-data-base.com/archives/26269 "敵対的生成ネットワーク（GAN）") 、Anomaly [Transformer](https://ai-data-base.com/archives/26535 "Transformer") などです。

なお、評価指標には、異常検知に特化した [F1スコア](https://ai-data-base.com/archives/26112 "F1スコア（F値）") （部分的な異常検知も正解とみなす）を用いています。

以下、実験結果です。

### LLMは単変量時系列データの異常検知に有効か？

LLMが単変量時系列データの異常検知に対して一定の有効性を示すことが明らかになりました。また、提案された2つのアプローチのうち、DETECTORアプローチがPROMPTERアプローチよりも優れた性能を示しました。DETECTORアプローチのF1スコアは、PROMPTERアプローチを135%上回る結果となりました。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69867_8.png)

精度、 再現率 、F1スコアの要約

PROMPTERアプローチにおいては、使用されたLLMによって性能差が見られました。MISTRALを用いた場合、GPTを用いた場合と比較して2倍の性能を達成しました。

また、実験ではDETECTORアプローチにおいても様々な設定が比較されました。異常スコアの計算方法や、予測値の集約方法などが検討され、それぞれの設定が異常検知の性能に与える影響が明らかにされました。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69867_9-1024x398.png)

DETECTORのすべてのバリエーションのF1スコア

### 既存手法と比べてどの程度の性能を示すか？

SIGLLMフレームワークと既存の時系列異常検知手法との性能比較が行われました。結果、SIGLLMフレームワークがAnomaly [Transformer](https://ai-data-base.com/archives/26535 "Transformer") などのトランスフォーマーベースの手法よりも優れた性能を示すことが明らかになりました。

また、MovingAverageのようなシンプルな手法と比較しても、SIGLLMフレームワークは14.6%高いF1スコアを達成しました。

しかし、SIGLLMフレームワークの性能は、最先端の深層学習手法（AERなど）には及ばないことも明らかになりました。平均で30%の性能差が見られ、深層学習手法の優位性が示されました。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69867_10-1024x348.png)

F1スコアのベンチマーク要約結果

### 提案手法の成功例と失敗例は何か？その理由は？

提案された2つのアプローチ（PROMPTERとDETECTOR）の成功例と失敗例が分析されました。

DETECTORアプローチは、多くのデータセットで異常を適切に検出できることが示されました。

一方、PROMPTERアプローチは、極端な値（外れ値）の検出には有効であったものの、時系列内に埋もれた異常の検出には苦戦する様子が見られました。つまり、PROMPTERアプローチが局所的な文脈に基づいて異常を判断していることが示唆されました。

また、DETECTORアプローチにおいても、時系列の非定常性（トレンドなど）を捉えるのが難しいケースがあることが明らかになりました。この問題は、LLMの文脈把握能力の限界に起因すると考えられます。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69867_11-1024x467.png)

（左）PROMPTERによって特定された異常の例 （右）DETECTORによって正常に特定された異常の例

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69867_12.png)

PROMPTERとDETECTORの記録時間

## 考察

実験から得られた知見や課題について。

### プロンプトエンジニアリングの難しさ

LLMに異常を直接指摘させるPROMPTERアプローチでは、適切なプロンプトを設計するのは容易ではありませんでした。3ヶ月にわたる実験期間中、様々なプロンプトを試しましたが、LLMが望ましい応答を生成するためには、ユーザーとシステムの役割を明示的に指定するチャットテンプレートの使用が必要でした。

また、GPTとMISTRALでは、同じプロンプトに対する応答が異なる場合がありました。例えば、GPTは「find indices」プロンプトに対して異常インデックスのリストを生成しましたが、MISTRALは値のリストを生成しました。これらの違いを考慮して、プロンプトを調整する必要がありました。

### LLMの記憶力に関する懸念

LLMは大量のデータで学習されているため、リークが懸念されます。（なおGPTモデルは学習データを特に記憶しやすいと言われています）。本研究では、時系列データを独自の文字列表現に変換することで、元のデータとの違いを作り出し、記憶の可能性を減らしています。また、異常検知は、LLMの学習方法（次のトークンを予測すること）とは異なるタスクであるため、学習データの記憶の影響は限定的であると考えられます。

### 実用性の検討

LLMを異常検知に使用する利点は、追加の学習を必要としないことです。しかし気になる点として、LLMの応答時間が長いことが明らかになりました。またDETECTORアプローチは、PROMPTERアプローチの約2倍の時間を要しました。ローリングウィンドウを用いているためです。

ただし、本研究の実験ではオフラインでの評価を行っているため、実際のデプロイメントではより短い応答時間が期待できます。オンラインでは、コンテキストサイズが小さくなり、ローリングウィンドウが不要になるためです。

また、LLMの使用にはコストがかかる点も気にかかります。実験では、PROMPTERアプローチで1シグナルあたり約1.69ドル、DETECTORアプローチで約4.3ドルのコストがかかりました。

## まとめ

本記事では、LLMを用いた時系列データの異常検知に関する研究を紹介しました。

LLMに時系列データの異常検知を行わせるという新しい試みが行われ、プロンプトを用いる方法(PROMPTER)と、予測に基づく方法(DETECTOR)の2つのアプローチが提案されています。

研究チームは、時系列データをLLMが扱える形式に変換するためのフレームワーク「SIGLLM」を開発し、492の時系列データを用いて、提案手法の有効性を実験的に検証しています。実験の結果、LLMは一定の異常検知性能を示すことが明らかになりました。ただし実用化に向けては、応答時間やコストの問題への取り組みが必要だと指摘されています。

LLMを用いた異常検知は、まだ発展途上の技術ですが、その利便性の高さから、実用化が進めば、様々な業務の効率化に役立つことでしょう。

- 参照論文URL： [https://arxiv.org/abs/2405.14755](https://arxiv.org/abs/2405.14755)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[自然言語プログラミングを可能にするシステム『CoRE』](https://ai-data-base.com/archives/69789)

[多くの「長いコンテキストを要するタスク」を、短いコンテキストウィンドウのLLMで解決する手法](https://ai-data-base.com/archives/69938)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)