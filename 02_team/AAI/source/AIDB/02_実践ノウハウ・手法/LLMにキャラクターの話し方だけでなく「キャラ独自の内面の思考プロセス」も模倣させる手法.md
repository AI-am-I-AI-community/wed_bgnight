---
title: "LLMにキャラクターの話し方だけでなく「キャラ独自の内面の思考プロセス」も模倣させる手法"
source: "https://ai-data-base.com/archives/86025"
author:
  - "[[AIDB Research]]"
published: 2025-02-27
created: 2025-06-13
description: "本記事では、LLMによるキャラクター再現に関する新しい研究を紹介します。従来のアプローチが表面的な情報の模倣に留まる中、この研究は人物の思考様式や価値観といった深層的な側面まで再現しようと試みています。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、LLMによるキャラクター再現に関する新しい研究を紹介します。

従来のアプローチが表面的な情報の模倣に留まる中、この研究は人物の思考様式や価値観といった深層的な側面まで再現しようと試みています。

単なる言葉遣いの模倣を超え、文学作品や歴史的人物との本格的な対話を実現する可能性を秘めた取り組みとして注目されています。

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_86025-1024x576.png)

参照論文情報は記事の下部に記載されています。

## 背景

LLMによるキャラクター再現は、日常生活からエンターテイメント、教育まで幅広い分野で応用可能性を秘めています。ユーザーが親しみを感じる架空の人物や歴史上の偉人との対話が実現すれば、より自然でパーソナライズされたコミュニケーション体験が生まれます。

また、文学作品や映画の登場人物との対話を通じた深い作品理解や、歴史的人物との対話による教育効果も期待されています。しかし、真に説得力のあるキャラクター再現には、単なる言葉遣いの模倣だけでなく、その人物特有の思考の理解が不可欠です。

LLMによるキャラクターの再現について、従来の研究には明確な限界がありました。これまでの手法では表面的な情報や単純な対話ログに頼る傾向があり、その結果としてキャラの内面や世界観といった深い部分への理解が不足していました。

人間の「個性」とは本質的に複雑なものであり、単なるプロフィール情報の記憶だけでは到底捉えることができません。実際の人物を正確に表現するためには、表面的な情報を超えて、その人物独自の思想体系や倫理観、物事への姿勢といった内面的要素も再現する必要があります。

この課題に対応するため、今回研究者たちは新たなアプローチを模索しました。文章における語彙選択や文体といった言語的特徴はもちろんのこと、問題に対する思考プロセスや価値判断の根幹まで再現できるよう、多面的な学習方法の開発に着手したのです。

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_86025_1.png)

特定のキャラになりきって応答する手法を比較したイメージ

## キャラクターをどう評価するか

本研究では「深いレベルでのキャラクターの再現」を”数学的に”定義しています。研究者たちはLLMに複数の異なる課題を与えることで、人間らしい個性や思考パターンがどこまで正確に表現できるかを評価しました。

この評価方法は、ある人物の言葉遣いや文体といった表面的な特徴だけでなく、その思想や価値観といった内面的な側面まで再現できているかを確かめるために設計されました。分かりやすく言えば、「その人らしさ」を様々な角度から検証できるよう、複数の異なるテストが設けられたのです。

モデルは「M」として呼ばれ、このモデルMが持つパラメータ（θで表される）に、対象となる人物特有の語り口や思考パターンが刻み込まれていきます。「Mがどう答えるか」や「どの選択肢を選ぶか」を通じて、人格の再現度が評価される仕組みです。

### 選択式問題による評価

最初の評価方法は選択式の質問に答えさせるものです。例えば「あなたが文学の停滞を批判するならば、どの意見に最も同意しますか？」という問いに対して、複数の選択肢からモデルMが最も適切と判断するものを選びます。

この方法は非常に分かりやすい評価が可能で、「正しい選択肢を選べたか」という形で、モデルが対象人物の主張や考え方をどれだけ理解しているかを数値化できます。

### 自由回答形式による評価

次の評価方法は、自由記述形式での回答生成です。例えば「あなたが見てきた社会問題の原因は何だと考えますか？」といった質問に対して、モデルMが文章として回答します。

ここでは「その人物らしい」意見や表現ができているかに焦点が当てられます。研究チームは、生成された回答を「内容面」と「文体面」の二つの観点から評価しました。つまり、回答が対象人物の本来の考え方をどれだけ反映しているか、また文章の書き方や言い回しがどれだけ似ているかを別々に採点したのです。

### 文体変換による評価

最後に取り入れられたのは文体変換の課題です。これは無味乾燥な文章を「対象人物らしい」書き方に変換できるかを試すものです。

例えば、あえて事務的な表現で書かれた文章を、対象となる作家特有の比喩や言い回し、語彙選択を用いて書き直す、といった具合です。研究では、変換された文章が元の人物の文体にどれだけ似ているかを客観的な指標で測定しています。

これら三つの評価方法（選択式問題、自由回答、文体変換）を組み合わせることで、人物像の表面的な模倣を超えた深層理解が可能になると考えられました。一つの評価方法だけでは見落としてしまう側面も、多角的なアプローチによって照らし出すことができるのです。

研究結果では、適切に訓練されたモデルMが内容と文体の両面で対象人物を深く理解できるようになったことが報告されています。詳細は後述します。

## キャラクターの思想と文体をどう学習させるか

研究チームは、LLMに人物の思想と文体を効果的に取り込むための段階的な手法を開発しました。単に大量のテキストを学習させるだけでは、対象となる人物の独特の言葉遣いや思想を正確に再現するのは難しいため、より緻密なアプローチが採用されています。

以下では、前処理段階、複数の下流タスクによる微調整、そして効率的な学習を可能にするCharLoRAという手法について順に説明します。

### 人物の基本的な文体と思想を学ばせる前処理

まず第一段階として、対象となる人物の文体や主張をLLMに吸収させます。汎用的な文章理解能力をすでに持つLLMをベースに、個別の作家や思想家の特徴的な言い回しや考え方を学習させます。

具体的には、著者が書いたエッセイを大量に収集し、それを以下の二つの形式でモデルに与えます。

1. **原文そのままの形式** ：著者が書いた通りの文章
2. **視点を三人称に置き換えた形式** ：例えば「私はこう考える」という一人称の文を「彼はこう論じている」という三人称に書き換えたもの

この視点変換には重要な意図があります。モデルは「発話者自身の一人称的主張」と「客観的に表現された同一内容」を並行して学習することで、書き手の思想と文体を区別して理解できるようになります。つまり「何を言っているか」と「どう言っているか」を分けて捉える能力が育まれるのです。

前処理段階では、長文のエッセイを一文ずつ分割し、それぞれに視点転換を施したペアデータを作成します。作者特有の書き方や論理展開がモデルに自然と染み込んでいくというイメージです。

### 複数のタスクで人物像を多面的に鍛える微調整

前処理によって文章全般の書き口や思想の特徴がある程度取り込まれた後は、「複数の下流タスクを使った微調整」へと進みます。人物らしさをより立体的に表現するため、以下の三種類のタスクが設計されました。前セクションで説明した「問題の定式化」をそのまま踏襲した内容です。

#### 1\. 選択式回答（Multiple-Choice Question）

このタスクでは、人物の思想に沿った正答を選べるかどうかが評価されます。作品に基づいて作られた問題文と四つの選択肢が提示され、どれを選ぶかをLLMに判断させます。

例えば「社会改革について、あなたはどの立場を支持しますか？」という問いに対し、実際の人物が著作の中で示した価値観に最も近い選択肢を選べるかが試されます。このプロセスを通じて、モデルは対象人物の思想体系をより深く理解していきます。

#### 2\. 自由形式の質疑応答（Generative Question Answering）

次のタスクでは、特定の質問に対してLLMが文章生成の形で回答します。例えば「現代社会における文学の役割をどう考えますか？」といった問いに対し、元の著作に近いトーンと深みを持った見解を示せるかが検証されます。

ここでは単なる事実の羅列ではなく、対象人物特有の論理展開や価値判断、そして文体的特徴が求められます。評価では内容の忠実さと文体の類似度が別々に採点され、「本人が言いそうな回答」がどれだけ生成できているかが測定されます。

#### 3\. 文体変換（Style Transfer）

三つ目のタスクでは、中立的な文章を与えて、「この人物ならどう表現するか」という観点から文体を変換させます。長年にわたって独自の論調や比喩表現を磨いてきた作家の場合、その特徴的な言葉選びや論理展開を再現できるかが問われます。

例えば「天気が悪くて外出できない」という無機質な文を、対象となる作家特有の比喩や語彙を用いて書き換えるといった具合です。文体の類似度を測る指標を用いて、変換がどれだけ忠実に行われたかが客観的に評価されます。

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_86025_2.png)

前処理と微調整を組み合わせた学習フローの概要図

### 効率的な学習のための手法CharLoRA

上記のプロセスを効率化するため、今回CharLoRA（キャラクターLoRA）という独自の手法が考案されました。これは、ベースとなるLLMの全パラメータを更新せず、一部のみを低ランク行列として追加学習するLoRA（Low-Rank Adaptation）をさらに改良したものです。

CharLoRAの本質は、二種類のパラメータを使い分ける点にあります。

1. **共有パラメータ** ：人物像に関する基礎的な知識（文体や思想の核心部分）を維持
2. **タスク固有パラメータ** ：各タスク（選択問題、質疑応答、文体変換）に最適化された情報

複数のタスクを同時に学習しても人格的特徴やスタイルは崩れません。前処理段階では文章を予測しながら作家特有の表現を学習し、微調整段階では三種類のタスクを通じて異なる側面の能力が育まれていきます。

LLMの全パラメータ（数十億～数千億）ではなく、少量の追加パラメータだけを更新するため、計算負荷は大幅に軽減されます。それでいて、人物の本質的な特徴を損なうことなく微調整が可能になるという、まさに一石二鳥の効果が確認されています。

様々な形式の応答練習を経ることで、情報の正確さと独特の文体が総合的に向上していくといった手法です。

なお、本手法や、本手法を用いて実際に開発されたモデルは下記のリポジトリに公開されています。

[https://anonymous.4open.science/r/characterbot-9445/readme.md](https://anonymous.4open.science/r/characterbot-9445/readme.md)

## キャラクターボット作成実験と性能評価結果

研究チームは、本手法を用いて開発したLLMがどれほど正確に対象人物の思想と文体を再現できるか、多角的な検証を行いました。単に「似ている」という曖昧な評価ではなく、具体的なデータや客観的な指標に基づいて性能が測定されています。

以下では、実験に使用されたデータセット、比較対象となった他のモデル、評価指標、そして得られた結果について説明します。

### データセット

実験の土台となったのは、対象人物（魯迅）が残した17の随筆集から集められた638篇の文章です。研究チームが多彩なエッセイを選んだのには理由があります。文体と思想の両面を効果的に学習させるには、様々なテーマや文脈に触れさせることが重要だからです。

これらの文章は目的に応じて適切に処理されました。まず、前処理フェーズでは視点変換（一人称から三人称への書き換え）などの操作が行われました。そして全体の85%をトレーニングセット、5%を検証セット、10%をテストセットとして分割しています。

微調整段階では、以下の三種類のタスクに対応するデータセットが別途作成されました。

1. **選択式問題用データ** ：作者の考え方に基づいた四択問題
2. **自由形式質疑応答用データ** ：作者の思想や価値観を問う質問と模範回答
3. **文体変換用データ** ：中立的な文章と、それを作者の文体で表現した対訳

各データセットは原文から逸脱しないよう慎重に作られ、人物像を多面的に捉えられるよう設計されています。

### ベースラインモデル

研究の成果を客観的に評価するため、様々な比較対象モデルが選ばれました。

**汎用的な多言語LLM**

- Llama 3.1-8B：多言語処理に対応した大規模モデル
- Qwen2.5-7B：中国語処理に強みを持つモデル
- GPT-4o：多様な応答能力を持つ高性能モデル

**キャラクター再現に特化したモデル**

- CharacterGLM-6B：会話型AIに役割演技させる目的で開発されたモデル
- Baichuan-NPC-Turbo：対話におけるキャラクター性を重視したモデル
- Tongyi Xingchen：パーソナライズされた対話プラットフォーム

**文体変換に特化したモデル**

- LuXun-GPT：入力文を魯迅の文体に変換することに特化したモデル

### 実装の詳細

実験環境としては、 [PyTorch](https://ai-data-base.com/archives/26256 "PyTorch") をフレームワークとし、NVIDIA A100 [GPU](https://ai-data-base.com/archives/26570 "GPU") を計算基盤として使用しています。今回の実験では中国語テキストを扱うため、ベースモデルにはQwen2.5-7B-Instructが選ばれました。

モデルの訓練には、前述で紹介したCharLoRAと呼ばれるカスタマイズされた低ランク適応法が採用されています。

学習設定として、以下のハイパーパラメータが使用されました。

- 学習率：5.0×10^(-5)
- [バッチサイズ](https://ai-data-base.com/archives/26582 "バッチサイズ") ：4
- [エポック](https://ai-data-base.com/archives/26594 "エポック") 数：3
- 最大トークン長：前処理段階で2048、微調整段階で1024
- LoRAランク：64（低ランク行列の次元数）

タスクごとに学習データを切り替えながら段階的に訓練が進められ、計算資源を効率的に活用しつつ、多彩な課題に対応できるモデルが構築されました。

### 評価指標

提案モデルの性能は、タスクごとに異なる評価指標で測定されました。

**選択式問題タスク**

[正解率](https://ai-data-base.com/archives/25930 "正解率") （Accuracy）：正しい選択肢を選べた割合

**自由形式質疑応答タスク**

内容スコア（Content Score）：回答が原著者の思想をどれだけ正確に反映しているか（1〜5段階）

文体スコア（Style Score）：回答が原著者の言語表現をどれだけ再現しているか（1〜5段階）

**文体変換タスク**

BLEU：生成文と参照文の単語一致度を測る指標

ROUGE-1：生成文と参照文の単語重複率を測る指標

スタイルマッチングスコア：文体の類似度を専用のモデルで評価した指標

評価は専門家の監修のもと行われました。

### 主な結果

実験の結果、提案されたアプローチが比較対象となった既存モデルを多くの指標で上回ることが確認されました。

選択式問題タスクでは、提案モデルは88.0%の正解率を達成し、次点のTongyi Xingchen（78.8%）やQwen2.5-7B（78.7%）を大きく引き離しました。この結果は、モデルが対象人物の思想体系を深く理解できていることを示しています。

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_86025_3.png)

選択式回答・自由応答・文体変換タスクにおける実験結果一覧

自由形式質疑応答タスクでは、内容スコアでGPT-4oと同等の3.214を記録し、文体スコアでは2.885を達成して他のモデルを上回りました。つまり、対象人物の考え方だけでなく、独特の表現方法も効果的に再現できていると言えます。

文体変換タスクでも、BLEU（0.293）、ROUGE-1（0.410）、スタイルマッチングスコア（0.937）のすべてで最高値を記録し、文体変換専用のLuXun-GPT（それぞれ0.127、0.283、0.387）をも上回りました。単なる語彙選択の模倣ではなく、文章の論理構造や独特の表現パターンまでを学習できていることが裏付けられました。

これらの結果から、前処理と複数タスクでの微調整を組み合わせた本研究のアプローチが、人物の表面的な模倣を超えた深い理解と再現を可能にしたことが示されました。特に視点変換技術と複数タスクの併用が、思想と文体の両面を捉える上で重要な役割を果たしたと考えられます。

## 詳しい分析と考察

研究チームは実験結果を詳細に分析し、さまざまな角度からキャラクターボットの性能を評価しました。以下では、実験から得られた主な知見と今後の展望について解説します。

### 要素別の効果検証

研究チームはモデルの主要構成要素がそれぞれどのように性能に貢献しているのかを調査するため、いくつかの部品を取り除いた「縮小版」のモデルでも評価を行いました。まず、CharLoRA（キャラクター特化型の低ランク適応法）を通常のLoRAに置き換えたパターンでは、選択問題の正解率が約9%低下したほか、文体スコアも顕著に減少しました。したがって、タスク間で知識を共有しながらも個別最適化を行うCharLoRAの仕組みが重要であることが明らかになりました。

また、視点変換処理（一人称から三人称への書き換え）を省いた場合も、自由形式回答の文体スコアが約15%低下するなど、性能の低下が見られました。視点変換によって「何を言っているか」と「どう言っているか」を分けて学習できるようになるため、文体再現力が高まったものと考えられます。

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_86025_5-1024x208.png)

アブレーション実験の結果比較図

これらの実験から、提案されたアプローチの各構成要素がそれぞれ重要な役割を果たしており、総合的な性能向上に寄与していることが裏付けられました。

### ユーザー評価による検証

数値的な評価だけでなく、実際の人間による主観評価も行われました。研究チームは中国文学に精通した専門家を評価者として招き、モデルの出力結果を原文と比較してもらいました。

評価では、内容の正確さ、文体の再現度、そして全体的な一貫性について5段階で採点が行われました。その結果、提案モデルはGPT-4oやTongyi Xingchenといった最先端モデルと比較しても、内容面で約7%、文体面で約12%高いスコアを獲得しました。

専門家からは「原文の思想をよく捉えている」「魯迅特有の皮肉や比喩表現が再現されている」といった肯定的なコメントが寄せられました。一方で、「時折現代的な表現が混じる」といった指摘もあり、完全な再現にはまだ課題があることも明らかになっています。

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_86025_6.png)

人間評価による出力内容と文体評価のスコア比較

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_86025_7-1024x652.png)

モデルCharacterbotとベースライン各モデルの出力事例対比表

### 成功例と課題

モデルの出力を詳細に分析した結果、いくつかの興味深いパターンが浮かび上がりました。成功例としては、魯迅特有の社会批判や皮肉表現が適切に再現されたケースが多く見られました。例えば「伝統文化に対する批判的視点」や「知識人の責任論」など、魯迅の中核的な思想が正確に表現されていました。

一方で、課題も明らかになりました。歴史的な文脈が複雑に絡む話題では、時代背景の理解が不十分なケースが見られたほか、魯迅が生きていなかった近現代の出来事について質問された場合、回答の一貫性が損なわれることもありました。

また、極端に短い質問や曖昧な問いかけに対しては、文体の再現度が低下する傾向も確認されました。これらの課題は、モデルがより多様な文脈や質問パターンに対応できるよう、さらなる改良の余地があることを示しています。

### 今後の展望

研究チームは、キャラクターボットの今後の発展方向性についても言及しています。まず技術的な観点からは、より少ないデータでも効果的に学習できる手法の開発や、複数の人物の特徴を同時に学習させる「マルチキャラクターモデル」の構築などが挙げられています。

応用面では、教育分野での活用が最も期待されています。文学作品の理解を深めるための対話型学習ツールや、歴史上の偉人との仮想対話を通じた歴史学習支援などが考えられます。また、文化遺産のデジタル保存という観点からも、偉大な思想家や芸術家の思考プロセスを記録・再現することの意義が強調されています。

一方で倫理的な課題も指摘されており、架空の発言を実在の人物に帰属させるリスクや、歴史的人物の思想を現代的な文脈で解釈する際の慎重さの必要性なども議論されています。これらの課題に対応しつつ、技術を発展させていくことが今後の重要な方向性となるでしょう。

## まとめ

本記事では、LLMを活用してキャラクターの文体と深層的な思考過程を再現する研究について解説しました。従来の手法が表面的な情報の模倣にとどまっていたのに対し、この研究では人物の内面まで掘り下げた再現を目指す新たなアプローチが提案されています。

研究チームが開発したCharacterBotは、LLMに付与した追加パラメータと多段階の学習設計を通じて、単なる文体の模倣を超えた論理展開や思想の再現を実現しようとしています。前処理段階での視点変換技術や、複数タスクを組み合わせた微調整プロセスといった工夫により、対象人物の思考様式や価値観までも捉えようとする試みが注目に値します。

実験結果からは、このアプローチが既存の手法と比較して優れた性能を示していることが伺えます。選択式問題での高い正答率や、自由形式回答における内容・文体の両面での高評価は、モデルが人物の表層的な特徴だけでなく、深層的な思想構造も把握できていることを示唆しています。

しかしながら、研究にはいくつかの限界点も見受けられます。論文全体の書き方からは研究者の立場に偏った主張が見られる部分もあり、より客観的な検証が必要と感じられます。また、実験が一人の文学者（魯迅）のみを対象としていることから、この手法が他の著者や異なるタイプの文章にも同様に適用できるかどうかは未知数です。

今後の展望としては、様々な著者や時代の文章を扱った検証や、異なる文化的背景を持つ人物への応用が期待されます。また、学術的な再現性の向上や、より多角的な視点からの評価方法の確立も課題となるでしょう。

**参照文献情報**

- タイトル：Beyond Profile: From Surface-Level Facts to Deep Persona Simulation in LLMs
- URL：https://doi.org/10.48550/arXiv.2502.12988
- 著者：Zixiao Wang, Duzhen Zhang, Ishita Agrawal, Shen Gao, Le Song, Xiuying Chen
- 所属：Mohamed bin Zayed University of Artificial Intelligence, Shandong University

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[Claude 3.7 Sonnet　その安全性と性能](https://ai-data-base.com/archives/86028)

[LLMのアンサンブル（組み合わせ）で重要なのは多様性か、それとも優秀さか。](https://ai-data-base.com/archives/86165)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)