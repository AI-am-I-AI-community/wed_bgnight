---
title: "小さなRetrieverとLLMの組み合わせによる実用的なワークフロー生成システム またはRAGで幻覚を減らす手法"
source: "https://ai-data-base.com/archives/68219"
author:
  - "[[AIDB Research]]"
published: 2024-04-25
created: 2025-06-13
description: "自動化のためのワークフロー生成における、ハルシネーションを低減するRAGシステムに関する研究について紹介します。限られたリソースでも信頼性の高いLLMアプリケーションを構築するためにRAGの実装を工夫した取り組みです。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

自動化のためのワークフロー生成における、ハルシネーションを低減するRAGシステムに関する研究について紹介します。

限られたリソースでも信頼性の高いLLMアプリケーションを構築するためにRAGの実装を工夫した取り組みです。

実験の結果、わずか110Mパラメータの小さなretrieverと7BパラメータのLLMを組み合わせるだけで、性能を損なうことなく実用的なシステムを構築できることが示されています。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68219-1024x576.jpg)

**参照論文情報**

- タイトル：Reducing hallucination in structured outputs via Retrieval-Augmented Generation
- 著者：Patrice Béchard, Orlando Marquez Ayala
- 所属：ServiceNow

**本記事の関連研究** ：

- [LLMによりクエリを生成するアプローチで情報検索の精度を上げる方法](https://ai-data-base.com/archives/66942)
- [RAGにおいてLLMが「役立たない情報を無視」できるようにする『RAFT』QAタスクで従来の手法を大幅に上回る結果を達成](https://ai-data-base.com/archives/66269)
- [RAGにおいて取得された情報と事前知識が矛盾しても、情報に説得力があるときLLMは受け入れる](https://ai-data-base.com/archives/64979)
- [ファインチューニングとRAGを比較実験した結果　LLMに外部知識を取り入れる手法としての違い](https://ai-data-base.com/archives/63401)

## 背景

近年LLMの性能向上によって、自然言語による指示から、プログラミングコードなどの構造化された出力を、高精度に生成可能になってきました。

同様に、自然言語の指示から、構造化された「ワークフロー」を生成するアプリケーションも開発されています。ワークフローとは、ある一連の手続きの流れをシステム化したものです。

ビジネスの場では、このようなワークフローを用いて単純作業を自動化し、生産性を向上させる場面が多くあります。特に、最近では生成AIの活用によって、簡単な自然言語の指示だけで、非エンジニアでもワークフローを生成できると期待が高まってきました。

しかし、LLMには「幻覚（ハルシネーション）」という決定的な弱点があります。ハルシネーションとは、LLMが事実とは異なる出力を生成してしまう問題のことです。

その問題に対処するために、RAG(Retrieval-Augumented Generation)という手法が用いられてきました。RAGとは、外部の情報を検索し、その情報をもとにLLMが回答を生成するという手法です。ハルシネーションを低減させ、事実にもとづく出力が実現できるとされています。

本論文では、自然言語の指示からワークフローを生成するタスクにおいて、RAGを用いることでハルシネーションを減らし、より品質の高いワークフローを生成する方法が提案されています。

本研究では、ワークフローはJSON形式として表現され、各処理ステップがJSONオブジェクトとなります。下図は、テキスト指示と、それに対応するJSONドキュメントの例です。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68219_3.png)

上図の例では、trigger（トリガー）によってワークフローstepsが開始されます。ここでは、triggerはdaily（毎日）となっているので、毎日特定のタイミングでstepsが開始されるでしょう。

そして、steps内のstepの順番に、nameに記載されている処理が行われます。

## 方法論

本研究で提案されたRAGの概要は、以下の図の通りです。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68219_4-1024x254.png)

まず、ユーザーがテキスト指示を入力すると、Retrieverがそれに基づいて、必要な処理とステップをデータベースから検索します。

そして、先ほどRetrieverが抽出した処理とステップに関する情報を、ユーザーによるテキスト指示文に加え、ともにLLMに入力します。

最後に、入力に基づいて、LLMがワークフローを生成するのです。

### Retrieverの学習

Retrieverの目的は、「ユーザーからの自然言語の指示」と「JSONオブジェクト」の対応関係を学習することです。

具体的には、ワークフローを生成する際に必要なステップやデータベーステーブル名を、ユーザーの自然言語入力から推測できるよう学習します。

この論文での「テーブル」とは、データベーステーブルのことを指しています。ワークフローを生成する際、ステップの一部にはデータベーステーブル名を指定する必要があります。

例えば、ある処理を実行する前に、特定のデータベーステーブルから情報を取得したり、処理の結果をデータベーステーブルに書き込んだりする場合などです。

Retrieverモデルの学習手順は、以下の通りです。

1. 「ユーザークエリ」と「ステップ/テーブルのJSONオブジェクト」のペアを用意
2. Siamese [Transformer](https://ai-data-base.com/archives/26535 "Transformer") エンコーダを用いて、クエリ、ステップ、テーブルをそれぞれベクトルに変換
3. ポジティブペア(対応するクエリとステップ/テーブル)とネガティブペア(対応しないもの)を用意
4. 対照学習により、ポジティブペアの距離を最小化し、ネガティブペアの距離を最大化するように学習

ネガティブペアの構築には、ランダム [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") 、BM25、ANCEの3つの戦略を用いています。また、 [損失関数](https://ai-data-base.com/archives/27017 "損失関数") には対照損失を使用し、ポジティブペアのコサイン類似度を最大化し、ネガティブペアのコサイン距離を最小化するように学習します。

推論時は、FAISSを用いてステップとテーブルのインデックスを構築し、ユーザークエリに対して最大K個のステップとテーブルを検索します。

### LLMの学習

本研究では、RetrieverとLLMを同時に学習するEnd-to-endのRAGシステムではなく、両者を別々に学習されています。

まず、学習済みのRetrieverを用いてデータセットを拡張し、各サンプルにステップ名とテーブル名の候補を追加します。そして、このデータセットを用いて、通常の教師あり学習でLLMをファインチューニングします。

LLMの入力にRetrieverの出力をJSONフォーマットで挿入することで、構造化された出力の生成タスクが容易になります。

下図は、学習サンプルの例を示しています。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68219_2.jpg)

上図最後の4行以外はLLMへの入力であり、Retrieverが提案したテーブルとステップが下線付きで示されています。

ちなみにベースのLLMについては、StarCoderBaseやCodeLlama-7B、Mistral-7B-v0.1などが用いられています。その際、モデルサイズのRAG性能への影響を測定するために、異なるサイズのモデルをファインチューニングしています。

また、今回使用されたStarCoderBaseは、JSONを含む多くのプログラミング言語で事前学習されており、構造化データに強いことが期待されます。

さらに、Retrieverモデルとしては、all-mpnet-base-v2をベースに使用しており、GTRT5モデルと比較しています。

### データセット

RAGシステムの開発のために、あらかじめ独自データセットが構築されています。

まず、社内のエンタープライズプラットフォームのデプロイメントから、約4,000件のワークフローの例を抽出し、アノテーターに自然言語によるキャプションを記述してもらっています。

以下の表は、社内のデータセット分割の統計を示しています。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68219_7.png)

ちなみに、これらの社内データセットの大部分がITドメインに偏っているため、HRや財務など多様なドメインに適用するために、5つの分野のワークフローもデータセットに追加しています。

以下の表は、これらのドメインのデータの統計を示しています。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68219_9.png)

## 評価指標

RAGシステム全体を評価するために、3つの指標が使用されています。

- Trigger Exact Match (EM)：生成されたJSONトリガーが正解と完全に一致するかを検証
- Bag of Steps (BofS)：生成されたJSONステップと正解ステップの重複度を、順序によらない形で測定
- Hallucinated Tables (HT)とHallucinated Steps (HS)：ワークフローごとに存在しないテーブル/ステップの割合（LLMによる捏造）を測定

Retrieverの評価において、ステップにはRecall@15を、テーブルにはRecall@10を使用しています。

その際、自然言語の指示が与えられたとき、それぞれのインデックスからトップKのステップ/テーブルを検索し、ワークフローを表すJSONドキュメントに含まれるステップとテーブルをカバーしているかを検証しています。

## 実験結果

### Retriever encoder

Retrieverの性能を評価するため、「Human Eval（人手で作成されたデータセット）」分割でのステップとテーブルの検索結果を示しています。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68219_6.png)

結果より、GTR-T5のようにエンコーダのサイズを大きくしても、両方の検索指標で大幅な改善は見られませんでした。

一方で、最小のエンコーダー（110Mパラメータ）をファインチューニングした結果、また、すべてのネガティブ [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") 戦略で微調整を行った結果、all-mpnet-base-v2が最高の性能を発揮することが分かっています。

### RAG性能

Retrieverを使った場合と、使わなかった場合の性能の違いは、以下の通りです。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68219_1.png)

Retrieverを使わない場合、StarCoderBaseモデルのサイズを大きくすると、Bag of StepsとTrigger Exact Matchの指標は向上しますが、一定ではありません。一方で、Retrieverを使うと、より一貫した改善が見られました。

また、Retrieverを使うことで、小さなLLM(3B)でも、Retrieverなしの大きなLLM(15.5B)と同等以上の性能を達成できたことが示されています。

さらに、大量の自然言語データ（非構造データ）で事前学習したLLM(CodeLlama-7B, Mistral-7B)は、RAGを使ってもStarCoderBaseより劣っているため、事前学習データの性質が本研究でのタスクに合っていない可能性があると考察されています。

### OOD評価

RAGでファインチューニングしたStarCoderBase-7Bモデルを、表2で示した5つのOOD分割でテストした結果、Retrieverのおかげで全ての指標が「Human Eval」分割の結果と同等であることが分かりました。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68219_8.png)

平均して、Retrieverの影響で全てのOOD指標が「Human Eval」分割のドメイン内の結果と同等であることがわかります。

### エラー分析

生成されたワークフローのエラーパターンを調べたところ、RetrieverとLLMの両方に起因する問題が見られました。

複雑なフローでは、使用頻度の低いステップを検索する必要がありますが、重要なコンポーネントがRetrieverの提案に含まれていない場合、LLMが要件に沿った有効なワークフローを生成するのは難しくなります。

そこで、クエリをより短いテキストに分解し、各ステップに対して検索ステップを詳細化することができます。これは、1回の検索呼び出しを行うのではなく、ステップごとに複数の検索呼び出しを行うことを意味します。

また、LLMが望ましい構造を生成しない場合もあります。これは、IF、TRY、FOREACHなどのロジックを決定するステップを使用する際によく見られます。

ちなみに、以下の図で生成されたワークフローの正誤例を確認できます。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68219_5-1024x798.jpg)

上図では、左が完璧な正答、真ん中がRetrieverによるエラー、右がLLMによるエラーを表します。

### 実システムへの適用における課題

提案手法を実際のシステムに適用する際の工夫や課題についても述べられています。

モデルに7Bのパラメータを採用したことで、1つの [GPU](https://ai-data-base.com/archives/26570 "GPU") を使用して [バッチサイズ](https://ai-data-base.com/archives/26582 "バッチサイズ") を大きくし、処理速度を向上させることができましたが、応答速度にはトレードオフが生じます。特に、トークン数が多い長いクエリは、多くの生成トークンを必要とし、多数の短いクエリと一緒にバッチ処理する際に、処理のボトルネックとなることがあります。

ただ、ストレステストとユーザー調査により、システムの全体的な応答時間は許容範囲内であることが確認されました。

また、Retrieverに非常に小さなエンコーダ（110Mパラメータ）をファインチューニングした結果、同じ [GPU](https://ai-data-base.com/archives/26570 "GPU") 上でLLMと一緒に配置しても、影響はほとんどないことがわかりました。つまり、Retrieverの小さなサイズのおかげで、CPU上にも配置することが可能です。

その他、システムの応答時間を短縮するためのアイデアとして、以下のようなものが挙げられています。

- 構造化された出力形式をJSONからYAMLに変更してトークン数を減らす
- 推論の並列化
- ワークフロー全体ではなく1ステップずつユーザーにストリーミング

## まとめ

この論文では、Retrieval-Augmented Generation (RAG)を用いることで、自然言語の指示からワークフローを生成する際の「幻覚(ハルシネーション)」を低減できることが示されました。

提案手法では、Retrieverエンコーダーを用いて、自然言語とJSONオブジェクトの関連付けを学習し、そこから得られた知見をLLMに組み込むことで、適切なワークフローの生成を可能にしています。

実験の結果、RAGを用いることで幻覚が大幅に減少し、生成されるワークフローの品質が向上することが確認されました。また、高性能な小さなRetrieverを用いることで、LLMのサイズを小さくしてもパフォーマンスを維持できることが示されました。

- 参照論文URL： [https://arxiv.org/abs/2404.08189](https://arxiv.org/abs/2404.08189)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[強くて軽いモデルPhi-3の評価結果　Microsoftの論文（テクニカルレポート）より](https://ai-data-base.com/archives/68184)

[LLMでWikipediaのような文書を作成する方法「STORM」スタンフォード大学研究者ら開発](https://ai-data-base.com/archives/68269)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)