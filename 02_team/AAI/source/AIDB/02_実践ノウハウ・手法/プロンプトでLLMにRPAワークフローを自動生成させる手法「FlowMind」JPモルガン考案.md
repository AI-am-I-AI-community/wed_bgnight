---
title: "プロンプトでLLMにRPAワークフローを自動生成させる手法「FlowMind」JPモルガン考案"
source: "https://ai-data-base.com/archives/68095"
author:
  - "[[AIDB Research]]"
published: 2024-04-23
created: 2025-06-13
description: "LLMとユーザーフィードバックを巧みに組み合わせることで、即興タスクに対応可能な自動ワークフロー生成システムを実現する手法「FlowMind」が発表されています。幅広い産業での応用が期待されるフレームワークです。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

LLMとユーザーフィードバックを巧みに組み合わせることで、即興タスクに対応可能な自動ワークフロー生成システムを実現する手法「FlowMind」が発表されています。幅広い産業での応用が期待されるフレームワークです。

JPモルガンの研究者らは、金融分野のベンチマークデータセットNCEN-QAを作成し、自動ワークフロー生成の性能を検証しました。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68095-1024x576.jpg)

**参照論文情報**

- タイトル：FlowMind: Automatic Workflow Generation with LLMs
- 著者：Zhen Zeng, William Watson, Nicole Cho, Saba Rahimi, Shayleen Reynolds, Tucker Balch, Manuela Veloso
- 所属：JPモルガン

**本記事の関連研究** ：

- [GPT-4のコード生成能力を飛躍的に向上させるプロンプトフレームワーク『AlphaCodium』](https://ai-data-base.com/archives/63003)
- [LLMに敢えて間違わせてルールを覚えさせるプロンプト手法　Google DeepMindなどが考案](https://ai-data-base.com/archives/64057)
- [LLMにタスクに応じた推論プロセスを自ら考えるようにするプロンプト手法『SELF-DISCOVER』Google DeepMindなどが開発](https://ai-data-base.com/archives/64136)
- [プロンプトに例を多く載せるほど、どんなタスクでも性能が上がるのか？DeepMindによる『Many-shot Learning』の実験結果](https://ai-data-base.com/archives/67883)

## 背景

RPAの分野は大きく発展したものの、ユーザーから要求される即興的あるいは予測不可能なタスクに対しては、まだ対応できる手法が十分に確立されていません。現状のRPAが基本的に専門家の知識と明確に定義された手順に依存しているためです。

そんな中、LLMがRPAタスクを自動化することに期待が寄せられています。LLMのコーディング能力に関する研究も盛んに行われており、LLMは、few-shot学習 (少数の例を用いて新しいタスクを学習する手法) といったプロンプトエンジニアリング手法がコード生成性能を上げるなどの現象が報告されています。

現在、LLMのコード生成能力を活用し、Langchain、HuggingFace’s [Transformer](https://ai-data-base.com/archives/26535 "Transformer") Agent、AutoGPTなどのワークフロー生成ツール（いわゆるエージェント関連ツール）が開発されています。しかし、データプライバシーの問題や、組み込む関数やモデルの種類に関する柔軟性の欠如といった課題があると指摘されています。

このような背景のもと、研究者らはLLMを用いた自動ワークフロー生成システム「FlowMind」を考案しました。データプライバシーの問題に対処しつつ、ユーザーリクエストに柔軟に対応できる汎用的で適応性の高いアプローチだと言います。要するに、エージェントに期待される機能の一種をプロンプトエンジニアリングで実装しようという試みです。

今回、金融分野におけるベンチマークで本手法の評価も行われました。以下で手法と実験結果の詳細を紹介します。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68095_1.png)

FlowMindの概念図。ドメイン専門家が設計した反復タスクの自動化を超えて、ユーザーが要求する即興的タスクをその場でワークフローを生成することで自動化するというコンセプト。

## FlowMind

FlowMindは、2つのステップで機能します。

### ステップ1: LLMへのレクチャー

FlowMindのステップ1では、LLMにタスクの文脈と利用可能なAPIについてレクチャーを行います。研究者らは、「レクチャーレシピ」と呼ばれる汎用的なプロンプト設計方法を提案しました。以下の3つの要素で構成されています。

**文脈(Context)**

ユーザーから期待されるタスクやクエリのドメインを書きます。例えば、研究者らの実験では、ユーザーからの情報検索を処理する文脈を設定しました。

**API**

利用可能なAPIの構造化された説明のリストを提供します。各関数の名前、入力引数、出力変数など。関数名、入力引数、出力の説明は、上記の文脈に関連するものであり、LLMが関数を理解して適切に使用できるようにする必要があります。

**コード(Code)**

最後に、LLMにユーザークエリやタスクを受け取ったら提供されたAPIを使ってワークフローのコードを書くように指示します。

上記レシピに従って生成されたプロンプトの例が以下です。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68095_3-1024x378.png)

```js
（※コンテキスト）
想像してみてください。私たちはドキュメントボットを使って作業しています。このボットの役割は、ユーザーからの情報に関する質問に応答することです。
主に使用できる関数は以下の通りです:

（※ツールの説明）
get_all_reports(): すべてのN-CENレポートを返します。
get_report(fund_name): fund_nameで指定されたファンドを含むN-CENレポートを返します。
segment_report(report): 入力されたレポートから、各ブロックがファンドを記述しているパースされたブロックを返します。
fetch_block(report, fund_name): 入力されたレポートの中から、指定されたファンドに対応するブロックを返します。
extract_entity(block, entity_label): 入力されたテキストブロックから、指定されたentity_labelにあるエンティティの名前を抽出します。
extract_value(block, value_name): 入力されたテキストブロックから、value_nameで指定された数値を抽出します。

（※コード生成の指示）
ユーザークエリを待ち、これらの関数を使用してpythonコード(モジュール化して)で応答してください。ユーザークエリの準備ができたら教えてください。
```

### ステップ2: ワークフローの生成と実行

次に、LLMがステップ1で得たAPIの知識を活用して、ユーザーのクエリやタスクを受け取り、対応するワークフローコードを生成します。

ここではコード生成とコード実行の2つの重要な要素があります。コード生成では、LLMがユーザーのクエリやタスクに効果的に対処するために、紹介されたAPIを利用してワークフローを作成します。そして、ワークフローが実行され、ユーザーに出力が生成されます。

なお、FlowMindによって自動生成されたワークフローと、いくつかのサンプルユーザー質問に対する回答の例は後ほど実験結果セクションで示します。

FlowMindの特徴は、ステップ2でユーザーフィードバックを取り込むことにあります。生成されたワークフローの概要をユーザーに提示し、ユーザーが基礎となるコードを詳しく調べる必要なく、ワークフローの機能と構造を理解できるようにします。

下記はステップ1とステップ2を図示したものです。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68095_2-1024x231.png)

## 実験

FlowMindの有効性を評価するために、研究者らはファイナンス分野のファンドに関する [N-CENレポート](https://www.sec.gov/dera/data/form-ncen-data-sets) から、「NCEN-QA」というベンチマークデータセットを作成しました。N-CENレポートは、米国の登録投資会社が義務付けられている年次報告書で、ファンドの管理者、価格設定サービス、投資顧問、手数料、純資産などの豊富な情報を提供している資料です。

研究者らは、SECの公開データベースEdgarから最新のN-CENレポートを収集しました。彼らは過去3年分のレポートを最大10レポート/秒のスループットで取得し、合計8,548のレポートを収集しました。なお重複があったため、各ファンドの最新の報告のみを残すようにデータをクリーニングしました。その結果、12,000のファンドをカバーする2,794のレポートが得られました。

収集したデータを基に、研究者らはファンドに関する質問を難易度別に作成し、NCEN-QA-Easy、NCEN-QA-Intermediate、NCEN-QA-Hardの3つのデータセットを作成しました。各データセットには200の質問と回答のペアが含まれています。

**NCEN-QA-Easy**

各質問は、あるファンドの1つの情報に焦点を当てています。質問に答えるには、そのファンドが報告されているN-CENレポートの中の特定のテキストブロックを調べる必要があります。

**NCEN-QA-Intermediate**

各質問は1つのファンドのみに焦点を当てていますが、NCEN-QA-Easyよりも少し複雑です。質問されたファンドに関する複数の情報に加え、数学的操作(例:割り算)が必要なためです。

**NCEN-QA-Hard**

各質問は複数のファンドに焦点を当てているため、NCEN-QA-EasyとNCEN-QA-Intermediateよりも大きな課題となっています。質問に答える為には、複数のファンドにまたがる集計や、特定のサービスを利用しているすべてのファンドの調査を必要とします。

### N-CEN APIの提供

研究者らは、N-CENレポートを処理するためのドメイン固有のAPIを開発し、FlowMindにこれらのAPIの高レベルな自然言語による説明を提供しました。提供された6つの重要なAPIの機能は、検索、分割、抽出に分けられます。

（１）検索

get\_report関数は、ファンド名をN-CEN Accession Number(\*1)に変換し、そのファンドの最新レポートを取得します。またget\_all\_reportsは、データセット内のすべてのファンド名に対してget\_reportを適用した結果をキャッシュします。さらにfetch\_blockは、入力されたレポートの中から、指定されたファンド名に対応する単一のファンドのテキストブロックを取得します。

（２）分割

segment\_report関数は、入力されたN-CENレポートをファンドブロックのリストに分割します。クエリに対してレポート内のすべてのファンドを調べる必要がある場合に役立ちます。

（３）抽出

extract\_entityとextract\_valueは、それぞれエンティティ名と特定の数値を抽出する責任があります。

### FlowMindの評価実験結果

研究者らは、ユーザーフィードバックがある場合／ない場合のFlowMindと、いくつかの手法と性能を比較しました。

比較対象となった手法は、文脈検索に基づくGPTの質問応答手法であるGPT-Context-Retrievalです。ユーザー質問に関連する上位k個のファンドブロックを取得し、質問に付加してGPTに入力するものです。

また、レクチャープロンプトから文脈、API、コード生成指示をそれぞれ抜いた手法も比較対象としました（FlowMind-NCT、FlowMind-BA、FlowMind-NCP）。

結果は以下のとおりです。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68095_4-1-1024x123.png)

1. ユーザーフィードバックがなくても、FlowMindはGPT-Context-Retrievalを大幅に上回りました。
2. アブレーション研究から、レクチャーレシピの各要素の重要性が明らかになりました。
	- （FlowMind-NCTが標準のFlowMindよりも性能が低かったことから、）文脈の必要性が強調されました。
	- （FlowMind-BAの性能は大幅に低下したため、）意味のある引数名を持つ良質なAPIの記述の重要性が浮き彫りになりました。
	- （FlowMind-NCPは最も精度が低く、）コード作成の明示的な指示の必要性を示しました。
3. なお、ユーザーフィードバックを取り入れることで、FlowMindの性能がさらに向上しました。
	- NCEN-QA-Easyでは、「2月」をファンド名の一部と誤解していたFlowMindが、ユーザーフィードバックによって修正されました。
	- NCEN-QA-IntermediateとNCEN-QA-Hardでは、ユーザーフィードバックにより、抽出APIで抽出可能な情報に関するFlowMindの誤った仮定が修正されました。

FlowMindによって自動生成されたワークフローといくつかのサンプルユーザー質問に対する回答の具体例を下記に示します。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68095_5-1024x317.png)

NCEN-QA-Easyデータセットでの質問例と、FlowMindが生成したワークフローと結果の例

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68095_6-1024x372.png)

NCEN-QA-Intermediateデータセットでの質問例と、FlowMindが生成したワークフローと結果の例

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68095_7-1024x545.jpg)

NCEN-QA-Hardデータセットでの質問例と、FlowMindが生成したワークフローと回答の例

なお下記の図は、ユーザーフィードバックに基づいてFlowMindがワークフローを修正した例を示しています。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68095_8-1024x457.jpg)

## まとめ

本記事では、LLMを用いて自動的にワークフローを生成するための新しいアプローチ「FlowMind」を紹介しました。

プロンプト設計、ユーザーフィードバック、安全で基礎付けられた推論を組み合わせることで、即興のタスクを自動生成されたワークフローで確実かつ効率的に処理するための信頼性が高く適応性の高いソリューションを提供します。

研究者らは、ファイナンス分野における新しいベンチマークデータセットNCEN-QAを作成し、本手法の性能を評価しました。実験の結果、FlowMindはベースラインの手法を大幅に上回る性能を示しました。また、提案されたレクチャーレシピの各要素の重要性と、ユーザーフィードバックの有効性が明らかになりました。

以上のようにFlowMindは、タスクの即興性が重要な産業におけるLLMを用いた自動ワークフロー生成の可能性を示した新しい研究事例です。実用を見据えたメソッドが検証されるのは非常に重要なことですね。

- URL： [https://arxiv.org/abs/2404.13050](https://arxiv.org/abs/2404.13050)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[LLMにおける、長いコンテキストから欲しい情報を見つけ出す「needle-in-a-haystack（干し草の中の針）」テスト結果とプロンプト例](https://ai-data-base.com/archives/68016)

[強くて軽いモデルPhi-3の評価結果　Microsoftの論文（テクニカルレポート）より](https://ai-data-base.com/archives/68184)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)