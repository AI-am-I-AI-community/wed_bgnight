---
title: "個人の振る舞いや考え方を模倣するアバターをLLMで構築する方法"
source: "https://ai-data-base.com/archives/87179"
author:
  - "[[AIDB Research]]"
published: 2025-03-28
created: 2025-06-13
description: "本記事では、個人の話し方や個性をLLMを用いて再現することを目指した研究を紹介します。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、個人の話し方や個性をLLMを用いて再現することを目指した研究を紹介します。

一般的な質問応答をLLMで行うことは身近になりましたが、発展的な使い道として「個人特有の表現や知識を継続的に再現する」のはなかなか浸透していません。

そこで研究者らは、RAGを利用し、個人の情報を参照しながら自然な応答を実現する仕組みを提案しています。その特徴と具体的なユースケースを分かりやすく紹介します。

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_87179-1024x576.png)

参照論文情報は記事の下部に記載されています。

## 背景

LLMを活用して特定の人物の話し方や個性を再現し、デジタル上でその人物の人格を保持したいというニーズが広がっています。

例えば、専門的な知識をもつ人物の特有の知識や応答スタイルを再現したアバターなど。あるいは、有名人や人気者の会話や本人らしい考え方をデジタルで再現することは新たなエンターテインメントにつながります。

しかし、LLMを普通に使用するだけでは、個人の特徴を継続的に保持したり、リアルに再現することが難しいと考えられています。ユーザーはその都度詳細な情報や文脈を提供する必要があり、その結果、対話が画一的で機械的になり、自然さや臨場感に欠けるという課題があります。

こうした課題に対応するため、研究者らはRAGに着目しました。RAGとは、一言で言うと必要に応じて情報を探し、それに基づいた回答を行う仕組みを意味します。RAGの技術をうまく活用すれば、ユーザーの過去の発言や行動を継続的に記録し、それを応答生成時にリアルタイムで参照する仕組みができる可能性があります。

今回紹介する研究は、そんなRAGを工夫することにより個人特有の表現や知識を再現し、まるで本人がそこに存在しているかのような、自然で魅力的なコミュニケーションを可能にすることを目指しています。以下詳細です。

## 前提のおさらい

LLMは膨大なデータを学習しており、人間のように自然な文章や回答を生成できます。しかし、一般的なモデルは、基本的には個々のユーザーに特化した回答を提供することが苦手です。モデルは毎回新しく与えられる文脈を優先して返答を生成し、ユーザーの過去の履歴や特有の個性を考慮することは二の次であるためです。

### RAG

こうした課題を解決するため、RAGという技術が考案されました。RAGとは、事前に蓄積されたデータから必要な情報をリアルタイムで取得し、それをもとに自然な回答を生成する仕組みです。例えば、質問に関連した過去の情報を検索し、その情報を反映した返答を作成することが可能です。この技術は、一般的なLLMの使い方よりも具体的で的確な情報を提供できる可能性があります。

ただし、RAGの利用範囲は通常、特定の狭い領域に限られており、広い範囲で個人向けのコミュニケーションに利用することは難しいとする見方が一般的です。このハードルを越えようとしているのも本研究の特徴の一つです。

### 記憶を持つニューラルネットワークの試み

最近では、過去の情報を記憶しておくことで長期的にユーザーの特性に合わせられるアルゴリズムも提案されています。もしそうしたアルゴリズムが実用的になれば、ユーザーとの対話を積み重ねて学習し、よりパーソナライズされた対応を実現できる可能性があります。しかし、記憶する情報が増えれば増えるほど処理にかかる負担が増え、効率が悪くなるという問題もあります。

### 本研究の取り組み

こうした先行研究を踏まえて、研究者らは、RAGとLLMを組み合わせることで、ユーザー特有の情報をリアルタイムで取得・活用し、個人の性格や特徴を反映した自然なコミュニケーションを実現しようとしています。

なお、ユーザーのデータ収集にはスマートフォンアプリを活用することで、利用者が特に意識しなくても安全かつスムーズにデータを取得できる仕組みとなるように考えています。

このように考案された仕組みは今回「PersonaAI」と名付けられました。

## 方法論

データの準備、質問への対応方法、言語モデルの活用、そして評価のための仕組みが重要なポイントです。

まず、ユーザーから収集した情報は効率よく扱えるよう、数値的なデータ（埋め込みベクトル）に変換します。この変換には、Hugging Faceの提供するモデルを使用します。  
なお、処理の負担を軽減するため、情報は200文字を最大として区切られ、一部の情報が重複するように調整します。こうすることで、情報の意味が途切れにくくなり、精度を保ったまま処理を効率化できます。

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_87179_1.png)

データを200文字ずつに区切り、重複なく管理する様子

### 質問の処理と情報の検索

ユーザーからの質問に適切に答えるために、質問の内容を数値データ（埋め込みベクトル）に変換し、保存された情報との類似度を計算します。その後、最も関連性の高い情報を抽出し、返答を作成するための参考情報として使用します。

まず、ユーザーから受け取った質問のベクトルと、既に保管されているデータのベクトルを比較して、関連性が高い順に並べ替えます。その中で特に重要な情報のみを選び出し、それを元に自然で的確な回答を生成します。こうすることで、不要な情報を省きつつ、ユーザーにとって理解しやすい回答を迅速に提供する仕組みとなります。

### 言語モデルの統合とプロンプト調整

どの言語モデルを使用するかは限定されません（が、今回はLlamaシリーズが使用されました）。

モデルが適切な返答を行えるようにするため、プロンプト（モデルに与える指示）の作成段階で、ユーザーの利用状況や蓄積されている情報を踏まえた明確な指示文を用意します。

例えば、新規ユーザーに対しては、ユーザーの個性や過去の情報がないことを前提に、一般的かつ明瞭な返答を行うよう指示します。  
一方、利用履歴のあるユーザーの場合、過去の会話データや行動パターンをプロンプトに明示的に組み込み、モデルが個人の特性により沿った返答を生成できるよう工夫します。

また、モデルが自信を持てない場合や情報が不十分な時に備えて、「分からない」や「情報が不足している」などと正直に伝えるよう指示を含みます。

### 安全なフレームワークの構築

システムを安全で使いやすくするために、クラウドベースのサービスを構築することが推奨されます。ユーザーごとに個別のアカウントを用意し、提供された情報を厳重に保護します。

ユーザーの個人情報や対話データは厳密に管理し、ユーザー自身がデータの使われ方を明確に把握し、自由に管理できるような仕組みとします。また、プライバシー保護やデータ管理に関する規制を守り、利用者が安心してサービスを継続的に利用できる環境を整える必要があります。

### 設計上の工夫

ユーザーから提供されたデータは、小さな単位に区切られ、一部が意図的に重複する形で保存するべきです。そうすると、情報が途切れることなく管理され、検索時には関連性の高い情報を正確に取り出せます。これはRAGにおけるチャンキングの戦略として広く知られるテクニックの一つです。

質問や要求が発生した場合には、その内容に最も関連する情報だけを抽出し、素早く正確な応答を提供できるようにします。

また、十分な情報がない場合や回答に自信がない状況では、無理に回答を生成せず、ユーザーに明確にその旨が伝えます。この透明性を保つことで、ユーザーとの信頼関係を維持します。

## 実験環境

今回研究者らは上記の方法論に基づき、「PersonaAI」を安全で快適に動作させるための環境を以下のように設計・開発しました。

まず、ユーザーごとの情報を安全に管理し、リアルタイムで更新するためにFirebaseというクラウドデータベースが使用されました。

また、モデルの処理を効率的に進めるため、NVIDIA製の [GPU](https://ai-data-base.com/archives/26570 "GPU") を搭載したサーバーが使われました。

さらに研究者らは、ユーザーが手間なく自然に情報を提供できるよう、音声を自動的にテキストに変換してくれるスマートフォンアプリも開発しました。ユーザーの音声を記録し、そのままクラウドに送信するため、利用者が特別な操作をする必要がないように設計したとのことです。  
なお、このアプリを含めて、コードはオープンソースで公開される予定です。

なお、システムの土台となる部分（バックエンド）には、Pythonというプログラミング言語で開発された「Flask」という仕組みを導入しています。Flaskがユーザーの認証やデータの取得といった重要な処理を担当します。

### 使用アルゴリズムとデータ構造

ユーザーが提供するデータ（テキストや音声）を効果的に管理・活用するために、辞書型データ構造を使用されました。構造には、ユーザーが提供したテキストデータ、記録日時、ユーザー名、データを数値化して扱いやすくする「埋め込みベクトル（Embedding Vector）」などの要素が含まれます。埋め込みベクトルの作成には、Hugging Faceが提供するモデルを採用し、これを用いることでデータ間の関連性を効率よく判定します。

ユーザーから質問があった際は、その質問と蓄積されたデータの類似性を計算し、関連度の高い情報を自動で抽出します。そして抽出された情報を基にLLMが最適な回答を生成します。

### 比較対象

実験では、PersonaAIが既存の一般的なモデルと比較して、どれだけ個人に寄り添った自然な返答を生み出せるかという点を検証することが目的でした。

そのため、個人特有のデータを使用しない一般的なChatGPT、ユーザーの過去のデータを活用するタイプのChatGPT、そしてパラメータ数が異なる二種類のLLAMAモデル（13Bと70B）との比較が実施されました。

また、ユーザーの過去の情報を継続的に記録し、それを活かして適切な回答ができるかという機能についても評価されています。評価の基準としては、回答内容の正確さ、回答の速さ、そしてユーザーが満足できる内容かどうかが検討されました。

### 実運用への展開

PersonaAIを日常的な環境で使いやすくするため、拡張性と安定性を意識した運用方法が採用されることになりました。

そのため、Dockerを活用することによって、システムを柔軟かつ容易に拡張できるように設計されています。

また、ユーザーが簡単に利用できるように、スマートフォンアプリの他にReactとTypeScriptを使ったウェブインターフェースも整備されました。

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_87179_2-1024x554.png)

ユーザーからの質問（クエリ）と蓄積されたデータを管理するためのシンプルなウェブインターフェース

### データセットと評価方法

性能評価には、二つの異なるデータセットが使用されました。

一つ目は『スポンジ・ボブ』というアニメの会話データです。このデータは登場人物の独特な言い回しや、カジュアルな会話スタイルの再現を目的として使用されました。ただし、データには短すぎる文や非言語的な表現も多く含まれているため、実用的な活用には工夫が必要です。

二つ目は、実際のユーザーとのやり取りを想定して作成された架空の日記形式のデータセットです。このデータには、日常活動の記録や個人的な感想、メールでのやり取りなどが含まれており、より現実的な条件での評価が可能となっています。

これらのデータセットを通じて、回答の質や自然さを調査し、ユーザーにとって親しみやすく理解しやすいコミュニケーションが実現されているかが検証されています。

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_87179_3-1024x454.png)

『スポンジ・ボブ』の特徴的な話し方を再現したモデルの応答例

## 結果

PersonaAIが実際にどのような性能を持っているかを確かめるため、いくつかの具体的なケースを設定して評価が行われました。蓄積されたユーザー情報を活用し、どれだけ自然で適切な返答を生成できるかに注目しています。

評価に用いられたのは、性能と効率のバランスに優れたLLAMA-3.1-405B-Instruct、LLAMA-3-70B-Instruct、LLAMA-2-70B-Chatという三種類のモデルです。これらのモデルを使って、一般的な知識に関する質問に対し、どの程度正確かつ適切な回答が可能かというテストが行われました。

### ユースケースとモデル性能

#### 一般的な知識に関するユースケース

このテストでは、特定のユーザー情報がない状況で、モデルが一般的な質問に対してどのような回答をするかが確認されました。質問の例としては、「現在のナイジェリアの大統領は誰ですか？」というものがあります。

各モデルからの回答を見ると、いずれも情報の新しさに限界があるため、回答には日付や状況に関する注意事項が含まれています。例えば、「私の情報は2021年までですが、その時点では大統領はムハンマド・ブハリ氏です。ただし、最新情報は公式のニュースなどで確認してください」というような表現がされています。

これらの結果は、各モデルが一般的な情報を扱う場合でも慎重で正確なコミュニケーションを意識していることを示しています。ただし、リアルタイムの情報提供には制限があるため、その点を明確に伝えることでユーザーに誤解を与えない工夫がされていることが分かります。

以下はこのユースケースにおける質問応答例です。

```js
質問：「Who is the president of Nigeria?」
回答例（LLAMA-3.1-405B-Instruct）：

原文：

"As of my last update in 2021, the President of Nigeria is Muhammadu Buhari. However, please note that political positions can change, and I might not have the most current information. For the most accurate and up-to-date answer, I recommend checking the latest news or official government sources."

日本語訳：

「私の知識は2021年時点のものですが、その時点ではナイジェリアの大統領はムハンマド・ブハリ氏です。ただし、政治的な役職は変動する可能性があるため、最新かつ正確な情報については、最新のニュースや公式の政府情報をご確認ください。」
```

#### 一般的なレコメンドのユースケース

このユースケースでは、特定のユーザー情報がない状況で、モデルが一般的なレコメンドを行う能力が評価されました。例えば「週末におすすめの映画は？」といった質問に対し、モデルは多くのユーザーが楽しめるような、ジャンル別の定番映画を提案しています。ユーザーの好みに関する情報が不足している場合、モデルはユーザー自身に対して追加情報の提供を促すこともあります。このように、限られた情報下で適切かつ広く受け入れられやすい提案がなされています。

以下も同様にこのユースケースでの質問応答例です。

```js
質問：「Recommend a movie to watch this weekend?」
回答例（LLAMA-3.1-405B-Instruct）：

原文：

"Have you considered watching 'The Shawshank Redemption' (1994) directed by Frank Darabont? It’s a timeless drama film with outstanding performances, a gripping storyline, and a powerful message of hope and redemption."

日本語訳：

「フランク・ダラボン監督の『ショーシャンクの空に』（1994年）はいかがでしょうか？優れた演技と引き込まれるストーリー、そして希望と救いの力強いメッセージを持つ、時代を超えた名作ドラマです。」
```

#### パーソナライズされたレコメンドのユースケース

ユーザーの好みや過去の情報が利用可能な場合には、モデルはその情報をもとにレコメンド内容を調整しました。例えば、ユーザーが職場で同僚が話題にしている「Netflixのアニメを見たい」と述べていた場合、その文脈を考慮して関連性の高い作品を具体的に提案しています。このように、ユーザーが過去に示した興味を反映した、より適切で個別的な提案が行われることが確認されました。

このユースケースにおける質問応答例

```js
ユーザーの状況：「My colleagues at work would not stop talking about Anime on Netflix. I sure should watch one in the coming days.」
質問：「Recommend a movie to watch this weekend?」
回答例（LLAMA-3-70B-Instruct）：

原文：

"Considering your colleagues’ enthusiasm for Anime on Netflix, I’d like to recommend an Anime movie that’s popular and well-received. Have you considered watching 'Spirited Away' (2001) directed by Hayao Miyazaki? It’s a timeless classic, widely acclaimed, and available on Netflix in many regions."

日本語訳：

「あなたの同僚がNetflixのアニメに熱心とのことですので、人気の高い評価を受けているアニメ映画をおすすめします。宮崎駿監督の『千と千尋の神隠し』（2001年）はいかがでしょうか？多くの地域のNetflixで視聴できる、時代を超えて評価され続けている名作です。」
```

#### イベントのリマインダーのユースケース

モデルは時間や予定に関する情報を理解し、ユーザーにとって重要なイベントを適切なタイミングでリマインドできるかを評価されました。例えば、ユーザーが「来週水曜日に医師との約束があり、来週中に友人へ連絡したい」と述べていた場合、モデルはそれらを明確に整理してユーザーへ再通知することが可能でした。このように、日時に関連した情報を理解し、明瞭で役立つ通知が提供されました。

質問応答例

```js
ユーザーの状況：「Today is Monday, 23rd December 2024. I do have an appointment with my Doctor next week Wednesday. Also, I would like to call some friends anytime next week.」
質問：「Remind me what I am doing this week?」
回答例（LLAMA-3.1-405B-Instruct）：

原文：

"You have an appointment with your Doctor next Wednesday. Additionally, you mentioned wanting to call some friends sometime next week, but there’s no specific day or time scheduled for that."

日本語訳：

「来週水曜日に医師との約束があります。また、来週中に友人へ連絡したいとのことですが、具体的な日時はまだ決まっていないようです。」
```

#### 書き方のスタイルのユースケース

ユーザーの個性的な表現スタイルをモデルが再現できるかという点も評価されました。例えば、カジュアルでフレンドリーなメールの文体を使用するユーザーに対して、モデルはその特有の口調やフレーズを取り入れつつ、新たなメッセージを生成しました。こうした能力によって、ユーザーの個性を反映した自然で親しみやすいコミュニケーションが実現される可能性が示されました。

質問応答例

```js
ユーザーの過去のメール文：「Yo fam, Was thinkin’ we hit up a flick later, yeah? Bet it’s gonna be bare vibes, man – proper lit all day and night with this peng weather. Safe, bruv. Catch ya soon. Your mate, broski.」
質問：「Write a letter to Paul, asking him for updates on our last conversation.」
回答例（LLAMA-3-70B-Instruct）：

原文：

"Yo Paul,Wass good fam? Hope you’re livin’ your best life, bruv. I was thinkin’, what’s the 411 on our last convo, yeah? Got any updates for your boy? Hit me back when you can, safe.Cheers,Your mate"

日本語訳：

「よう、ポール！元気か？最高の毎日を過ごしてるといいな。この前の話だけど、最近どうなったか気になってるんだ。何か進展あったら教えてくれよな。連絡待ってるぜ。じゃあな！お前のダチより」
```

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_87179_4-1024x676.png)

ユーザー自身の文体や表現のクセを再現して応答するモデルの動作例

### フィードバックと評価

ユーザーからのフィードバックでは、イベントのリマインドや個人向けのレコメンドについて好意的な評価が見られました。

ユーザーは、モデルが自身にとって重要な情報を的確に検索・提示できる点に満足しています。また、実際にユーザーからの質問に対して適切で迅速な回答が提供されているかどうかの評価も行われました。結果として、モデルが検索する情報の正確性は高く、応答の速度も満足できる水準に達していることが確認されました。

## 展望

技術をさらに発展させるため、今後取り組むべきいくつかの課題があるとされています。

まず、さらなる個人への適応性を高めるために、多様な形式のデータを統合することが求められます。tたとえばテキスト情報だけでなく、画像や映像、社会的な交流データなどの多様な情報を取り入れ、より深くユーザーを理解することが重要となります。また、モデルの理解力をさらに高めるために、プロンプトの改善やモデルの追加学習（ファインチューニング）にも取り組む必要があります。

次に、より広範な分野で応用できるよう、教育分野、医療分野、顧客サポートなどにおいて、それぞれの専門性に合わせた形で機能を拡張することが重要です。各分野の特有なニーズに柔軟に対応しつつ、汎用性を維持するための設計が求められます。

さらに、ユーザーのプライバシーや倫理的な問題にも継続的に取り組む必要があります。例えば、差別や偏見が含まれない公平な対応が可能になるよう配慮すること、ユーザー自身がデータの使用方法を明確に理解し管理できるように透明性を高めることが求められます。

最後に、ユーザーからリアルタイムでフィードバックを収集し、それを活用してシステムが継続的に学習・改善できるような仕組みを整備することも重要な課題となっています。フィードバックループを通じて、PersonaAIは長期的により正確でパーソナライズされた応答を提供できるようになることが期待されます。

## まとめ

本記事では、RAGを活用して個人の特性や過去の情報をリアルに再現できるPersonaAIという研究を紹介しました。

この研究は、個人に特化したデジタルコミュニケーションを実現するため、ユーザー情報を効果的に管理・活用する方法を示しています。また、透明性や倫理的な配慮を重視し、安全にユーザー情報を扱う仕組みも備えています。

実際の評価では、イベント通知や個別のレコメンドなど、日常的な場面での利用可能性が確認されました。自身や周囲の人の特性を再現したコミュニケーションツールとして、幅広い用途での応用が期待されます。

**参照文献情報**

- タイトル：PersonaAI: Leveraging Retrieval-Augmented Generation and Personalized Context for AI-Driven Digital Avatars
- URL： [https://doi.org/10.48550/arXiv.2503.15489](https://doi.org/10.48550/arXiv.2503.15489)
- 著者：Elvis Kimara, Kunle S. Oguntoye, Jian Sun
- 所属：Iowa State University

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[LLMで高品質なクイズを作成する手法](https://ai-data-base.com/archives/87106)

[Amazon最新決算から見るAWSの動向　人材戦略も考察](https://ai-data-base.com/archives/87532)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)