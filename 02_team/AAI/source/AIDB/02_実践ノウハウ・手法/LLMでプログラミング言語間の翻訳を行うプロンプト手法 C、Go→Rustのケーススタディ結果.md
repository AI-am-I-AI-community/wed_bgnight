---
title: "LLMでプログラミング言語間の翻訳を行うプロンプト手法 C、Go→Rustのケーススタディ結果"
source: "https://ai-data-base.com/archives/69610"
author:
  - "[[AIDB Research]]"
published: 2024-05-24
created: 2025-06-13
description: "LLMを活用して実世界のコードを異なる言語に変換する研究をMPI-SWS、ブリストル大学、ウィーン工科大学、そしてAmazon Web Servicesの研究者たちが共同で行っています。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

LLMを活用して実世界のコードを異なる言語に変換する研究をMPI-SWS、ブリストル大学、ウィーン工科大学、そしてAmazon Web Servicesの研究者たちが共同で行っています。研究者らは、実世界のオープンソースプロジェクトから抽出されたコードを対象に、5つの最先端のLLMの性能を評価しました。変換精度を向上させるためのフィードバック戦略（プロンプトの工夫）についても知見が得られています。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69610-1024x576.jpg)

**参照論文情報**

- タイトル：Towards Translating Real-World Code with LLMs: A Study of Translating to Rust
- 著者：Hasan Ferit Eniser, Hanliang Zhang, Cristina David, Meng Wang, Maria Christakis, Brandon Paulsen, Joey Dodds, Daniel Kroening
- 所属：MPI-SWS, University of Bristol, TU Wien, Amazon Web Services

## 背景

あるプログラミング言語で書かれたコードを別の言語に変換するタスク、つまりプログラム変換においてもLLMが有望視されています。例えばC言語やGo言語など従来の言語で書かれたレガシーコードを、Rust言語のような安全性の高い現代的な言語に変換することへの期待が高まっています。

LLMを用いたプログラム変換に関する先行研究の多くは、競技プログラミングのウェブサイトや教育用のウェブサイト、あるいは手作りのコーディング問題から抽出したコードを対象としており、実用性が十分とは言えません。ベンチマークはプリミティブなデータ型のみを使用する単一の関数であるのに対し、実世界のコードには多くの関数やユーザー定義のデータ型（構造体など）が含まれています。

そこで今回研究者らは、現実のコードをRustコードへの変換を生成できるエンドツーエンドのコード変換ツールを開発し、実験結果をまとめました。

## フレームワークの概要

以下では、研究者らが開発・検証したコード変換ツール「FLOURINE」におけるロジックが説明されています。どのような自動化を行った場合にどれほど精度が出るのか、といったケーススタディとして捉えていただくと良いかと思います。

なお、以下では「プログラム変換」と「コード変換」は同様の意味で使用されており、「プログラム変換」「コード変換」どちらも言語変換プロセスを指しています。

### コード変換タスクの定式化

研究者らは、まずコード変換のタスクとはどういうものかを形式的に定義しています。

プログラミング言語 l とその言語で書かれた有効なプログラムの集合 Pl を考えます。コード変換においては、言語 l で書かれたプログラム p を、別の言語 l’ に変換することが目的です。つまり、p と同じ振る舞いを持つプログラム p’ を見つけることが目標となります。

なおプログラム（p または p’）は、以下の要素の集合体です。

1. 関数：プログラムの主要な処理を行うコードブロック
2. ユーザー定義の型：プログラマが定義したデータ構造（例：構造体）
3. グローバル変数：プログラム全体から参照可能な変数
4. インポート/インクルード文：他のファイルやライブラリからコードを読み込むための命令

そして、プログラムの実行は、特定の関数から開始されます。この関数をエントリーポイントと呼びます。多くの言語では、この関数は「main」と呼ばれることが一般的です。  
エントリーポイント（main）は、以下のようなデータ型の変数を入力として受け取り、出力として返します。

1. プリミティブ型：整数、浮動小数点数、文字列などの基本的なデータ型
2. ユーザー定義型：プログラマが定義した構造体やクラスなどのデータ型
3. ポインタ型：メモリ上の特定の場所を指し示すデータ型

### 反復的なコード変換アルゴリズム

この研究では、あるプログラミング言語で書かれたコードを別の言語に自動的に変換するための、繰り返し処理を用いた手法が提案されています。目的は、元のプログラム（ソースプログラム）と同じように動作する、変換後のプログラム（ターゲットプログラム）を見つけ出すことです。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69610_0.png)

LLMは、人間が自然な言葉で与える指示（クエリ）を理解し、それに基づいてプログラムの変換案を生成します。元のプログラムと、それをどのように変換するかという指示を受け取ると、変換後のプログラムの候補を出力するのです。

次に、変換候補の正しさを評価するために、「ファザー」と呼ばれるテストツールが使われます。ファザーは、元のプログラムと変換候補の両方に、同じ入力を与えて実行し、その出力を比較します。もし両者の出力が一致すれば、それは変換が正しく行われたことを示す「正例」となります。一方、出力が一致しない場合は、変換に誤りがあることを示す「反例」（または「カウンター例」）となります。

ファザーによる評価の結果は、「フィードバック」として LLM に返されます。フィードバックには、正例と反例の情報が含まれており、これを基に LLM は新しい変換案を生成します。つまり、フィードバックは、LLM が変換をより良いものにするための指針となるのです。

以上のプロセスを、次のようにステップで表現できます。上のアルゴリズムで記述されている内容になります。

1. LLMが初期の指示から変換候補を生成する
2. 変換候補がコンパイル（プログラムを実行可能な形式に変換）できるかどうかがチェックされる
3. コンパイルに失敗した場合、手法は失敗として終了する
4. コンパイルに成功した場合、ファザーが変換候補の正しさを評価する
5. ファザーが反例を見つけなければ、変換は成功とみなされる
6. 反例が見つかった場合は、フィードバックを基に新しい変換の指示がLLMに与えられる
7. 予算（例えば、処理時間や処理回数の上限）に達するか、ファザーのチェックをパスする変換候補が見つかるまで、このプロセスが繰り返される

この一連のプロセスにより、元のプログラムと同等に動作する変換後のプログラムを、自動的に見つけ出すことができます。ただし、完全な変換を保証するものではなく、あくまで「候補」を生成するものであることに注意が必要です。

### 具体例

この研究では、Go言語で書かれたプログラムをRust言語に自動変換する手法を、具体的な例を用いて説明しています。go-gtというライブラリにあるaddという関数を例に取り上げています。

まず、Go言語で書かれたaddの元のコードと、それをRustに変換するための指示を含む「クエリ」が作成されます。このクエリは、言語モデル（LLM）に与えられ、LLMはこれを基にRustコードの候補を生成します。このRustコードの候補は、コンパイラによるチェックを通過し、必ずコンパイル可能な状態になります。ただし、このコードが元のGoコードと同じように動作するかどうかは、まだ保証されていません。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69610_5.png)

go-gtのadd関数のRust変換例

そこで、元のGoコードとRustコードの候補が、テストツール「ファザー」に渡されます。ファザーは以下のようなプロセスでコードの同等性をチェックします。

1. ファジング（ランダムなデータを生成してプログラムに与えるテスト手法）を使って、テストデータを生成する
2. 生成されたデータを、元のGoコードとRustコードの両方に入力して実行する
3. 両方のコードの出力が同じであることを確認する

ここでの課題は、GoとRustという2つの異なる言語で書かれたコードに対して、同じ入力データを与え、その出力を比較することです。今回の例では、単純な型だけでなく、ユーザー定義のデータ構造も変換する必要があります。この課題を解決するために、JSONという汎用的なデータフォーマットを介してデータを変換する手法が開発されました。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69610_7.png)

関数addのシリアライズされたJSON入力状態

もしファザーが、出力が一致しないケース（カウンター例）を発見した場合は、「フィードバック手法」が呼び出されます。フィードバック手法は、このカウンター例を用いて、LLMに新しいクエリを生成させ、新しいRustコードの候補を作成させます。

適切なフィードバック手法を設計することは、この自動変換手法のもう1つの重要な側面です。LLMに新しいコードを生成させるためのクエリの作り方には様々な選択肢がありますが、それぞれ成功の可能性が異なります。研究チームは、この問題に取り組むために、複数のフィードバック戦略を提案し、その効果を評価しています。詳細は後述します。

## コード変換プロセス

コード変換プロセスは、大きく分けて2つの段階から構成されています。変換の取得と変換の検証です。

### 変換の取得

変換の取得では、C言語やGo言語で書かれたプログラムをRust言語に変換するために、ゼロショットプロンプティングが使用されます。ゼロショットプロンプティングとは、事前の微調整なしに、LLMに自然言語の指示を与えることで、タスクを直接実行させる手法のことです。

LLMへの入力となる初期のクエリは、以下の3つの要素から構成されています。

1. 全体的なタスクを記述するプリアンブル
2. 変換対象のプログラム
3. LLMが従うべき特定の制約

制約には、次の3種類があります。

- フォーマットのガイドライン
- コードの特性
- ファザーの制約

LLMが生成した変換が最初はコンパイルできない可能性があるため、コンパイル可能になるまでLLMにエラーの修正を反復的に問い合わせるアプローチが取られています。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69610_8.png)

変換を取得するためのLLMプロンプト例

### 変換の検証

コード変換の検証では、元のソースプログラムと変換後のRustプログラムが同じ入力に対して同じ出力を返すかどうかをテストすることが重要です。この論文では、そのためのテストツールが開発されました。

このテストツールは、前述したようにファジングと呼ばれる技術を使っています。ファジングとは、プログラムに大量のランダムな入力データを与えて、バグや脆弱性を見つける方法です。元のプログラムと変換後のRustプログラムの両方に、自動生成したランダムな入力を与えて実行し、その出力を比較します。

ただし、元のプログラムとRustプログラムでは、データの表現方法が異なる可能性があります。そこで、このテストツールは、JSONを使って、プログラムの状態をシリアライズ（直列化）します。

JSONを使う利点は、以下の2つです。

1. ユーザー定義のデータ型（クラスや構造体など）のフィールドを、名前に基づいて自動的にマッピングできる
2. ほとんどのプログラミング言語が、基本的なデータ型やユーザー定義のデータ型をJSONに変換する機能を持っている

ただし、このテストツールにも限界があります。例えば、Rustの一部の機能（特性定義やライフタイムなど）は完全にはサポートされていません。また、並行処理やネットワーク通信、ファイル入出力などの機能もサポートされていません。テストツールは、あくまでプログラムの動作が同等であることを経験的に保証するものであり、完全な正当性を保証するものではありません。とはいえ、テストツールは平均で97％のコードをカバーしており、かなり高い信頼性を持っていると言えるでしょう。

## フィードバック戦略

テストツールが元のプログラムと変換後のRustプログラムの動作が同等であることを確認した後、もしRustプログラムが正しく動作しない場合、どのようにしてそれを修正するかが問題になります。今回の研究では、そのための4つの戦略が提案されています。

**Simple Restart (Restart)  
**Restartは、最もシンプルな戦略です。うまく動作しなかったRustプログラムを捨てて、もう一度最初からLLMに変換を依頼します。

**Hinted Restart (Hinted)  
**Hintedは、Restartとほぼ同じですが、LLMに変換を依頼する際に、ヒントを与えます。テストツールが見つけた「良い例」（元のプログラムとRustプログラムの出力が一致した入力）と「悪い例」（出力が一致しなかった入力）を一緒に教えます。LLMは、どのような入力に対してうまく動作し、どのような入力に対してうまく動作しないかを学習します。

**Counterexample-Guided Repair (BaseRepair)  
**BaseRepairは、もう少し洗練された戦略です。Rustプログラムがテストに失敗したとき、すぐに捨ててしまうのではなく、まずは修正を試みます。テストツールが見つけた「悪い例」をLLMに与えて、その例に対して正しく動作するようにプログラムを修正するよう依頼します。

**Conversational Repair (CAPR)  
**CAPRは、BaseRepairをさらに発展させた戦略です。LLMとの対話を通じて、プログラムを徐々に修正していきます。最初はBaseRepairと同じように「悪い例」をLLMに与えますが、もし修正後のプログラムがまだテストに失敗する場合は、その新しい「悪い例」もLLMに与えます。このようにして、LLMとの対話を重ねながら、プログラムを正しいものに近づけていくのです。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69610_9.png)

BaseRepairとCAPRのLLMプロンプト。BaseRepairは黒で示され、CAPRは黒とマゼンタで示されている。

これらの戦略のうち、RestartとHintedは比較的シンプルで低コストですが、BaseRepairとCAPRは対話的なアプローチを取るため、より多くの手間がかかります。

研究者たちは、各戦略の効果を実験的に評価しています。次のセクションに続きます。

## 実験

研究者らは、5つのモデル、4つのフィードバック戦略、408のベンチマークを使用して、合計8160のコード変換実験を行いました。変換は、コンパイルに成功し、ファザー（テスト）に合格した場合に成功とみなされます。

なお、実験で使用されたLLMは次のとおりです。

- GPT-4-Turbo
- Claude 2.1
- Claude 3 Sonnet
- Gemini Pro
- Mixtral

以下、大きなテーマとそれに付随する小さな問い、その回答です。

### （１）LLMは実世界のプロジェクトから抽出したコードをRustに変換することにどの程度成功するか

Claude 2で47.7%、Claude 3で43.9%、Mixtralで21.0%、GPT-4-Turboで36.9%、Gemini Proで33.8%の全体的な成功率を達成しました。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69610_11.png)

各ベンチマークにおける各LLMの成功率。すべてのフィードバック戦略の平均値。

**各LLMは各プロジェクトからいくつのベンチマークを変換できるか**

最良のLLMは、ベンチマークによって20-60%の成功率を達成し、Claude 2がACHで80%の異常値を示しました。Mixtralは他のLLMよりも5-20%低い成功率ですが、実行コストは少なくとも10倍低いです。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69610_10.png)

ベンチマークの詳細情報。

**コードの複雑さは変換の成功率にどのように影響するか**

コードの行数が増えると、成功率が低下する傾向があります。100行以上では顕著でした。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69610_12.png)

コード行数でグループ化されたベンチマークにおける各LLMの成功率。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69610_13.png)

関数の数でグループ化されたベンチマークにおける各LLMの成功率。

**LLMが生成するRustコードはどの程度慣用的か**

LLMは、正しさの警告をほとんど生成しませんが、時々（1-15%の頻度で）、よりイディオマティックで簡潔で高性能なコードを生成できます。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69610_14.png)

各LLMのlinter警告の種類ごとの割合。

### （２）フィードバック戦略は変換のバグ修正にどの程度効果的か

**フィードバック戦略は変換の成功率をどの程度向上させるか**

最も効果的なフィードバック戦略でも、成功率は平均で6-8%しか向上しません。

**どのフィードバック戦略が成功率を最も向上させるか**

驚くべきことに、Restart（単に同じプロンプトを繰り返す）が最も信頼できる戦略でした。また、カウンター例をプロンプトに提供するのは、LLMの混乱を招く恐れがあると指摘されています。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69610_15.png)

フィードバック戦略を適用した後の成功率の初期成功率からの絶対的な改善。

### （３）LLMの変換はルールベースの変換ツールとどのように比較されるか

[ルールベース](https://ai-data-base.com/archives/26614 "ルールベース") のC2Rustが生成するコードの大部分はunsafeであり、LLMの変換よりもはるかに冗長で非慣用的だと考察されています。

### （４）変換が失敗する主な原因は何か

変換が失敗する理由は以下の3つです。

1. コンパイル可能な変換が見つからない（失敗の7.0%）
2. ファザーがデータ型をシリアライズ/デシリアライズできない（失敗の52.6%）
3. 最終変換でカウンター例が見つかる（失敗の40.3%）

### 結果についての考察および今後の展望

**フィードバック戦略の改善**  
この研究では、プログラムの変換が失敗した際に、その失敗例（カウンター例）をLLMに与えてフィードバックすることで、変換の品質を改善できるかが検証されました。しかし、結果は期待に反して、カウンター例を与えることが逆効果になるケースがありました。

研究者らは、この結果が他の研究と矛盾している点に注目しました。他の研究では、カウンター例が効果的だったと報告されているためです。この違いについて、研究者らは次のように推測しています。他の研究では、人間が作成したテストケースからカウンター例を抽出していたため、よりLLMにとって「理解しやすい」例だった可能性があります。一方、この研究では、無作為に生成された入力データからカウンター例を抽出しているため、LLMにとって「理解しにくい」例が含まれていた可能性があるというのです。

今後はどのようなカウンター例がLLMにとって有用なのかを詳しく調査していく必要がある、と研究者らは述べています。

**より大きなプログラムの処理**  
LLMは、一度に処理できる情報量に限りがあるため、大規模なプログラムを一度に変換することは困難です。研究者らは、LLMが次の単語を予測する際の確率的な性質が、この制限の根本的な原因だと推測しています。

この問題を解決するために、研究者らは、大規模なプログラムを小さな「チャンク」に分割し、それぞれのチャンクを個別に変換・検証する方法を提案しています。するとLLMの能力の限界内でプログラムを変換できるようになるかもしれないとのことです。

**テストツールの改善**  
この研究で使用されたテストツール（ファザー）は、JSONシリアライゼーションを使ってプログラムの状態を比較しています。しかし、JSONシリアライゼーションがサポートしていないデータ型があるため、テストが失敗することがあります。

研究者らは、より多くのデータ型をサポートするように、テストツールのシリアライザーを改善することが重要だと述べています。

## 結論と注意点

この研究を通して得られた主な結論は次の二つです。

1. LLMは、実際のプロジェクトで使われているようなコードを変換することができる。
2. しかし、LLMが生成した変換が間違っている場合、その間違いを例として与えても、LLMはそこから効果的に学習することができない。

ただし、いくつか注意点があります。

まず、変換の正確さを確認するために使用したテストツールが、間違いを見逃している可能性があります（ただしこのテストツールは平均して97%のコードをチェックできているため、変換は「ほぼ」正確だと考えられます）。

また、この研究ではCとGoというプログラミング言語を対象にしていますが、他の言語、例えばJavaやPythonのようなよく使われる言語でも同じ結果が得られるかどうかはわかりません。ただ、JavaやPythonに関する情報はLLMの学習データに多く含まれているため、うまくいく可能性は高いと考えられます。

次に、LLMに間違いの例を与える方法を工夫すれば、LLMがその情報をもっとうまく活用できるようになるかもしれません。ただ、この研究で使ったテストデータはかなり複雑なので、そう簡単ではないかもしれません。

最後に、LLMが生成する変換結果はかなりランダムで、同じ入力に対して毎回同じ出力が得られるとは限りません。この研究では、変換を繰り返し生成することで、このランダム性の影響を減らそうとしていますが、完全ではありません。ただ、これ以上繰り返しを増やしても、結果はあまり変わらないだろうと予想されています。

## 本論文で提案されている手法の振り返り

論文で提案されているLLMを用いたプログラム言語間の翻訳のプロンプト手法について、Algorithm1（フレームワークの概要で提示）の手順に沿ってまとめます。

**手順1: 初期プロンプトqの作成**

- 初期プロンプトqは以下の4つの部分で構成されます。
	1. Preamble: 全体的なタスクの説明。例えば、「与えられたC/Goプログラムを、Rustに翻訳する必要がある」など。
	2. 変換対象のプログラムコード。
	3. Instruction: 具体的な変換の指示。例えば、「上記のC/Goコードに対応するRustの翻訳を提供してください」など。
	4. Constraints: 変換時の制約条件。例えば、「安全なRustのみを使用する」「カスタムジェネリクスは使用しない」など。

**手順2: LLMによる候補翻訳の生成**

- 初期プロンプトqをLLMに入力し、候補翻訳p’を生成します。

**手順3: コンパイルドリブンリペア**

- 生成された候補翻訳p’がコンパイルエラーを含む場合、コンパイルが通るまでLLMを用いて繰り返し修正します。
- 修正のためのプロンプトには、翻訳コードとRustコンパイラのエラーメッセージを含めます。

**手順4: ファジングによる等価性チェック**

- コンパイル可能な翻訳が得られたら、元のプログラムpと翻訳p’に対してクロスプログラミング言語のdifferential fuzzing（差分ファジング）を行います。
- ファジングにより、pとp’のI/O等価性を確認する。等価であれば翻訳成功とみなし、p’を返します。

**手順5: 反例に基づくフィードバック**

- ファジングにより反例（pとp’の出力が異なる入力）が見つかった場合、反例をプロンプトに含めてLLMにフィードバックし、翻訳の修正を促します。
- 本論文では、以下の4つのフィードバック戦略を比較しています。
	1. Restart: 反例を含めず、初期プロンプトqをそのまま再利用する。
	2. Hinted: 初期プロンプトqに、ファジングで得られた正例と反例を追加する。
	3. BaseRepair: 反例を含むプロンプトを用いて、翻訳の修正をLLMに依頼する。
	4. CAPR: BaseRepairと同様だが、修正が失敗した場合、以前の失敗した翻訳をプロンプトに含める。

**手順6: 反復と終了条件**

- 手順2～5を、予算（論文ではb=5）の回数だけ繰り返します。
- 期待通りの翻訳が得られるか、予算を使い切ったら終了します。

## まとめ

本記事では、LLMを用いて実世界のコードをRust言語に変換する能力を研究した論文を紹介しました。

研究者らは、エンドツーエンドのRust変換ツールFLOURINEを開発し、5つの最先端のLLMを使って、実世界のプロジェクトから抽出したC言語とGo言語のコードをRust言語に変換するテストを行いました。その結果、LLMがコードをRust言語に変換できることが実証されましたが、まだ改善の余地があることも示されました。また、ランダムなファジング入力をカウンター例としてLLMにフィードバックすることは、効果的ではないことも明らかになりました。

今後、LLMを用いたコード変換技術がさらに発展し、実用的なツールとして広く活用されることが期待されます。その際に本研究結果は一つの知見として使われると考えられます。

- 参照論文URL： [https://arxiv.org/abs/2405.11514](https://arxiv.org/abs/2405.11514)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[LLMエージェントの設計16パターン](https://ai-data-base.com/archives/69483)　

[自然言語プログラミングを可能にするシステム『CoRE』](https://ai-data-base.com/archives/69789)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)