---
title: "LLMアプリケーション約1,500事例から学ぶプロンプトテンプレート"
source: "https://ai-data-base.com/archives/87853"
author:
  - "[[AIDB Research]]"
published: 2025-04-08
created: 2025-06-13
description: "「プロンプトの書き方を工夫すれば、高コストな上位モデルを使わなくても安価なモデルで十分な品質の応答が得られる場合も多い」という実用的な知見が報告されています。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

「プロンプトの書き方を工夫すれば、高コストな上位モデルを使わなくても安価なモデルで十分な品質の応答が得られる場合も多い」という実用的な知見が報告されています。

LLMアプリケーション1,000事例を調査分析した結果、そのような示唆が得られたとのこと。

なお、ほとんどのプロンプトテンプレートは”質問”ではなく”命令”の形式で書かれており、出力はJSONで構造化されるのが一般的であることが明らかになりました。また、「～～はしないでください」といった制約が多用されているそうです。

最終的に、現状における「プロンプトテンプレートの効果的な書き方」、「JSON出力形式の指定方法」、「制約の書き方パターン」などが体系的に明らかになっています。

![](https://ai-data-base.com/wp-content/uploads/2025/04/AIDB_87853_top2-1-1024x576.png)

## 背景

LLMを使ったアプリはどんどん増えており、幾多のサービスが世の中に出ています。それに伴い、自然な言葉でモデルに指示を出す「プロンプトエンジニアリング」がとても大切になってきています。

ただ、ここで問題があります。ユーザー目線で考えたとき、「効果的なプロンプトを作るのは思ったより難しい」ということです。

この問題に対処するため、多くの開発者は「プロンプトテンプレート」という方法を使っています。ユーザーにプロンプトを毎回ゼロから書かせるのではなく、「システム側で考えた固定部分」と「必要な分だけユーザーに記述させる部分」を組み合わせる方法です。

しかし現状では、このプロンプトテンプレートの作り方にはっきりとしたルールがありません。各開発者が自分の経験と試行錯誤だけを頼りに作っているため、「どうすればもっと効果的なテンプレートが作れるのか？」という実践的な質問に対する共通の指針が足りていません。

LLMを導入する企業やエンジニアたちは、「出力をどう整えればいいか？」「余計な説明をどう減らせばいいか？」「テンプレートの中の要素をどんな順番で並べるべきか？」といった疑問に直面します。  
なお、個人的にプロンプトテンプレートを整理する際にも、まったく同じ課題が出てきます。

また、多くの場合、LLMを使う際に最新の高性能モデルを選びがちですが、実は適切なテンプレート設計をするだけで、比較的安いモデルでも十分満足できる品質の出力が得られる可能性があります。

つまりテンプレートは、その設計次第でコスト効率が大きく変わるため、どのモデルを選ぶかやプロジェクトの成功にも影響する重要な要素です。

このような背景から、研究者たちは「実際のLLMアプリケーションで、プロンプトテンプレートがどう設計され、どんなパターンや要素が効果的なのか」を体系的に調査・分析しました。

GitHub上の1500以上のLLMアプリから2000件以上のプロンプトテンプレートを集め、それらを分類・分析し、さらに様々なテンプレートパターンを使って実際の出力結果を比較する実験も行いました。

その結果、「より効果的で安定したプロンプトテンプレートの設計方法」についての知見が得られました。  
LLMアプリ開発者だけでなく、個人的にプロンプトテンプレートを整理したい、いちユーザーの方々も参考になる内容です。

以下で詳しく紹介します。

![](https://ai-data-base.com/wp-content/uploads/2025/04/AIDB_87853_1-1024x273.png)

LLMアプリケーションで使用されるプロンプトテンプレートの実例

## 調査の進め方

実際に使われているプロンプトテンプレートを集めるため、オープンソースのLLMアプリから取り出された「 [PromptSet](https://doi.org/10.1145/3643795.3648395) 」というデータセットが使われました。ただ、すべてのプロンプトが分析に向いているわけではないので、次の条件で選ばれました：

- 英語で書かれていること
- GitHubで星が5つ以上あること
- 過去1年以内に更新されていること

これらの条件を満たす1,525の保管場所から、最終的に2,163個のプロンプトテンプレートが集められました。UberやMicrosoftなどの大手企業のプロジェクトも含まれています。

![](https://ai-data-base.com/wp-content/uploads/2025/04/AIDB_87853_2.png)

研究全体の分析手法と流れを示した概要図

![](https://ai-data-base.com/wp-content/uploads/2025/04/AIDB_87853_3.png)

UberやMicrosoftなど代表的なLLMアプリケーションリポジトリの一覧

### プロンプトテンプレートの分析方法

集められたプロンプトテンプレートを詳しく調べるため、次のような方法が使われました：

#### ①構成要素の分類

プロンプトテンプレートの中の共通する部品を見つけて、7つのグループに分けました。

1. **役割（Profile/Role）**  
	モデルがどんな立場で答えるかを決める部分（例：「あなたは翻訳者です」）
2. **指示（Directive）**  
	何をすべきかを伝える部分（例：「次の文章を要約してください」）
3. **手順（Workflow）**  
	タスクをどう進めるかの手順を示す部分
4. **背景情報（Context）**  
	参考にすべき情報やデータを提供する部分
5. **例示（Examples）**  
	模範となる例や望ましい出力例を示す部分
6. **出力形式（Output Format/Style）**  
	答えの形式やスタイルを指定する部分（例：「JSON形式で出力」）
7. **制約（Constraints）**  
	出力に関する制限事項（例：「長い説明は避ける」）

分類では一般的な基準や業界の標準を参考にし、LLMを使って各テンプレートの要素を特定した後、人間が確認も行いました。

![](https://ai-data-base.com/wp-content/uploads/2025/04/AIDB_87853_4.png)

異なるプロンプト設計フレームワークから統合した構成要素の分類表

#### ②変化する部分（プレースホルダ）の分類

テンプレート内で状況によって変わる部分を4つのタイプに分けました。

1. **ユーザー質問**  
	ユーザーからの質問を入れる部分（例：「{{question}}」）
2. **知識入力**  
	モデルが処理すべき主要データを入れる部分（例：「{{document}}」）
3. **文脈情報**  
	会話の履歴や背景情報を入れる部分（例：「{{chat\_history}}」）
4. **メタデータ/短い語句**  
	言語設定やユーザー名などの補足情報（例：「{{language}}」「{{username}}」）

#### ③よく見られるパターンの発見

テンプレート内でどの要素がどんな順番で配置されることが多いのかを統計的に分析しました。例えば、多くのテンプレートでは「指示（Directive）」が最初に置かれる傾向があります。また、JSON形式で出力する指定の仕方や、不要な説明を減らすための制約の書き方など、具体的なパターンも見えてきました。

### テンプレートパターンの効果を確かめる

見つかったテンプレートパターンがLLMの出力の質にどう影響するかを調べるため、次の手順で実験が行われました。

1. 特定のパターン（例：JSON出力形式の指定方法や長い文の配置方法）を持つテンプレートを選ぶ
2. 選んだテンプレートに同じ入力データを使う
3. LLMに実際に答えを作らせる
4. 作られた答えが指示に従っているか、指定された形式を守っているかなどを人間が評価する

## 分析結果から見える実践的なプロンプトテンプレート設計の知見

上述の方法で集めて分析したプロンプトテンプレートから、実際のLLMアプリでどんな書き方が効果的なのか、具体的なポイントがわかりました。

### 構成要素の実態と効果的な使い方

#### どの要素がよく使われているか

7つの構成要素の中で、実際のテンプレートで最もよく使われていたのは「指示（Directive）」で、全体の86.7%に含まれていました。次に多かったのは「背景情報（Context）」（56.2%）、「出力形式（Output Format/Style）」（39.7%）、「制約（Constraints）」（35.7%）の順です。

![](https://ai-data-base.com/wp-content/uploads/2025/04/AIDB_87853_6.png)

プロンプトテンプレート内の構成要素の出現頻度分布

これは現実のLLMアプリでは、「何をすべきか」をはっきり指示することと、参考情報を提供すること、そして答えの形式を予測できるようにすることが特に重視されていることを示しています。一方で「例示（Examples）」は19.9%と比較的少なく、用例を示す方法は入力文字数が増えるなどの理由から、実際の使用では限られた場面でしか採用されていないことがわかります。

![](https://ai-data-base.com/wp-content/uploads/2025/04/AIDB_87853_5.png)

一般的な構成要素の配置順序に従ったプロンプトテンプレート例

![](https://ai-data-base.com/wp-content/uploads/2025/04/AIDB_87853_7.png)

各構成要素間の配置順序の確率を示すマトリクス図

#### 最も効果的な並べ方

分析の結果、最も一般的で効果的なプロンプト構成要素の並べ方がわかりました：

1. 役割（Profile/Role）
2. 指示（Directive）
3. コンテキスト（Context）とワークフロー（Workflow）
4. 出力形式（Output Format/Style）と制約（Constraints）
5. 例示（Examples）

注目すべきは、「役割」と「指示」がほぼ必ず最初に置かれること（それぞれ87%と65%の確率）と、「例示」が最後に置かれる傾向です。この順番はLLMに対して、まず「誰として答えるか（役割）」「何をするのか（指示）」をはっきりさせてから、詳しい情報や条件を与えるという自然な流れを作っています。

![](https://ai-data-base.com/wp-content/uploads/2025/04/AIDB_87853_8.png)

最も頻繁に見られる構成要素の典型的な配置順序

![](https://ai-data-base.com/wp-content/uploads/2025/04/AIDB_87853_9.png)

出力形式に関する頻出単語を視覚化したワードクラウド

### 効果的なJSON出力形式の指定方法

LLMアプリでは扱いやすさから、JSONが最もよく使われる出力形式でした。JSONの指定方法には3つの主なパターンがあり、それぞれ出力の質に違う影響を与えることがわかりました。

1. **シンプル指定（全体の36.21%）  
	**「JSONで出力してください」など、形式だけを指定
2. **項目名指定（19.83%）  
	**「name, age, locationを含むJSONで出力」など
3. **詳細説明付き（43.97%）  
	**「name: ユーザーの氏名、age: 年齢（数値）、location: 居住地の都市名（文字列）」など

![](https://ai-data-base.com/wp-content/uploads/2025/04/AIDB_87853_10.png)

3種類のJSON出力指定パターンの比較例

実験の結果、単に「JSONで出力」と指示するだけのシンプル指定では、項目の数や名前にバラつきがあり、形式の正確さの点数が低くなりました（llama3-70b-8192で3.09/5、gpt-4oで3.21/5）。

一方、項目名をはっきり指定すると形式の正確さの点数が大幅に上がり（llama3で4.66、gpt-4oで4.86）、さらに各項目の詳しい説明を加えると最高の点数が得られました（llama3で4.90、gpt-4oで4.96）。

この結果は、JSON項目について具体的で詳しい説明を加えるとLLMの出力の質が大きく良くなることを示しており、特に「項目の詳細説明」が強くおすすめされます。

### 制約条件の効果的な活用法

開発例を見ると、LLMの出力をより正確に制御するために、様々な制約が使われていました。特に「〜しないでください」という禁止型の制約が最も多く（46.0%）、次に「〜を含めてください」という指示型の制約（35.6%）が続いていました。

![](https://ai-data-base.com/wp-content/uploads/2025/04/AIDB_87853_13-1024x350.png)

LLMの出力を制限するための除外型制約の分類と具体例

禁止型の制約は主に5つの種類に分けられます。

1. **正確さと関連性の確保  
	**「答えを作り上げないでください」
2. **わからないことの明確化  
	**「わからない場合は『わかりません』と答えてください」
3. **出力の制御  
	**「JSONデータ以外の説明は出力しないでください」
4. **余計な情報の排除  
	**「文書に含まれていない情報は提供しないでください」
5. **技術的な制限  
	**「SELECT以外のクエリは書かないでください」

注目すべきは、JSONデータを出力するときに禁止型の制約を加えると、余計な説明文が削除され、一貫性が大幅に良くなることです。実験では、「JSONデータ以外の出力テキストを提供しないでください」という制約を加えることで、JSONデータだけの出力率がllama3モデルで40%から100%に、gpt-4oモデルで86.67%から100%に上がりました。

![](https://ai-data-base.com/wp-content/uploads/2025/04/AIDB_87853_14.png)

プロンプトテンプレート内のプレースホルダ種類別の分布

これは、出力形式の指定（こうしてください）と禁止型の制約（こうしないでください）を組み合わせることで、より確実に望みの出力形式が得られることを示しています。

![](https://ai-data-base.com/wp-content/uploads/2025/04/AIDB_87853_15.png)

異なるJSON出力指定パターンによるLLM出力品質の評価比較

![](https://ai-data-base.com/wp-content/uploads/2025/04/AIDB_87853_16.png)

3つのJSON出力パターンが実際の出力に与える影響の具体例

### 変数（プレースホルダ）の効果的な配置

プロンプトテンプレートの中でも特に「知識入力」の変数（文書やデータを入れる部分）の配置場所が、LLMの出力の質に大きな影響を与えることがわかりました。

![](https://ai-data-base.com/wp-content/uploads/2025/04/AIDB_87853_11.png)

プレースホルダがテンプレート内のどの位置に配置されるかを示す分布図

次の2つの配置パターンを比較する実験が行われました。

1. **指示優先**  
	（タスク指示 → 知識入力 → ユーザー質問）
2. **変数優先**  
	（知識入力 → タスク指示 → ユーザー質問）

![](https://ai-data-base.com/wp-content/uploads/2025/04/AIDB_87853_12.png)

知識入力プレースホルダの配置位置が異なるテンプレート例の比較

結果として、「変数優先」パターンが一貫して高いタスク指示の守られ方を示しました（llama3で4.63/5\[+0.91\]、gpt-4oで4.60/5\[+0.34\]）。

なお、知識入力が長い文章になるほど、この効果は顕著になります。これは長い知識入力を処理する過程で「指示優先」パターンでは最初に読んだ指示内容が忘れられてしまう可能性があるのに対し、「変数優先」パターンでは最後に読んだ指示を覚えやすいためと考えられます。

この発見は、特に複数の文書や長い文章を扱う質問応答タスクなど、様々な長さの入力に対応する必要があるLLMアプリにとって実用的な価値の高い知見となる可能性があります。

![](https://ai-data-base.com/wp-content/uploads/2025/04/AIDB_87853_17.png)

知識入力プレースホルダの配置位置による出力品質への影響比較

![](https://ai-data-base.com/wp-content/uploads/2025/04/AIDB_87853_18.png)

知識入力の配置位置が異なる場合のLLM出力例の比較

### 変数（プレースホルダ）の名前づけの課題

現在のアプリの変数の名前づけには改善の余地があることもわかりました。現在、「text」（4.44%）や「input」（2.35%）といった意味の薄い名前が広く使われています。

これはプログラミングでの変数名と同じ問題を持っており、意味のある名前（例：「document」「question」など）に比べて、開発者やユーザーが理解しにくくなる可能性があります。テンプレートの管理のしやすさや読みやすさを良くするためには、具体的で意味のある変数名を使うことが勧められます。

## 実務でのLLMプロンプトテンプレート設計のガイドライン

これまでの実験から得られた知見は、LLM技術を使うさまざまな立場の人にとって実用的な価値があります。ここでは、LLMを使うユーザーや開発者への具体的な応用方法を見ていきましょう。

### LLMサービス選びのポイント

現在、OpenAI、Google、Anthropicなど多くのLLMサービス提供会社がプロンプトテンプレート機能を提供していますが、効果的なテンプレート設計についての具体的な指針はまだ十分ではありません。LLMサービスを選ぶときは、次のような点を考えるとよいでしょう。

#### ①用意されているテンプレートの充実度をチェック

LLMサービスを選ぶときは、よくあるタスク向けの既製テンプレートがどれだけ揃っているかを確認するとよいでしょう。例えば、情報検索用のJSON出力テンプレートや、RAG（検索拡張生成）方式の質問応答テンプレートなどが用意されているサービスは、開発の手間をかなり減らせます。

理想的なテンプレートは、この研究で明らかになった最適な要素の並び順（役割→指示→背景情報…）に従い、それぞれのタスクに合った最適なパターンを取り入れたものです。開発者の労力を減らしながら、高品質な出力を確保できるサービスを選びましょう。

#### ②テンプレートを評価・改良するツールがあるか

プロンプトテンプレートをテストして改良するための自動評価ツールを提供しているサービスも魅力的な選択肢です。このようなツールがあれば、同じ入力データに対して異なるテンプレートパターンを比較し、最適な設計を効率よく見つけられます。

理想的な評価ツールは、テンプレート内の制約条件や出力要件などの要素を分析し、「指示内容がどれだけ守られているか」や「出力形式の一貫性」といった客観的な評価基準に基づいて点数をつけ、改善点も教えてくれるものです。さらに、モデルのバージョン間の比較やテンプレート変更の履歴追跡といった機能があれば、開発の流れがさらに効率化されます。

これからは、これらの機能を提供する、自社のニーズに合ったサービスを選ぶことが重要です。また、自社でLLMアプリを提供する立場なら、このような支援ツールを自社で開発・提供することで、他社との差別化を図ることも検討できるでしょう。

### LLMアプリ開発者が役立てられる知見

#### ①プロンプトテンプレートの継続的な改善

プロンプトテンプレートは、ユーザー体験を良くするために常に調整すべきです。ユーザーからのフィードバックや専門家のレビューを取り入れて、継続的に改良することが望ましいでしょう。

入力の長さやコンテンツの種類など、過去の使用データを分析することで、変数（プレースホルダ）を最適化し、要素の配置を調整できます。これは特に長い入力を扱う場合に、重要な情報が見落とされるのを防ぐのに効果的です。

また、実際の使用場面に合わせて変数を調整することも大切です。例えば、背景情報と分析データを別々の変数に分けることで、わかりやすさと使いやすさが向上します。さらに、{output\_format}などの設定用変数を組み込むことで、柔軟性と安定性が高まり、さまざまなユーザーのニーズに対応できます。

そして、実験結果でわかったように、多くのプロンプトテンプレートではまだ「text」といったあいまいな変数名が使われています（約5%）。このような意味の薄い変数名は、前後関係なしでは理解しにくく、メンテナンス時に問題を起こす可能性があります。はっきりとわかりやすい名前を使うことで、エラーを減らし、開発者の記憶の負担を軽くし、開発者が入れ替わったときの問題を減らし、ソフトウェアの長期的な信頼性を確保できます。

#### ②適切なテンプレートで低コストモデルを強化

実験結果が示すように、適切に設計されたプロンプトテンプレートは、比較的性能の低いモデル（llama3-70b-8192など）の指示遵守能力を大幅に向上させることができます。場合によっては、これらのテンプレートにより、低コストモデルでも最高性能モデル（gpt-4oなど）に近い性能を実現できます。

例えば、長い文章の入力実験では、適切なプロンプトテンプレートによるllama3-70b-8192の性能向上が、gpt-4oの性能向上のほぼ2倍になりました。これは、慎重に設計されたプロンプトテンプレートが、性能の低いモデルを最適化する上でとても重要な役割を果たすことを示しています。

LLMアプリの基盤となるモデルを選ぶとき、開発者はより高度なモデルに切り替える前に、まず目的のタスク向けのプロンプトテンプレートの再設計を検討すべきです。適切に設計されたプロンプトテンプレートにより、性能の低いモデルの指示遵守能力を大幅に強化でき、コスト削減につながります。これはビジネスの成功にとって欠かせない要素です。

#### ③用例（Few-shot）アプローチのメリットとデメリット

幾つかの例を入力してその場で学習させる”Few-shotプロンプティング”は、ソフトウェア開発の研究で広く採用されているプロンプト工夫の手法です。しかし、構成要素の分布に関する統計分析から、データセット内のアプリの20%未満しかプロンプト内に例を含めていないことがわかりました。変数を通じて動的に読み込まれる例を考慮しても（5%未満）、用例はプロンプトテンプレートではまだ一般的ではありません。

過去の研究でも、はっきりと定義されたタスクは、用例なしでも用例ありの場合と同等以上の生成品質を達成できることが示されています。適切に定義されたプロンプトテンプレートを使う場合、用例は必ずしも必要ではなく、むしろ入力文字数の増加や意味の混乱リスクといったデメリットをもたらす可能性があります。

Few-shotプロンプティングは効果的ですが、万能の解決策ではありません。LLMアプリを設計するとき、開発者はFew-shotプロンプティングを標準とするのではなく、プロンプトテンプレートを改良・最適化してタスクの要件に合わせることを優先すべきです。

### プロンプトテンプレート設計の考察

実例分析と実験から、LLMアプリ開発におけるプロンプトテンプレート設計の重要性が以下のように明らかになりました。

1. プロンプトテンプレートの構造と要素の並び順が出力品質に大きく影響する
2. JSON出力の場合、単に形式を指定するだけでなく、項目名とその詳しい説明を含めることで、より正確で一貫性のある出力が得られる
3. 「〜してください」と「〜しないでください」の指示を組み合わせることで、出力の一貫性と予測可能性が向上する
4. 長い入力データを処理する場合、その配置場所がLLMの記憶と指示遵守に大きく影響する
5. 適切なプロンプトテンプレート設計により、必ずしも最新・最高性能のモデルを使わなくても、十分な品質の出力を得られる可能性がある

## まとめ

本記事では、実際のLLMアプリケーションで使用されているプロンプトテンプレートの構造と効果を体系的に分析した研究を紹介しました。

研究者らはGitHub上の多数のリポジトリから収集したテンプレートを分析し、効果的なテンプレート設計のパターンを明らかにしました。構成要素の配置順序、JSON出力の指定方法、制約条件の活用法、プレースホルダの配置など、様々な設計要素がLLMの出力品質に大きく影響することが実証されています。

今回得られた知見は、LLMを活用したアプリケーション開発において、適切なプロンプトテンプレート設計によるコスト効率の向上や出力品質の改善に役立てることができる可能性があります。

**参照文献情報**

- タイトル：From Prompts to Templates: A Systematic Prompt Template Analysis for Real-world LLMapps
- URL： [https://doi.org/10.48550/arXiv.2504.02052](https://doi.org/10.48550/arXiv.2504.02052)
- 著者：Yuetian Mao, Junjie He, Chunyang Chen
- 所属：Technical University of Munich

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[標準作業手順書（SOP）をもとにLLMエージェントシステムで業務の自動化をする方法](https://ai-data-base.com/archives/87250)

[手元のドキュメントからLLM評価用のオリジナルベンチマークを作成する](https://ai-data-base.com/archives/87773)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)