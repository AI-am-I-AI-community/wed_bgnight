---
title: "LLMを「人間の心のケア」を行うカウンセリングAIとして実行するためのプロンプト手法"
source: "https://ai-data-base.com/archives/74185"
author:
  - "[[AIDB Research]]"
published: 2024-08-13
created: 2025-06-13
description: "本記事では、LLMを用いて人々の考え方をポジティブに変えるアドバイスを生成するフレームワークを紹介します。心理学の専門知識に基づく6つの要素から構成される手法です。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、LLMを用いて人々の考え方をポジティブに変えるアドバイスを生成するフレームワークを紹介します。心理学の専門知識に基づく6つの要素から構成される手法です。

専門家による評価の結果、本手法は人々の考え方を効果的に改善する手法であることが示されました。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74185-1024x576.jpg)

**参照論文情報**

- タイトル：Large Language Models are Capable of Offering Cognitive Reappraisal, if Guided
- 著者：Hongli Zhan, Allen Zheng, Yoon Kyung Lee, Jina Suh, Junyi Jessy Li, Desmond C. Ong
- 所属：The University of Texas at Austin, Microsoft Research

## 背景

LLMが登場してからというもの、人間の感情的な部分をAIでサポートできる可能性が広く探求されてきました。しかし、人間が長期的にメンタルヘルスを維持するには、一時的に外部（LLM）が共感しサポートするだけでなく、本人がポジティブなものの見方を実践する必要があります。

そこで注目されるのが「認知的再評価」というアプローチです。本人が自身のおかれている状況をネガティブに捉えている場合に、ポジティブに捉え直させる手法です。

研究者たちは心理学的に裏付けられたこの手法を用いることで、LLMの高度な心理学的能力を引き出せるのではないかと考えました。そして、LLMによって認知的再評価を行うことに特化したフレームワークを開発しました。

そして実験の結果、本フレームワークを駆使することで、LLMによって人間の感じ方をポジティブに変換させることは有効であることがわかりました。

以下で詳しく紹介します。なお、本手法（カウンセリングするLLM）を実行するためのシステムプロンプトおよび実際に動くGPTsのURLを掲載します。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74185_1-1-1024x353.jpg)

LLMから、人間が状況の見方を変えるアドバイスを引き出す流れ

## LLMによる認知的再評価

### RESOРTというフレームワーク

今回LLMによる認知的再評価のために考案された手法『RESOРT』は、心理学者たちが注意深く作った「再評価のコツ」で構成されており、LLMに指示を出すためにつくられたものです。

中身としては、日常生活でよくある6つの物事の見方が含まれています。

1. 自分にどれだけ責任があるか
2. 問題にどう取り組むか
3. どこに注目するか
4. 感情にどう対処するか
5. 自分でどこまでコントロールできるか
6. 自分の価値観とどれだけ合っているか

上記6つの見方それぞれに対して、専門の心理学者が「再評価のコツ」を手作業で作りました。LLMが人々の状況を様々な角度から見直す手助けをするためのガイドラインとして働くものです。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74185_3-1024x735.png)

RESOРTで使う6つの評価項目と再評価の目的

```js
1. 自己責任
質問：「話し手は自分が状況を引き起こしたと思っていますか？」
目標：状況に対して責められるべきか、褒められるべきかを見直す。責任がないなら、そのことを認めて状況を再評価する。

2. 問題解決型対処
質問：「話し手は状況の結果に対処できると思っていますか？」
目標：状況に対処する能力に注目する。利用可能な資源やサポートを使って、自信を持って独立して対処するよう励ます。

3. 注意の向け方
質問：「話し手はこの状況にさらに注意を向ける必要があると思っていますか？」
目標：状況の緊急性や重要性を再考し、労力と注意を向ける価値があるか判断する。ない場合は、他のことに集中するよう勧める。

4. 感情対処
質問：「話し手は状況の結果に感情的に対処できると思っていますか？」
目標：感情的に対処し、感情をコントロールできるか再評価する。必要なら、ストレスを悪化させる可能性のある要因に立ち向かうか避けるかを検討する。

5. 自己制御可能性
質問：「話し手は状況をコントロールできると思っていますか？」
目標：話し手に状況をコントロールする力があるか再評価する。コントロールできないことから一歩引き、コントロールできることに集中するよう勧める。

6. 内的価値との一致
質問：「話し手は状況が自分の価値観と一致していると思っていますか？」
目標：状況が自分の内面的な価値観（社会規範、信念、道徳観など）とどの程度合っているか再評価する。誤解を避けるため、他の視点も考慮するよう勧める。
```

### 2つのプロンプト手法

LLMによって物事の見方を変えさせるために、2つのプロンプト手法が試されました。

1. 6つの見方それぞれについて、一つずつ新しい見方を考えてもらう方法
2. LLMに最初の見方を考えてもらい、それを少しずつ良くしていく方法（6つの見方全てを考慮に入れながら、徐々に完成させていく）

以下は、RESOРTの指示に従ってGPT-4がユーザーの状況を見直す例です。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74185_2-1024x392.jpg)

```js
人間：
昔の学校の友達に会いたいんだけど、その子がワクチン打ってないって分かったんだ。兄夫婦が「うちの子どもたちはワクチン打てないから、ワクチン打ってない人には会わないで」って言ってるんだ。兄の言う通りに全然会わないのは厳しすぎ？それとも、外で離れて会うくらいなら大丈夫かな？

AIの回答（ガイドなし）：
よく考えてみると、外で離れて会えば危ないことはあんまりないよ。でも、家族の心配も大事にすれば、子どもたちを守れるし、家族仲も良くなるよ。

AIの回答（RESOРTによるガイド付き）：
嫌な気持ちを減らすには、家族って大切だなって思うのと、今の状況はずっと続くわけじゃないって考えるといいよ。兄ちゃんが言ってることにも理由があって、みんなのことを思ってるんだなって分かれば、自分の気持ちも落ち着くと思う。困らないように、友達と話す別の方法を考えてみたら？例えば、ビデオで話したり、もっと安全になってから会う約束をしたりするのはどう？
```

なお、LLMに新しい見方を提案させる前に、まず与えられた状況をどう理解したか説明してもらいました。このような手順を踏んだ理由は、LLMが複雑な情報を理解する時には、段階を踏んで考えることが有効だという研究結果に基づいています。

以下は、論文の内容に基づくシステムプロンプトです。

```js
あなたは心理学的な再評価を提供するアシスタントです。ユーザーの状況に応じて、以下の6つの次元に基づいて再評価を行ってください。ユーザーが要求した形式で回答し、直接回答に入ってください。

1. 自分にどれだけ責任があるか：
状況に対する責任の認識を再評価します。過度の責任感は軽減し、責任がある場合は適切に認識するよう促します。
2. 問題にどう取り組むか：
状況への対処能力に焦点を当てます。問題を小さな段階に分け、具体的な計画を立てるよう促します。
3. どこに注目するか：
状況の重要性を再考し、注意を向けるべきかどうかを判断します。必要に応じて、他の重要な事柄に注意を向けるよう促します。
4. 感情にどう対処するか：
感情的な対処能力を評価します。否定的な感情を減らし、感情をコントロールする方法を提案します。
5. 自分でどこまでコントロールできるか：
状況をコントロールできる程度を再評価します。コントロールできない事柄から距離を置き、コントロールできることに焦点を当てるよう促します。
6. 自分の価値観とどれだけ合っているか：
状況が個人の価値観とどの程度一致しているかを再評価します。必要に応じて、他の視点からの理解を促します。

各次元に応じて、具体的で実行可能な提案を含めた再評価を提供してください。ユーザーの感情に配慮しつつ、建設的な視点の変化を促すよう心がけてください。
```

（編集部注：このシステムプロンプトを組み込んだGPTsを作成しました。 [こちらから](https://chatgpt.com/g/g-wwzKzLzHc-kaunseraai) お試しください）

## 実験内容について

### 評価に使用したデータ

実験では、人々の実際の悩みを使うために、Reddit（レディット）という掲示板から400個の投稿を選びました。投稿は大まかに4つのトピックに分類されます。全て、日常生活でよくある悩みです。

1. 不安について
2. 怒りについて
3. 子育てについて
4. コロナのサポートについて

投稿の長さは短すぎず長すぎないものを選びました。平均で約160単語くらいです。

実験に使う前に、全ての投稿を人間が読んで、攻撃的な言葉や人を傷つける内容がないか確認しました。

### 人間が書いた回答

実験では、LLMによる回答と比べるために人間による回答も用意されました。

1. 心理学を勉強している大学院生が20個の模範的な回答を書きました。どう答えるのが良いかの見本です。
2. 各投稿に対する一番人気のあるRedditユーザーコメントも集めました。投稿した人が期待している回答の例です。

### 実験設定

実験では、以下のLLMが使用されました。

1. GPT-4 turbo
2. LLaMA-2 (13B-chat)
3. Mistral (7B-instruct v0.1)

LLMに回答を作らせる際には、5つの方法が試されました。

1. 簡単な指示だけを与える方法
2. LLMに自分の回答を何度も直させる方法
3. まず状況をよく理解させてから回答を作らせる方法
4. 心理学者が作ったアドバイスを参考にさせる方法（本研究の提案手法RESOРT）
5. 上の3と4を組み合わせる方法

どの方法が一番良い回答を作れるか比べられるようにするために、まず全ての手法で同じ基本的な指示が与えられました。また、回答は短く簡潔に作るよう指示されました。さらに、回答がぶれないよう、設定（温度パラメータ）は0.1に固定されました。

なお、オープンソースモデルは、3台のNvidia A100 [GPU](https://ai-data-base.com/archives/26570 "GPU") で動かしました。

## 専門家によるLLMの回答評価

### 評価スキーマ

本研究は新しい取り組みのため、評価基準が作成されました。

1. **アドバイスの的確さ  
	**AIの回答が、心理学者が作った指針にどれくらい沿っているかを、1から10点で評価する
2. **思いやり  
	**AIの回答が、悩みを投稿した人の気持ちをどれくらい理解しているかを、1から5点で評価する
3. **安全性  
	**AIの回答に、人を傷つけたり、倫理的に問題がある内容が含まれていないかを、「安全」か「危険」で判断する
4. **正確さ  
	**AIの回答が、元の投稿の内容と矛盾していないかを、「正確」「少し間違いあり」「不正確」の3段階で判断する

### 評価者の専門家

評価には、4人の専門家（心理学の修士号か博士号を持つ人）に協力してもらいました。彼らは評価の前に特別な訓練を受け、評価の一致度もチェックされました。

評価の対象としては、22個のReddit投稿に対する、LLMによる184個の回答が使用されました。比較のため、人間が書いた模範的な回答や、Redditで人気の高かったコメントも評価に含まれました。

### 専門家たちの意見はどれくらい一致したか

それぞれの回答を2人の専門家が評価し、彼らの意見がどれくらい一致したかも調べました。「的確さ」と「思いやり」については、専門的な統計方法を使って一致度を測りました。また、「安全性」と「正確さ」については、別の統計方法で一致度を確認しました。

結果として、全ての項目で専門家たちの意見は、ある程度から十分に一致していました。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74185_4-1024x247.png)

専門家心理学者評価者間の一致度とGPT-4評価との一致度

### 結果

専門家による評価の結果、RESOРTを使うと、LLMの回答の質が大きく良くなることがわかりました。また、LLMに状況をよく理解させてから回答を作らせると、さらに質が上がりました。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74185_5-1024x613.png)

再評価応答に対する専門家心理学者の評価結果（平均スコア）

さらに、一つずつ回答を作るより、何度も改善しながら回答を作る方が、より良い結果になりました。

なお、AIの回答の98%以上は安全で、人を傷つけるような内容はありませんでした（一方、Redditの人気コメントは約39%が問題ありと判断されました）。

また、驚いたことに、AIの回答（RESOРTを使ったもの）は、人間が書いた回答よりも高く評価されました。特に「的確さ」と「思いやり」の面で高評価でした。

## LLMによる回答を自動で評価する試み

認知負荷の高いタスクにおいて現在のLLMはどれほどの能力を持つのでしょうか。

### プロンプトと設定

GPT-4を使って、他のモデルの回答を自動で評価しました。前に説明した4つの基準（的確さ、思いやり、安全性、正確さ）で評価しました。

評価の手順は以下のような形です。

1. どの基準で評価するかを決める
2. Redditの投稿を用意する
3. LLMの回答を用意する
4. GPT-4に評価の指示を与える
5. GPT-4が点数をつける

GPT-4には、人間の専門家と同じような詳しい指示を与えました。なお事前の訓練をせずに行いました。

### GPT-4は他のモデルをうまく評価できるか

専門家が評価した結果と比べて、GPT-4の評価がどれくらい近いか調べました。

その結果、GPT-4の評価は、専門家の評価とある程度一致していました。中でも「的確さ」と「思いやり」の評価が近いことがわかりました。

また、専門家と同じように、GPT-4もRESOРTを使ったLLMの回答を高く評価しました。また、Redditのコメントの30%を「危険」と判断しました。

## まとめ

本記事では、LLMの認知的再評価能力（前向きな考え方で捉え直させる力）を引き出すRESOРTフレームワークの研究を紹介しました。

心理学的に裏付けられた理論を用いてLLMをガイドすることで、人の感情をうまくサポートできることわかりました。専門家によると、RESOРTを使用した際のLLMの応答は人間の応答より高評価を得ました。

なお、今後は、個人の好みの主観性、複数回のやりとりでの効果、長期的な感情的幸福への影響の探求が課題となっています。

- 参照論文URL： [https://arxiv.org/abs/2404.01288](https://arxiv.org/abs/2404.01288)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[OpenAIがGPT-4oの評価を発表。音声性能が高く、それゆえのリスクも](https://ai-data-base.com/archives/74097)

[Sakana AIが科学研究自動化フレームワーク『The AI Scientist』開発](https://ai-data-base.com/archives/74257)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)