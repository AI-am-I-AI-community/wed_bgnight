---
title: "マルチモーダルLLMによる表やグラフの理解力を向上させる方法"
source: "https://ai-data-base.com/archives/82014"
author:
  - "[[AIDB Research]]"
published: 2025-01-14
created: 2025-06-13
description: "表やグラフといった構造化された画像は、私たちの日常生活において重要な役割を果たしていますが、LLMはこれらの画像を理解する際に「人間のように重要な部分に注目する能力」が不足しています。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

表やグラフといった構造化された画像は、私たちの日常生活において重要な役割を果たしていますが、LLMはこれらの画像を理解する際に「人間のように重要な部分に注目する能力」が不足しています。

そこで研究チームは、LLMに画像編集機能を組み込む手法を開発しました。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82014-1024x576.jpg)

**発表者情報**

- 研究者：Xingyu Fu et al.
- 研究機関：ペンシルベニア大学, バージニア工科大学, マイクロソフト

## 背景

私たちの日常生活では、表やグラフを通じて重要な情報がやり取りされています。例えば、企業の業績報告で使われる表や、データの傾向を示すグラフなどです。LLMにもこのような情報を理解してほしいところですが、現状では人間のような「賢い読み方」ができていません。

人間は表やグラフを見るとき、まず全体を見渡し、そこから必要な部分に注目し、順を追って情報を理解していきます。例えば売上データの表を見るとき、最初に「売上」の列を探し、その中から特に気になる期間の数字に注目する、といった具合です。しかしLLMは通常、画像全体を一度に処理しようとするため、このような段階的な理解が苦手です。

そのような課題に対し、マイクロソフトなどの研究チームは、LLMに「画像の見方」を教える新しい手法を開発しました。重要な部分を強調したり不要な部分を隠したりする編集機能を組み込むことで、LLMも人間のように段階的に画像を理解できるようになるとのことです。

研究者らはLLMが画像中の見るべき部分にフォーカスできるようにしたいと考えました。そこで画像編集ツールをLLMが自ら扱えるようにフレームワーク『REFOCUS』を作成しました。

下記にプロジェクトページがあります。  
[https://zeyofu.github.io/ReFocus/](https://zeyofu.github.io/ReFocus/)

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82014_1-1024x384.jpg)

提案手法『REFOCUS』の概要

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82014_2-1024x404.jpg)

GPT-4o単体とREFOCUS使用時との比較例

## 画像処理対象

REFOCUSが処理対象とする構造化画像には、主に2種類があります。

1つ目は表形式の画像で、Wikipediaの表をスクリーンショットで切り取ったものや、HTMLから生成された合成データが含まれます。

表形式データを処理する際は、 [OpenCV](https://ai-data-base.com/archives/26307 "OpenCV") ライブラリを使用して表の構造を解析します。縦線と横線の検出、テキストの位置特定、行と列の長さの計測といった処理により、表の各要素の正確な座標が取得されます。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82014_5-1024x251.jpg)

OCR （ 光学文字認識 ）能力の向上を示す例 列のハイライトによってGPT-4の文字認識精度が向上することを示す

2つ目はグラフ形式の画像で、棒グラフや学術論文で使用される複雑なグラフなどが対象となります。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82014_3-1024x421.jpg)

複数のサブプロットがある科学的なチャートで、関連する部分に焦点を当てることで正確な回答が可能になることを示す

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82014_4-1024x344.png)

ChartQAの垂直棒グラフでの視覚的理解と計数能力の向上を示す例

## 利用される視覚的編集ツール群

REFOCUSでは、3種類の基本的な視覚的編集手法が実装されています。マスク処理による不要部分の除去、ボックス描画による重要部分の強調、色によるハイライト表示です。編集ツールはPythonコードとして実装され、LLMからの指示に基づいて実行されます。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82014_6-1024x516.png)

列をハイライトするためのPythonコード例

### 表データ向け編集ツール

表形式のデータに対しては、6つの機能が用意されています。これらは既存のツールではなく、今回開発されたものです。そのため、もし自ら実装を再現する場合はコンセプトを参考にしてください。

（１）Highlight Column

指定された列に薄い赤色の半透明オーバーレイを重ねることで、注目すべき列を視覚的に強調します。

（２）Highlight Row

同様に、指定された行に対して半透明の赤色オーバーレイを適用し、重要な行を目立たせます。

（３）Mask Column

注目する必要のない列を白色で塗りつぶすことで、視覚的なノイズを低減します。

（４）Mask Row

同様に、重要でない行を白色で隠蔽し、必要な情報に集中しやすくします。

（５）Draw Column

指定された列の周囲に赤色の実線ボックスを描画することで、視覚的な注目を促します。

（６）Draw Row

指定された行の周囲に赤色の実線ボックスを描画し、その行の重要性を示します。

### グラフデータ向け編集ツール

グラフデータに対しても、同様の3種類の編集手法（マスク、描画、ハイライト）が実装されています。ただし、適用対象は以下の3つの要素に特化されています。

- [CharXiv](https://charxiv.github.io/) 用の複数サブプロット処理
- 垂直棒グラフのX軸値に基づく処理
- 水平棒グラフのY軸値に基づく処理

各編集ツールは、 [OpenCV](https://ai-data-base.com/archives/26307 "OpenCV") を使用して検出された座標情報に基づいて動作します。編集操作は画像全体の構造を保持したまま、必要な部分のみを強調または隠すといった内容です。

## 実装内容

本手法のコンセプトとしては、視覚的編集ツールがLLMに対して関数名のリストとして提供されます.

LLMはその関数を用いてPythonコードを生成し、画像編集を実行します。

編集された画像は再びLLMに入力として与えられ、最終的な回答が得られるまでこのプロセスが繰り返されます。

### インタラクションの仕組み

プロセスは次のような流れで進行します。

1. まず、LLMには質問と画像が入力として与えられます。
2. LLMは質問を理解し、必要な視覚的編集を判断します。
3. 判断に基づいて、適切な関数を呼び出すPythonコードを生成します。  
	（例えば、表の特定の列に注目したい場合は、 `focus_on_columns_with_highlight` 関数を呼び出すコードが生成されます）
4. 生成されたコードは実行環境で処理され、画像が編集されます。
5. 編集された画像は再びLLMに提供され、LLMは編集結果を確認しながら次のステップを判断します。
6. 必要に応じて、さらなる編集操作が行われます。

### プロンプトの構成

LLMへの指示（プロンプト）には、以下の要素が重要なものとして含まれます。

- 利用可能な編集ツールの一覧と各ツールの詳細な説明
- 入力画像のフォーマットと座標情報の説明
- コード生成時の制約条件（例：関数の引数の形式）
- 編集プロセスの終了条件の定義

プロンプトは、LLMが適切なタイミングで適切なツールを選択できるよう、具体的な例も含めて構成されています。例えば、表の列を強調したい場合のサンプルコードや、グラフの特定の部分をマスクする際の座標指定方法などが示されています。

### エラー処理とフィードバック

編集操作の実行時には、エラー処理も行われます。生成されたコードが実行できない場合や、座標情報が不正確な場合には、LLMにフィードバックが提供され、修正されたコードの生成が促されます。修正のプロセスは、最終的に適切な編集が実現されるまで継続されます。

## 実験構成と分析結果

実験では、REFOCUSの効果を複数の異なるタイプの画像理解タスクにおいて検証しました。ベースラインとして最新のGPT-4oモデルが使用され、表形式データとグラフデータの両方で評価が行われました。

### ベースラインモデルの選定

評価の基準として、GPT-4oの2024年5月版と8月版が使用されました。比較対象として、LLaVA-NeXT、Phi 3 Vision、Gemini Pro 1.5といった最新のLLMも含まれています。公平な比較のため、すべてのモデルで会話形式の入力が採用されました。

### 表形式データにおける評価

表形式データの実験では、WikiTableQuestionから派生したVWTQデータセット、合成データセットのVWTQ\_syn、事実検証タスクのVTabFactが使用されました。実験結果では、REFOCUSを適用することで平均11.0%の性能向上が確認されました。性能向上の主な要因は、LLMが表の中の重要な情報に段階的に焦点を当てられるようになったことです。

### グラフデータにおける評価

グラフデータの実験では、学術論文で使用される複雑なグラフ（CharXiv）、水平棒グラフ、垂直棒グラフの3種類が評価対象となりました。実験結果では、平均6.8%の性能向上が達成されました。視覚的な編集機能により、LLMはグラフの特定の部分に注目しやすくなり、より正確な情報抽出が可能になりました。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82014_7-1024x414.png)

GPT-4oに使用した場合

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82014_8-1024x356.png)

オープンソースモデルに使用した場合

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82014_9-1024x283.png)

入力形式の違いによる性能比較。テキストのみ、画像のみ、テキスト+画像といった異なる入力形式での性能。

### 性能向上のメカニズム分析

REFOCUSが性能向上をもたらす理由について、詳細な分析が行われました。追加情報を導入することなく性能が向上した主な要因として、以下の点が明らかになりました。

1. 視覚的な情報のグラウンディング（画像内の位置特定）の改善
2. 文字認識（ [OCR](https://ai-data-base.com/archives/26261 "光学文字認識（OCR）") ）の精度向上
3. 誤った推論（ハルシネーション）の削減

### 編集ツールの効果比較

VWTQとVWTQ\_synデータセットを用いて、マスク処理、ボックス描画、ハイライト機能の効果が比較されました。実験結果では、どの編集ツールも同程度の効果を示し、特定のツールが突出して優れているという傾向は見られませんでした。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82014_10.png)

異なる編集ツールがモデルのパフォーマンスにどのように影響するかを分析した結果

### 編集頻度の分析

画像編集の頻度についても分析が行われ、タスクによって編集の必要性が異なることが明らかになりました。VWTQとCharXivでは85%以上の事例で編集が必要とされた一方、他のデータセットでは40-55%程度の編集頻度でした。編集の頻度は、タスクの複雑さや画像の構造に依存することが示唆されています。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82014_12.png)

視覚的編集がどの程度頻繁に実行されるかを示す統計グラフ データセットごとの編集頻度の違いを示す

## REFOCUSデータを用いたモデルの改良

REFOCUSの視覚的な編集機能は、プロンプトベースの手法として効果を発揮しましたが、さらなる発展として、モデル自体にREFOCUSの能力を組み込む試みが行われました。研究チームは、視覚的な推論プロセスをモデルに直接学習させることで、より効率的な画像理解の実現を目指しました。

### トレーニングデータの収集方法

ChartQAデータセットの訓練データ15,059件を基に、REFOCUSとGPT-4oを用いて新しいトレーニングデータが作成されました。作成プロセスでは、正しい予測が得られた場合、テキストによる推論チェーン、画像編集用のPythonコード、注目すべき領域の座標情報が記録されました。誤った予測の場合は、正解を提示して再試行が行われ、それでも誤った場合はデータから除外されました。最終的に14,344件のトレーニングデータが得られ、そのうち12,819件に編集プロセスが含まれていました。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82014_11-1024x124.png)

### モデル改良の実験設定

ベースモデルとしてPhi-3.5-visionが採用され、標準的な教師あり学習（SFT）が実施されました。入力形式として、画像、質問文、推論過程、注目領域の座標情報、回答が一つのセットとして使用されました。比較のため、同じデータセットから質問と回答のペアのみを抽出した従来型のトレーニングデータも用意されました。

### 実験結果の分析

実験結果では、REFOCUSの視覚的推論データで学習したモデルが、以下の点で優れた性能を示しました。

- ベースモデルと比較して3.2%の性能向上
- 従来型の質問回答データによる学習と比較して8.0%の性能向上
- 推論チェーンのみのデータと比較して2.6%の性能向上

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82014_13.png)

SFT（Supervised Fine-tuning）の精度結果を示す 異なるトレーニング方法での性能比較

### 結果の解釈

実験結果から、視覚的な推論プロセスを含むデータでの学習が、単純な質問回答データよりも効果的であることが明らかになりました。画像のどの部分に注目すべきかという情報が、モデルの理解力向上に重要な役割を果たしていると考えられます。具体的な座標情報を含むことで、モデルは画像内の重要な領域をより正確に識別できるようになったと解釈されます。

## まとめ

本記事では、LLMの構造化画像理解能力を向上させる新しいフレームワーク「REFOCUS」について紹介しました。REFOCUSは、画像編集を通じた段階的な視覚的推論を実現し、表やグラフの理解タスクにおいて有意な性能向上を達成しています。研究チームは更に、REFOCUSによって生成された視覚的推論データを用いた学習が、従来の質問回答データよりも効果的であることを実証し、LLMの視覚的理解能力向上における新たな可能性を示しました。

**参照文献情報**

- タイトル：ReFocus: Visual Editing as a Chain of Thought for Structured Image Understanding
- URL： [https://arxiv.org/abs/2501.05452](https://arxiv.org/abs/2501.05452)
- 著者：Xingyu Fu, Minqian Liu, Zhengyuan Yang, John Corring, Yijuan Lu, Jianwei Yang, Dan Roth, Dinei Florencio, Cha Zhang
- 所属：University of Pennsylvania, Virginia Tech, Microsoft

## 理解度クイズ（β版）

1\. REFOCUSが解決を目指す主な課題は何ですか？

LLMは画像全体を一度に処理しようとするため、人間のような段階的な理解が困難でした。REFOCUSは画像編集機能を組み込むことで、重要な部分に順を追って注目できるようにしました。

解説を見る

2\. REFOCUSが実装している3つの基本的な視覚的編集手法はどれですか？

REFOCUSは不要部分の除去(マスク処理)、重要部分の強調(ボックス描画)、色による強調(ハイライト表示)を実装しています。これらの編集ツールはPythonコードとして実装され、LLMからの指示で実行されます。

解説を見る

3\. REFOCUSの処理フローとして正しい順序はどれですか？

REFOCUSは質問と画像を受け取り、LLMが必要な編集を判断してPythonコードを生成し、編集後の画像を基に回答を生成します。この過程は必要に応じて繰り返されます。

解説を見る

4\. Phi-3.5-visionモデルでREFOCUSを学習させた際の最も顕著な改善点は？

REFOCUSの視覚的推論データで学習したモデルは、従来の質問回答データによる学習と比較して8.0%の性能向上を達成しました。視覚的な推論プロセスを含むデータでの学習が、単純な質問回答データよりも効果的であることが実証されました。

解説を見る

5\. 表形式データとグラフデータにおけるREFOCUSの性能向上の違いは？

表形式データでは平均11.0%、グラフデータでは平均6.8%の性能向上が確認されました。表形式データでより大きな改善が見られた理由は、LLMが表の中の重要な情報に段階的に焦点を当てられるようになったためです。

解説を見る

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[科学研究の自動化だけでなく人間と協働する「コパイロットモード」も備えるLLMエージェント登場](https://ai-data-base.com/archives/81883)

[単一のLLMから２つのエージェントを作成し自分（たち）で改善させる手法が有効](https://ai-data-base.com/archives/82124)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)