---
title: "多くの「長いコンテキストを要するタスク」を、短いコンテキストウィンドウのLLMで解決する手法"
source: "https://ai-data-base.com/archives/69938"
author:
  - "[[AIDB Research]]"
published: 2024-05-29
created: 2025-06-13
description: "長いコンテキストのタスクに対し、短いプロンプトのみ処理できるモデルでも取り組める「LC-Boost」フレームワークが考案されました。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

長いコンテキストのタスクに対し、短いプロンプトのみ処理できるモデルでも取り組める「LC-Boost」フレームワークが考案されました。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69938-1024x576.jpg)

**参照論文情報**

- タイトル：Are Long-LLMs A Necessity For Long-Context Tasks?
- 著者：Hongjin Qian, Zheng Liu, Peitian Zhang, Kelong Mao, Yujia Zhou, Xu Chen, Zhicheng Dou
- 所属：Renmin University of China, Beijing Academy of Artificial Intelligence

**本記事の関連研究** ：

- [LLMのプロンプトに数百から数千の例を含める超長尺のコンテキスト内学習（In-context learning）とファインチューニングの性能比較](https://ai-data-base.com/archives/68564)
- [LLMにおける、長いコンテキストから欲しい情報を見つけ出す「needle-in-a-haystack（干し草の中の針）」テスト結果とプロンプト例](https://ai-data-base.com/archives/68016)
- [GPT-4o、Gemini、Claude 3などにおける「長いプロンプトのマルチモーダルタスク」性能を測定した結果](https://ai-data-base.com/archives/69354)
- [スタンフォード大学の研究者ら、GPT-4oとGemini1.5 Proで「マルチモーダルモデルにおける『Many-Shot』の効果」を検証](https://ai-data-base.com/archives/69211)

## 背景

最近、長文の質問応答や要約などのタスクにLLMが活用されるようになってきました。しかし、一部のモデルは長いプロンプトを処理できるようになっていますが、既存のLLMの多くは、限られた長さのコンテキストしか処理できないという制約があります。

一般的に、LLMのコンテキストウィンドウを拡張すれば長いコンテキストへの対応が可能になります。しかしモデルの学習や適用に膨大なコストがかかるだけでなく、短いコンテキストに対する汎用性が損なわれる恐れもあります。そこで、長いコンテキストを短いコンテキストに分解することで、効率的に長いコンテキストのタスクを解決できないかという発想が生まれました。

こうした背景から、短いコンテキストのみ処理するLLMを用いて長いコンテキストのタスクに取り組む新たな手法LC-Boost（Long-Context Bootstrapper）が考案されました。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69938_1-1024x534.jpg)

LC-Boostの概念図。ブルートフォース法、Naive RAG、LC-Boost (RAG)、LC-Boost (Divide-and-Conquer)の4つのアプローチを比較

## LC-Boostの方法論

LLMが、自身のコンテキストウィンドウを大幅に超える入力を処理しなければならない場合があります。例えば、あるLLMが4,000単語までしか処理できない場合に、10,000単語の文章を与えられることがあります。

この問題に対処する最もシンプルな方法は、LLMのコンテキストウィンドウを増やすことです。つまり、モデルが処理できるコンテキストの長さを伸ばせば、長い文章も一度に処理できるようになるというわけです。

しかし、研究者らは別の可能性を探ろうとしています。それは長い文章を小さく分割して処理できるようにしようというアイデアです。では、これが本当に可能なのでしょうか？

研究者たちは、質問応答や要約、フューショット学習など、長いコンテキストを必要とするさまざまなタスクで実験を行いました。GPT-4を使い、以下の2つの方法でタスクを解かせました。

1. 長いコンテキスト全体をGPT-4に一度に入力し、答えを直接生成させる（ブルートフォース法）。
2. 長いコンテキストを短いコンテキストに分割し、提案手法を使って最小限の必要なコンテキストを近似的に抽出し、それを使って答えを生成させる（LC-Boost法）。

その結果、LC-Boost法はブルートフォース法と同等かそれ以上の性能を示し、質問応答やフューショット学習などのタスクではLC-Boost法が優れていました。ただし要約やコード生成などのタスクでは、短いコンテキスト間の依存関係が強いため、LC-Boost法での性能向上は限定的でした。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69938_2-1024x501.jpg)

様々なタスクにわたるパイロットスタディ。全体のコンテキストをGPT-4-128Kに入力する「Brute-force」設定と、最大コンテキストウィンドウを4Kに制限し、LC-Boostを用いて長いコンテキストの問題を短いコンテキストで解決する設定を比較

実験結果のさらなる説明は後述します。  
下記ではLC-Boostという手法について詳しく見ていきます。

本手法の主なアイデアは、長いコンテキストを一度に処理するのではなく、必要な短いコンテキストだけを戦略的に選択し、それらから関連情報を柔軟に取り出すことです。

### フレームワークのステップ

#### (1) タスクの受け取りと初期化

まず、入力としてユーザーのクエリと長いコンテキストを受け取ります。長いコンテキストはそのままでは処理が難しいため、複数の部分コンテキストに分割します。次に、関連情報を保存するための変数を初期化します。この段階で、抽出された関連情報はまだ何も含まれていない状態です。

#### (2) タスク理解 (Task Understanding)

次に、クエリとタスクの内容を分析し、与えられたタスクに対して最も効果的な処理方法を計画します。ここで、フレームワークは次に取るべき具体的なアクションを決定します。

#### (3) コンテキストへのアクセス (Access)

続いて、コンテキストへのアクセスに移ります。このステップでは、コンテキスト全体から関連性の高い部分を検索し、必要な情報を取得します。長いコンテキストを一度に処理するのではなく、段階的に必要な部分だけを取り出して処理します。

#### (4) 情報の利用 (Utilize)

次のステップでは、取得した情報を利用します。現在の部分コンテキストから独立して関連情報を抽出し、蓄積された情報に追加する場合もあれば、以前に取得した情報と統合する場合もあります。

#### (5) クエリへの回答 (Answer)

最後に、クエリへの回答を生成します。取得した全ての情報を基に、ユーザーのクエリに対する最終的な回答を作成します。直接回答を生成することもあれば、複数の情報を統合して総合的な回答を生成することもあります。

下記は、LC-Boostフレームワークのアルゴリズムです。長いコンテキストタスクを効率的に処理する手順が示されています。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69938_3-1024x453.png)

1. クエリ (q) と長いコンテキスト (X) を入力として受け取り、X を部分コンテキストに分割します。
2. 抽出された関連情報を保存する変数 X̃ を初期化します。
3. タスク理解ステップを実行して、適切な処理方法を計画します。
4. 各部分コンテキストに対して適切なアクションを選択し、情報を抽出または統合します。
5. すべての部分コンテキストを処理し終えたら、最終的な回答を生成し、出力します。
- **q**: 入力クエリ
- **X**: 長いコンテキスト
- **Y**: 出力される最終的な回答
- **X1, X2, …, Xn**: 分割された部分コンテキスト
- **X̃**: 抽出された関連コンテキスト
- **A**: アクションの集合（Move, Retrieve, Append, Merge, Answer, Aggregation）
- **γ**: モデルが実行する関数、特にアクションの選択や回答生成を指します
- **i**: 現在の処理ステップのインデックス

## 実験

本手法が実際に長い文章を扱うタスクで効果があるのかを確かめるために、研究者たちは12個のデータセットを使って実験を行いました。現実世界で出会うような長い文章を使った質問応答や要約のタスクが含まれています。また、研究用に作られた人工的なタスクも含まれています。

以下は実験に使用された各データセットの説明です。

1. **NarrativeQA**
	- 長い物語について質問に答えるタスクです。物語全体を理解して質問に答える必要があります。
2. **Qasper**
	- 研究論文に基づく質問応答タスクです。論文の内容に関連する質問に対して正確に答えることが求められます。
3. **MultiFieldQA**
	- 複数の分野にまたがる質問応答タスクです。異なるトピックのコンテキストを理解して質問に答える必要があります。
4. **HotpotQA**
	- マルチホップ質問応答タスクで、複数の文書から関連情報を結びつけて質問に答えます。長いコンテキストをまたいで情報を統合する能力が試されます。
5. **MuSiQue**
	- マルチドキュメント質問応答タスクです。複数の情報源からの情報を組み合わせて質問に答える必要があります。
6. **2WikiMQA**
	- 複数のウィキペディア記事に基づく質問応答タスクです。異なる記事から関連情報を引き出して質問に答えます。
7. **GovReport**
	- 政府報告書の要約タスクです。長い政府報告書を短く要約する能力が評価されます。
8. **MultiNews**
	- ニュース記事の要約タスクです。複数のニュース記事から情報を抽出し、要約します。
9. **SAMSum**
	- ダイアログ（会話）の要約タスクです。会話内容を要約し、重要なポイントを抽出します。
10. **Passage Count**
	- パッセージの数を数える合成タスクです。与えられたコンテキストから特定のパッセージを数えます。
11. **Self-Constructed Dataset**
	- 実際のシナリオから抽出された長いコンテキストに基づく質問応答タスクです。例えばオリンピックのスケジュールや学会の受諾論文リストなどがあります。
12. **LCC (LongCoder Code Completion)**
	- コード補完タスクです。長いコードのコンテキストから正確にコードを補完する能力が試されます。

LC-Boostの性能を評価するために、研究者たちは3種類の言語モデルを比較対象として用意しました。1つ目は、扱える文章の長さが比較的短いモデル（32,000単語未満）、2つ目は、長い文章を扱えるモデル（32,000単語以上）、そして3つ目は、内部構造が公開されていない非公開のモデルです。

実験で使用されたモデルは、詳しくは以下の通りです。

1. 短いコンテキストのLLM（コンテキストウィンドウが32K未満）:
	- Llama2-7B-Chat-4K
	- Llama3-8B-Instruct-8K
	- Vicuna-v1.5-7B-16K
2. 長いコンテキストのLLM（コンテキストウィンドウが32K以上）:
	- LongChat-v1.5-7B-32K
	- Mistral-7B-Instruct-v0.2-32K
	- Llama3-8B-80K
	- Phi-3-mini-128K
	- Yi-9B-200K
3. 非公開のLLM:
	- DeepSeek-v2 (32K)
	- Claude-3-Haiku (200K)
	- GPT-3.5-turbo-16K

実験の結果、LC-Boostはほとんどすべてのタスクにおいて、他のモデルよりも優れた性能を示しました。注目すべきは、LC-Boostが扱える文章の長さを4,000単語に制限しているにもかかわらず、優れた結果を達成したことです。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69938_4-1024x543.png)

主な実験結果。各タスクにおける全モデルの平均スコア（%）

一方で、長い文章を扱えるモデルは、短い文章を扱うモデルよりも全般的に高い性能を示しました。ただし、タスクによって性能のばらつきが見られ、必ずしも一貫した結果ではありませんでした。モデルを長い文章用に最適化すると、汎用性が失われる可能性を示唆しています。つまり、特定のタスクには強いが、他のタスクではパフォーマンスが落ちるということです。

また、LC-Boostは、その基盤となったモデル（GPT-3.5-turbo-16K）と比較しても、全てのタスクで大幅な性能向上を達成しました。これは、LC-Boostが少ないリソースで効果的に性能を引き出せることを示しています。

LC-Boostの設計の必要性を確認するために、研究者たちはLC-Boostの行動選択方法を変更する追加実験も行いました。その結果、LC-Boostが状況に応じて動的に行動を選択することが、大きな性能向上につながることが分かりました。なお質問応答タスクでは、LC-Boostが関連するコンテキストを的確に選択し、不要な情報を除外できるため、非常に効果的でした。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69938_5-1024x349.jpg)

異なるコンテキスト処理戦略の性能比較。NarrativeQA、HotpotQA、SAMSumタスクにおける結果

ただし、少ない事例から学習するフューショット学習タスクでは、LC-Boostの動的な行動選択があまり活かされませんでした。これは、タスク自体に十分な学習情報が含まれているため、コンテキスト選択の影響が小さいことが原因と考えられます。

さらに、研究者たちは独自のデータセット（文章全体を理解しないと答えられない難しい質問が含まれる）を作成し、LC-Boostの性能をより詳細に分析しました。実験の結果、多くの言語モデルは十分な長さのコンテキストを与えられたにもかかわらず、正しい回答を生成できませんでした。しかし、LC-Boostは状況に応じて柔軟に対処することで、短いコンテキストでも効果的に問題を解決できました。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69938_6-1024x449.png)

自作データセットにおける、各モデルの応答例。正解は青、不正解は赤、あいまいな回答はオレンジで示されている

さらにLC-Boostのエネルギー効率についても分析が行われ、長い文章を扱う他のモデルと比べて大幅なエネルギー消費削減が確認されました。ただし、タスクの種類によってはトークン（単語）の消費量が増える場合もあることが分かりました。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69938_7.png)

Brute-force方法とLC-Boost方法の理論的および実際のエネルギー消費を比較

## まとめ

本記事では、長いコンテキストのタスクを短いコンテキストで解決するLC-Boostの研究を紹介しました。

12のデータセットでの実験から、LC-Boostは4Kのコンテキストウィンドウで優れた性能を達成しつつ、大幅なリソース節約を実現できることが示され、質問応答タスクでは顕著な性能向上が見られました。

また、難しい推論タスクへの動的な対処や、省エネルギー性とタスクに応じたトークン消費量の傾向も明らかになりました。

長いコンテキストのタスクに対する効果的かつ効率的な解決策として、今後の発展と実用化が期待される手法です。

- 参照論文URL： [https://arxiv.org/abs/2405.15318](https://arxiv.org/abs/2405.15318)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[時系列データの異常検知にLLMを使用する手法と実行プロンプト](https://ai-data-base.com/archives/69867)

[AGIへのロードマップ　カーネギーメロン大学など複数機関からの研究グループが提唱](https://ai-data-base.com/archives/70005)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)