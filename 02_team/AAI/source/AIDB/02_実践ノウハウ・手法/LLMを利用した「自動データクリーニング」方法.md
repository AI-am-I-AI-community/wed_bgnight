---
title: "LLMを利用した「自動データクリーニング」方法"
source: "https://ai-data-base.com/archives/80508"
author:
  - "[[AIDB Research]]"
published: 2024-12-13
created: 2025-06-13
description: "本記事では、データ活用の現場で大きな壁となっているデータクリーニングという作業を効率化する自動化手法を紹介します。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、データ活用の現場で大きな壁となっているデータクリーニングという作業を効率化する自動化手法を紹介します。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80508-1024x576.jpg)

**発表者情報**

- 研究者：Lan Li et al.
- 研究機関：イリノイ大学

## 背景

私たちの身の回りには、様々な形でデータが記録・蓄積されています。その中で、例えば飲食店の衛生検査データを管理する係だったとします。同じスターバックスコーヒーの店舗でも、「STARBUCKS COFFEE #279」「Starbucks Coffee #2901」のように表記が揺れていたり、検査結果が「pass」「PASS」「Pass」と異なる形式で記録されていたりすることがあります。エクセルで管理している顧客データでも、「株式会社」「（株）」「KK」など、企業名の表記が担当者によってバラバラ、という経験をお持ちの方も多いのではないでしょうか。

このようなデータの不整合は、分析結果に大きな影響を与える可能性があります。同じ店舗が別々の店舗としてカウントされたり、検査合格店舗の集計に誤りが生じたりするかもしれません。顧客データの場合、同じ企業が重複してカウントされることで、取引先の総数が実際より多く見積もられてしまう恐れもあります。

こうした問題を解決するために必要なのが、データクリーニングと呼ばれる作業です。しかし、大量のデータを手作業で確認し、修正していくのは途方もない時間と労力がかかります。実際、データを扱う専門家であるデータサイエンティストでさえ、作業時間の80%以上をこのデータクリーニングに費やしているという調査結果があります。

さらに、データクリーニングの方法は目的によって変わってきます。例えば店舗数を正確に把握したい場合は表記ゆれを統一する必要がありますが、各店舗の詳細な情報を分析したい場合は、むしろ細かな表記の違いを残しておくことが重要かもしれません。

そんな中、研究者らはこの課題を解決するため、LLMを活用した自動データクリーニングシステムの開発に取り組みました。人間の言語を理解し、状況に応じて適切な対応ができるLLMの能力は、データクリーニングの自動化にも大きな可能性を秘めているのです。

以下で詳しく紹介します。

## 3段階のプロセスによる自動データクリーニングの提案

研究者らは、データクリーニングを自動化するための「AutoDCWorkflow」という仕組みを考案しました。データと分析目的を入力として受け取り、クリーニング済みのデータと作業手順（ワークフロー）を出力するというアイデアです。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80508_1-1024x579.png)

データキュレーター/研究者からの目的設定に基づき、LLMがクリーニング目標を判断しワークフローを生成する流れを示す。

例えば、「飲食店の検査データから、地域ごとの合格店舗数を集計したい」という目的が与えられた場合、店舗名や検査結果の表記ゆれを自動的に修正し、分析可能な形に整えていきます。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80508_2-1024x708.png)

シカゴの食品検査データを例に、目的によって必要なクリーニング方法が変わることを示す具体例。

### アイデアの全体像

AutoDCWorkflowは大きく2つのパートで構成されます。

1. LLMによる作業計画の立案
2. [OpenRefine](https://openrefine.org/) （既存のデータクリーニングツール）による実際の処理

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80508_4-1024x219.png)

LLMエージェントによる計画立案とOpenRefineによる実行の2段階で構成される全体像

重要なのが、LLMによる作業計画の立案です。以下の3つのステップを繰り返すことで進められます。

ステップ1：必要な列の特定  
ステップ2：データの品質チェック  
ステップ3：必要な作業の選定

### システムの動作の流れ

LLMが作成した作業計画は、 [OpenRefine](https://openrefine.org/) という（データのクレンジングや変換、復元などを簡単に行うために設計された、オープンソースの）データクリーニングツールによって実際に実行されます。実行結果は記録され、次の作業計画の立案に活用されます。こうした流れを繰り返すことで、徐々にデータがクリーニングされていきます。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80508_3-1024x517.jpg)

OpenRefineにおけるデータクリーニングレシピのスクリーンショット。 実際のデータクリーニング作業手順を示す。

では、先ほど説明した3つについて、より詳しく見ていきましょう。

#### 効率的な列の選択

分析に必要な列だけを選ぶことで、効率的なクリーニングを行います。LLMは、テーブルの概要情報（列の名前や、各列の最初の15個程度のデータ）と分析目的を確認し、必要な列を判断します。

例えば飲食店の検査データで「合格店舗数を知りたい」という目的の場合、「店舗名」と「検査結果」の列は必要ですが、「検査官ID」といった列は不要と判断されます。

#### 4つの観点からの品質チェック

データ品質の評価は以下の4つの観点から行われます。

1. 正確性：明らかな間違いがないかをチェックします。間違いの例としては、数値が文字列として入力されているなどです。
2. 関連性：分析目的に合っているかを確認します。例えば「地域別の集計」なら住所情報が必要です。
3. 完全性：データの欠損状況を評価します。重要な情報が空欄になっていないかなどを見ます。
4. 簡潔性：表記の統一性を確認します。例えば同じ店舗名が異なる形式で記録されていないかなど。

チェックで問題が見つかった場合、具体的な修正方針が立てられます。

#### 高度な作業の自動化

LLMは以下の2種類の複雑な作業を自動化します。

（１）似た表記の統一（mass\_edit）  
LLMが似た表記を自動的に見つけ出し、適切な統一形を提案します。  
例：「STARBUCKS」「Starbucks」「スターバックス」を一つの表記に統一

（２）パターンに基づく修正（regexr\_transform）  
LLMがパターンを認識し、必要な変換ルールを自動生成します。  
例：「2024年3月1日」「2024/3/1」「20240301」といった日付形式の統一

より細かくは、以下の操作が行われます。

- 大文字への変換
- 余分な空白の削除
- 数値形式の統一
- 日付形式の統一
- 似た表記の統一
- 特定のパターンに基づく修正

下記はLLMに対してデータクリーニング操作の定義と使用例を示すプロンプト内容です。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80508_t1-edited.jpg)

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80508_5-1-1024x139.png)

各操作の説明と、それらが影響を与える品質の側面を整理

この3つのステップを繰り返し実行することで、分析目的に適した形へとデータを段階的にクリーニングしていきます。

この方法論のポイントは、人間の判断プロセスをLLMで再現しようとしている点です。データ品質の評価基準を明確に定義し、それに基づいて必要な作業を選定していく流れは、熟練したデータアナリストの作業プロセスに近いものとなっています。

## 3つのLLMを使用した本提案手法の評価実験

### 評価用データの選定と準備について

研究者らは、実務での活用を想定し、3つの異なる分野から実データを収集しました。

まず、ニューヨーク公共図書館が公開しているレストランメニューのデータを採用しました。このMenuデータセットには、料理名や価格といった基本情報に加え、メニュー上での料理の登場頻度や価格の推移など、豊富な情報が含まれています。会場名の表記ゆれや歴史的な料理名の標準化など、実務的な課題も含まれており、評価データとして適していました。

次に、シカゴ市が公開している飲食店衛生検査のデータ（CFIデータセット）を活用しました。各店舗の検査結果をはじめ、店舗名、施設タイプ、住所などの基本情報が記録されています。このデータセットでは、店舗名の表記揺れや検査結果の形式不統一といった、実際の業務でよく直面する課題が含まれていました。

さらに、より異なる分野のデータとして、米国中小企業庁が公開しているコロナ支援融資データ（PPPデータセット）も評価対象としました。融資額や企業種別、企業規模といった情報が含まれており、企業名の不統一や業種分類の揺れなど、金融データ特有の課題を持つデータセットとなっています。

なお、これらのデータセットは、そのままでは規模が大きすぎるため、重要な特徴を保持しながら適切な大きさに調整しました。Menuデータセットからは100行20列を、CFIデータセットは12の小テーブル（各10行11列）を、PPPデータセットからは11の小テーブル（各20行14列）を抽出して使用しました。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80508_6-1024x178.png)

使用したデータセットのテーブル数、行数、列数、目的数

さらに、実務での課題をより明確に評価するため、表記ゆれや余分な空白、不適切な句読点といった一般的なエラーを意図的に追加しました。そして、「地域ごとの合格店舗数を知りたい」といった具体的な分析目的を計67個設定し、各目的に対して人手による理想的なクリーニング結果を用意しました。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80508_8-1024x210.png)

目的に必要な列数や列のデータ型による分類を示す

### 実験の設定

3つの異なるLLM（Llama 3.1-7b、Gemma 2-27b、Mistral-8b）が用いられました。

各LLMには、先述の4つのデータセットと、それぞれに設定された分析目的が与えられました。全部で67の分析目的が用意され、各目的に対して理想的なクリーニング手順が人手で作成されました。人手によって作成された手順は、LLMが生成した作業手順を評価するための基準として使用されています。

### 性能評価の観点

第一に、分析目的が達成できているかという観点です。クリーニング後のデータを使って、目的とする分析が正しく行えるかが確認されました。例えば、「合格店舗数を知りたい」という目的に対して、正しい数が得られるかといった点です。

第二に、データの正確さという観点です。クリーニング結果が、人手でクリーニングした理想的なデータにどれだけ近いかが評価されました。例えば、店舗名の表記の統一具合などが確認されています。

第三に、作業手順の適切さという観点です。LLMが選んだクリーニング作業が、人手で作成した理想的な手順とどれだけ一致しているかが検証されました。

### 評価結果

研究者らは、提案手法の性能を3つの観点から定量的に評価しました。評価には2つのベースとなるデータを用意し、一つは各データセットの元のデータ（ベースライン）、もう一つは人手でクリーニングした理想的なデータ（シルバースタンダード）です。

実験結果を3つの評価軸で見ていくと、まず、分析目的の達成度においては、Llama 3.1が総合的に最も高いスコアを記録しました。具体的には、精度（Precision）が0.6153、 [再現率](https://ai-data-base.com/archives/26095 "再現率") （Recall）が0.6227、 [F1スコア](https://ai-data-base.com/archives/26112 "F1スコア（F値）") が0.6105と、ベースラインの0.47前後を大きく上回りました。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80508_9.png)

3つの評価次元（目的回答、列値、ワークフロー）における各LLMの性能を示す

データの正確さを示すColumn Value Dimensionでは、データセットによって異なる結果が得られました。メニューデータにおいて、Gemma 2は0.5913という高い一致率を示し、人手でクリーニングしたデータに最も近い結果を生成することに成功しました。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80508_10.png)

数値を求める目的に対する各モデルの正確性を示す

作業手順の適切さを評価するWorkflow Dimensionでは、Gemma 2が0.8557という高い精度（Precision）を達成。しかし、再現率（Recall）は0.6157にとどまり、必要な作業の一部が実行されていない可能性が示唆されました。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80508_11.png)

テキストベースの回答に対する性能評価結果

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80508_7-1024x597.png)

各データセットで使用された操作（upper, trim等）の分布を示す棒グラフ

また、データセット間での性能差も顕著でした。例えば、PPPデータセットでは全モデルが比較的高いスコアを記録したのに対し、CFIデータセットでは性能にばらつきが見られました。これは、データの性質や含まれるエラーの種類によって、モデルの対応能力に差があることを示しています。

このように、提案手法は全体として従来のベースラインを上回る性能を示しましたが、データの種類や目的によって最適なモデルが異なることも明らかになりました。

なお、下のグラフは4つのデータセットにおけるワークフロー長の分布です。各LLMが生成したワークフローの効率性を可視化しています。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80508_12-1024x671.png)

Operation List Length（手順の総ステップ数）とOperation Set Length（ユニークな操作数）を比較したグラフ

## ケーススタディ（データクリーニングの実例分析）

先の評価実験で使用したデータセットから、研究者らは2つの代表的なケースを選び、LLMによるデータクリーニングの詳細な動作分析を行いました。

### 施設タイプの標準化における処理の詳細

CFIデータセットの中から、”Facility Type”（施設タイプ）列に焦点を当てた分析では、LLMが以下のような問題をどう処理するかが明らかになりました。

- 表記の不統一：「SCHOOL」「School」「SCHOOOL」といった表記の揺れ
- 書式の不統一：末尾の句読点や余分な空白の存在
- 同一施設の異表記：「MOBILE FROZEN DESSERTS VENDOR」と「Mobile Frozen Desserts」

Llama 3.1は、このケースで特に効果的な処理を示しました。まずupperコマンドで大文字への統一を行い、その後mass\_editコマンドで類似表記の統一を実施。人手による処理が6ステップ必要だった操作を、わずか2ステップで完了させました。この効率的な処理により、施設タイプの正確な集計が可能になりました。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80508_13-1024x216.png)

元データと各LLMによるクリーニング結果の比較例

### 会場名の正規化から見える異なるアプローチ

Menuデータセットでの会場名の分析では、LLMが異なるアプローチで同じ目的を達成する興味深い例が観察されました。具体的な例として、

- Llama 3.1は略語を正式名称に展開するアプローチを選択（例：「GOV」→「Government」）
- Gemma 2は最も頻出する表記に統一するアプローチを採用
- Mistralは単純な大文字変換のみを実施

などが見られました。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80508_14.png)

venue列における各LLMのクリーニング結果の比較例

注目すべきは、Llama 3.1とGemma 2が異なるアプローチながら、どちらも正確な会場数の集計に成功した点です。このことは、データクリーニングにおいて「正解」が必ずしも一つではないことを示す重要な発見となりました。

ケーススタディを通じて、LLMが人間のような柔軟な判断でデータクリーニングを実行できること、そして目的に応じて適切な処理方法を選択できることが実証されました。一方で、Mistralの事例が示すように、不適切な処理選択のリスクも存在することが明らかになりました。

## まとめ

本記事では、LLMを活用した自動データクリーニングの仕組み「AutoDCWorkflow」を紹介しました。

データキュレーターの目的設定に基づき、LLMが適切なクリーニング作業を判断・計画し、OpenRefineで実行する2段階のプロセスで構成されています。

実験では従来のベースラインを上回る性能を示しましたが、データの種類や目的によって最適なモデルが異なることも明らかになりました。

**参照文献情報**

- タイトル：AutoDCWorkflow: LLM-based Data Cleaning Workflow Auto-Generation and Benchmark
- URL： [https://arxiv.org/abs/2412.06724](https://arxiv.org/abs/2412.06724)
- 著者：Lan Li, Liri Fang, Vetle I. Torvik
- 所属：University of Illinois, Urbana-Champaign

## 理解度クイズ（β版）

1\. 提案手法「AutoDCWorkflow」の主な目的は何ですか？

LLMを活用してデータクレンジング手順を自動的に決定・実行することで、従来手動で時間のかかった処理を効率化します。

解説を見る

2\. AutoDCWorkflowでLLMが生成した計画を実行するために用いられたツールは何ですか？

LLMが立案したクリーニング手順はOpenRefineで実行され、結果が再フィードバックされる仕組みになっています。

解説を見る

3\. 評価実験では分析目的達成度、データ正確性、作業手順適切度の3観点でモデルを評価しましたが、その中でLlama 3.1が特に良好な結果を示したのはどの観点ですか？

Llama 3.1は分析目的達成度の指標で総合的に高スコアを記録し、ベースラインを大きく上回りました。

解説を見る

4\. CFIデータセットでの「施設タイプ」列のクリーニング例では、Llama 3.1は手動で6ステップかかった処理を何ステップで実現しましたか？

Llama 3.1はupperとmass\_editの2ステップで表記揺れと余分な空白を整え、施設タイプの正確な集計を可能にしました。

解説を見る

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[科学者はLLMをどう使っているのか、何を好むのか](https://ai-data-base.com/archives/80509)

[LLM同士による人工言語コミュニケーションで発見された「言語構造の創発」](https://ai-data-base.com/archives/80658)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)