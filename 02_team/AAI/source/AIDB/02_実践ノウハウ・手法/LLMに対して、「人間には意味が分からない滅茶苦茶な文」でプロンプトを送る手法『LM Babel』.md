---
title: "LLMに対して、「人間には意味が分からない滅茶苦茶な文」でプロンプトを送る手法『LM Babel』"
source: "https://ai-data-base.com/archives/68433"
author:
  - "[[AIDB Research]]"
published: 2024-05-01
created: 2025-06-13
description: "LLMは人間の言葉を理解し、自然な対話ができるまでに能力が向上してきました。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

LLMは人間の言葉を理解し、自然な対話ができるまでに能力が向上してきました。人間の言葉がわかるだけでなく、LLMにしか理解できない言葉というのも存在するのでしょうか？今回AWSとStanford大学の研究者らは、人間にはまるでデタラメに見える文字列を使ってモデルを操作する方法を検証しました。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_-68433-1024x576.jpg)

**参照論文情報**

- タイトル：Talking Nonsense: Probing Large Language Models’ Understanding of Adversarial Gibberish Inputs
- 著者：Valeriia Cherepanova, James Zou
- 所属：AWS, Stanford University

**本記事の関連研究** ：

- [LLMが思考のネットワークを構築し、人間の推論プロセスを模倣する『THOUGHTSCULPT』プロンプティング](https://ai-data-base.com/archives/67755)
- [Microsoftなどのプロンプト圧縮技術『LLMLingua-“2″』タスクの精度を維持したまま圧縮率2-5倍](https://ai-data-base.com/archives/66170)
- [LLMが「自然言語で記述されたアルゴリズムを実行する」能力で非常に高い性能を示す](https://ai-data-base.com/archives/65949)
- [LLMの記号推論タスク（化学式や絵文字の理解など）で記号を自然言語に変換することの有効性を確認](https://ai-data-base.com/archives/65784)
- [「ポジティブ思考」プロンプトでLLMの性能向上　さらに自動最適化プロンプトが上をいくが、奇妙な現象も](https://ai-data-base.com/archives/65164)

## 背景

「LLMは、人間にとって理解できない言葉で話しかけられても、理解できるのか？」

そんな疑問を抱いた研究者らは、LLMに意味不明な入力を与えたときの振る舞いを調べ、その根底にあるメカニズムを解明しようとしています。グリーディ座標勾配最適化（最適なプロンプトを自動的に探索するアルゴリズム）を用いて、一見するとでたらめな文字列なのにLLMに一貫した応答をさせるプロンプトを作り出しました。

本手法は「LM Babel」と名付けられ、LM Babelに操作されたLLMの振る舞いが体系的に調べられました。この研究は、LLMと対話するための新しい言語について理解を深めるもので、LLMの内部動作を解明する上で重要な知見が得られています。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_68433_1.png)

LLaMA2-Chat-7Bモデルで整合性のある応答を生成したLM Babelの例

## 実験の設計

この研究では、最近発表された [グリーディ座標勾配（GCG）アルゴリズム](https://arxiv.org/abs/2307.15043) を採用しています。元々、LLMに有害な質問に答えさせたり、有害な文章を生成させたりするために開発されたものです。

研究者らは、GCGアルゴリズムを使って、あらかじめ用意した文章（ターゲットテキスト）をLLMに生成させるためのプロンプトを作り出しました。本研究ではこれを「LM Babel」と呼んでいます。

### 実験で使用したデータセット

LM Babelの生成には、以下の4つのデータセットから [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") したターゲットテキストが使用されました。

1. Wikipedia: 一般的な情報を含む文章
2. CC-News: ニュースのタイトル
3. AESLC: 企業の電子メールの一部
4. AdvBench: 有害な文章

### 実験で使用したLLM

実験には、オープンソースのLLaMA-2とVicuna（7BおよびB）が使用されました。研究コミュニティで広く使われており、サイズも手頃で、内部の情報を詳しく調べるのに適しているためです。

### LM Babelの性能評価

LM Babelの性能は、以下の2つの指標で評価されました。

1. 完全一致率: LLMの出力がターゲットテキストと完全に一致する割合
2. 条件付きパープレキシティ: ターゲットテキストがLLMにとってどの程度「予想外」であるかを測る指標

完全一致率が高いほど、また条件付きパープレキシティが低いほど、LM Babelがうまく機能しているということです。

上記の設定のもと、研究者らはLM BabelがLLMの振る舞いに与える影響を詳しく調べました。

## LM Babelプロンプトの有効性

### ターゲットテキストに依存

研究者らは、LM Babelを使ってLLMを操作する際、ターゲットテキストの種類によって成功率が異なることを発見しました。

下記の表は、4つのデータセットと4つのLLMに対するLM Babelの成功率を示しています。これを見ると、Vicunaモデルの方がLLaMA-2モデルよりも操作しやすいことがわかります。研究者らは、Vicunaモデルが人間に役立つように大きくファインチューニングされているため、通常とは異なる入力に対しても反応しやすくなっているのではないかと推測しています。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_68433_5.png)

4つのデータセットと4つのモデルにおけるLM Babelの成功率

また、有害な文章を含むAdvBenchデータセットでは、他のデータセットよりもLM Babelの成功率が高くなっています。LLaMAとVicunaのモデルは有害なコンテンツを生成しないように調整されているため、驚くべき結果です。

一方、企業の電子メールを含むAESLCデータセットでは、LM Babelの成功率が最も低くなっています。

### LM Babelの成功を左右する要因

研究者らは、LM Babelがうまく機能するかどうかは、以下の2つの要因に大きく依存することを明らかにしました。

1. ターゲットテキストの長さ
2. ターゲットテキストの複雑さ（パープレキシティ）

下の図は、ターゲットテキストの長さとLM Babelの成功率の関係を示しています。10トークン以下の短いテキストでは成功率が90％を超えていますが、22トークンを超える長いテキストでは20％を下回っています。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_68433_3.png)

ターゲットテキストの長さとLM Babelの成功率の関係

研究者らは、LLMが次のトークンを生成する際に直前のコンテキストに大きく依存するため、LM Babelが主に最初に生成されるトークンのコンテキストにしか影響を与えられないことが原因だと考えています。

また、下の図は、データセットごとのターゲットテキストの平均パープレキシティとLM Babelの成功率の関係を示しています。パープレキシティが低いWikipediaやAdvBenchでは成功率が高く、パープレキシティが高いCC-NewsやAESLCでは成功率が低くなっています。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_68433_4.png)

データセットレベルでのターゲットの複雑さ（パープレキシティ）とLM Babelの成功率の関係

上記の結果から、研究者らは、LLMにとって「自然な」（パープレキシティが低い）文章ほど、LM Babelで生成させやすいのだろうと結論付けました。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_68433_6.png)

4つのデータセットと4つのモデルにおける、LM Babelと自然言語プロンプトに対するターゲットテキストのパープレキシティ

### 忘れさせたはずの情報も生成可能

研究者らは、特定の情報を忘れるようにファインチューニングしたLLMでも、その情報を含む文章をLM Babelで生成できるかどうかを調べました。

「ハリー・ポッター」シリーズの内容を忘れるようにファインチューニングしたLLaMA-2モデルを使用しました。元のモデルの66％と比べると大幅に低下するものの、ファインチューニング後のモデルでもLM Babelの成功率は36％に達しています。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_68433_7.png)

ハリー・ポッター関連のデータにおけるLM Babelの成功率と平均パープレキシティ

この結果は、情報を忘れさせるファインチューニングによって、LLMがその情報を生成するのは難しくなるものの、完全には防げないことを示唆しています。

## プロンプトの構造

LM Babelで最も驚くべき点は、（繰り返しになりますが、）人間にはでたらめに見える一連のトークンであるにもかかわらず、LLMがそれに反応して定義済みの一貫したテキストを生成することです。つまりLLMにしかわからない言語に近いものが誕生しているのかもしれません。

LM Babelの例とそれに対するモデルの応答を下記の表に示します。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_68433_2-1024x683.jpg)

LM Babelプロンプトとモデルの応答例

完全にランダムなトークン列でLLMにプロンプトを与えると、通常は質問が意味不明であると言って拒否されてしまいます（当たり前ですが）。なぜLM Babelだと応答が成立するのか？研究者らはその謎を解明すべく分析しています。

### トークンレベルでのLM Babelの特徴

研究者らは、LM Babelに含まれるトークンを分析することで、いくつかの興味深いパターンを発見しました。

下の図は、ターゲットテキストとLM Babelのプロンプトで共通するトークン数の分布を示しています。平均すると、LM Babelのプロンプトには、長さ20トークンのうち約2トークンがターゲットテキストから取られていることがわかります。また、共通トークン数とLM Babelの成功率の間には、統計的に有意な相関は見られませんでした。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_68433_8.png)

LM Babel、自然言語プロンプト、ランダムプロンプトのLLaMA2-7Bモデルにおける最終隠れ状態の表現（UMAPで可視化）

次に下の図は、Vicuna-7BモデルのLM Babelで最も頻繁に現れるトークンを示しています。データセット固有のトークンに関して、興味深いパターンが見られます。例えば、Wikipediaデータセットを対象としたプロンプトには、「Wikipedia」や「ipedia」、「wiki」といったトークンが頻出します。ターゲットテキストにはこれらの語が含まれていないにもかかわらずです。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_68433_9.png)

ターゲットテキストとLM Babelプロンプトで共有されるトークン数のヒストグラム

同様に、CC-Newsデータセットのプロンプトには、「news」や「title」といったトークンが含まれることがあります。おそらくLLMの学習データに含まれていたものと考えられます。

研究者らは、LM Babelがこのようにしてモデルの内部知識を巧妙に利用し、文脈に即した関連性のある単語を用いることで、モデルの出力を効果的に操作しているのではないかと推測しています。

### LM Babelの構造

LM Babelは、でたらめに見えていても、その背後に何らかの構造が隠れているのではないかと研究者らは考えました。

実験の結果、LM Babelのパープレキシティは、同じ数のトークンからなるランダムな文字列と同程度に高いことがわかりました。

さらに研究者らは、条件付きエントロピーという概念を用いてLM Babelの構造を分析しました。条件付きエントロピーは、あるトークンが直前のトークンに依存してどの程度不確実性を持つかを測る指標です。

その結果、LM Babelの条件付きエントロピーは、自然言語のプロンプトより高いものの、ランダムな文字列よりは低いことがわかりました。つまり、LM Babelは自然言語ほど構造化されてはいませんが、ランダムな文字列よりは一定の秩序を持っているのです。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_68433_11.png)

LM Babel、ランダムプロンプト、自然言語プロンプトの平均パープレキシティとエントロピー

## プロンプトの堅牢性

研究者らがLM Babelの堅牢性を調べるために行った実験について説明します。プロンプトの最適化プロセスが、ターゲットテキストの生成につながる「平らな最小値」に収束するのか、それともトークンの微小な変更でLM Babelが機能しなくなるのかを見極めています。

### トークンレベルの摂動に対するLM Babelの反応

研究者らは、以下の3種類のトークンの摂動（攪乱）を用いて実験を行いました。

1. 置換（トークンの入れ替え）
2. 削除（トークンの取り除き）
3. 置換（トークンの位置の入れ替え）

下の図は、7Bのモデルにおけるこれらのトークンの摂動に対するLM Babelの反応を示しています。わずか1つのトークンを削除または置換するだけで、70％以上の成功したLM Babelプロンプトが機能しなくなることがわかります。また、2つ以上のトークンを変更すると、90％以上のプロンプトが無効になってしまいます。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_68433_10.png)

トークンの置換の影響は少し小さめですが、それでも4つ以上のトークンを入れ替えると、95％以上のプロンプトが機能しなくなります。

### 句読点の重要性

LLaMA-2モデルのLM Babelの多くには句読点が含まれていることから、研究者らはその役割に注目しました。実験の結果、プロンプトから句読点を取り除くと、97％のLM Babelプロンプトが機能しなくなることがわかりました。このことはパラフレーズやリトークン化と並んで、通常とは異なる言語の入力に対する単純な防御策として利用できると研究者らは指摘しています。

総合的に考えると、LM Babelはトークンレベルの変化に非常に脆弱であることが明らかになりました。わずかな変更でLM Babelの大半が機能しなくなるという結果です。LLMがこれらのプロンプトをどのように処理しているのかを理解する上で重要な手がかりとなりそうです。

## まとめ

本記事では、一見でたらめな入力（LM Babel）に対してLLMが一貫した応答を生成する現象を調べた研究を紹介しました。

研究者らは、最適化アルゴリズムでLM Babelを生成し、操作されたLLMの振る舞いを分析しました。その結果、LM Babelの有効性はターゲットテキストの長さや複雑さに依存し、ある程度の構造を持つことがわかりました。一方で、LM Babelは摂動に脆弱で、有害なテキストの生成は無害なテキストと同程度に可能であることも判明しました。

今回の実験結果はLLMが対話可能な言語の理解を深め、LLMの安全性向上と内部動作の解明に重要な示唆を与えるものでした。急速な発展の中で、このような地道な研究の積み重ねこそが重要かもしれません。

- URL： [https://arxiv.org/abs/2404.17120](https://arxiv.org/abs/2404.17120)

## 参考

本研究で参照されているGCGアルゴリズムの論文をもとに、LLM Babelプロンプトを生成するための大まかな手順を書き下します。

1. 変換対象のターゲットプロンプトを設定します。
2. モデルが問い合わせに対して肯定的な応答を始めるように誘導します。たとえば、「はい、以下が詳細です…」といった開始フレーズを使います。
3. 最適な敵対的サフィックス（プロンプトの末尾に追加される部分）を見つけるために、貪欲法と勾配法を組み合わせた探索を行います。トークンレベルでの勾配を利用して、最も成功確率を高めるトークンの置換を行います。
4. 一つのサフィックスが複数の異なるプロンプトに対して、また複数のモデルに対しても効果的であることを確かめるために、多様なプロンプトとモデルを用いてテストします。
5. 生成されたプロンプトの効果を評価し、必要に応じて微調整を行います。

詳しくはもとの文献である [GCGアルゴリズムの論文](https://arxiv.org/abs/2307.15043) を参照してください。なお、倫理面に配慮し、適切な用途であることとLLMプロバイダー側のガイドラインに従っていることを確認してください。

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[マルチモーダルLLMにおける欠点と原因を明らかにする調査研究の結果](https://ai-data-base.com/archives/68367)

[量子化はLLMの性能にどう影響を与えるか？モデルが持つ「自信」の観点から説明](https://ai-data-base.com/archives/68518)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)