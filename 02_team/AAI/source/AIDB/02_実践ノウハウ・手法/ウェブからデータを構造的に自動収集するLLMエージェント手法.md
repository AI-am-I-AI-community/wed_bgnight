---
title: "ウェブからデータを構造的に自動収集するLLMエージェント手法"
source: "https://ai-data-base.com/archives/90371"
author:
  - "[[AIDB Research]]"
published: 2025-06-02
created: 2025-06-13
description: "本記事では、ウェブ上から構造化データを自動で収集するLLMエージェントの研究を紹介します。自然言語での依頼を起点に、複数のエージェントが連携して調査・実装・検証を行う構成が特徴です。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、ウェブ上から構造化データを自動で収集するLLMエージェントの研究を紹介します。

自然言語での依頼を起点に、複数のエージェントが連携して調査・実装・検証を行う構成が特徴です。汎用エージェントや従来型の情報抽出手法とは異なる設計思想が採られています。

情報収集業務の自動化や設計を検討する際の参考材料として位置づけられる内容です。

![](https://ai-data-base.com/wp-content/uploads/2025/05/AIDB_90371-1024x576.png)

## 背景

業務でデータを活用したいと考えたとき、多くの人が最初に直面するのが「必要な情報をどこから、どうやって集めるか」という問題です。ウェブ上のデータを集めるにも、その取得にはHTMLやAPIの理解、スクレイピングの実装など、専門的な作業がつきまといます。

最近ではエージェント型のAIサービスも登場し、「調べる」「書く」といった作業の支援はかなり進化しています。しかし、それらを使って「自然言語で指示するだけで、構造化されたデータセットが完成する」ところまで持っていくのは、まだ難しいのが現実です。途中で人が介入して設計したり、エラーに対応したり、動的なウェブの構造変化を確認したりする必要があります。

また、LLMベースの自動化を進めようとすると、すぐに別の問題も浮上します。処理にかかるコストです。ウェブ上の大量データを対象にすると、LLMのトークン使用量が跳ね上がり、時間や料金が無視できなくなります。部分的な自動化はできても、「業務で回し続けられる仕組み」にはなりにくいのです。

こうした中で、今回研究者たちは「自然言語による一文の依頼から、必要な情報をウェブ上で探し出し、構造化して返してくれる仕組み」を新たに提案しました。情報探索から実行コードの作成、データの収集・検証までを複数のAIエージェントが分担して行う仕組みです。コスト面にも配慮されています。

AI開発のためだけでなく、調査や分析、レポート作成など、さまざまな業務でデータを活かしたいと考える人にとって、注目すべきフレームワークです。

![](https://ai-data-base.com/wp-content/uploads/2025/05/AIDB_90371_1-1024x570.png)

自然言語の依頼をもとに、調査から収集までをAIエージェントが分担して進める全体像

## 先に前提として押さえておきたいこと

自然言語での依頼に対して、自動でウェブから情報を集め、整ったデータとして返す。今回紹介する研究は、そうした処理を複数のLLMエージェントで分担しながら実現する構成を目指したものです。

ただし、こうした仕組みが現実に動くためには、いくつか前提となる考え方や設計上の要件があります。とくに重要なのは「どのように情報がやり取りされるか」、そして「どのようにユーザーの入力が扱われるか」という2点です。

まず、複数のエージェントが連携して動く場合、誰がどの情報を誰に渡すのかをうまく制御しなければなりません。従来のグラフ構造では、単純な一対一のやり取りしか表現できず、実際のような複数エージェント間の同時共有や非対称な情報の流れは扱いにくいという課題がありました。

そこで今回は、有向ハイパーグラフという構造が採用されています。これは、ひとつの送信者から複数の受信者に対して同時に情報を伝えるといったやり取りも自然にモデル化できる構造です。情報の流れに方向があるため、実行の順序や責任の所在も明確になります。

また、こうした仕組みを使う際に技術的な知識が求められてしまっては、多くのユーザーにとっては実用性が下がります。そのため、入力はすべて自然言語で行えるよう設計されており、「〇〇の論文を集めて」「〇〇の株価を取ってきて」といった日常的な言葉がそのまま出発点になります。

対象とするのは、企業の内部データではなく、誰もがアクセス可能なウェブサイトやAPIです。オープンな情報を対象に、自動でアクセスし、構造化して返す。そうした処理が前提になります。

## 情報収集タスクを進行する方法論

自然言語で依頼された内容をもとに、ウェブから情報を集め、構造化されたデータとして返すには、タスク全体をいくつかの役割に分けて進めると整理しやすくなります。調査から実装、検証までの流れをあらかじめ区切っておくと、各フェーズを専門化でき、後からの修正や再利用もしやすくなります。

### 8つのエージェントで分担する

まずは全体を以下のような8つの役割に分け、それぞれをエージェントとして動かすことを明確にします。

- 自然言語の依頼を作業タスクに分解するプランエージェント
- 対象サイトの構造や取得手段を調査するウェブエージェント
- 検索やHTML整形など補助的な操作を担うツールエージェント
- 調査結果を整理し設計図にまとめるブループリントエージェント
- 設計図に従って実際の取得コードを実装するエンジニアリングエージェント
- 作成されたプログラムをテスト実行し、不具合を確認するテストエージェント
- 出力されたデータの整合性や欠損をチェックするバリデーションエージェント
- 全体の進行やエージェント間の調整を担うマネージャーエージェント

調査・設計・実装・検証という一連の流れを、役割分担されたエージェントに割り当てて進めていくことで、大規模な情報収集でも処理の安定性と拡張性が保たれます。初期の段階で各エージェントの責任範囲を明確にし、通信のルールとデータ形式を定めておくと、後からの変更や規模の拡大にも対応しやすくなります。

以下、プロセスを時系列で説明します。手順としては大きく8つのステップがあります。

### 1\. タスクの起点を分解する

自然言語での依頼を受け取ったら、まずはその内容をいくつかの実行可能なタスクに分けていきます。たとえば「NeurIPS 2024の論文を集めて」という依頼があった場合は、「対象会議を特定する」「論文リストのページを見つける」「各論文の詳細を抽出する」といった小さな作業単位に分けます。この分解があいまいだと、後工程での設計や実装に無理が生じます。

### 2\. 調査をもとに構造を把握する

ウェブサイトが静的HTMLで構成されているのか、JavaScriptで内容が描画されているのか、あるいはREST APIで提供されているのかを判別します。構造を確認しながら、どの要素を抽出対象とするかを洗い出します。必要に応じてGoogle検索やフォーマット変換ツールを補助的に組み込みます。

### 3\. 調査内容を設計図にまとめる

収集対象の情報とアクセス方法が定まったら、それらを整理して全体の処理設計としてまとめます。どのページを巡回し、どの要素をどの順番で取得するか、得られたデータをどの形式で保存するかを記述します。設計図は後のコード実装にそのまま使えるように構造化しておくと扱いやすくなります。

### 4\. コードとして実装する

設計図に基づいて、実際のデータ取得コードを記述します。ウェブスクレイピングやAPI呼び出しなどの手段を使い、再利用しやすい関数やテンプレートとして整理します。変化に対応しやすくするために、ドメインや構造が異なる対象にも使えるような処理のパターンを想定しておきます。

### 5\. 実行とデバッグで安定化させる

コードが完成したら、実際に実行して動作を確認します。対象のウェブサイトに構造変更があった場合や、通信エラーが発生した場合の対応も含めて確認し、想定外のデータや欠損が出ないようにテストを重ねます。

### 6\. 出力されたデータを検証する

収集されたデータが想定どおりの構造と件数になっているか、重複や欠損、整形ミスがないかを確認します。単純な件数チェックだけでなく、構文レベル・意味レベルでの整合性も確認できるように比較ルールを用意します。問題があった場合は設計フェーズに戻って修正します。

### 7\. 情報のやり取りを最適化する

エージェント間で情報を共有する際は、すべてのエージェントに一斉送信するのではなく、送信相手を指定して必要な情報だけを届ける構成にします。誰が何を受け取るかを明示することで、処理の無駄を抑えることができます。自然言語でやり取りするのではなく、役割ごとに定義された構造化メッセージを使うと、誤解や処理の重複が減ります。

### 8\. 通信の負荷を抑える

HTMLファイルやPDFのような重いデータは、通信メッセージの中に含めず、別のキャッシュ領域に保存して識別子だけを送る形式にします。処理の中で必要なときにファイル本体を参照する構成にすることで、通信量を減らし、レスポンスを安定させます。

## 実務に近い環境で性能を測るための評価設計

ウェブデータの自動収集を実用化するには、仕組みが動くだけでは不十分です。自然言語での依頼に対して、正しい情報を、構造化された形で安定して返せるかどうか。実際の業務を想定したうえで、その信頼性を客観的に測る必要があります。

こうした観点から、本研究では評価環境そのものも独自に設計されています。自然言語による依頼からデータ収集を行い、その結果が正確に整っているかどうかを数値で検証できるようになっています。

リポジトリはこちらです。 [https://github.com/GraphResearcher/AutoData](https://github.com/GraphResearcher/AutoData)

### 自然言語で依頼できる収集タスクの定義

まず、評価の起点となるのは、自然言語で表現された依頼文です。「2024年のNeurIPSで採択された論文を一覧で集めてください」といった形式で、対象とするデータと条件が記述されます。

依頼文はテンプレート化されており、対象の年や会議名、トラックなどを変数として組み込める仕組みです。テンプレートの書き換えにより、評価対象を簡単に切り替えながら性能を試すことができます。

![](https://ai-data-base.com/wp-content/uploads/2025/05/AIDB_90371_2-1024x547.png)

学術データ収集タスクの対象例と、会議名や年度を変えて使える依頼テンプレートのパターン

### 正解と照らし合わせるための仕組み

評価では、実際に収集されたデータをあらかじめ定義された「正解データ」と比較して検証します。ただし、システムが直接この正解データにアクセスすることはできません。正解は評価ロジック側で保持されており、収集結果との一致度によって [F1スコア](https://ai-data-base.com/archives/26112 "F1スコア（F値）") などが算出されます。

このような構成にすることで、「収集対象のページを事前に知っていたから成功した」といった状況を防ぎ、自然言語からの処理精度そのものを評価できます。

### 長期的な運用を見据えた対象選定

ウェブ上の情報は日々変化するため、安定した評価を続けるには対象データにも工夫が必要です。たとえばSNSやニュースのように更新頻度が高い情報は、時間が経つと再評価ができなくなります。

そこで、この評価環境では、比較的変動の少ない3つの分野が選ばれています。

1. 学術論文（主要会議の公開データ）
2. 金融市場の時系列データ
3. スポーツの試合結果や統計情報

これらは継続的に公開されており、プライバシーや権利上の懸念も少なく、長期的に安定した評価を行うのに適しています。

### 学術論文の収集を例に見ると

たとえば、学術分野での評価タスクでは、機械学習や [自然言語処理](https://ai-data-base.com/archives/26319 "自然言語処理（NLP）") 、 [コンピュータビジョン](https://ai-data-base.com/archives/26602 "コンピュータビジョン") の主要会議を対象に、論文情報の収集が求められます。依頼のバリエーションには以下のようなパターンがあります。

- 特定の会議と年度の論文をすべて集める
- 特定の会議とトラックを指定して絞り込む
- 同じ会議の複数年分をまとめて扱う

収集対象となる情報には、タイトル、著者、要約、論文リンク、BibTeX形式などが含まれており、実務でそのまま使えるような構造化形式になっています。

### 現実に近づけるための工夫

この評価設計では、従来の静的なデータセットを用いたベンチマークとは異なり、以下のような点が特徴として挙げられます。

- 静的なアーカイブではなく、現在稼働中のウェブページを対象とする
- 情報の取得方法はHTMLでもAPIでも自由に選べる
- 自然言語の条件によって収集対象が柔軟に変化するため、文脈理解力も試される

動いたかどうかではなく、実務で信頼できるかどうか。その観点で性能を測るための仕掛けが意識されています。

### 評価と同時に使えるデータが手に入る

評価結果として得られるのはスコアだけではありません。自然言語の依頼から自動生成されたデータセットそのものが、別のタスクにも応用可能な形式になっています。

- 学術論文をもとにした推薦システムの訓練データ
- 金融データを活用した価格予測モデルの入力
- スポーツ統計を使った分析や実況文の自動生成

つまり、この評価環境は性能を測る道具であると同時に、実務に役立つデータを自動生成する基盤としても機能します。構築した情報収集システムをどう評価し、どう活用につなげるかを考えるうえで、ひとつの参考になります。

## 収集の自動化はどこまで実用に耐えるのか

ウェブからの情報収集が、ただの言葉の依頼だけで完了するようになっても、それが本当に役立つかどうかは、数字を見て初めてわかります。重要なのは、どこまで正確に、どこまで効率よく、実務レベルのタスクに対応できるかという点です。

今回、現実のウェブ環境を想定した評価や、人間・他ツールとの比較を通じて、どこまで信頼できるかが検証されています。

### 精度と効率のバランス

自然言語での依頼に対して、動的なウェブサイトから情報を収集するタスクでは、高い精度とスピードの両立が求められます。学術・金融・スポーツの各分野でのF1スコアは90以上を記録しており、従来のエージェント型システムはもちろん、手作業や支援ツールも及びません。

とくに学術分野ではF1スコア91.85を記録し、次点のシステムとの差は20ポイント以上。作業時間もわずか5.6分、コストは0.57ドル。これは、精度を維持したまま従来手法の数十分の一で仕事を終えていることを意味します。時間もコストも削減しながら正確性を保つというのは、現場での自動化にとっては非常に重要な条件です。

![](https://ai-data-base.com/wp-content/uploads/2025/05/AIDB_90371_3-1024x292.png)

学術・金融・スポーツ領域での既存手法との比較による精度・所要時間・コストのまとめ

### コーディング精度も想定以上に高い

情報収集には裏側で動くプログラムの自動生成も必要です。その精度を測るため、HUMANEVALベンチマークを用いた検証では、専用のコード生成システムとほぼ同等、あるいは上回る結果が出ています。

こうした数値は、設計が複雑なスクレイパーやAPI呼び出しでも十分に対応できる水準であり、「LLMでコーディングはここまで来た」と実感できるものです。

![](https://ai-data-base.com/wp-content/uploads/2025/05/AIDB_90371_5.png)

HUMANEVALベンチマークでのコード生成性能（Pass@1）の比較

### 従来型のベンチマークでも堅実に成果

静的ページを対象とする従来のベンチマークでも、高い水準を維持しています。情報抽出ベンチマークとして知られるSWDEとEXTENDED SWDEでは、それぞれF1スコア89.25、77.44を記録。これは専用設計の [ルールベース](https://ai-data-base.com/archives/26614 "ルールベース") システムと肩を並べる精度であり、汎用エージェントとしては十分に合格点といえます。

![](https://ai-data-base.com/wp-content/uploads/2025/05/AIDB_90371_4-1024x195.png)

既存の情報抽出ベンチマークでのF1スコアや精度・ 再現率 の比較結果

### 設計がただの工夫ではなく効果を持っているか

この仕組みは、エージェントの分業や通信の最適化など、さまざまな設計上の工夫に支えられています。そのひとつひとつが本当に意味を持っているかを確かめるため、段階的に構成要素を外して性能を比較する実験も行われました。

調査や実装のどちらかのチームを外すと、処理効率はやや改善する一方で精度は大きく落ちます。通信方式を旧来のブロードキャスト型に戻すと、性能もコストも大幅に悪化。構造化されたメッセージを自然文に戻すだけでも、情報抽出の質が下がるなど、影響は顕著です。

つまり、こうした設計は理屈だけの話ではなく、実際の数字で見ても効果があるということが明確に裏づけられています。

![](https://ai-data-base.com/wp-content/uploads/2025/05/AIDB_90371_6.png)

各構成要素を取り除いたときの性能やコストの変化を比較したアブレーション結果

### 実務に近いケースでも性能が出るか

評価用のデータセットだけでなく、実務に近い条件でのタスクもいくつか検証されています。その中でも特筆すべきは、児童向け絵本データベースの構築と、論文サーベイからの参考文献抽出です。

前者では、精度89.6%、完全性98.1%、コスト0.91ドル。比較対象は精度63.9%、完全性79.8%、コスト1.86ドル。数字を見れば一目瞭然で、品質も効率も圧倒的です。

![](https://ai-data-base.com/wp-content/uploads/2025/05/AIDB_90371_7.png)

絵本データベース構築タスクにおける出力の精度やコストに関する人手評価の結果

後者の参考文献抽出ではF1スコア91.2を記録。こうした作業は研究者にとって価値が高いものの手間もかかる領域で、そこを自動化できるとなればインパクトは大きいはずです。

![](https://ai-data-base.com/wp-content/uploads/2025/05/AIDB_90371_8.png)

論文サーベイから参考文献を抽出するタスクでの精度・再現率・コストの比較結果

### モデル切り替えへの対応力

実務では、特定の大規模言語モデルに縛られた設計はリスクになります。この仕組みでは、GPT-4o以外でも性能が維持できるかどうかが検証されており、GPT-4o-miniやDeepSeekなどのモデルでも、必要水準を満たす結果が確認されています。

モデル切り替えを前提とした設計がされていることは、将来的な柔軟性の点でも評価できます。

### 導入を検討するうえでの視点

これらの結果を踏まえると、単なる技術デモや学術的な面白さではなく、実際の業務に耐える仕組みとして成立していることがわかります。とくに次のような点が導入検討の材料になります。

- 現実のタスクにおける高精度かつ高速な処理
- 設計要素ごとの実効性の検証
- 異なるモデルへの対応力
- 業務に近い場面での成果実績

こうした観点から見れば、今後のデータ収集や業務自動化の選択肢のひとつとして、現実味を持って検討に値する内容です。

## これまでの手法と何が違うのか

ウェブからの情報収集を自動化する技術は、これまでにも数多く提案されてきました。ブラウザ操作を模倣するエージェント、HTMLから情報を抽出するアルゴリズム、あるいは汎用の大規模言語モデルを使ったナビゲーション支援など、その手法は多様です。

最近注目されているLLMベースのエージェントは、検索やクリック、入力などを柔軟にこなす一方で、設計上は汎用性を優先しているものが多く、大量のウェブページを対象に情報を収集するようなタスクにはあまり向いていません。モデルの呼び出し回数が多くなりやすく、コストや処理時間の面で非効率になる傾向があります。

一方で、今回紹介している仕組みは、汎用性をやや犠牲にしながらも、情報収集という特定の目的に最適化する方向で構成されています。特徴的なのは、収集の一連の流れを先に設計し、コードとして出力したうえで実行するという点です。あらかじめ実行計画を立ててから処理に入ることで、モデルの呼び出しを最小限に抑えることができます。

また、情報抽出の分野で用いられてきたような、1ページずつの処理を繰り返すスタイルとは違い、収集対象全体の構造を捉えて処理を最適化しようとする構成になっています。ページの構造やレイアウトに応じて一から学習させるのではなく、調査、設計、実行、検証といったプロセスをエージェントで分担しながら、スクリプトとして統合していく流れです。

エージェント間の通信についても、従来のように全員に同じ情報を送るのではなく、必要な情報を必要な相手にだけ渡す構造が採られています。やり取りは構造化されたメッセージで行われ、通信の無駄を減らすことが意図されています。

全体としては、ウェブ情報の読み取り精度そのものを高めるというより、プロセス全体の効率と再利用性を重視するアプローチだといえそうです。すでに確立されている汎用エージェントや情報抽出の手法とは方向性が異なっており、比較的限定された用途を想定する代わりに、収集タスクにおける設計自由度とスケーラビリティを確保しようとしています。

この構成がすべての場面で優れているとは限りませんが、どのような設計思想が採られていて、何を優先しているのかを整理しておくことは、他の選択肢を検討するうえでも参考になるかもしれません。

## まとめ

本記事では、ウェブデータ収集に特化したマルチエージェントシステムに関する研究を紹介しました。

特徴的なのは、プロセス全体をあらかじめ設計し、効率化を図るという構成です。既存の汎用エージェントや情報抽出手法とは異なる立ち位置で設計されています。

評価実験では一定の実用性が示されており、対象とするタスクによっては検討の余地がありそうです。

特定の情報収集業務を整理したいとき、自動化の設計を考える参考として活用できるかもしれません。

**参照文献情報**

- タイトル：AutoData: A Multi-Agent System for Open Web Data Collection
- URL： [https://doi.org/10.48550/arXiv.2505.15859](https://doi.org/10.48550/arXiv.2505.15859)
- 著者：Tianyi Ma, Yiyue Qian, Zheyuan Zhang, Zehong Wang, Xiaoye Qian, Feifan Bai, Yifan Ding, Xuwei Luo, Shinan Zhang, Keerthiram Murugesan, Chuxu Zhang, Yanfang Ye
- 所属：University of Notre Dame, Amazon, University of Washington, Purdue University, IBM Research, University of Connecticut

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[グラッドキューブの事業報告から学ぶAIビジネス動向とスキルとキャリア](https://ai-data-base.com/archives/90600)

[「現実の問題を数理モデルで解く」LLMエージェントを設計する](https://ai-data-base.com/archives/90253)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)