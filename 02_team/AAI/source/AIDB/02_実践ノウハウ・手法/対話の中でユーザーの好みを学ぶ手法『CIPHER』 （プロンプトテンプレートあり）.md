---
title: "対話の中でユーザーの好みを学ぶ手法『CIPHER』 （プロンプトテンプレートあり）"
source: "https://ai-data-base.com/archives/76527"
author:
  - "[[AIDB Research]]"
published: 2024-10-03
created: 2025-06-13
description: "本記事では、LLMとユーザーの対話の中で得られるユーザーフィードバックを活用してLLMの応答をパーソナライズする新手法を紹介します。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、LLMとユーザーの対話の中で得られるユーザーフィードバックを活用してLLMの応答をパーソナライズする新手法を紹介します。

モデルを個別のユーザーに対してパーソナライズする方法はいくつか考案されてきましたが、最適なアプローチはまだ見つかっていません。そんな中、今回Cornell大学やMicrosoftの研究者らは、対話の中で自然に得られるユーザーからの返事をフィードバックとして活用する効率的な手法を提案しています。

この手法を使うとモデルがユーザーの好みを解釈して自然言語で説明できる点も特徴となっています。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_76527-1024x576.jpg)

**参照論文情報**

- タイトル：Aligning LLM Agents by Learning Latent Preference from User Edits
- 著者：Ge Gao, Alexey Taymanov, Eduardo Salinas, Paul Mineiro, Dipendra Misra
- 研究機関：Cornell University, Microsoft Research

## 背景

LLMやLLMエージェントは、様々なアプリケーションで活用されるようになってきました。しかし、個々のユーザーや特定のタスクに適応するパーソナライズ機能においてはまだ十分とは言えません。

従来のフィードバック手法、例えば比較ベースの [強化学習](https://ai-data-base.com/archives/26125 "強化学習") などは、専門の注釈者に複数のモデル応答を提示して順位付けをしてもらう必要があるため、コストがかかります。

さらに現実問題、各ユーザー向けにLLMエージェントをパーソナライズするのは本来であれば非常にコストがかかります。もしLLMのパラメータを微調整するとなれば、安全性が失われるリスクもあります。

そこでCornell大学やMicrosoftの研究者らは「対話の中で得られるユーザーのフィードバックも、LLMエージェントがユーザーの好みを学ぶ貴重な情報源なのではないか」と考えました。

多くのアプリケーションでは、ユーザーはLLMの出力に対して訂正を行うことがよくあります。つまり、ユーザーはLLMに指示を出して出力を得ますが、最終的にはLLMの応答をユーザーが必要なだけ編集して使用しているのです。

研究者らは、これまでの提案手法に代わるものとして「ユーザーの嗜好を推論し、応答生成に利用するプロンプトポリシーの学習」に焦点を当てることにしました。これはコスト効率、安全性の両面から優れたアプローチとなる可能性があります。

以下で手法や実験結果を紹介します。

## LLMエージェントとは

まず、LLMエージェントについて説明します。本研究におけるLLMエージェントとは、以下の特徴を持つ存在です。

- テキストや画像などの入力を受け取ることができる
- 追加のプロンプト（今回で言えば、学習した好みの説明など）も受け取れる
- 入力と追加のプロンプトを元に、テキストの応答を生成する

内部処理は複雑な場合もありますが、共通して言えるのはLLMを使って入力から出力を生成するシステムだということです。

## ユーザーの返答からのインタラクティブな学習

次に、今回研究者らが考案した「ユーザーの返答を利用した学習」の仕組みを説明します。基本的には、文章作成支援などのアプリケーションを想定しています。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_76527_1-1024x464.jpg)

ユーザー編集からの対話的学習の図解。ユーザーがモデルの出力を編集し、モデルがそれを学習して改善していくプロセスを示している

### 学習の流れ

1. ユーザー（および環境）がコンテキストを提供する
2. エージェントがそのコンテキストに基づいて応答を生成する
3. ユーザーがその応答を編集する（自分の本当に求めていた応答に改善して提示する）
4. エージェントは元の応答とユーザーによる編集の差分を受け取る

このプロセスが何回も繰り返されます。エージェントの目標は、エージェントの応答とユーザーの編集の差分を最小化すること、つまり「ユーザーが求めていた応答」に限りなく近い応答をはじめから行えるようになることです。

下記はこの流れをプロトコルで示したものです。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_76527_2-1024x237.png)

### 差分の計算方法

エージェントの応答とユーザーの編集後の文章の違いは、数値化することが可能です。一方の文章をもう一方に変換するのに必要な最小の操作回数（単語の挿入、削除、置換）を数えるだけです。「Levenshtein距離」と呼ばれる計算方法です。

上記の考え方は「PRELUDE」フレームワークと命名されました。今回考案された新しい概念です。

### ユーザーの好みを学習する難しさ

前提として、ユーザーの好みを学習するのは簡単ではありません。その理由として、以下が挙げられます。

1. ユーザーの好みは多面的で複雑
2. 状況（コンテキスト）によって好みが大きく変わることがある
3. ユーザーの編集から好みを読み取るのは難しく、解釈が分かれる可能性がある

今回の研究はこのような課題を認識しつつも、最大限の効果を得ることを目的としています。

## CIPHERアルゴリズム

本手法は、アルゴリズムで表現することが可能です。研究者らはこのアルゴリズムに対しCIPHER（Consolidates Induced Preferences based on Historical Edits with Retrieval）と名づけました。

### 特徴

1. 過去の編集履歴を保存する
2. 新しいコンテキストが与えられたとき、似た過去の事例を参照する
3. 参照した事例から学んだ好みを集約して、現在のコンテキストに適した好みを推測する
4. 推測した好みを使って応答を生成する
5. ユーザーの編集を見て、新しく学んだ好みを履歴に追加する

### 詳細な動作

アルゴリズムは以下のステップで動作します。

（１）コンテキストの表現

入力されたコンテキストを数値ベクトルに変換し、コンテキスト同士の類似度を計算できるようにします。

（２）類似事例の検索

現在のコンテキストに近い過去の事例を見つけ、最も似ている上位k個の事例を選びます。

（３）好みの集約

選ばれた事例それぞれから推測された好みを集めます。また、これらの好みをまとめて、現在のコンテキストに適した好みを推測します。この作業にはLLMを利用します。

（４）応答の生成

推測した好みを考慮しながら、応答を生成します。

（５）学習

ユーザーが大きな編集をした場合、その編集から新しい好みを推測します。編集が小さかった場合は、使用した好みがうまく機能したと判断します。これらの情報を履歴に追加します。

以上の流れは次のように構造化して記述されます。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_76527_4-1024x483.png)

### 本手法の優れている点

優れている点は以下のようにいくつかありますが、全体的には計算コストの削減が実現されているところが大きいです。

まず、1回の応答生成で最大3回のLLM呼び出しで済むため、計算コストを効果的に抑えることができます。

次に、メモリ効率の面でも優れています。コンテキスト全体ではなく、その表現（ベクトル）のみを保存することで、必要なデータ量を大幅に削減しています。

さらに、LLMへの入力を最小限に抑えることで、クエリコストも削減しています。

### プロンプトテンプレート

CIPHERアルゴリズムで使用されるプロンプトテンプレートを下記に示します。要約タスクとメール作成タスクの両方に対して、ユーザーの好みを推論し、それを統合するプロセスを表現するものです。アルゴリズムの異なるステップ（タスク実行、好み推論、好みの統合）に対応します。

**要約タスク**

（１）タスクプロンプト

```js
Article: {user-provided article}
Assume that you need to summarize the above article for a user, who prefers the following style: {inferred user preference}. Please write a summary of the above article to address those specified preferences.
```

日本語訳：

```js
記事: {ユーザー提供の記事}
上記の記事を要約する必要があると仮定してください。ユーザーは次のスタイルを好みます: {推測されるユーザーの好み}。指定された好みに沿って、上記の記事の要約を書いてください。
```

（２）ユーザー好み推論プロンプト

```js
Original summary of an article: {agent-generated summary}
Revised summary by a user: {user revision}
Based on the edits and revision by this user on the original summary in the above examples, what do you find about this user's generic preference in terms of writing style and formatting? Please answer in a short phrase and only recommend those preferences that are widely used.
```

日本語訳：

```js
元の要約: {エージェント生成の要約}
ユーザーによる修正後の要約: {ユーザー修正版}
上記の例でユーザーが行った修正や編集に基づいて、このユーザーの一般的な文体やフォーマットの好みについてどのように推測できますか？短いフレーズで答えてください。広く使われている好みのみを推奨してください。
```

（３）好み統合プロンプト

```js
List of user preferences successfully being used to generate summaries of similar documents:
- {inferred preference in a retrieved example}
- {inferred preference in a retrieved example}
...
Based on the the above examples, please come up with short phrase with the most represented summarization preferences of the user.
```

日本語訳：

```js
類似したドキュメントの要約作成に成功したユーザーの好みのリスト：
- {取得された例で推測された好み}
- {取得された例で推測された好み}
...
上記の例に基づいて、このユーザーの要約における最も代表的な好みの短いフレーズを作成してください。
```

**メール作成タスク**

（１）タスクプロンプト

```js
Notes: {user-provided notes}
These notes are written by a user who prefers the following style of emails: {inferred user preference}. Please write a short email based on the above notes to address those specified preferences.
```

日本語訳：

```js
メモ: {ユーザー提供のメモ}
これらのメモは、次のスタイルのメールを好むユーザーによって書かれました: {推測されるユーザーの好み}。指定された好みに沿って、上記のメモに基づいて短いメールを書いてください。
```

（２）ユーザー好み推論プロンプト

```js
Original email: {agent-generated email}
Revised email: {user revision}
Based on the edits and revision by this user on the original email in the above examples, what do you find about this user's generic preference in terms of writing style and formatting? Please answer in a short phrase and only recommend those preferences that are widely used.
```

日本語訳：

```js
元のメール: {エージェント生成のメール}
修正後のメール: {ユーザー修正版}
上記の例でユーザーが行った修正や編集に基づいて、このユーザーの一般的な文体やフォーマットの好みについてどのように推測できますか？短いフレーズで答えてください。広く使われている好みのみを推奨してください。
```

（３）好み統合プロンプト

```js
List of user preferences successfully being used to generate emails of a similar kind:
- {inferred preference in a retrieved example}
- {inferred preference in a retrieved example}
...
Based on the the above examples, please come up with short phrase with the most represented writing preferences of this user.
```

日本語訳：

```js
類似した種類のメール作成に成功したユーザーの好みのリスト：
- {取得された例で推測された好み}
- {取得された例で推測された好み}
...
上記の例に基づいて、このユーザーの最も代表的な書き方の好みの短いフレーズを作成してください。
```

## 実験の設定と結果

### 実験環境

研究者たちは、CIPHERの性能を評価するために2つの実験環境を設定しました。

一つ目は文書要約タスクで、与えられた文書の要約を生成します。ニュース記事、Reddit投稿、Wikipedia記事など、様々な種類の文書を使用します。

二つ目はメール作成タスクで、与えられたメモを基にメールを作成します。こちらは個人的な問題、論文レビュー、論文のツイートなど、様々な種類のメモを使用します。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_76527_5-1024x616.png)

文書ソースごとの潜在的ユーザー設定とそのシナリオ

実験では、各タスクで200回のやり取りを行います。文書の種類は均等に混ぜて、時間的な偏りがないようにします。また、エージェントには文書の種類は知らせません。

また、ユーザーはGPT-4で模倣しました。文書の種類ごとに、異なるユーザーの好みを設定します。例えば、ニュース記事なら子供向けの語り口、Reddit投稿なら二人称の語り口といった具合です。

ユーザーの編集は2段階のプロセスでシミュレートされます。まず、エージェントの応答が好みに合っているか確認し、合っていない場合に好みに基づいて編集を行います。

評価指標としては、

- 累積編集コスト
- 好みの推測精度
- LLMの使用量

の3つが使用されました。累積編集コストはユーザーがどれだけ編集したかを測定し、好みの推測精度はエージェントが推測した好みが正しいかを評価します。LLMの使用量は入力と出力のトークン数で計算されます。

### 実装の詳細と比較システム

本実験では、GPT-4を基本のLLMとして使用しています。文脈表現にはMPNETとBERTの2種類を試験し、類似例の検索数（k）は1と5の2パターンが試されました。

比較対象のベースライン手法としては、以下が用いられました。

（１）学習なしのシステム

ユーザーの編集があっても学習を行わないシステム

（２）探索後利用（E-then-e）LPI

最初の数回は学習せずに探索し、その後学んだ1つの好みを使い続ける手法

（３）継続的LPI

毎回過去の全ての編集から1つの好みを学習し、その好みを使って応答を生成する手法

（４）ICL-edit

過去の類似する編集例を参照し、それらを使って直接応答を生成する手法

（５）CoT-edit

好みを推測してから応答を生成する手法

なお、オラクル手法という、正しい好みを知っている理想的なシステムが他の手法の上限とされます。オラクル手法では、各ラウンドで正しいユーザーの好みを完全に知っていると仮定します。つまり、

1. 各文書タイプに対して、予め定義された「真の」ユーザー好みを使用する
2. エージェントはこの「真の」好みを直接利用して応答を生成する

といった手順がオラクル手法です。

### 主な結果と考察

全体的に、CIPHERは他の手法と比べて優れた性能を示しました。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_76527_6-1024x436.png)

ベースラインと提案手法の累積編集距離コスト、分類精度、計算コストを比較

まず、「最小の編集距離コスト」を達成しました。要約タスクでは編集を31%削減し、メール作成タスクでは73%削減しました。ユーザーの好みをより正確に学習し、それに合わせた文章を生成できたことを意味します。

次に、「最高の好み推測精度」を達成している点にも注目です。他の手法よりも正確にユーザーの好みを理解できたということです。

また、他の手法と比べて計算コストが低いことが分かりました。これは、効率的に学習と推論を行えることを示す結果です。

学習曲線を見ると、CIPHERは時間とともに編集コストが減少する傾向が見られました。経験を積むにつれてユーザーの好みをより良く理解し、適切な文章を生成できるようになったと解釈できます。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_76527_7-1024x435.png)

時間経過に伴う各手法の累積コスト

なお、質的分析では、CIPHERが学習した好みの例を示しています。例えば、Wikipediaの記事に対しては箇条書きの好みを学習し、Reddit投稿に対しては二人称の語り口を学習したことが分かりました。様々な状況に応じて適切な好みを学習できることを意味する結果です。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_76527_8-1024x255.png)

時間経過に伴うゼロコスト例の割合

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_76527_9-1024x692.png)

要約タスクでCIPHER-5-MPNETが学習した設定の例

### 人間による評価

研究者たちは、CIPHERに対して、人間による評価も行いました。なお、要約タスクが使用されました。

まず、CIPHERの出力と他の手法の出力を比較し、どちらが高品質かを人間の評価者に判断してもらう評価を行いました。  
結果として、CIPHERはベストな比較対象（ICL-edit-5-MPNET）に対して73.3%の勝率を達成しました。

次に、人間のユーザーによる編集を調査しました。CIPHERの出力とオラクル手法の出力に対して、人間のユーザーが実際に編集を行いました。  
すると、CIPHERの出力に対する平均編集距離は211で、オラクル手法の98と比べるとまだ改善の余地があることが分かりました。

また、編集が全く必要なかった例の割合を見ると、CIPHERが60%、オラクル手法が76.7%でした。  
CIPHERがかなり高い確率で人間の好みに合った文章を生成できていることを示していますが、同時にまだ改善の余地があることも示しています。

## まとめ

本記事では、ユーザーのフィードバックを活用してLLMの応答をパーソナライズする研究を紹介しました。

今回研究者らは、ユーザーの好みを推論し応答生成に利用するPRELUDEフレームワークとCIPHERアルゴリズムを提案しています。

CIPHERは文書要約と電子メール作成タスクで評価され、編集コストの削減とユーザー好みの正確な学習を実現しました。ただし今後の課題として、実際の人間との対話を通じた評価や、微調整可能な場合のアルゴリズム開発が挙げられています。

- 参照論文URL： [https://arxiv.org/abs/2404.15269](https://arxiv.org/abs/2404.15269)
- コードとデータ： [https://github.com/gao-g/prelude](https://github.com/gao-g/prelude)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[専門家が作成したプロンプトと同等以上の性能を達成する自動プロンプト生成手法『Minstriel』](https://ai-data-base.com/archives/76468)

[「o1-preview」は従来のモデルとは明確に異なり「珍しいタイプの問題」にも強い](https://ai-data-base.com/archives/76609)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)