---
title: "ファインチューニングがLLMの幻覚（ハルシネーション）に与える影響 Googleなどによる検証結果"
source: "https://ai-data-base.com/archives/69421"
author:
  - "[[AIDB Research]]"
published: 2024-05-22
created: 2025-06-13
description: "LLMをファインチューニングしたとき、幻覚（ハルシネーション）誤った情報の生成にはどう影響するのかが調査されました。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

LLMをファインチューニングしたとき、幻覚（ハルシネーション）誤った情報の生成にはどう影響するのかが調査されました。指示に従うタスクや人間のフィードバックを通じて、望ましい行動をとるように調整することを「微調整」または「ファインチューニング」と呼びます。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69421-1024x576.jpg)

**参照論文情報**

- タイトル：Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?
- 著者：Zorik Gekhman, Gal Yona, Roee Aharoni, Matan Eyal, Amir Feder, [Roi](https://ai-data-base.com/archives/26574 "ROI（Region of Interest）") Reichart, Jonathan Herzig
- 所属：Technion – Israel Institute of Technology, Google Research

**本記事の関連研究** ：

- [マルチモーダルLLMにおけるハルシネーション（幻覚）の原因と対策](https://ai-data-base.com/archives/68720)
- [LLMの内部状態を観察することで「出力がハルシネーションか否かを判別する」手法『LLMファクトスコープ』](https://ai-data-base.com/archives/61651)
- [LLMの誤り（ハルシネーション）発生原因と、「創造性と事実性のバランス」などの対策ロードマップ](https://ai-data-base.com/archives/58767)
- [ファインチューニングデータが十分に大きい場合、タスク性能向上に追加の事前学習は不要の可能性　Googleなどによるスケーリング則の実験から](https://ai-data-base.com/archives/64001)

## 背景

モデルは微調整中に新しい事実に遭遇することがあります。そして、新しい知識に触れることが、いわゆる「ハルシネーション」を引き起こす可能性があると考えられています。モデルが事実とは異なる誤った応答を生成する現象です。  
事前学習においては知識を効果的に利用する方法を学びますが、微調整を通じて新しい知識を取得するのは難しいのではないかと議論されていますが、明確な答えは出ていません。

そこで今回研究者らは、新しい知識がLLMの性能に与える影響を詳細に調査することにしました。

## 研究デザイン

### データセット

本研究ではまず、質問応答（QA）の形式でファインチューニングデータセットが作成されました。 [Wikidata](https://www.wikidata.org/w/index.php?title=Wikidata:Main_Page&uselang=ja) というWebサイトから抽出された多様な知識を含む、ENTITYQUESTIONSというデータセットをもとにしています。質問は「(主語, 関係, 目的語)」の形式で構造化された事実情報から生成され、回答はその目的語になります。例えば、「パリはどこにありますか？」という質問に対する回答は「フランス」となります。

ファインチューニングデータセットの一部として、モデルにとって未知の情報を含む質問応答ペアが意図的に含められました。そして、未知の情報の割合を変化させながら、モデルの性能への影響が調べられました。

新しい情報の影響を他の要因から切り離して調べるために、ファインチューニングデータセットのサイズが固定され、未知の情報を含む質問応答ペアの割合のみが変化させられました。  
さらに、未知の情報の影響が、ファインチューニング時に使用された知識の関係以外にも及ぶかどうかを調べるために、ファインチューニングデータセットには含まれていない関係についてもテストが行われました。

### モデルと指標

実験されたモデルは、PaLM 2-Mというベースモデルです。モデルの性能は、正解と完全に一致する割合を示す指標である [正解率](https://ai-data-base.com/archives/25930 "正解率") （Exact Match; EM）で評価されました。

## 知識の定量化方法

研究者らは、大規模言語モデル（LLM）が新しい知識をどのように取り込むかを評価するために、モデルの知識を定量化する方法を考案しました。本方法は、SliCK（Sampling-based Categorization of Knowledge）と名付けられています。

LLMが質問に対して正しい答えを出せるかどうかは、その質問に関する知識がモデルにとって既知であるか未知であるかに依存します。そこでSliCKでは、まず各質問と回答のペアを「既知（Known）」と「未知（Unknown）」に分類します。

既知の知識は、さらに以下の3つのカテゴリに分けられます。

1. 高度に既知（HighlyKnown）：モデルが常に正しい回答を生成できる。
2. ある程度既知（MaybeKnown）：モデルが時々正しい回答を生成できる。
3. 弱く既知（WeaklyKnown）：モデルが確率的に正しい回答を生成できる。

モデルが特定の質問に対して正しい回答を生成する確率を示す指標として、PCorrectを定義しています。モデルがどれだけ正確に回答を生成できるかを評価する指標です。

**PCorrectの計算**

1. 各質問に対して、複数の例示（few-shot exemplars）をランダムに選択する。
2. 選択した例示を用いて、モデルに回答を生成させる。
3. 生成された回答と正解を比較し、正解と一致する割合を計算する。

この方法を使うことで、モデルが質問に対して正しい回答をどの程度の確率で生成できるかを見積もることができます。

そして、PCorrectの値に基づいて、各質問と回答のペアを以下のように分類します。

- 高度に既知：PCorrect = 1（常に正解を生成）
- ある程度既知：0 < PCorrect < 1（時々正解を生成）
- 弱く既知：PCorrect = 0 かつ 温度 [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") ※で正解を生成
- 未知：PCorrect = 0（正解を生成できない）

※温度 [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") ：モデルの出力をランダムにする手法。温度が高いほど多様な回答が生成されやすくなります。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69421_2-1024x339.png)

知識カテゴリーの定義と具体例。既知の例はHighlyKnown, MaybeKnown, WeaklyKnownに分類され、未知の例はUnknownとされる。

以上の手法には次のようなメリットがあります。

- LLMの知識を定量的に評価できる。
- 既知の知識と未知の知識を明確に区別できる。
- 新しい知識がLLMの学習に与える影響を詳細に解析できる。

## 実験結果

この研究の主題は、ファインチューニングを通じて新しい知識（未知の例）を学習することが、LLMのハルシネーションにどのような影響を与えるかを調べることです。前述の通り、研究者らはファインチューニングデータセットに意図的に未知の例を含めることで、新しい知識の影響を調べました。以下はその実験結果です。

### 未知の例の割合が高いほどモデルの性能が低下

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69421_3-1024x372.jpg)

上の図におけるaは、ファインチューニングの期間の違いごとに、未知の例の割合とテストセットでの性能の関係を示しています。ファインチューニングの期間に関わらず、未知の例の割合が高いほどモデルの性能が低下することが明らかになりました。未知の例の割合が高いほど、 [過学習](https://ai-data-base.com/archives/26427 "過学習") のリスクが高まることに起因すると考えられます。

次に、未知の例が単に性能向上に寄与しないだけなのか、それとも積極的に有害なのかを調べるために、未知の例をすべて取り除いた場合の影響が調べられました。図bは、早期終了（Early Stopping）の場合、未知の例を取り除いても性能にほとんど影響がないことを示しています。つまり、この時点では未知の例は中立的な存在だと言えます。一方、ファインチューニングを十分に長く行った場合（Convergence）、未知の例を含むデータセットは、未知の例を取り除いたデータセットよりも性能が大幅に低下しました。この性能低下の度合いは、未知の例の割合に比例していました。つまり、長いファインチューニングにおいては、未知の例は有害な存在だと言えます。

### 未知の例は既知の例よりも学習が遅い

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69421_1.png)

次に上の図は、ファインチューニングの期間に対する、既知の例と未知の例の学習曲線を示しています。早期終了の時点では、モデルは既知の例の大部分を学習しているのに対し、未知の例はほとんど学習していないことがわかります。つまり、未知の例は既知の例よりも学習が遅いのです。LLMがファインチューニングを通じて新しい知識を獲得することが難しいことを示唆しています。むしろ、既知の例を使って、事前学習で獲得した知識を活用する方法を学んでいると考えられます。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69421_4.png)

早期終了時点での、各データセット変種における学習済み例の割合。未知の例は学習が遅い。

### 線形モデルで見る未知の例と既知の例の影響の違い

下の表は、テストセットでの性能を、モデルが学習した既知の例と未知の例の数で予測する線形モデルの結果を示しています。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69421_5.png)

このモデルでは、未知の例を学習することは性能を下げ、既知の例を学習することは性能を上げることが示されました。また、未知の例による負の影響と、既知の例による正の影響の大きさはほぼ同程度でした。

### 未知の関係への一般化

ファインチューニングに使われなかった関係についても同様の実験が行われ、未知の例の割合が高いほど性能が低下することが確認されました。ある関係について未知の例を学習することが、一見無関係な別の関係についての幻覚を引き起こす可能性を示唆しています。

上記の実験結果をまとめると以下のようになります。

- 未知の例の割合が高いほど、LLMの性能が低下し、 [過学習](https://ai-data-base.com/archives/26427 "過学習") のリスクが高まる。
- 未知の例は既知の例よりも学習が遅い。
- ある関係について未知の例を学習することが、別の関係についてのハルシネーションを引き起こすことがある。

## 知識の種類による影響

現象を深く理解するため以下の2つのテーマが探求されることになりました。

Q1: 各カテゴリーの学習例は、テスト性能にどのような影響を与えるか？  
Q2: 各カテゴリーのテスト例に対するモデルの性能はどうか？

そこで、特定のカテゴリーの例のみを含むファインチューニングデータセットの変種が作成されました。例えば、高度に既知（HighlyKnown）の例のみを含むデータセットが作成されました。比較のために、ENTITYQUESTIONSデータセットの自然なカテゴリー分布を持つ変種も用意されました。

### ある程度既知（MaybeKnown）の例の重要性

結果は、高度に既知（HighlyKnown）の例のみを用いたファインチューニングが最良の結果をもたらすわけではないことを示しました。高度に既知（HighlyKnown）の例のみを含むデータセットは、高度に既知（HighlyKnown）のテスト例では優れた性能を示しましたが、他のカテゴリーでは性能が劣っていました。

驚くべきことに、ある程度既知（MaybeKnown）の例のみを含むデータセットが最も高い全体的な性能を達成しました。  
高度に既知（HighlyKnown）の例のみを含むデータセットと比較して、ある程度既知（MaybeKnown）の例のみを含むデータセットは、高度に既知（HighlyKnown）の性能を損なうことなく（98.7 → 98.4）、ある程度既知（MaybeKnown）の性能を大幅に向上させました（60.1 → 69.9）。  
ある程度既知（MaybeKnown）の学習例が、推論時にそのようなタイプの例を正しく処理するために不可欠であることを示唆しています。また、適切な学習例を用いることで、モデルが事前知識をより効果的に活用できるようになることも示されました。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69421_6-1024x265.png)

各カテゴリーの例のみでファインチューニングした結果。MaybeKnownが最も高性能。

### 半端な知識が過学習を増大させる

また、未知（Unknown）の例がモデルの [過学習](https://ai-data-base.com/archives/26427 "過学習") のリスクを増大させることに加え、弱く既知（WeaklyKnown）の例についても同様のことが言えることがわかりました。

弱く既知（WeaklyKnown）の例のみを含むデータセットと未知（Unknown）の例のみを含むデータセットは、学習を十分に長く行った場合（Convergence）、早期終了（Early Stopping）と比較して著しい性能低下を示しました。これらのデータセットでは、弱く既知（WeaklyKnown）と未知（Unknown）のテスト例では若干の性能向上が見られましたが、高度に既知（HighlyKnown）とある程度既知（MaybeKnown）では大幅な性能低下が見られました。この性能低下は、事前学習で獲得済みの知識に関する幻覚の増加に起因していると考えられます。

注目すべきは、自然なカテゴリー分布を持つデータセットが早期終了時点ではある程度既知（MaybeKnown）の例のみを含むデータセットと同等の性能を示したことです。これは、ある程度既知（MaybeKnown）の例が単にデータセットに存在するだけで、ある程度既知（MaybeKnown）のテスト例に対する高い性能が得られることを示唆しています。ただし、自然なカテゴリー分布を持つデータセットの性能は十分に長い学習後に大幅に低下しました。これは、弱く既知（WeaklyKnown）と未知（Unknown）の例が含まれているために [過学習](https://ai-data-base.com/archives/26427 "過学習") が起きたと考えられます。

以上の結果から、ある程度既知（MaybeKnown）の例のみを含むデータセットは高性能と [過学習](https://ai-data-base.com/archives/26427 "過学習") リスクの低減の両面で際立っていることがわかります。

※難解のため、上記結果を箇条書きでまとめます。

- 高度に既知（HighlyKnown）の例のみを用いたファインチューニングは、最良の結果をもたらすわけではない。
- ある程度既知（MaybeKnown）の例のみを含むデータセットが最も高い全体的な性能を達成した。
- ある程度既知（MaybeKnown）の学習例は、推論時にそのようなタイプの例を正しく処理するために不可欠である。
- 適切な学習例を用いることで、モデルが事前知識をより効果的に活用できるようになる。
- 弱く既知（WeaklyKnown）の例は、未知（Unknown）の例と同様に、モデルの [過学習](https://ai-data-base.com/archives/26427 "過学習") のリスクを増大させる。
- ある程度既知（MaybeKnown）の例が単にデータセットに存在するだけで、ある程度既知（MaybeKnown）のテスト例に対する高い性能が得られる。
- ある程度既知（MaybeKnown）の例のみを含むデータセットは、高性能と [過学習](https://ai-data-base.com/archives/26427 "過学習") リスクの低減の両面で際立っている。

## まとめ

本記事では、LLMのファインチューニング時に新しい知識を学習することがハルシネーションに与える影響を調査した研究を紹介しました。新しい知識の獲得はハルシネーションと相関があり、知識を獲得するには主に事前学習が向いていることが示唆されました。実用面では、新しい知識を含む学習例の悪影響は [過学習](https://ai-data-base.com/archives/26427 "過学習") として現れるため、早期終了やこれらの例の除外・ラベル付け直しにより軽減できる可能性があります。モデルの設計や選択において役立つ知見といえます。

- 参照論文URL： [https://arxiv.org/abs/2405.05904](https://arxiv.org/abs/2405.05904)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[GPT-4o、Gemini、Claude 3などにおける「長いプロンプトのマルチモーダルタスク」性能を測定した結果](https://ai-data-base.com/archives/69354)

[LLMエージェントの設計16パターン](https://ai-data-base.com/archives/69483)　

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)