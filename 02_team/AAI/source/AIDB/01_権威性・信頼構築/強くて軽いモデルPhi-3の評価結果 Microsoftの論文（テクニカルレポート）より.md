---
title: "強くて軽いモデルPhi-3の評価結果 Microsoftの論文（テクニカルレポート）より"
source: "https://ai-data-base.com/archives/68184"
author:
  - "[[AIDB Research]]"
published: 2024-04-24
created: 2025-06-13
description: "Microsoftの研究者らは、モバイルデバイス上で動作可能なほど小型の言語モデル「phi-3-mini」を開発しました。3.8Bパラメータで、3.3兆トークンのデータで学習されています。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

Microsoftの研究者らは、モバイルデバイス上で動作可能なほど小型の言語モデル「phi-3-mini」を開発しました。3.8Bパラメータで、3.3兆トークンのデータで学習されています。驚くべきことに、phi-3-miniの性能は、GPT-3.5やMixtral 8x7Bといった大規模モデルに匹敵するレベルに達していると言います。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68184-1024x576.jpg)

**参照論文情報**

- タイトル：Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone
- 著者：Marah Abdin et al. （多数）
- 所属：Microsoft

**本記事の関連研究** ：

- [Microsoftなどのプロンプト圧縮技術『LLMLingua-“2″』タスクの精度を維持したまま圧縮率2-5倍](https://ai-data-base.com/archives/66170)
- [Microsoftの研究者ら、比較的小さなサイズでもタスクによってはOpenAIのGPT-4を凌駕する言語モデル『Orca2』を開発](https://ai-data-base.com/archives/59349)
- [1.1Bパラメータの小さなモデルを巨大データ（約3兆トークン）で訓練したモデル『TinyLlama』が、比較的優秀な性能を発揮](https://ai-data-base.com/archives/61914)
- [Appleが開発、スマホのスクリーンを理解してユーザーと対話できる『ReALM』端末上で動く軽量モデル](https://ai-data-base.com/archives/66828)

## Phi-3シリーズの概要

phi-3-miniが高い性能を実現できた要因は、トレーニングデータにあると言います。研究者らは、以前のモデルphi-2の開発で使用したデータセットを拡張し、ウェブデータを厳選したものと、言語モデルが生成した合成データを組み合わせました。そうすることで、モデルサイズを小さく抑えながらも、大型モデルに匹敵する性能が得られたのです。

研究者らはまた、70億個と140億個のパラメータを持つモデル「phi-3-small」と「phi-3-medium」も開発しました。48兆トークンのデータで学習されており、phi-3-miniをさらに上回る性能を示しています。例えば、phi-3-smallとphi-3-mediumは、それぞれMMLU（多分野の知識テストベンチマーク）で75％と78％、MT-bench（会話で的確な返答ができるか評価するベンチマーク）で8.7と8.9を達成しています。

以下で論文（テクニカルレポート）をもとに、評価結果などを中心にPhi-3の詳細を紹介します。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68184_2-1024x621.jpg)

4ビット量子化されたphi-3-miniがiPhone上でネイティブに動作し、1秒あたり12トークン以上を生成している様子

## phi-3のアーキテクチャ

phi-3-miniモデルは、トランスフォーマーデコーダー [アーキテクチャ](https://ai-data-base.com/archives/26562 "アーキテクチャ") を採用しています。またデフォルトのコンテキスト長（モデルが一度に処理できる入力の長さ）は4,000トークンです。なお、研究者らはLongRopeと呼ばれる手法を用いて、コンテキスト長を128,000トークンに拡張したバージョン「phi-3-mini-128K」も開発しています。

phi-3-miniは、Llama-2モデルと同様のブロック構造を採用し、同じトークナイザーとボキャブラリーサイズを使用しています。トークナイザーとはテキストを単語や文字などの単位（トークン）に分割するツールのことで、ボキャブラリーサイズはモデルが認識できる単語や文字の種類の数を意味します。

Llama-2向けに開発されたパッケージをphi-3-miniに直接適用できるため、オープンソースコミュニティに大きく貢献できると期待されています。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68184_3-1024x350.png)

“データ最適レジーム”に近いスケーリング則（左からphi-1.5, phi-2, phi-3-mini, phi-3-small）と、同じ固定データで訓練されたLlama-2モデルファミリー（7B, 13B, 34B, 70B）の比較。MMLUエラーの対数とモデルサイズの対数をプロットしている。

### phi-3-miniの詳細なパラメータ

phi-3-miniは、隠れ層の次元数が3,072、ヘッド数が32、層数が32で構成されています。モデルの学習には、bfloat16という数値表現が用いられ、合計3.3兆トークンのデータが使用されました。また、モデルはチャット形式に最適化されており、ユーザーの入力とアシスタントの応答を区別するためのテンプレートが用意されています。

### モデルの特徴

なお、冒頭にも述べた通り、研究者らは、phi-3-miniに加えて70億個のパラメータを持つ「phi-3-small」と140億個のパラメータを持つ「phi-3-medium」というモデルも開発しました。多言語対応のためにtiktokenトークナイザーを採用し、ボキャブラリーサイズを100,352に拡張しています。

phi-3-smallは、キーバリューキャッシュ（トランスフォーマー [アーキテクチャ](https://ai-data-base.com/archives/26562 "アーキテクチャ") における注意機構の計算を高速化するためのメモリ）のフットプリントを最小化するために、グループ化されたクエリアテンションを活用しています。さらに、密なアテンションとブロックスパースアテンション（注意機構の計算量を削減するために、一部の要素を0に設定する手法）を交互に使用することで、長いコンテキストでの性能を維持しつつ、キーバリューキャッシュの節約を実現しているとのことです。

## ベンチマーク評価結果

研究者らは、phi-3-miniモデルの推論能力を評価するために、一般常識推論と論理的推論に関する標準的なオープンソースのベンチマークを使用しました。その結果、phi-3-miniは、phi-2、Mistral-7b-v0.1、Mixtral-8x7b、Gemma 7B、Llama-3-instruct-8b、GPT-3.5といった他のモデルと比較して、優れた性能を示しました。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68184_4-991x1024.jpg)

評価においては、Few-shot学習が用いられました（少数のサンプルを含むプロンプトを使用する手法）。研究者らは、Microsoftの社内のツールを用いてプロンプトとサンプル数を決定し、phi-3モデル用に最適化は行わず、全てのモデルで同じ評価パイプラインを使用しました。

### phi-3-miniの優れた性能

phi-3-miniは、上記の表で分かる通り、MMLUで68.8％、HellaSwagで76.7％、ANLIで52.8％、GSM-8Kで82.5％、MedQAで53.8％、AGIEvalで37.5％、TriviaQAで64.0％、Arc-Cで84.9％、Arc-Eで94.6％、PIQAで84.2％、SociQAで76.6％、Bi [gB](https://ai-data-base.com/archives/26343 "勾配ブースティング") ench-Hardで71.7％、WinoGrandeで70.8％、OpenBookQAで83.2％、BoolQで77.2％、CommonSenseQAで80.2％、TruthfulQAで65.0％、HumanEvalで59.1％、MBPPで70.0％という結果を示しました。他のモデルと比較して非常に高い性能であることを示しています。

それぞれのベンチマークが評価する対象の特徴を下記に並べます。

- MMLU: 数学、物理、化学、生物学などの学術的な問題に関する推論能力
- HellaSwag: 文章の続きを予測する常識的な推論能力
- ANLI: 自然言語推論における言語理解の堅牢性
- GSM-8K: 算術的な文章題を解く能力
- MedQA: 医療分野の質問に回答する能力
- AGIEval: 人工一般知能（AGI）のための包括的な評価
- TriviaQA: 一般的な雑学に関する質問応答能力
- Arc-C: 複雑な推論を必要とする質問応答能力
- Arc-E: 初等レベルの科学的知識と推論能力
- PIQA: 物理的な常識や因果関係の理解
- SociQA: 社会的な常識や規範の理解
- Bi [gB](https://ai-data-base.com/archives/26343 "勾配ブースティング") ench-Hard: 言語モデルの包括的な能力を評価する難易度の高いタスク実行能力
- WinoGrande: 代名詞の指示対象を解決する常識的な推論能力
- OpenBookQA: 科学的な知識と推論を組み合わせる能力
- BoolQ: 質問に対して「はい」か「いいえ」で答える能力
- CommonSenseQA: 一般的な常識に関する質問応答能力
- TruthfulQA: 言語モデルの誠実さと倫理的な判断力
- HumanEval: プログラミングコードを生成する能力
- MBPP: 数学的なプログラミング問題を解決する能力

### phi-3-smallとphi-3-mediumの性能

研究者らは、phi-3-smallとphi-3-mediumモデルの性能も評価しました。phi-3-miniをさらに上回る結果を示しており、例えばMMLUでは75.3％と78.2％、GPQAでは34.3％、MT Benchでは8.70と8.91を達成しました。ただし、phi-3-mediumの一部のベンチマークについては、まだ調査中であり、予備的な結果として扱われています。

## 安全性への取り組み

研究者らは今回、 [Microsoft社の責任あるAIの原則](https://www.microsoft.com/ja-jp/ai/principles-and-approach) に基づいて、phi-3-miniの開発を行いました。安全性に配慮した学習、レッドチーミング、自動テストなど、多岐にわたる評価が含まれています。

なおレッドチーミングとは、システムの脆弱性を発見するために、敵対的な立場から評価を行うことです。phi-3-miniは、大規模言語モデルに匹敵する言語理解と推論能力を持っていますが、そのサイズゆえの限界も存在します。特に、モデルの容量\*が小さいため、大量の事実知識を蓄えることが難しいのです。実際、TriviaQAのような事実知識を問うタスクでは、phi-3-miniの性能が低くなっています。

phi-3-miniの学習においては、有害な応答を抑制するためのデータセットを活用しました。様々な分野における高品質な例が含まれており、安全性の向上に寄与しています。また、Microsoft社の独立したレッドチームがphi-3-miniを繰り返し検査し、改善点を特定しました。その結果、有害な応答の割合が大幅に減少したことが確認されています。

また研究者らは、社内のベンチマークを用いて、phi-3-miniとphi-3-mini-128K、phi-2、Mistral-7b-v0.1、Gemma 7B、Llama-3-instruct-8bの安全性を比較しました。評価者としてGPT-4を用いて5つのカテゴリーにおける複数ターンの会話をシミュレートし、モデルの応答を評価しました。その結果、phi-3-miniは他のモデルと比較して、より安全性の高い応答を生成することが示されました。

ただし、まだ他のモデルと同様に、不正確さ、バイアス、不適切なコンテンツの生成などの課題が残されています。研究者らは、慎重にキュレーションされた学習データや、ターゲットを絞った学習、レッドチームからのフィードバックを取り入れることで問題を軽減するように努力しています。しかし、さらなる研究が必要とされています。

## 技術的な課題

### （１）知識面

phi-3-miniは、大規模な言語モデルに匹敵する言語理解と推論能力を持っていますが、やはりその小さなサイズゆえの限界も存在します。例えば、モデルの容量が小さいため、大量の事実知識を蓄えることが難しいです。実際、TriviaQAのような事実知識を問うタスクでは、phi-3-miniの性能が低くなっています。

ただし、検索エンジンとの連携によって解決できる可能性はあります。HuggingFaceのChat-UIを使用したデモンストレーションでは、phi-3-miniが検索機能を活用することで、より正確な応答を生成できることが確認されました。

### （２）言語面

phi-3-miniのもう一つの制約は、主に英語に特化していることです。研究者らは、phi-3-small（miniではなくsmall）において多言語データを取り入れることで、小規模言語モデルの多言語対応の可能性を探っています。まだ初期段階ですが実験結果は有望であり、今後の発展が期待されます。

## まとめ

本記事では、Microsoftの研究者らが開発した小型言語モデル「phi-3-mini」に関する研究を紹介しました。高品質なトレーニングデータを活用することで、スマートフォン上で動作可能な小型モデルでも、GPT-3.5やMixtral 8x7Bといった大規模モデルに匹敵する性能を達成できることを示しています。

また、より大きなモデルであるphi-3-smallとphi-3-mediumも開発し、さらなる性能向上を実現しています。

安全性の面でも、有害な応答の割合を大幅に減少させることに成功しました。ただし、事実の不正確さやバイアスの問題などの解決にはさらなる研究が必要とされています。

現在、phi-3を新しいソリューションの開発に役立てる動きも始まっています。今後注目されるモデルの一つです。

- 参照文献URL： [https://arxiv.org/abs/2404.14219](https://arxiv.org/abs/2404.14219)
- ブログ： [https://news.microsoft.com/ja-jp/2024/04/24/240424-the-phi-3-small-language-models-with-big-potential/](https://news.microsoft.com/ja-jp/2024/04/24/240424-the-phi-3-small-language-models-with-big-potential/)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[プロンプトでLLMにRPAワークフローを自動生成させる手法「FlowMind」JPモルガン考案](https://ai-data-base.com/archives/68095)

[小さなRetrieverとLLMの組み合わせによる実用的なワークフロー生成システム　またはRAGで幻覚を減らす手法](https://ai-data-base.com/archives/68219)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)