---
title: "LLMにおける長文処理能力の進化を調査 Claude 3.5は情報の流れを追跡するスキルに長ける"
source: "https://ai-data-base.com/archives/78379"
author:
  - "[[AIDB Research]]"
published: 2024-11-13
created: 2025-06-13
description: "本記事では、LLMの長文処理能力について、その進化と直面する課題の発見を紹介します。現代の最先端モデルは、書籍何冊分もの長さのテキストを一度に処理できるようになりましたが、この能力を検証する適切な評価方法が不足しています。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、LLMの長文処理能力について、その進化と直面する課題の発見を紹介します。

現代の最先端モデルは、書籍何冊分もの長さのテキストを一度に処理できるようになりましたが、この能力を検証する適切な評価方法が不足しています。これまでの評価方法ではモデルの真の限界を試すことができず、より詳細な分析が必要とされています。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78379-1024x576.jpg)

**参照論文情報**

- タイトル：Needle Threading: Can LLMs Follow Threads through Near-Million-Scale Haystacks?
- 著者：Jonathan Roberts, Kai Han, Samuel Albanie
- 所属：University of Cambridge, The University of Hong Kong

**本記事の関連研究**

- [RAGにおいて長文を検索することで一気に効率を上げるアプローチ『LongRAG』](https://ai-data-base.com/archives/71774)
- [RAGとLong-Contextの比較、そしてハイブリッドで活用する新しい方法](https://ai-data-base.com/archives/73468)
- [ロングコンテキストLLMでも、情報の数は「多ければ多いほど良い」わけではない](https://ai-data-base.com/archives/77127)
- [ロングコンテキストLLM台頭の今もRAGを使用する理由](https://ai-data-base.com/archives/75289)

## 背景

LLMは、コンピューティングリソースの拡大やアルゴリズムの改善によって、より長いコンテキストウィンドウ（一度に処理できるテキストデータ量）を持つようになっています。例えば、Gemini 1.5 Proの200万トークンというコンテキストウィンドウは、小説「 [白鯨](https://www.amazon.co.jp/%E7%99%BD%E9%AF%A8-%E4%B8%8A-%E5%B2%A9%E6%B3%A2%E6%96%87%E5%BA%AB-%E3%83%8F%E3%83%BC%E3%83%9E%E3%83%B3%E3%83%BB%E3%83%A1%E3%83%AB%E3%83%B4%E3%82%A3%E3%83%AB/dp/4003230817) 」(約30万トークン)を5回近く収められるほどの長さです。

長いコンテキストを活用すれば、より多くの情報をプロンプトからその場で学ぶことができるため、モデルのパフォーマンス向上につながります。また、可能なアプリケーションや達成可能なタスクの範囲が広がります。例えば法律文書の検索、パズルの解決など、さまざまな種類の情報をより良く処理できるようになります。

しかし、そんなに長いコンテキストをどのように効果的に利用すればいいのかは十分に理解されていません。なぜなら、現在の評価方法には、いくつかの重要な欠点があります。

まず、「干し草の中の針」テストを基にした多くのベンチマークは、単純な検索ベースの実験に焦点を当てていますが、最先端モデルはこれらのタスクでほぼ完璧なスコアを達成してしまうため、そこから有用な知見を得ることが難しい状況です。

また、ほとんどの長文コンテキストベンチマークでは、評価対象が10万トークン未満のコンテキストに限定されており、最先端LLMのコンテキスト制限と比べて1桁も小さい範囲に留まっています。

さらに、実際の文書を使用することや、複数のタスクを総合的な指標にまとめる傾向があります。そのため、コンテキスト長の増加に伴うパフォーマンス低下という大まかな傾向はわかったものの、それ以上の具体的な知見は得られていません。

このような背景から、今回ケンブリッジ大学などの研究者らは最先端モデルを対象に長文処理能力の実験を網羅的に行いました。

## タスク

本研究では、LLMの長文理解能力を評価するために、人工的に生成された合成データを用いた抽象的なタスクが実施されました。合成データを採用することで、質疑応答の作成や [アノテーション](https://ai-data-base.com/archives/26297 "アノテーション") にかかるコストを削減でき、ノイズのない高品質なデータを確保することができます。

データ構造としては、キーとバリューのペアを文字列化したJSONオブジェクトが使用されました。キーとバリューは、いずれも32文字で構成される128bit値のUUIDです。プロンプトは、タスクの説明、JSONデータ、出力フォーマットの指示、質問に使うキー、そして回答スペースという基本構造で構成されました。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78379_figure2-1-851x1024.jpg)

長文の文脈理解に関する私たちのキー・バリュー検索タスクの概略図

### タスク１：シングルニードル検索

最も基本的な能力を測るタスクです。大量のデータの中から、指定された1つのキーに対応する値を正確に見つけ出せるかを調べます。長い文章の中から特定の情報を探し出す能力に相当します。

### タスク２：マルチプルニードル検索

より実践的な状況を想定したタスクです。一度に複数（2個から25個）の情報を探し出す必要があります。情報が散らばっている場合と、まとまって配置されている場合の両方で実験が行われ、LLMが複数の情報を同時に扱う能力を評価します。

### タスク３：条件付きニードル検索

特定のパターンに基づいて情報を探し出す能力を測ります。たとえば「\*」や「&」という特殊な記号を含むキーに対応する値をすべて見つけ出す必要があります。特定の条件に合致する情報を網羅的に収集する能力の評価につながります。

### タスク４：スレッディング

情報の連鎖をたどる能力を評価するタスクです。最初のキーに対応する値が次のキーとなり、そのキーに対応する値がさらに次のキーとなる、というように情報をつなげていきます。文章中で複数の情報が関連づけられている場合に、その関連性を理解して追跡できるかを測ります。

### タスク５：マルチスレッディング

複数の情報の連鎖を同時に追跡できるかを調べるタスクです。たとえば、複数の登場人物の行動を同時に追跡するような場面を想定しています。LLMが並行して複数の文脈を維持できる能力を評価します。

## 実験

LLMの長文理解能力を包括的に評価するため、17種類のLLMを使って実験が行われました。

評価対象のモデルの大半は非公開（クローズドソース）のものですが、比較対象として一部のオープンソースモデルも含まれています。

- クローズドソース：GPT-4、Gemini 1.0/1.5、Claude 3/3.5、Rekaシリーズ
- オープンソース：Jamba 1.5、Mistral、LLaMA 3.1シリーズ

可能な限り、チャットやインストラクション（指示）に対応するよう調整されたモデルが選ばれました。指示に従う能力が高いモデルの方が、より広範なタスクに対応でき、自動評価も容易だからです。

各モデルの最大文脈長が図に示されています。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78379_figure1-1024x715.png)

また、実験では、シンプルなプロンプト方式が採用されました。各タスクに対して、質問と出力フォーマットの指示を含む単一のユーザープロンプトが使用されました。（これまでの研究に倣い、）システムプロンプトの変更やモデルごとのプロンプトの調整は行われていません。また、出力フォーマットの例示以外のfew-shot例（お手本となる例）は使用せず、推論のための明示的な促しも行われませんでした。

#### その他の設定

すべての実験は、zero-shot（事前の例示なし）の設定で行われました。また、再現性を確保するため、できるだけ決定論的な生成となるようモデルのパラメータが設定されました。具体的には、毎回同じ結果が得られるよう乱数シードを固定し、温度パラメータを0に設定して、最も確率の高い出力が選ばれるようにしました。

評価は、各モデルのAPIを通じて実施されました。可能な限り各モデルの文脈長の上限まで評価を試みましたが、APIの制限により必ずしもそれが叶わないケースもありました。

また、（最近の研究に倣い）評価対象のLLMからの出力を、より強力なLLM（Gemini 1.5 Flash）を使って特定のフォーマットに整形してから、正解との完全一致で評価が行われました。ほとんどのモデルは出力形式に従う能力が高いため、このLLMベースの整形と評価は、他の評価手法と高い相関を示すことが先行研究で確認されています。

なお予備的な実験で、トークン化（文章を細かい単位に分割すること）の方式に、モデル間で大きな違いがあることが判明しました。下の図に示されるように、同じUUIDのペアに対して、GPT-4oは約50トークン、Gemini 1.5は75トークンを使用しています。長い文脈では、この違いが顕著になります。例えば、Gemini 1.5 Flashの100万トークンという文脈長は、GPT-4oでは約70万トークンに相当します。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78379_figure3-1024x746.jpg)

この発見を踏まえ、本研究では、特に断りのない限り、LLaMA 3.1のトークナイザーで計測したトークン数を基準として使用しています。

### タスク１：シングルニードル検索の実験

まず、最も基本的な能力について。大量のデータ（haystack）の中に、決まった場所に置かれた1つの情報を見つけ出せるかというテストです。情報は、全体を10%ずつに区切った場所に配置されています。

実験の結果（下の図）、短い文章ではほとんどのAIがこの簡単な検索をうまくこなせることが分かりました。しかし、文章が長くなるにつれて、正確に情報を見つけられなくなっていきました。LLMが「扱える」とされる文章の長さと、実際に「正確に理解できる」長さには差があることを示しています。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78379_figure4-1024x386.jpg)

ただし、GPT-4oとJamba-1.5 Largeは特別で、文章の長さに関係なく完璧な成績を維持しました。また、図5の結果を見ると、多くのLLMは文章の真ん中あたりにある情報を見つけるのが特に苦手だということも分かりました。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78379_figure5-1024x236.png)

### タスク２：マルチプルニードル検索の実験

次に、一度に複数（1〜25個）の情報を見つけ出す能力を調べました。全体的な結果、代表的なLLMの詳しい分析が示されています。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78379_figure6-1024x325.jpg)

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78379_figure7-1024x261.png)

前の実験と同じように、文章が長くなると成績は下がっていきます。ただし、このテストではより急激に成績が落ち、文章が長くなりすぎると、いくつかのLLMは [正解率](https://ai-data-base.com/archives/25930 "正解率") が20%を下回りました。これは、複数の情報を同時に探す作業では、LLMが正確に理解できる文章の長さがさらに短くなることを意味しています。

ここでもGPT-4oは群を抜く性能を見せました。また、Gemini 1.5 Flashの分析からは、探す情報がまとまって置いてあるか、バラバラに置いてあるかは、あまり結果に影響しないことが分かりました。さらに、性能の高いLLMの場合、同時に探す情報の数よりも、文章の長さの方が結果に大きく影響することも判明しました。

### タスク３：条件付き検索の実験

「\*」という特殊な記号を含む情報を1〜25個探し出すテストを行いました。全体的な傾向は前の実験と似ていますが、短い文章でも急に成績が下がり、その後はゆっくりと低下していきました。

詳しい分析（下の図）からは、このテストでは情報の配置が重要だと分かりました。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78379_figure8-1024x264.png)

探すべき情報がまとまって置いてある場合の方が、バラバラに散らばっている場合よりも、正確に見つけられました。また、情報がバラバラの場合は、探す数が増えるほど成績が下がる傾向がありました。「.」など他の記号でも同じテストを行いましたが、全体的に成績は低くなりました。

### タスク４：スレッディング実験

これまでは1回で情報を見つける実験でしたが、ここからは情報をつなぎ合わせる必要がある、より難しい実験に移りました。2〜25個の情報をつなげて、最後の情報を正確に見つけられるかを調べました。また、情報をつなげる方向（前に進む、後ろに進む、ランダム）による違いも検証しました。

全体的な結果、代表的なLLMの詳しい分析を示します。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78379_figure9-1024x164.png)

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78379_figure10-1024x376.png)

情報をつなぎ合わせる必要があるため、このテストでは成績が大幅に下がりました。多くのLLM（例：Gemini 1.5 FlashやClaude 3 Haiku）は、文章が長くなるとほとんど正解できなくなりました。

### タスク５：マルチスレッディング実験

複数の情報の連鎖を同時に追跡できるかが調べられました。

長さ2〜5のつながりを2〜5本同時に追いかけ、それぞれの最後の情報を正確に見つけ出せるかをテストしました。情報のつながりの方向（すべて前方向、すべて後ろ方向、すべてランダム、方向もランダム）も変えて実験を行いました。

代表的なLLMの詳しい分析が図に示されています。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78379_figure11-1024x389.png)

興味深いことに、2本の情報の連鎖を追う場合と5本を追う場合で、大きな差は見られませんでした。テストで設定した範囲内では、LLMが複数の文脈を同時に追跡する能力を失わないことを意味します。

この「複数の文脈を同時に追える」という能力は、下の図にさらに詳しく示されています。Claude 3.5 Sonnetは25本の情報の連鎖を同時に追っても性能が落ちず、GPT-4oとGemini 1.5 Proも緩やかな低下に留まりました。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78379_figure12-1024x256.png)

### 全体的な分析

各LLMの総合的な性能を比較するため、5つのテスト（シングルニードル、マルチプルニードル、条件付きニードル、スレッディング、マルチスレッディング）の点数を同じ重みで平均しました。

結果は下の表に示されています。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78379_table1-1024x443.png)

最も優れたLLMは、文章の長さによって異なることが分かりました。

- 最も短い文章では、GPT-4oが最高の成績
- 中程度の長さ（2.5k〜32k）では、Claude 3.5 Sonnetが最も優秀
- より長い文章では、Gemini 1.5 Proが最高の性能

また、全体を通して非公開のLLMの方が、オープンソースのLLMよりも優れた成績を収めました。

そして、すべてのテストを通じて、「文章が長くなると性能が下がる」という傾向が見られました。これは、LLMが扱えるとされる文章の長さ（理論上の上限）と、実際に正確に理解できる長さに差があることを示しています。

そこで、より詳細な分析のため、各テストの結果をグリッド状に並べ、75%の正解率を基準として「実効的な文脈長」を計算しました。たとえば、シングルニードル検索では、文脈内の位置に関係なく最も短い長さを採用し、その他のテストでは特定の条件（例：10個の検索や5ステップのつながり）での長さを基準としました。

この分析結果は表にまとめられています。モデルによって使用するトークン（文章の区切り方）が異なるため、文字数を基準にして比較を行いました。結果として、ほとんどのLLMにおいて、簡単なテストでさえ、実際に正確に扱える文章の長さは、理論上の上限よりもかなり短いことが明らかになりました。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78379_table2-1024x407.png)

## まとめ

本記事では、大規模言語モデルの長文処理能力を詳細に検証した研究を紹介しました。

研究チームは、単純な情報検索から複数の情報を同時に追跡する複雑なタスクまで、様々な実験を行いました。実験の結果、以下の重要な知見が得られています。

- 長い文章の中央部分では情報検索の精度が低下する傾向がある
- 条件付き検索では、関連情報が集まっている場合の方が精度が高い
- ほとんどのモデルは、前から後ろへの情報追跡の方が、逆方向よりも高い精度を示す
- 複数の情報を同時に追跡する能力は、多くのモデルで安定している

また、この研究では、モデル間でトークンのカウント方法が大きく異なることも明らかになりました。研究チームは、このような違いを考慮に入れた新しい評価指標を提案しています。

今回の研究データとコードは公開されており、各人が活用することが期待されています。

- 参照論文URL： [https://arxiv.org/abs/2411.05000v1](https://arxiv.org/abs/2411.05000v1)
- データ： [https://needle-threading.github.io/](https://needle-threading.github.io/)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[上司役のLLMが部下LLMたちに的確に仕事を振り分ける『Magentic-One』マイクロソフトが開発](https://ai-data-base.com/archives/77850)

[Llama 3.1シリーズ、8ビット量子化で半分以下のサイズでも性能をほぼ完全維持、実験で確認](https://ai-data-base.com/archives/78430)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)