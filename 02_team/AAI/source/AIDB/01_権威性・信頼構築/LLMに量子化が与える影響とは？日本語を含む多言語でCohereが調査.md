---
title: "LLMに量子化が与える影響とは？日本語を含む多言語でCohereが調査"
source: "https://ai-data-base.com/archives/72292"
author:
  - "[[AIDB Research]]"
published: 2024-07-08
created: 2025-06-13
description: "本記事では、量子化がLLMに与える影響を調査した研究を紹介します。8億から103億パラメータの様々なLLMを対象に、日本語を含む20以上の言語で自動評価や人間評価が行われました。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、量子化がLLMに与える影響を調査した研究を紹介します。8億から103億パラメータの様々なLLMを対象に、日本語を含む20以上の言語で自動評価や人間評価が行われました。

研究の結果、量子化の影響は言語やタスクの難易度によって異なること、自動評価と人間評価に乖離があることを示しています。

調査を行ったのはCommand R+などを開発して話題になっている企業Cohereです。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_72292-1024x576.jpg)

**参照論文情報**

- タイトル：How Does Quantization Affect Multilingual LLMs?
- 著者：Kelly Marchisio, Saurabh Dash, Hongyu Chen, Dennis Aumiller, Ahmet Üstün, Sara Hooker, Sebastian Ruder
- 所属：Cohere

## 背景

LLMの性能向上とともに、その計算コストや推論速度の課題が注目されています。そこで、量子化が広く使われるようになりました。モデルの重みやアクティベーションを低ビット表現に圧縮する技術です。推論速度の向上やモデルの軽量化が叶うメリットがあります。

量子化の影響に関する研究もよく行われていますか、多くは英語に焦点を当てており、英語以外での影響については十分に調査されていません。自分たちの国でLLMを活用するためには、軽量でありながら性能や信頼性の高いモデルであることを把握する必要があります。

なお、計算リソースの制約が厳しい地域は「低リソースのジレンマ」と呼ばれる課題に遭遇します。サービスが行き届いていない国と計算リソースが枯渇している国は同じであることが多いそうです。

量子化や疎性（スパーシティ）などの圧縮技術は、ロングテール（頻度の低い特徴）に対して不均衡な影響を与える可能性が指摘されています。これが何を意味するか？マイナー言語はこのロングテールに該当する可能性があり、モデルの性能に良くない影響が出るかもしれないということです。

このような背景から、量子化がLLMに与える影響を言語の観点から調査する必要性が高まっています。そこで研究者らは、さまざまな手法を駆使して、LLMの日本語を含む非英語能力における量子化の影響を調査しました。以下で詳しく紹介します。まずはじめに、量子化とは何か？という点からまとめます。

## 量子化についてのあれこれ

量子化とは、LLMの性能を維持しつつ、計算コストを削減し、推論速度を向上させるための技術です。モデルの重みやアクティベーションを低ビット表現に圧縮することで、モデルの軽量化を図ります。最近ではLLMの大規模化に伴い、量子化技術の重要性がより高まっています。

量子化の多言語タスクにおける影響は、言語や評価方法によって異なることが明らかになっています。例えば、非ラテン文字系言語（アルファベットベースではない言語）はラテン文字系言語よりも大きな影響を受ける傾向があります。また、単一言語での評価と多言語評価では結果が異なる場合があり、言語の公平性という観点からも注目されています。

大変興味深いことに、量子化の影響は必ずしもネガティブなものだけではありません。タスクや言語によっては、軽度の量子化によって性能が向上する場合もあります。もしかすると量子化が一種の正則化として機能し、モデルの汎化性能を高めているのかもしれません。

なお、モデル圧縮や効率化のための様々な技術は量子化以外も研究されています。例えば、知識蒸留、プルーニング、低ランク近似などがあります。量子化と同様に言語や特徴によって異なる影響を与える可能性があります。

さらに、モデルの性能や公平性に影響を与える要因としてはハードウェアの選択、 [アンサンブル学習](https://ai-data-base.com/archives/26456 "アンサンブル学習") 、差分プライバシー技術なども関わってきます。稀な特徴や過小評価されたサブグループに対して特に不均衡な影響を及ぼす可能性があります。  
LLMの設計や選択は、上記のような複数の要因を総合的に考慮する必要があります。

今回は、量子化に焦点を当てて、英語以外のさまざまな言語において性能がどう変わるのか詳細に実験されました。

## 実験内容

### 評価対象モデル

本研究では、最先端の多言語LLMの代表として、以下のモデルが評価されました。

- Command R+（103億パラメータ）
- Command R（35億パラメータ）
- Aya 23（35億および8億パラメータ）

HuggingFaceで公開されている重みを用いて量子化が行われました。

### 量子化手法

以下のような様々な量子化技術が適用され、その影響が検証されました。

（１）重みのみの量子化

- 8ビット（W8）：列ごとのスケーリングを使用
- 4ビット（W4-g）：GPTQを用いたグループごとのスケーリングを採用

（２）重みとアクティベーションの量子化

- 8ビット（W8A8）：重みには列ごと、アクティベーションにはトークンごとのスケーリングが適用

さらに、Command R+モデルでは以下の手法も検討されました。

- W8A8-SmoothQuant：アクティベーションの分布を滑らかにする手法
- 列ごとのスケーリングを用いた4ビット重みのみの量子化（W4）

なお、Aya 23モデルについては、bitsandbytesライブラリを使用して8ビットおよび4ビットの量子化が実施されました。

### 自動評価

評価は主に10言語（アラビア語、フランス語、ドイツ語、英語、スペイン語、イタリア語、ポルトガル語、韓国語、日本語、中国語）で行われました。量子化されたモデルは、元の16ビット浮動小数点（FP16）版と比較され、相対的な性能低下が報告されています。

評価指標は以下が用いられました。

（１）多言語MMLU（mMMLU）

- 14,000以上の多肢選択問題からなる多領域質問応答タスク
- Google翻訳を用いて9言語に翻訳
- 5ショット設定での正確性を測定

（２）MGSM

- GSM8Kから手動で翻訳された生成的数学評価セット
- ドイツ語、スペイン語、フランス語、日本語、中国語で利用可能
- 各言語250問のテストセットでの正確性を報告

（３）FLORES-200

- 多方向並列テストセットを用いた翻訳能力の評価
- 英語との間の翻訳を評価
- SacreBLEUスコアを報告

（４）言語混同

- モデルが指定された言語で応答する能力を評価
- 単一言語設定と異言語間設定の2種類を実施
- fastTextによる言語識別を用いて行レベルの合格率を報告

（５）Aya評価

- Aya 23モデル用に拡張された評価セットを使用
- XWinograd、XCOPA、XStoryCloserなどの未見の識別タスクも含む

### 人間による評価

#### 評価対象言語

人間による評価は、スペイン語、フランス語、韓国語、日本語の4言語で実施されました。

#### 評価データセット

（１）内部評価スイート

150の多様なプロンプトが用意されました。公開されているベンチマークよりも複雑に設計されており、難易度が高いため、量子化による性能低下がより顕著に現れることが予想されました。全言語で同じ内容のプロンプトが使用されるよう、英語から人手で翻訳が行われました。

（２）Aya Dolly-200

オープンエンドな生成能力を評価するために使用されました。韓国語と日本語では、Aya Dolly-200テストセットの機械翻訳版が使用され、フランス語とスペイン語では、機械翻訳版を人手で編集したものが使用されました。各言語で最初の150プロンプトが評価対象となりました。

#### アノテーター

評価は、各言語のネイティブレベルの話者が担当しました。なお全てのアノテーターは英語も堪能です。

※時給制で雇用され、各国の連邦最低賃金を上回る報酬が支払われました。

#### 評価方法

（１）ペアワイズ評価

アノテーターには、プロンプトと2つのモデル出力（FP16モデルと量子化モデル）が提示されました。出力の順序はランダム化されています。

（２）評価基準

各応答は5段階のリッカート尺度で評価され、2つのモデル出力の優劣が判定されました（同等、弱い選好、強い選好）。アノテーターにはタイ（同等）の評価を避けるよう指示が出されました。

（３）勝率の算

優劣の判定のみに基づいて計算されました。

### LLM/RM-as-a-Judge評価

人間による評価は時間とコストがかかるため、代替手段としてLLMやReward Model（RM）を評価者として使用する方法も採用されました。

LLM-as-a-JudgeではGPT-4がプロキシ評価者として使用されました。入力は<指示, モデルA出力, モデルB出力>の形式で与えられ、バイアスを最小限に抑えるため、モデル出力の順序はランダム化されました。

一方、RM-as-a-Judgeでは多言語Reward Modelが使用されました。<プロンプト, 完了>のペアに対してスコアを付与し、各モデル出力に対するスコアを基に勝率が計算されました。

評価データとしては、内部評価スイートとAya Dolly-200の両方が使用されました。人間による評価と同じプロンプトと出力ペアが使用され、人間評価との比較を可能にしました。

## 結果

量子化がLLMに与える影響について、以下のように様々な観点から分析が行われました。

### 量子化レベルによる影響

モデル別に見てみます。

#### Command RおよびR+モデル

各評価指標の結果が量子化レベルごとに集計されました。言語間でスコアが平均化され、16ビット浮動小数点（FP16）版からの相対的な性能低下が計算されています。

結果として、量子化が進むほど、性能低下が大きくなる傾向が見られました。

中でも103億パラメータのモデルでは、以下のような性能低下が観察されました。

- W8（8ビット量子化）：-0.2%
- W8A8（8ビット重み・アクティベーション量子化）：-0.8%
- W4-g（4ビットグループ量子化）：-0.9%

ただし35億パラメータのモデルでは、W8A8で翻訳と言語混同評価において若干の性能向上が見られました。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_72292_1-1024x341.png)

103BおよびCommand 35Bモデルの各量子化レベルにおける非英語言語での平均パフォーマンス

#### Aya 23モデル

Aya 23モデルでも同様の傾向が観察され、W4（4ビット量子化）は、大きな性能低下をもたらしました。この傾向はタスクや言語を問わず一貫していました。

しかしW8（8ビット量子化）による量子化では、どのタスクでも顕著な性能低下は見られませんでした。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_72292_2-1024x248.png)

Aya 23の35Bと8Bモデルの各量子化レベルにおける非英語言語での平均パフォーマンス

### タスク別の影響

各タスクにおける量子化の影響においては、主な結果は以下の通りです。

#### （１）数学的推論（MGSM）での顕著な性能低下

量子化による影響が最も顕著に現れたタスクでした。35億パラメータのW4-gモデルでは、平均で-13.1%もの性能低下が観察されました。

中でも中国語では最大で-17.3%の低下が見られました。

Aya 23モデルのW4量子化でも、8億パラメータモデルで-7.5%の低下が報告されています。

#### （２）その他のタスク

mMMLU（多言語多分野理解力テスト）も量子化の影響を大きく受けました。

またFLORES（翻訳タスク）では、モデルのサイズによって影響の傾向が異なりました。

- 103億パラメータのCommandモデルは、L2→英語の翻訳でより敏感に反応した
- 35億パラメータのCommandモデルと Aya 23モデルでは、逆の傾向が見られた

未見の識別タスク（XWinograd、XCOPA、XStoryCloze）では、量子化の影響はほとんど見られませんでした。

#### （３）予想外の性能向上

いくつかのケースでは、量子化によって性能が向上する現象も観察されました。

Aya 23モデルのW8量子化で、MGSMタスクにおいて1.8%～2.1%の向上が見られました。FLORESタスクでも軽微な改善が報告されています。

また、35億パラメータのCommandモデルでは、W8A8量子化で翻訳タスクの性能が向上しました。

さらに単一言語の言語混同タスクでは、どのモデルにおいても量子化の影響がほとんどないか、わずかな改善が見られました。そして異言語間の言語混同タスクでは、量子化レベルが上がるにつれて性能が向上するケースもありました。

### 言語別の影響

量子化が言語に与える影響については、いくつか重要な発見がありました。

非ラテン文字系言語（アラビア語、日本語、韓国語、中国語）は、ラテン文字系言語よりも量子化による影響を大きく受ける傾向が見られました。

※ラテン文字系言語とはアルファベットを使用して書かれる言語のこと

35億パラメータのCommandモデルでは、W4-g量子化によって全言語で顕著な性能低下が観察されました。また、103億パラメータのモデルにW4量子化を適用した場合、中国語、日本語、韓国語で特に大きな影響が見られました。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_72292_3-1024x278.png)

Commandモデルの言語別相対パフォーマンス（FP16比）、mMMLU、FLORES、Language Confusionタスクの平均

一方で、いくつかの興味深い例外も観察されました。35億パラメータのCommandモデルにW8A8量子化を適用すると、平均して全言語で性能が向上しました。この現象は主に異言語間の言語混同タスクでの改善によるものです。また、Aya 23モデルでは、W8量子化によってMGSMタスクの非ラテン文字系言語の性能が向上し、FLORESタスクでも全言語で改善が見られました。  
量子化の影響が必ずしも一様ではないことを示しています。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_72292_4.png)

Commandモデルの言語別相対パフォーマンス（FP16比）、MGSM、mMMLU、FLORES、Language Confusionタスクの平均

### モデルサイズによる影響

モデルのサイズと量子化レベルの関連性については以下のことがわかりました。

まず、より小さなモデルほど、極端な量子化（W4/W4-g）の影響を受けやすいことが分かりました。例えばCommandモデルのW4-g量子化では、以下のような結果が得られました。

- 103億パラメータモデル：平均-0.9%の性能低下
- 35億パラメータモデル：平均-2.8%の性能低下
- MGSMタスクでは、-2.9%対-13.1%という顕著な差が見られた

そしてAya 23モデルでも同様の傾向が観察されました。

- 35億パラメータモデル：平均-2.9%の性能低下
- 8億パラメータモデル：平均-3.7%の性能低下
- Belebeleタスクでは、-5.9%対-8.5%の差が報告された

言い換えればより大きなモデルの方が量子化に対する耐性が高いことが示唆されています。

### 量子化戦略による影響

SmoothQuantやグループ単位のスケーリングなど、異なる量子化戦略がどのような影響を与えるか分析されました。その結果は以下の通りです。

W8A8-SmoothQuant（SQ）とW8A8の比較では以下のことがわかりました。

- 平均的にSQの方が良好な結果を示した
- mMMLUタスクでもSQの優位性が確認された
- ただし、MGSMタスクではSQがわずかに性能を低下させる結果となった

W4-g（グループ単位）とW4（列単位）の比較結果では、

- グループ単位のスケーリングが大幅に性能を改善した
- MGSMタスクのラテン文字系言語では、6パーセントポイント以上の回復が見られた

ただし非ラテン文字系言語は、ほぼすべてのケースで大きな影響を受けました。

タスク固有の影響として、異言語間の言語混同タスクでは、以下のように量子化戦略によって異なる効果が観察されました。

- SQはW8A8で失われた性能をすべて回復した
- グループ単位のスケーリングは逆に性能を低下させた
- W4はラテン文字系言語とアラビア語で性能を向上させたが、他の言語では低下させた

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_72292_5-1024x200.png)

103Bモデルにおける量子化緩和戦略の効果、ラテン文字系/インド・ヨーロッパ語族言語と他の言語の比較

以上を総合すると、最適な量子化戦略は全体的な性能を向上させる傾向があります。一方で、特定のタスクでは悪影響を及ぼす可能性があることが明らかになりました。

### LLM/RM-as-a-Judge評価の結果

人間による評価の代替手段として、LLMとRM（報酬モデル）を評価者として使用した結果が以下のように報告されました。

内部評価セットでは以下のことがわかりました。

- LLMとRMは、W4およびW4-g量子化が性能を大幅に低下させるという点で一致
- 非ラテン文字系言語でのDollyタスクにおいても、W4-g量子化による深刻な性能低下が観察された
- フランス語では、W8A8-SmoothQuant量子化による顕著な性能低下が報告された

言語間の比較をすると以下のようになりました。

- LLMの評価では、内部評価セットの方がDollyタスクよりも大きな性能低下が報告された
- しかし、RMの評価ではW8とW8A8-SmoothQuantについて逆の結果が得られた

各評価手法間の相違点として、複数のケースでLLMとRMが性能の向上または低下について異なる判断を下しました。またDollyタスクでは結果が明確でない場合が多く見られました。タスクが比較的容易であるため、モデルの出力が類似し、判断にノイズが生じやすくなった可能性が指摘されています。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_72292_6-1024x234.png)

103B量子化モデルのLLM/RM-as-a-Judgeによる評価、内部評価セットとAya Dollyサブサンプルテストセットでの相対パフォーマンス

### 人間による評価

一方で、人間の評価者による結果は以下のようになりました。

自動評価や機械による評価と比較して、より現実的なデータとして捉えることができるかもしれません。

内部評価セット（より難しいプロンプト）では、評価された言語全体で量子化レベルが上がるにつれて性能が着実に低下する傾向が見られました。中でもフランス語では、W4-g量子化で最大16.6%の性能低下が報告されました。日本語では興味深い傾向が観察され、W8量子化で7.4%の性能向上が見られた一方、より極端な量子化（W4-g）では16.0%の性能低下が確認されました。

Dollyタスクでは、日本語において量子化されたモデルの出力が一貫して好まれる傾向が見られましたが、他の言語では概して量子化されたモデルの出力は好まれませんでした。

評価セット間の比較としては、内部評価セットの方がDollyタスクよりも全体的に大きな性能低下が報告されました。内部評価セットで平均5.7%の相対的な性能低下が見られたのに対し、Dollyタスクでは平均2.4%の相対的な性能低下にとどまりました。これはつまりタスクの難易度や言語によって量子化の影響が異なることを示唆しています。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_72292_7.png)

103B量子化モデルの人間評価者による評価、内部評価セットとAya Dollyサブサンプルテストセットでの相対パフォーマンス

## まとめ

本記事では、量子化が多言語LLMに与える影響を調査した研究を紹介しました。

8億から103億パラメータのモデルが20以上の言語で評価され、自動評価や人間評価が行われました。

主な発見として、量子化の悪影響は自動評価よりも人間評価で顕著であり、非ラテン文字系言語がより大きな影響を受けること、難しいタスクほど性能が低下することが明らかになりました。一方で、量子化が性能向上をもたらす場合もあります。

LLMの実用においてはより効率的で軽量なモデルを使用すること、そして英語以外でもパフォーマンスを維持することが重要になります。このような調査は有用な知見として活用できるかもしれません。

- 参照論文URL： [https://arxiv.org/abs/2407.03211](https://arxiv.org/abs/2407.03211)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[人間のような内省メカニズムをLLMに導入することの効果 Google DeepMindなどが検証](https://ai-data-base.com/archives/72194)

[LLMの価値観は一貫しているのか？](https://ai-data-base.com/archives/72401)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)