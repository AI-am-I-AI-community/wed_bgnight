---
title: "コンテキスト内で重要な情報同士が離れすぎるとLLMの性能は大幅に下がる"
source: "https://ai-data-base.com/archives/77563"
author:
  - "[[AIDB Research]]"
published: 2024-10-28
created: 2025-06-13
description: "本記事では、LLMの長文理解における「情報間の距離」の問題について紹介します。最近のLLMは20万単語を超える長い文章も処理できるようになりましたが、それに伴い新たな課題も見えてきました。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、LLMの長文理解における「情報間の距離」の問題について紹介します。

最近のLLMは20万単語を超える長い文章も処理できるようになりましたが、それに伴い新たな課題も見えてきました。例えば、業務でよくある「複数の重要情報を組み合わせて分析する」ようなケースでは、情報同士の距離が離れすぎると上手く処理できないことが新たに判明しています。

この点を解明すべく、研究チームは「LONGPIBENCH」という新しいベンチマークを作成し、調査を行いました。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77563-1024x576.jpg)

**参照論文情報**

- タイトル：Distance between Relevant Information Pieces Causes Bias in Long-Context LLMs
- 著者：Runchu Tian, Yanghao Li, Yuepeng Fu, Siyang Deng, Qinyu Luo, Cheng Qian, Shuo Wang, Xin Cong, Zhong Zhang, Yesai Wu, Yankai Lin, Huadong Wang, Xiaojiang Liu
- 所属：Tsinghua University, ModelBest Inc., Renmin University of China, Apple Inc.

**本記事の関連研究**

- [ロングコンテキストLLMでも、情報の数は「多ければ多いほど良い」わけではない](https://ai-data-base.com/archives/77127)
- [ロングコンテキストはRAGもText to SQLも解決するか　Googleがケーススタディを実施](https://ai-data-base.com/archives/71486)
- [多くの「長いコンテキストを要するタスク」を、短いコンテキストウィンドウのLLMで解決する手法](https://ai-data-base.com/archives/69938)
- [LLMにおける、長いコンテキストから欲しい情報を見つけ出す「needle-in-a-haystack（干し草の中の針）」テスト結果とプロンプト例](https://ai-data-base.com/archives/68016)

## 背景

最近のLLMは、コードの分析や情報抽出など、長い文章を処理する必要がある場面で活用されています。そのような需要もあり、20万単語以上の長い文章も扱えるように改良が進められてきました。

ただし、LLMには「情報の位置」に関する課題があることがわかってきました。例えば、大量の文章の中から重要な情報を見つけ出す課題では、文章の真ん中にある情報を上手く活用できない「真ん中で迷子になる」といった問題が報告されていました。

しかし、実際の業務では、1つではなく複数の重要な情報を組み合わせる必要があります。例えば、データ分析では、複数の重要なデータポイントを組み合わせて考察する必要があります。複数の情報を扱う場合、以下の2つの要素が重要になります。

1. 情報が文章全体の中でどこにあるかの「絶対的な位置」（前半、真ん中、後半など）
2. 重要な情報同士がどれくらい離れているかの「相対的な位置」

これまでの研究では、1つの情報の「絶対的な位置」のみが注目されており、複数の情報を扱う際の「相対的な位置」の影響は、あまり研究されていませんでした。

そこで研究チームは、この「情報の位置」による影響を総合的に評価できる新しいベンチマーク「LONGPIBENCH」を作成し、LLMの性能を詳しく調査することにしました。

その結果、LLMへのプロンプトでは「質問文を文章の最初に置くだけで」理解力が大幅に向上することなど実用上における重要な示唆も得られています。長い文章を扱う場合、この単純な工夫が特に効果的とのこと。

以下で研究内容や実験結果全体を詳しく紹介します。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77563_1.png)

「絶対位置」と「相対位置」の違いを図示。絶対位置は文章全体における位置を、相対位置は複数の重要情報間の距離を表す

## LONGPIBENCHの内容

### データセットの規模

LONGPIBENCHには、3種類の異なる課題が用意されました。文章の長さは4段階あり、一番短いもので3万2千語程度、一番長いもので25万6千語程度です。短い記事から本1冊分くらいまでの長さをカバーしているイメージです。

それぞれの課題には、重要な情報が文章のどこにあるか（前の方なのか、後ろの方なのか）や、重要な情報同士がどれくらい離れているかを変えた様々なパターンが用意されました。全部で7,680個のテストデータがあり、かなり大規模な評価データとなっています。

### データの作成プロセス

- テーブルから特定の情報を探し出す課題
- 出来事を時系列順に並び替える課題
- 方程式を解く課題

この3つの課題が選ばれ、それぞれに対して20個の基本となるデータが人の手で丁寧に作られました。各データには10個の重要な情報が含まれています。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77563_2-1024x282.jpg)

LONGPIBENCHの構築過程とタスク例を示す。手動で アノテーション したシードデータから、情報の位置を変えてデータを拡張する手法を説明

### データの増やし方

基本となるデータから、2つの方法でバリエーションが作られました。

1つ目は、重要な情報を文章のどこに置くかを変える方法です。例えば、文章の最初の方に置いたり、真ん中に置いたり、最後の方に置いたりします。

2つ目は、重要な情報同士の間隔を変える方法です。例えば、全部くっつけて置いたり、均等に散らばるように置いたり、その中間のように置いたりします。

このように様々なパターンを使用することでモデルがどんな配置が苦手なのかを詳しく調べようとしているのです。

### 品質の確保

テストデータの質を高く保つために、いくつかの工夫がされました。

まず、人の手で細かくチェックを行い、間違いがないか確認しています。また、LLMが事前に覚えている知識を使わないように、架空の情報なども含めています。自動で作られた部分についても、人が確認して問題がないか慎重にチェックしています。

## 実験の準備と方法

### 評価に使用したモデル

実験では、11個のLLMを使って評価が行われました。

1. オープンソースモデル（6種類）
- Llama-3.1-Instruct（70B）
- Qwen-2.5シリーズ（7B、14B、32B、72Bの4種類）
- WizardLM-2（8×22B）
1. 商用モデル（5種類）
- GPT-4o-mini
- Claude-3-Haiku
- Gemini-1.5-Flash
- GLM-4-air
- Deepseek-Chat-v2

以上のモデルは、現在よく使われている代表的な長文処理能力の高いモデルから選ばれました。

### 実験の設定

事前の試験段階で興味深い発見がありました。3つの課題のうち、「時系列の並び替え」と「方程式を解く」の2つは、最も性能の良いモデルでも [正解率](https://ai-data-base.com/archives/25930 "正解率") が0%～20%と非常に低いことが分かりました。

そのため、現時点ではこの2つの課題は将来のより高性能なモデルのために取っておき、今回の実験では「テーブルから情報を探す」という課題に焦点を絞ることにしました。

人工知能技術の進歩は速いため、現時点で難しすぎる課題は後回しにして、まずは基本的な課題から着実に理解を深めていくというアプローチが取られた格好です。

また、全てのモデルが共通して扱える長さとして、3万2千語程度の文章長に統一して公平な実験が行われました。

### 評価方法

テーブルから情報を探す課題では、モデルがどれだけ正確に必要な情報を見つけられるかが評価されました。例えば、「中国出身の人を全て探してください」という指示に対して、モデルがどれだけ漏れなく正しく情報を抽出できるかを測定しています。

## 実験結果と考察

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77563_3-1024x357.jpg)

11種のモデルにおける絶対位置と相対位置の影響を示すグラフ。絶対位置レベルは入力の後ろに近いほど高く、相対位置レベルは情報間の距離が大きいほど高い

### 絶対的な位置の影響

まず、文章の中のどこに重要な情報を置くか（最初、真ん中、最後など）による影響が調査されました。

興味深いことに、ほとんどの商用モデルと大規模なオープンソースモデルでは、情報がどの位置にあっても安定して処理できることが確認されました。

ただし、Qwen 2.5（7B）やWizardLM 2といった一部の小規模なオープンソースモデルでは、まだ「真ん中が苦手」という課題が残されていることも判明しました。

これは以前の研究結果と比べると大きな進歩として評価され、現代のモデルにおいて情報の位置による影響が軽減されてきていることが示されています。

### 相対的な位置の影響

次に、複数の重要な情報の間隔をどれくらい空けるかによる影響が検証されました。

実験の結果、全てのモデルにおいて注目すべき傾向が発見されました。情報同士の間隔が広がるにつれて性能の急激な低下が観察され、その後低下の度合いがゆるやかになっていくことが確認されました。特に単純な情報検索においても、間隔が開くことで正解率が20-30%も低下することが明らかにされました。

まとめると、情報同士の距離が離れすぎた場合、モデルの処理能力が著しく低下する可能性が示唆されています。

### さらに詳しい分析

#### パラメータ数の影響

Qwen 2.5シリーズの4つのモデル（サイズの異なるバージョン）が比較され、興味深い結果が得られました。絶対的な位置については、モデルがわずかに大きくされただけで「真ん中が苦手」という問題の改善が見られました。しかしながら、情報同士の間隔による影響については、モデルが大きくされても顕著な改善は観察されませんでした。

この結果から、単にAデルが大きくされるだけでは解決できない問題の存在が示唆されています。

#### 質問の位置による影響

質問文の配置位置による影響も詳しく調査されました。その結果、文章の後ろにだけ質問が置かれた場合、性能の大幅な低下が確認されました。一方で、前に置かれるか、前後両方に置かれた場合には、より良い結果が得られることが明らかにされました。ただし、前だけに置かれる場合と前後両方に置かれる場合の差異については、モデルによって異なる結果が観察されています。

これらの知見から、モデルが長い文章を処理する際には、質問が文章の前に置かれることの重要性が強調されています。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77563_4.png)

GPT-4o-miniとQwen-2.5-14Bにおける、クエリ配置（文頭、文末、両方）の影響を示すグラフ

## まとめ

本記事では、LLMの長文理解における「情報の位置」に関する課題を包括的に調査した研究を紹介しました。

研究チームは「LONGPIBENCH」という新しいベンチマークを開発し、11種類のモデルを対象に詳細な分析を実施しました。

その結果、最新のモデルは以前問題視されていた「文章の真ん中にある情報を見落とす」という課題は概ね克服している一方で、重要な情報同士が離れている場合の処理に課題があることが明らかになりました。

さらに最後の詳細な分析で示唆された「モデルが長い文章を処理する際には、質問が文章の前に置かれることの重要性」は、実用シーンにおいても覚えておくべき知見かと思われます。

- 参照論文URL： [https://arxiv.org/abs/2410.14641v1](https://arxiv.org/abs/2410.14641v1)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[LLMには正解例だけでなく、「よくある間違い例」と理由も一緒に教えるのが有効](https://ai-data-base.com/archives/77507)

[開発企業や言語ごとに異なるLLMのイデオロギー、価値観や態度](https://ai-data-base.com/archives/77645)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)