---
title: "実際の企業データからなるtext-to-SQLベンチマーク「Spider 2.0」と専門エージェント『Spider-Agent』"
source: "https://ai-data-base.com/archives/79831"
author:
  - "[[AIDB Research]]"
published: 2024-12-04
created: 2025-06-13
description: "本記事では、LLMが実際の企業環境でSQL生成タスクにどの程度対応できるのかを検証した最新の研究を紹介します。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、LLMが実際の企業環境でSQL生成タスクにどの程度対応できるのかを検証した最新の研究を紹介します。

従来の研究では単純なデータベースを用いた実験で高い精度を達成していたLLMですが、実務レベルの複雑なデータベースやワークフローに対する性能は未知数でした。

今回研究者らは、Google AnalyticsやSalesforceなどの実際の企業データを用いた新しいベンチマーク「Spider 2.0」を開発し、それを通じてLLMの実用性における現状と課題を明らかにしました。さらに、SQL生成に特化した専門的なエージェントも設計しました。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_79831-1024x576.jpg)

****発表者情報****

- 研究者：Fangyu Lei et al.
- 研究機関：University of Hong Kong, Salesforce Research, Sea AI Lab, Google DeepMind, Google Cloud AI Research, University of Waterloo

## 背景

大規模なデータ処理を必要とする現代において、人間とデータを効果的に橋渡しするコード生成技術が求められています。中でも、データベースに格納された膨大なデータにアクセスするためのインターフェースとしてSQLは欠かせない存在となっています。そこで、自然言語で指示をしてSQLを書く技術（text-to-SQL）は、日常的なクエリ作成を支援する有望な技術として注目されています。

text-to-SQLにおいてもLLMが役立っており、従来のベンチマークであるSpider 1.0で91.2%、BIRDで73.0%という高い実行精度を達成しています。

しかし、既存のベンチマークには現実世界のデータベース環境との大きな乖離があります。

1. テーブルやカラムが少ない非実用的なデータベースを使用している
2. 各データベースシステム固有のSQL方言や機能への対応が不足している
3. 数千のカラムを持つ大規模なスキーマや複雑なネスト構造を持つ実際のデータベースの特徴を反映していない
4. プロジェクトのコードベース活用、外部知識参照、複数ステップにわたるSQLクエリ構築など、実際のワークフローの複雑さを考慮していない

このような実際の企業環境とベンチマークとの乖離から、今回Googleなどの研究者らは、より現実的な企業レベルのベンチマークを開発することにしました。そして生まれたのがSpider 2.0です。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_79831_f1-1024x378.png)

Spider 2.0によるLLMの評価フレームワークの概要図

また研究者らは、実際のエンタープライズ環境でのデータベース関連タスクに特化したSpider-Agentというエージェントフレームワークを設計しました。

## ベンチマーク構築

まずはタスクの定義、構築時の注釈付けパイプライン、Spider 2.0とSpider 2.0-liteのデータセット統計について説明します。

### タスク定義

今回のデータセットでは、2種類のタスクが設定されています。

1つ目は、「コードエージェントタスク」です。以下の要素を使って反復的にコード（SQLやPython）を修正しながら、最終的な結果（テキスト、テーブル、またはデータベース形式）を導き出すタスクです。

- 質問文
- データベースを操作するためのインターフェース
- プロジェクトのコンテキスト、設定、ドキュメントを含むコードベース

上記は（Spider 2.0-liteではなく）Spider 2.0で評価できるタスクであり、テストの際にはエージェントにこれらすべての要素が与えられます。

2つ目は、「テキストからSQLへの変換タスク」です。これはSpider 2.0-snowとSpider 2.0-liteという簡略版のデータセットで評価できます。以下の要素だけが与えられ、これらの入力から適切なSQLクエリを直接生成することが求められます。

- データベースのスキーマ情報
- 自然言語での質問文
- 補助的なドキュメント

なお、Spider 2.0-liteは様々なデータベース上で実行される設定なのに対し、Spider 2.0-snowはSnowflakeというデータベース上でのみ実行される設定となっています。

まとめると、Spider 2.0は実際の業務に近い複雑なデータワークフローを扱うための完全版と、純粋にテキストからSQLへの変換に焦点を当てた簡略版の2つの形式が用意されています。

下の図は、従来型のtext-to-SQL出力とエージェント型の比較を示しています。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_79831_f2.png)

### データセット構築における注釈付けのパイプライン

SQLに精通したコンピュータサイエンス専攻の8名の作成者によって、データの注釈付けが6つのステップで行われました。

（１）まず、データベースとSQLの収集が行われました。クラウドデータウェアハウスから200列以上またはネストされたスキーマを持つデータベースが選ばれ、最終的に547個の高品質なSQLクエリと78個のDBTプロジェクトが選定されました。

（２）次に、データ漏洩を防ぐためにSQLの書き換えが実施されました。表面レベルで84.2%、 [セマンティック](https://ai-data-base.com/archives/26143 "セマンティック") レベルで42%のSQLが書き換えられました。その後、すべてのSQLが正常に実行され、妥当な時間内に完了し、空でない結果を返すことが確認されました。

（３）その後、コードベースとコンテキストの設定が行われました。SQLクエリに必要な外部参照ドキュメントが収集され、Spider 2.0ではプロジェクトのオリジナルコードベースやデータベースインターフェースも保持されました。

（４）さらに、自然言語タスク指示の注釈付けが行われました。SQLとそのコンテキストに基づいて質問が作成され、Spider 2.0とSpider 2.0-lite/snowの異なるバージョンが作成されました。

（５）次に、実行ベースの焦点評価が実施されました。データベースからプログラム的に結果が取得され、評価スクリプトが作成されました。また、結果をテーブルベースで評価する際には、重要な列に焦点を当てて評価が行われました。

（６）最後に、品質管理が行われました。各指示、ゴールドSQL、評価スクリプトが少なくとも3名の注釈付け者によってレビューされました。さらに、エラーがすべて修正されるまで、コードベースとコンテキストの設定、自然言語タスク指示の注釈付け、実行ベースの焦点評価の各ステップが繰り返し実施されました。

### データセットの統計

Spider 2.0、Spider 2.0-snowおよびSpider 2.0-liteが複数の先行データセットと比較されました。今回のデータセットは高い複雑性と現実性があるとのことです。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_79831_t2-1024x300.png)

下の図と表に示すように、多様なデータベースシステムを特徴としています。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_79831_f3.png)

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_79831_t3.png)

内訳は以下の通りです。

- BigQueryやSnowflakeなどのクラウドデータウェアハウス
- PostgresやClickHouseなどのローカルにホストされたデータベース
- SQLiteやDuckDBなどの軽量システム

従来の研究とは一線を画すほどの多様性がこだわりのポイントです。注目すべきは、サンプルの85.98%が各システムに特化した関数の使用を必要とし、平均で1つのSQLあたり7.1個の特殊関数が使用されていることです。

また、Spider 2.0のデータベースは大規模かつ以下のように複雑なスキーマを備えており、実際の企業環境を反映しています。

- 複数スキーマとネストされたスキーマ
- パーティション化されたテーブル
- 日次で更新される動的テーブル

さらにベンチマークのサンプルは、実際のチュートリアルやフォーラムから収集され、以下を含むデータパイプラインで遭遇する広範な課題をカバーしています。

- データのラングリング
- データの変換
- データ分析

また、タスクをこなす上では以下のようなドキュメントへのアクセスを必要とします。

- 外部知識
- データベースごとのSQL構文に関するドキュメント

Spider 2.0の各タスクでは、実際のワークフローを模擬するためのコードベースコンテキストが提供されます。注目すべきは、DBT（データ変換とアナリティクスエンジニアリングを管理するために広く使用されているツール）を使用したプロジェクトレベルのデータ変換ワークフローのようなタスクまで含まれていることです。

タスクを成功させるには、複雑なプロジェクトのコードベースとデータベースをナビゲートし、ドキュメントを理解し、複雑なコンテキストを処理し、マルチステップの実行と推論を通じて多様なクエリを生成する必要があります。

以上のように、今回作成されたSpide [r2](https://ai-data-base.com/archives/26434 "決定決定係数（R2）").0ベンチマークシリーズは非常に複雑です。現在のLLMやエージェントワークフローでは成功が難しいかもしれませんが、このような水準をクリアできることが現実で求められている品質なのです。

## 実験

**評価指標**

Spider 2.0での評価では、タスクを成功裏に完了できた割合を示すSuccess Rate（SR）が使用されました。

そしてSpider 2.0-liteとSpider 2.0-snowでは、広く使われているExecution Accuracy（EX）が使用されました。生成されたSQLの実行結果の正確性を測定するものです。

**評価の観点**

Spider 2.0では結果の成功、Spider 2.0-liteではSQLの実行結果の正確性とされました。評価スクリプトは文字列、テーブル、またはデータベース形式での出力を受け入れ、各例について0または1のスコアを出力します。

**難易度レベル**

空白で区切ったSQLクエリのトークン数に基づいて難易度が分類されています。

- Easy：80トークン未満
- Medium：80-159トークン
- Hard：160トークン以上

**実験に使用されたLLM**

下記のモデルが試されました。

- オープンソースのDeepseekCoder-V2.5、Qwen2.5-72B-Instruct、Llama-3.1-405B
- Gemini-Pro-1.5、Claude3.5-Sonnet、GPTファミリー（GPT-4o、GPT-4、o1-preview）

全てのモデルでtemperature=0を設定し、入力が最大トークン数を超える場合は先頭から切り詰めています。

**Spider 2.0-lite/snowで使用されたtext-to-SQLの変換手法**

以下の最新手法が評価されました。

- DIN-SQL
- DAIL-SQL
- CHESS
- SFT CodeS

**Spider 2.0で使用されたコードエージェントフレームワーク**

他のベンチマークで優れた性能を示している以下のものが使用されました。

- Reflexion
- CodeR
- AutoEval
- Spider-Agent（今回新たに開発）

### Spider-Agent

Spider-Agentは今回データベース操作タスクに特化して設計されたエージェントフレームワークです。ReactやIntercodeにインスパイアされて作られました。

最終的な回答が得られるまでコマンドラインインターフェースを通じてデータベースと複数回やり取りすることが特徴です。エージェントがデータベースとの対話にのみ集中できるよう、以下のように専用のアクションセットが設計されました。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_79831_t19-1024x274.png)

また、temperature 1.0とtop-p 0.9が使用され、モデルが必要とする最大トークン制限を超える場合は入力の先頭から切り詰めを行います。

エージェントは同じ結果を3回連続で出力した場合、あるいは任意のアクションが120秒以上かかった場合に自動的に終了します。

ほとんどのタスクに十分な数として、発見的にエージェントが最大30ステップでタスクを完了するよう要求しています。

今回実験で使用されたプロンプトは以下の通りです。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_79831_c6.png)

### 評価結果

結論から言うと、実際の業務レベルのテキストからSQLへのワークフローにおいて、現在のLLMにはまだ大きな改善の余地があることが分かりました。

最高性能を示したo1-previewモデルでも成功率は17.01%に留まり、Easy、Medium、Hard全ての難易度でGPT-4oやClaude-3.5-Sonnetを上回りました。

オープンソースのQwen-2.5-72Bは6.17%の性能を示し、他のオープンソースモデルよりも優れていましたが、まだ大きな改善の余地があります。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_79831_t4-1-1024x440.png)

異なるフレームワークとモデルのSpider 2.0での成功率

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_79831_f4.png)

（複数の予測を許容した場合の）結果を示すグラフ。予測数を増やすことで性能が向上することを示している

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_79831_t5-1024x285.png)

3つのtext-to-SQLデータセットでのベースライン手法の実行精度

### 異なるタスクタイプの分析

データベース関連のコーディングタスクにおいて、現存のコードエージェントフレームワークは課題を抱えています。強力なGPT-4oを使用しても、CodeRの成功率は7.91%に留まりました。

この低い性能の理由として、以下3つが考えられています。

1. データ変換プロジェクトでは、複数のSQLクエリを使って様々なモデルを完成させる必要がある
2. 複雑なコンテキストを使用し、モデルからの強力なリポジトリ探索能力が求められる
3. データはデータベースに保存されており、既存データを探索しながらデータを変換する必要がある

これらの課題に特化して開発したSpider-Agentが現在最高の性能を示しているため、今後の研究のベースラインになるでしょう。

## 分析

今回、LLMはプロジェクトベースのタスク、中でもDBTプロジェクト（データエンジニアリングやデータ分析のプロセスを効率化するためのプロジェクト）での性能が著しく低く、成功率はわずか12.82%にとどまりました。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_79831_t6-1024x291.png)

DBTプロジェクトにおける性能。プロジェクトあり/なしの場合の成功率を比較

その主な要因としては以下が考えられています。

- 1つのプロジェクトでは複数のSQLクエリを組み合わせて実行する必要があり、プロジェクト全体を俯瞰的に理解することが求められる
- データベースに格納されている既存データを探索しながら、新たなデータ変換とSQLコーディングを同時に行う必要がある
- 外部ドキュメントを参照する必要があるタスクでは成功率が10.98%まで低下し、LLMは文書自体は理解できても具体的なSQLへの変換で失敗する

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_79831_t7-1024x279.png)

外部ドキュメントを必要とするタスクでのモデル性能

- ネストされたデータ構造（配列やdict形式でデータが格納されている場合）の理解が特に困難である

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_79831_t8-1024x272.png)

ネストされた列を含むデータベースでのモデル性能

- データベースシステムごとに異なるSQL構文に対応する必要があり、同じタスクでもBigQueryでは12.78%、Snowflakeでは6.6%と性能に大きな差が出る

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_79831_t9.png)

異なるデータベースタイプごとのモデル性能

LLMが実務で使えるレベルになるためには、単純なSQL生成だけでなく、プロジェクト全体の理解や複雑なデータ構造への対応など、複数の課題を克服する必要があることを示唆する結果です。

### SQL生成に関するエラー分析

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_79831_f5.png)

エラーの統計データを示す円グラフ

300のサンプルケースを分析した結果、以下の主な知見が得られました。

まず、性能向上に効果的だった手法は以下の通りです。

- リファレンスプラン（SQLの書き方の段階的説明）の導入により、DAIL-SQLの精度が約3%向上
- 最新のo1-previewモデルと組み合わせることで、12.60%まで性能が改善
- データベースシステムごとの構文や関数のドキュメントを提供することで、わずかながら性能が向上

逆にFew-shotプロンプティング（類似例の提示）はほとんど効果がありませんでした。その理由として、事前学習データと実例の複雑さの差が大きすぎることや、大規模なスキーマ情報が学習を妨げている可能性が指摘されています。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_79831_t11.png)

以上から、段階的なアプローチや適切なドキュメント提供が性能向上に有効である一方、単純な例示による学習促進には限界があることが分かりました。

複雑なSQLの生成には、直接的な生成ではなく、Common Table Expression（SQLで使用される一時的な名前付き結果セット）を活用した段階的なアプローチが有効である可能性があります。

### 異なる実験設定の分析

データベースシステムごとの構文や関数のドキュメント（オラクル関数）が提供された手法では、性能はわずかに向上するにとどまりました。モデルが基本的な関数の選択と使用法を理解できているものの、ユーザーの意図に沿った適切な活用にはまだ課題があることが示されています。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_79831_t10.png)

オラクル設定（理想的な条件）でのSpider 2.0-liteにおけるベースライン手法の性能

## まとめ

新しいベンチマーク「Spider 2.0」を用いた検証の結果、最先端のo1-previewモデルでも成功率は17.01%にとどまり、従来のベンチマークでの高い性能（Spider 1.0での91.2%、BIRDでの73.0%）とは大きな開きがありました。

つまり、実世界のデータベース業務を想定したSQLタスクでは、現状のLLMやフレームワークにはまだ大きな改善の余地があることが示されました。中でも、データベースの構造理解、複雑なコンテキストの活用、段階的なアプローチの実行などが今後の重要な課題となっています。

今回の結果はLLMが実世界のデータエンジニアリングワークフローで実用的なツールとなるために必要な方向性を示しています。継続的に参考となるベンチマークになるでしょう。

**参照文献情報**

- タイトル：Spider 2.0: Evaluating Language Models on Real-World Enterprise Text-to-SQL Workflows
- URL： [https://arxiv.org/abs/2411.07763](https://arxiv.org/abs/2411.07763)
- 著者：Jixuan Chen, Yuxiao Ye, Ruisheng Cao, Dongchan Shin, Hongjin Su, Zhaoqing Suo, Hongcheng Gao, Wenjing Hu, Pengcheng Yin, Victor Zhong, Caiming Xiong, Ruoxi Sun, Qian Liu, Sida Wang, Tao Yu
- 所属：University of Hong Kong, Salesforce Research, Sea AI Lab, Google DeepMind, Google Cloud AI Research, University of Waterloo
- その他のURL： [https://spider2-sql.github.io/](https://spider2-sql.github.io/)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[時系列データをグラフにしてLLMに見せると文字だけより最大120%性能向上　トークンも節約](https://ai-data-base.com/archives/79686)

[テキストだけでなく画像・動画生成もこなすAmazon Novaモデルファミリー　高性能で高速](https://ai-data-base.com/archives/80001)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)