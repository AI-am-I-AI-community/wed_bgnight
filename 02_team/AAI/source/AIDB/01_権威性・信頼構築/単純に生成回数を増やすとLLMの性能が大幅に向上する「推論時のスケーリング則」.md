---
title: "単純に生成回数を増やすとLLMの性能が大幅に向上する「推論時のスケーリング則」"
source: "https://ai-data-base.com/archives/75838"
author:
  - "[[AIDB Research]]"
published: 2024-09-19
created: 2025-06-13
description: "この記事では、LLMの性能を向上させる新しい方法を提案している研究を紹介します。従来のモデルサイズの拡大やデータの増加とは異なり、今回研究者らは「推論時の計算量を増やす」ことで性能を高める方法を探っています。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

この記事では、LLMの性能を向上させる新しい方法を提案している研究を紹介します。

従来のモデルサイズの拡大やデータの増加とは異なり、今回研究者らは「推論時の計算量を増やす」ことで性能を高める方法を探っています。「反復 [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") 」という手法を使い、複数回の推論を行って最適な解答を選び出すアプローチを取っています。

研究チームはさまざまなタスクでこの方法の有効性を確認し、サンプル数を増やすことでカバレッジが向上することを実証しました。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75838-1024x576.jpg)

**参照論文情報**

- タイトル：Large Language Monkeys: Scaling Inference Compute with Repeated Sampling
- 著者：Bradley Brown, Jordan Juravsky, Ryan Ehrlich, Ronald Clark, Quoc V. Le, Christopher Ré, Azalia Mirhoseini
- 所属：Stanford University, University of Oxford, Google DeepMind

## 背景

LLMの能力向上は、これまで主に学習時の計算リソースを増やすことで達成されてきました。モデルのサイズを大きくしたり、より大規模なデータセットで事前学習を行ったり、人間の嗜好を反映したラベルを用いて後学習を実施するなど、学習段階への投資が大きな成果を生んでいました。

しかし、推論時の計算リソースの活用については、これまであまり積極的な投資が行われていませんでした。多くの場合、ユーザーや開発者は1回のみの試行で問題解決を試みており、推論時の計算能力が十分に活用されていなかった可能性があります。

この状況に注目し、今回スタンフォード大学、オックスフォード大学、Google DeepMindの研究者たちは推論時の計算リソースを拡大する方法として「反復 [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") 」の可能性を探ることにしました。「反復 [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") 」は、深層学習の他の分野ですでに成功を収めている考え方です。たとえば、ゲームの分野では、推論時に多くの未来の状態を探索して最適な手を決定する手法が使われています。また、LLMと組み合わせたツリーベースの方法も、モデルの計画立案やさまざまなアプローチの探索能力を高めるのに効果的であることが示されています。

さらに、コーディングや数学的推論、パズル解決などの分野でも、反復 [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") が効果的であることが先行研究で示されています。特にコーディングのタスクでは、最大で100万回の [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") まで性能が向上し続けることが報告されています。

こうした背景から、研究チームは反復 [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") をさまざまなタスクやモデルに適用し、その効果を体系的に調べる必要性を感じました。中でもカバレッジ（任意のサンプルで問題を解決できる割合）とサンプル数の関係、異なるモデルやタスクでのスケーリングの一貫性、そして自動検証が難しいタスクでの課題など、広範な理解が重要だと考えました。

また、推論時のスケーリング法則が存在する可能性を探ることも目的の一つとなっています。学習のスケーリング法則が投資にヒントを与えたように、推論時のスケーリング法則が発見されれば次の戦略が考えやすくなります。

なお、本研究の発表からほどなくしてOpenAIがo1モデルの発表を行いました。o1モデルがとっている戦略は「より長く考える」というもので、本件で検証されたアプローチとは異なります。しかし、推論時の計算量をスケールさせるという点では関連しています。o1モデルはさまざまなベンチマークでの性能向上が示されており、モデルの性能を向上させる一つの方向性を示唆しています。

以下では、本研究の実験内容と結果を中心に詳しく紹介します。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75838_1-1024x232.png)

反復 サンプリング の手順を示す図。LLMから多数の候補解を生成し、検証器で最終的な回答を選択するプロセス

## 繰り返しサンプリングのスケーリングについての検証

### 実験方法

この研究では、答えが正解か不正解かを明確に判断できる「合格/不合格タスク」が注目されています。こうしたタスクでは、モデルの性能を「成功率」、つまり正しく解けた問題の割合で評価します。

繰り返し [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") を行うと、成功率は次の2つの要因によって変わります。

（１）カバレッジ  
生成したサンプルの中で、少なくとも1つが正解となる問題の割合

（２）精度  
複数のサンプルから正しい答えを特定する能力

#### 評価対象のタスク

研究では、次の5つのタスクを評価しています。

（１）GSM8K  
小学生レベルの数学の文章問題

（２）MATH  
GSM8Kよりも難しい数学の文章問題

（３）MiniF2F-MATH  
MATHデータセットから形式化された数学問題（Lean4を使用）

（４）CodeContests  
プログラミングコンテストの問題

（５）SWE-bench Lite  
実際のGitHubの問題を解くタスク

タスクによっては、正解を自動で確認できるツールがある場合があります。例えば、Leanを使った形式的な証明では、証明チェッカーが自動で正解を確認できます。またコーディングタスクでは、ユニットテストを使って解答の正しさを検証できます。

今回は、評価されたタスクのうち、MiniF2F-MATH、CodeContests、SWE-bench Liteでは自動検証ツールが利用できます。自動検証ツールがある場合、カバレッジを高めることで成功率も直接向上します。

一方、GSM8KやMATHのような数学の文章問題では、自動検証ツールが限られています。そのため、多くの生成サンプルから正解を見つけ出す追加の検証方法が必要になります。

#### カバレッジの調査

研究者たちはまず、繰り返し [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") がモデルのカバレッジをどのように改善するかを調査しました。自動検証ツールがある場合、カバレッジを高めることで成功率も直接向上します。また、一般的にカバレッジは成功率の上限を示します。  
コーディングタスクでは、カバレッジは一般に使用される「pass@k」という指標と同じで、kはサンプルの数を表します。pass@kスコアの計算方法としては、各問題について、まずN個のサンプルを生成し、正解のサンプル数をC\_iとします。その後、興味のある各kについて、次の式で計算します。

pass@k = (1 / 問題数) × Σ(1 – ((N – C\_i) choose k) / (N choose k))

### 実験結果

#### 繰り返しサンプリングは複数のタスクで効果的

さまざまなタスクとサンプル予算にわたって、繰り返し [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") がカバレッジを改善することが実証されました。

実験では、CodeContests、MiniF2F、GSM8K、MATHといったタスクに対して、Llama-3-8B-InstructとLlama-3-70B-Instructというモデルを評価しました。

まず、各問題に対して1万個の独立したサンプルを生成しました。また、SWE-bench Liteでは、DeepSeek-Coder-V2-InstructをMoatless Toolsフレームワークと組み合わせて使用し、各問題を250回試行しました。

結果は下の図に示されています。

すべてのタスクでサンプル予算を増やすとカバレッジがなめらかに向上していることが分かります。興味深いことに、1回の試行ではGPT-4oがLlamaやDeepSeekモデルよりも優れていますが、サンプル数を増やすと、これらの比較的弱いモデルがGPT-4oの単一試行の性能を超えました。中でも、SWE-bench Liteでは、56%の問題を解決し、単一試行での最高記録である43%を上回りました。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75838_2-1-1024x412.png)

#### 繰り返しサンプリングはモデルサイズとファミリーに関わらず効果的

研究者らは、より広いモデルセットに対しても繰り返し [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") の効果を検証しました。

評価したのは、Llama 3ファミリー（Llama-3-8B、Llama-3-8B-Instruct、Llama-3-70B-Instruct）、Gemmaファミリー（Gemma-2B、Gemma-7B）、そしてPythiaファミリー（Pythia-70MからPythia-12Bまでの8つのモデル）です。

結果（下の図）を見ると、ほぼすべてのモデルでカバレッジが向上しており、特に小さなモデルほど改善が顕著です。例えば、CodeContestsタスクでのGemma-2Bのカバレッジは、pass@1では0.02%でしたが、pass@10kでは7.1%となり、300倍以上の向上を示しています。

しかし、例外としてPythiaファミリーはCodeContestsでカバレッジが0でした。研究者たちは、これはコーディングに特化したデータでの訓練が少なかったためではないかと考えています。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75838_3-1024x457.png)

#### 繰り返しサンプリングは性能とコストのバランスに役立つ

さらに、繰り返し [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") によって、弱いモデルの能力を高め、より強力で高価なモデルの1回のサンプルを上回る可能性があることが示されました。

研究者たちは、FLOPs（コンピュータの性能指標の一つで、1秒間に何問解けるか）をコストの指標として使い、Llama-3の結果を再度プロットしました。下の図は、サンプル予算の代わりに、総推論FLOPsに対するカバレッジを示しています。この分析から、タスクや計算予算、必要なカバレッジに応じて、最適なモデルサイズが異なることが示されました。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75838_4-1024x324.png)

さらに、SWE-bench Liteの問題解決における現在のAPI価格も比較されました。DeepSeek-Coder-V2-Instruct、GPT-4o、Claude 3.5 Sonnetを対象とし、結果が表にまとめられています。興味深いことに、DeepSeekモデルを5回 [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") することで、GPTやClaudeの単一試行と同じくらいの問題解決率を達成しつつ、コストを3分の1以下に抑えられることが分かりました。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75838_5-1024x215.png)

## 繰り返しサンプリングの利点を理解する

本研究の研究背景として、まず、言語モデルの損失（性能の指標）と訓練に使用する計算量の関係は「訓練スケーリング則」としてよく知られています。この法則は経験的に成り立つことが確認され、大規模な訓練への投資が報われるという確信に繋がりました。

そして今回、この訓練スケーリング則に刺激を受けて、推論時の計算量（サンプル数）とカバレッジの関係を詳しく特徴付ける試みが研究者たちによって行われました。分析の結果、以下の2つの重要な発見が得られました。

1. カバレッジとサンプル数の関係は、多くの場合、指数関数で表されたべき乗則でモデル化できる。
2. 同じモデルファミリー内の異なるモデルのカバレッジ曲線は、似た傾きのS字カーブとなり、水平方向にオフセットがある。

以下で詳しくみていきます。

### 繰り返しサンプリングのスケーリング法則

カバレッジcとサンプル数kの関係を明確にモデル化する試みが研究者たちによって行われました。GPT-4の技術報告書を参考に、次のようなべき乗則の関数が採用されました。

log(c) ≈ ak^(-b)

ここで、aとbはモデルに適合するパラメータです。カバレッジを直接予測するため、両辺を指数化して最終的なモデルは以下のようになります。

c ≈ exp(ak^(-b))

この指数化されたべき乗則モデルが、さまざまなタスクとモデルのカバレッジ曲線に当てはめられました。

結果は下の図に示されています。訓練スケーリング則ほど厳密ではありませんが（MiniF2F-MATHで顕著です）、推論におけるスケーリングの利点を特徴付けられる可能性を示す初期的なエビデンスと言えそうです。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75838_6-1024x537.png)

### モデル間のカバレッジ曲線の類似性

興味深いことに、同じモデルファミリー内の異なるモデルのカバレッジ曲線（x軸を対数スケールで表示）を比較すると、S字カーブが同じ傾きを持ち、水平方向に独自のオフセットがあることが観察されました。

この現象をさらに調べるため、同じファミリーの異なるモデルのカバレッジ曲線が重ね合わせられました。基準となるカバレッジ値cを選び、各曲線が左方向（対数空間で）にシフトされ、すべての曲線が点(1,c)を通るようにしました。

結果は下の図に示されています。同じファミリーのモデル間で、カバレッジをcからc’に改善するために必要なlog-サンプル予算の増加（またはサンプル予算の乗数的増加）がほぼ一定であることを示しています。  
つまりモデルファミリー内でのスケーリングの一貫性が示唆されています。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75838_7-1024x297.png)

## 繰り返しサンプリングの活用には精度が必要

更なる分析から、繰り返し [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") を効果的に使うためには、生成されたサンプルから正しい回答を見つけ出す能力（精度）が重要であることが強調されています。詳しくみていきます。

### 一般的な検証方法はサンプル予算に必ずしも比例しない

これまでの分析では、モデルのカバレッジ（最良のケースシナリオ）に焦点が当てられていました。そこで次に、生成されたサンプルから正しいものを識別する問題（精度）に注目しています。

GSM8KとMATHデータセットには、解答を自動で検証するツールがありません。そのため、研究者たちは最終的な回答を決定するための2つの一般的なアプローチを評価しました。

（１）多数決投票  
サンプル間で最も多い最終回答を選ぶ

（２）報酬モデルによるスコアリング  
各サンプルに報酬モデルでスコアを割り当てる

両手法を、Llama-3-8B-InstructとLlama-3-70B-Instructで生成した10,000サンプルに適用し、以下の3つの方法をベンチマークしました。

1. 多数決投票
2. 報酬モデル+Best-of-N（最高スコアのサンプルの回答を選ぶ）
3. 報酬モデル+多数決投票（各サンプルを報酬モデルのスコアで重み付けして多数決を行う）

なお、報酬モデルには、RewardBenchリーダーボードで最高の推論スコアを持つArmoRM-Llama3-8B-v0.1が使用されました。

### 結果と分析

結果は下の図に示されています。3つの方法すべてで、初めはサンプル数の増加とともに成功率が向上しましたが、約100サンプルあたりで頭打ちになりました。一方、カバレッジはサンプル数とともに増加し、95%を超えました。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75838_8-1024x339.png)

多数決投票の場合、この頭打ちは容易に説明できます。サンプル数が増えるにつれて、各回答への投票の割合が安定し、成功率が一定になるためです。GSM8KとMATHの一部の問題では、正解が1%以下の確率で [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") されることがあります（下の図を参照）。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75838_10-1024x299.png)

### 手動評価による検証

報酬モデルの性能が低いことを受けて、研究者たちは候補解の検証がどの程度「難しい」かを調べました。GSM8KとMATHでは、中間の思考過程を除いた最終回答のみが正解判定に使用されているのです。

この疑問に答えるため、GSM8Kの問題に対するLlama-3-8B-Instructの105の正解の思考過程が手動で評価されました。結果、評価された思考過程の90%以上が正しいことがわかりました。正しいサンプルを識別する際に利用できる手がかりがあることを示しています。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75838_9-1024x160.png)

### ソフトウェアタスクにおける検証器の注意点2つ

ソフトウェア開発タスクは、コードを実行してテストできる一方で、単体テストはコードの一部を検証するブラックボックスアプローチであり、証明チェッカーほど完全なものではありません。

例えば、SWE-bench Liteでは、11.3%の問題で、同じ候補解に対して一貫しない結果を出すテストスイートがありました。さらにCodeContestsの一部の問題では、正しい解答でもテストに失敗する可能性があります。これは、複数の正しい出力がある場合や、テストケースが問題の入力仕様に違反している場合に起こります。

繰り返し [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") を適用する際には上記のような状況は考慮すべきです。対策としては、サンプルを識別する方法の改善です。まさに「藁山の中から針を見つける」ような、稀な正解サンプルを見つけ出す方法の開発が重要です。

## 結論と今後の課題、および注意点

### 主な知見

本実験では、さまざまなモデルとタスクにおいて、繰り返し [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") によってカバレッジ（正解を含むサンプルの割合）が大幅に改善できることが示されました。

自動検証ツールなどで正解を識別できる場合、繰り返し [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") により推論時のモデルの能力を高めることが可能です。その結果、弱いモデルでも多数のサンプルを用いることで、強力で高価なモデルの少数の試行を上回る性能とコスト効率を達成できる可能性があります。

### 繰り返しサンプリングの改善方法

研究では、独立して生成された繰り返し [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") が用いられましたが、この手法は以下の点で改善が可能と述べられています。

1. 正の温度 [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") 以外の方法を組み合わせ、多様性を高める。
2. 実行フィードバックを提供し、解の質を向上させる。
3. 既存のサンプルを利用して、将来の試行に活用する。

### チャットボットには適していない

繰り返し [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") は、チャットボットに適した処理とは異なる点に注意しましょう。

チャットボットでは低レイテンシーが重視されますが、繰り返し [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") は全体のスループットとハードウェアの効率化に重点が置かれた手法です。

つまり、繰り返し [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") は、即時性よりも効率と量を重視する場合に適しているのです。

### 自動検証ツールがない場合の検証器について

もし自動検証ツールがない場合は、サンプルの検証方法を改善することが重要です。たとえばモデルに自身の出力を評価する能力を持たせることで、繰り返し [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") をより多くのタスクに適用できるようになります。

中でも、創造的な文章作成などの非構造化タスクでは、サンプル間の主観的な比較が必要となる可能性があります。

また、非形式的な数学的主張をLeanのような言語に形式化し、証明チェッカーを適用するなど、非構造化タスクを検証可能な形式に変換するアプローチも有効だと考えられます。

### この研究の不完全な点

この研究には、他にもいくつかの改善の余地があります。まず、今回調べた問題の種類が限られていることが挙げられます。答えがはっきりしている問題だけを対象としたため、小説を書くような創造的な課題では、この方法がどれくらい役立つかはまだ分かっていません。

また、実験で使用したモデルの種類が少ないことも不完全な点の一つです。今回は限られた種類のモデルしか使っていないため、異なる種類のモデルでは結果が変わる可能性があります。

さらに、この方法を実行するには多くのマシンパワーが必要です。モデルに何度も同じ質問をするため、十分なコンピューター資源がない環境では使いにくいかもしれません。

最後に、繰り返しになりますが自動で正解を判断できない問題では、多く回答の中から正しいものを選び出すのが難しいという課題があります。

これらの点をもとに研究を改善するとさらに知見が得られるというチャンスでもあります。

## まとめ

本記事では、言語モデルの推論時の計算量を増やすことで性能を向上させる研究を紹介しました。

複数回の [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") により、様々なタスクでモデルの能力を増幅できることが示されました。また、自動検証可能なタスクでは小規模モデルでも大規模モデルを上回る性能を達成できました。

ただし検証困難なタスクでは課題も残されています。

本研究結果の活用が、今後注目されます。

- 参照論文URL： [https://arxiv.org/abs/2407.21787](https://arxiv.org/abs/2407.21787)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[リアルなWindowsOS環境でのエージェント能力を評価する『WindowsAgentArena』およびエージェント『Navi（ナビ）』Microsoftが開発](https://ai-data-base.com/archives/75765)

[GPT-4oに”嘘をつく理由”を与えると正直さが約32.5%減少　LLMは役割に応じて”正直さ”が変化する](https://ai-data-base.com/archives/75881)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)