---
title: "現実における人間の多様性に対応したLLMペルソナ設計手法の検証"
source: "https://ai-data-base.com/archives/88247"
author:
  - "[[AIDB Research]]"
published: 2025-04-17
created: 2025-06-13
description: "本記事では、現実の人間の多様性をLLMの出力に反映させることを試みた研究を紹介します。単一のペルソナを与える従来の方法では再現が難しかった集団のばらつきに対し、視点と応答例を組み合わせる構成が提案されています。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、現実の人間の多様性をLLMの出力に反映させることを試みた研究を紹介します。  
単一のペルソナを与える従来の方法では再現が難しかった集団のばらつきに対し、視点と応答例を組み合わせる構成が提案されています。  
その設計思想と実験結果には、プロンプト設計に応用できる示唆が含まれており、実務にも展開可能な要素があります。  
研究そのものの詳細だけでなく、実際に使ってみる際の考え方についても整理します。

![](https://ai-data-base.com/wp-content/uploads/2025/04/AIDB_88247-1024x576.png)

## 背景

LLMは、マーケティングや製品開発、顧客体験の設計など、さまざまなビジネス領域で活用が進んでいます。ユーザーの反応を事前に検討したり、多様な顧客層の視点を取り入れたりする場面で、テキスト生成の能力が応用されています。

たとえば、新しい商品やサービスに対する反応をシミュレーションしたり、異なる属性の顧客の声を踏まえてレビューを分析したりする活用方法があります。また、従来の調査を補う形でマーケットリサーチに活用されたり、個別の利用者に合わせたメッセージを生成したりする場面もあります。

一方で、LLMの出力には偏りが見られることがあり、実際の顧客の多様性を十分に表現することが難しい場合があります。年齢や性別、価値観、購買傾向など、人の特性は多岐にわたりますが、学習済みのLLMはそれらを均等に捉えることができないことがあります。

また、LLMにペルソナ（想定される顧客像）を設定した場合でも、その応答に一貫性や多様性が見られず、別の属性の影響を受けたような出力になることが報告されています。

こうした課題を受けて、今回イエール大学などの研究者らは新しい手法を提案しています。

以下で詳しく紹介します。

## 問題の整理と思考の出発点

LLMの出力が、現実の顧客層の多様性を十分に表現できない…この課題に向き合うには、まず「多様な人々の反応とは何か？」を捉え直す必要があります。実務の現場でも、ユーザーの属性や価値観によって意見や行動が大きく異なることはよくあります。にもかかわらず、LLMにペルソナを与えても、どこか画一的な反応しか得られないという経験は、多くの人にとって共通しているかもしれません。

![](https://ai-data-base.com/wp-content/uploads/2025/04/AIDB_88247_1.png)

LLMによる単純生成とペルソナ適用時の出力比較

では、どうすればLLMを通じて“多様な顧客像”の反応を再現できるのでしょうか。  
一つの手がかりとして、ある集団は単一のペルソナではなく、複数の異なる視点を持った個人の集合として捉えられる、という考え方があります。たとえば映画レビューのようなケースでは、「映画に詳しい人」「アクション好き」「たまに映画を見るだけの人」など、異なる視点が自然に共存しています。そうした視点の交わりが、集団としての“らしさ”を形づくっているとも言えます。

この観点に立つと、集団レベルの反応をLLMで再現したいとき、必要なのは「単一のペルソナを与えること」ではなく、「複数の異なる視点をどう構成するか」になります。そして、その視点ごとの特徴が、どのように出力に現れるのかを理解することが鍵になります。

こうした考えに基づき、問題を定式化することが可能です。  
対象とする集団（たとえばある製品の顧客層）は、いくつかの視点（ペルソナ）に分解できると仮定します。それぞれのペルソナは、その集団における特徴的な意見や語り口を持っています。映画の例で言えば、同じ映画に対しても「映画評論家」「カジュアルな視聴者」「アクションファン」では評価の観点が変わってきます。

ここで重要なのは、「個人」を特定する必要はないという点です。実務でも、個人の詳細なデータにアクセスできない場面は少なくありません。そのため今回の研究でも、個々のユーザーの履歴に頼らず、集団全体の傾向を反映させる方法が検討されています。

たとえばレビューなどのデータセットを使えば、ある入力（たとえば映画タイトル）に対して複数の出力（異なる人のレビュー）が存在するという構造が得られます。そうした「ばらつき」が、まさに多様性の出発点です。この多様性をどうLLMに取り込むかという問いが、この問題設定のコアにあります。

## LLMの出力に多様性を持たせるにはどう設計すればよいか

前述の通り、LLMを活用して集団の反応を再現したいと考えたとき、最初に直面するのが「出力が単調で、現実のようなばらつきが出てこない」という問題です。たとえば、ある製品に関するレビューを生成しようとしても、どこか一面的な内容に寄ってしまい、多様な視点が反映されていないと感じることがあります。

このような課題に対して、今回研究者らは、集団の反応を「複数の異なる視点の組み合わせ」としてとらえるアプローチを採用しています。そうしてできた手法は、Mixture of Personas（MoP）と名付けられました。

この考え方に基づいて、自分のプロンプト設計を見直すこともできそうです。

### 単一の視点ではなく、複数の視点を組み合わせる

まず考えたいのは、ペルソナの与え方です。多くの人が、ターゲット像をひとつだけ指定して出力を得ようとしますが、それだけでは現実のような反応の幅をつくることは困難です。

そこで発想を変えて、「ひとつの集団は、複数の特徴を持ったグループの混合でできている」と考えてみます。たとえば映画レビューを生成する場合、「映画評論家」「普段はあまり映画を見ない一般視聴者」「アクション映画に強い関心を持つ人」など、いくつかの異なる視点を想定します。そして、どの視点をどの程度反映させるかを、入力の内容に応じて調整するという考え方です。

自分で試す場合には、あらかじめ複数のペルソナを定義し、プロンプトの中でその一部を確率的、あるいは意図的に組み合わせて出力に活かす構成にしてみるとよいかもしれません。入力がどのタイプの反応を引き出しやすいかを観察しながら、重みづけの工夫を加えていくこともできます。

### ペルソナだけでなく、具体的な例示も使う

視点を混ぜるだけでもある程度の多様性は得られますが、それだけでは事前学習されたLLMの傾向から大きく外れるのは難しいこともあります。  
そうしたときに有効なのが、プロンプトに実際の応答例を加えるという工夫です。

このとき重要なのは、「ひとつの例を与える」のではなく、複数の例を準備しておき、コンテキストに応じて使い分けるという設計です。例として提示された文章が、そのあとの出力のトーンや視点に影響を与えることは多くあります。

プロンプト設計では、入力とペルソナの内容に応じて、どの例を提示するかを選ぶ仕組みを加えると、さらに柔軟に反応を変化させることができます。選択はランダムでも構いませんが、類似度や関連度に基づいて例を切り替える方法を使うと、より狙った出力に近づけることが可能です。

![](https://ai-data-base.com/wp-content/uploads/2025/04/AIDB_88247_2-1024x288.png)

ペルソナと例示の組み合わせによる出力生成の全体構成

### 学習が不要な範囲でも応用可能な構成にする

このような出力制御の工夫は、本来であればゲーティングネットワークなどを別途学習して導入する構成ですが、実務ではそこまでのリソースが取れないこともあります。

そこで実際に応用する際には、「複数のペルソナ × 複数の例」の中から、スコアリングや [ルールベース](https://ai-data-base.com/archives/26614 "ルールベース") で絞り込みを行い、その組み合わせをプロンプトに埋め込むという形で再現する方法も検討できます。LLM本体を変えずに、プロンプトの工夫だけで多様性を演出することも十分に可能です。

また、モデルを再学習しない構成にしておけば、異なるLLMでも同じ仕組みを再利用しやすくなります。

### ペルソナをデータから自動で作るには

あらかじめペルソナを手作業で定義するのが難しい場合には、データからの自動生成を試す方法もあります。たとえば、過去のレビューやコメントのデータがあれば、それらを文章ベクトルとして変換し、クラスタリングすることで、似た傾向を持つグループに分けることができます。

そのうえで、各クラスタの特徴を簡単に要約してペルソナとして定義すれば、データの分布に即した自然なペルソナを構築できます。要約にはLLMを使って「このクラスタの共通の特徴を説明してください」といった指示を与えるだけでも、実用的な説明が得られます。

### まずはこの構成を試してみてもよいかもしれません

本手法のエッセンスをもっとも簡単に試すとすれば、プロンプトにおいて異なる立場を持つ複数のペルソナをあえて並べる方法があります。しかも、そのペルソナ同士が対立的であるほど、出力に幅が出やすくなります。

そのうえで、「必要に応じてペルソナを使い分けてください」「複数の視点から出力を構成してください」といった一文を添えておくと、LLMが自律的に視点を調整しながら出力を組み立てる余地が生まれます。

また、もし複数のペルソナをそのまま列挙するのが難しい場合は、それらを要約して統合した“ひとつの短いペルソナ”に変換するという手もあります。複数のペルソナ記述と例示を入力として受け取り、主要な関心領域・文体・テーマ的傾向を1文に凝縮する仕組みが使われています。

こうした「混合ペルソナ」の生成は、入力長を抑えながら異なる視点を統合する方法としても有効であり、少数（2〜4程度）のペルソナであれば、整合性を保ちつつ多様性を引き出す効果が確認されています。

本格的な実装に入る前に、このような簡易的な構成を手元で試してみると、出力の変化がより実感しやすくなるかもしれません。

プロンプト例は以下の通りです。

※具体的なペルソナの例が既に記載されています。該当部分を書き換えることでテンプレートとして応用できる可能性もあります。

原文：

```js
<|begin_of_text|><|start_header_id|>system<|end_header_id|>

You are a highly capable and insightful AI
assistant<|eot_id|><|start_header_id|>user<|end_header_id|>

Given a list of persona descriptions of a reporter and a list of news blurbs he/she has written,
construct a concise persona description that reflects the reporter’s primary focus, style, and
thematic interests.

Example persona descriptions:
You are a sports reporter, specializing in baseball news, with a focus on the Major League Baseball
(MLB) playoffs and postseason games.

Inputs:
1. List of persona descriptions: A list of general persona characteristics previously associated
   with the reporter.
2. List of news blurbs: A selection of sample news blurbs authored by the reporter, which reveal
   their tone, thematic focus, and writing style.

Using the inputs, generate a short persona description that synthesizes their focus, preferences,
and stylistic tendencies into a single cohesive statement.

List of persona descriptions:
{personas}

List of news blurbs:
{examples}

Please provide the short persona description.<|eot_id|><|start_header_id|>assistant<|end_header_id|>

The short persona is:
```

日本語訳：

```js
<|begin_of_text|><|start_header_id|>system<|end_header_id|>

あなたは極めて有能で洞察力に富む AI
アシスタントである<|eot_id|><|start_header_id|>user<|end_header_id|>

以下に記者のペルソナ記述一覧と、その記者が執筆したニュース記事見出しの一覧を与える。
これらを基に、記者の主要な関心領域・文体・テーマ的関心を反映した簡潔なペルソナ記述を作成せよ。

ペルソナ記述の例:
あなたは野球ニュースを専門とするスポーツ記者であり、メジャーリーグ
（MLB）のプレーオフとポストシーズンゲームに焦点を当てている。

入力:
1. ペルソナ記述一覧: その記者に以前関連付けられた一般的なペルソナ特徴のリスト
2. ニュース見出し一覧: 記者が執筆したサンプル記事の見出し。文体・テーマ・筆致を示す

上記入力を用いて、記者の関心・嗜好・文体的傾向を統合した、短いペルソナ記述を1文で生成せよ。

ペルソナ記述一覧:
{personas}

ニュース見出し一覧:
{examples}

簡潔なペルソナ記述を提示せよ。<|eot_id|><|start_header_id|>assistant<|end_header_id|>

簡潔なペルソナ記述:
```

## 実験から見えてきた多様性設計の効果と応用可能性

複数のペルソナと例示を組み合わせて、LLMの出力に多様性をもたせる。  
こうした考え方がどれほど有効なのか、さまざまな検証が行われました。以下では、そうした設計を実装した手法（研究内では *Mixture of Personas* 、略称MoP）を使って得られた結果を紹介します。

この仕組みをそのまま使わないとしても、「どう設計すれば出力にばらつきが出るのか」「合成データとして通用する質になるのか」といった観点は、自分のプロンプト設計にも応用できるヒントになるはずです。

### 実験の目的とデータセット

この検証では、主に次のような問いを軸にしています。

まず、LLMの出力を実際の集団の傾向にどこまで近づけられるのか。  
次に、生成されたデータを学習用データとして使ったときに、十分な性能が出るのかどうか。  
そして、構成を一度作ってしまえば、他のLLMにも応用できるのかどうか。

こうした検証に使われたのは、4つの異なる種類のデータセットです。ニュース記事、レストランレビュー、映画の [感情分析](https://ai-data-base.com/archives/26497 "感情分析") 、長文レビューと、内容や文体が異なるジャンルを対象に選ばれています。  
比較対象には、 [ZeroGen](https://arxiv.org/abs/2202.07922) 、 [AttrPrompt](https://github.com/yueyu1030/AttrPrompt) 、 [ProGen](https://aclanthology.org/2022.findings-emnlp.269/) 、 [PICLe](https://arxiv.org/abs/2405.02501) といった既存のプロンプト手法が含まれています。

### 出力の“らしさ”はどこまで再現できたか

まず確認されたのは、生成されたテキストが実際のデータにどれほど似ているかという点です。

その比較には、主に三つの観点が使われています。  
ひとつは、生成データと実データの分布の距離を測るFID（Frechet Inception Distance）。  
もうひとつは、テキスト分布間の類似性を測るMAUVEという指標。  
そしてもう一つが、応答同士の多様性を示すKL Cosineです。

これらを用いて比較した結果、本手法はすべてのデータセットで他の手法を上回るスコアを示しました。

この結果は、「単一の視点からの出力」ではなく、「複数の視点を混ぜて出力する」という設計が、より現実に近いばらつきと自然さを引き出している可能性を示しています。

![](https://ai-data-base.com/wp-content/uploads/2025/04/AIDB_88247_3-1024x224.png)

生成テキストにおけるFID・MAUVE・KLスコアの比較

### 合成データは実際に使えるのか

実務で考えたとき、生成されたテキストが“らしく”見えるだけでは足りません。そのデータを使ってモデルを学習し、実際のデータに対しても性能が出るのかという点は、実用上とても重要です。

そこで研究者らは、本手法で生成されたデータを使ってDistilBERTという分類モデルを訓練し、そのモデルが実データにどれほど対応できるかを検証しています。

その結果、たとえばニュース記事分類では、既存手法を用いたモデルよりも約4ポイント高い [F1スコア](https://ai-data-base.com/archives/26112 "F1スコア（F値）") を記録しています。映画レビューでも、最大で約5ポイントの改善が見られました。

これは、限られた実データしか手元にない場合でも、今回のように手法を工夫すれば合成データで性能を底上げできる可能性があることを示しています。ドメイン特化の環境など、収集コストが高い場面で参考になる考え方かもしれません。

![](https://ai-data-base.com/wp-content/uploads/2025/04/AIDB_88247_4.png)

合成データで訓練した分類モデルのF1スコア

### 一度作った設計は、他のLLMにも応用できるのか

プロンプトの構成やペルソナの調整にはある程度の設計コストがかかります。そのため、一度設計した仕組みを他のモデルにもそのまま使えるかどうかは、運用面での重要なポイントです。

この点に関して、研究ではLlama3で構築した設計を、そのままGemma2やMistralといった別のLLMに適用するテストも行われました。結果として、再調整なしでも一定の効果が確認されており、特定のモデルに依存しすぎない設計であることが示されています。

業務の中でも、初期は軽量なモデルで設計を試し、のちに高性能モデルに移行するという運用は珍しくありません。そうした場面にも適した柔軟性を備えています。

![](https://ai-data-base.com/wp-content/uploads/2025/04/AIDB_88247_5.png)

構成を他のLLMに適用した際のFID・MAUVE・KLスコア

### どの構成要素が重要か

さらに細かい検証では、構成要素を一部取り除いて性能にどのような変化があるかも確認されています。  
いわゆるアブレーション実験にあたるもので、再現や応用を考える際の参考になります。

まず、例示を使わなかった場合は、出力の品質が大きく低下しています。例示が応答の具体性や自然さに直結していることが伺えます。

また、ペルソナの設定方法も性能に影響します。クラスタリングなどによって自動的に生成されたペルソナは、ランダムに与えたものに比べて明らかに良好な結果を出しており、データに合わせた視点設計の重要性が示唆されます。

![](https://ai-data-base.com/wp-content/uploads/2025/04/AIDB_88247_6.png)

例示・ペルソナの省略時における性能変化

ペルソナや例示の数については、増やすほど精度が上がる傾向にありますが、例示は2,000件前後で性能が飽和するという観察もあります。現実的なリソースとの兼ね合いを考えると、ペルソナは100前後、例示は1,000〜2,000件程度がバランスの取れた水準と言えそうです。（想像していたよりも多い、と思われた方もいるかと思いますが、もちろんこれ以下でも効果はあります）

![](https://ai-data-base.com/wp-content/uploads/2025/04/AIDB_88247_8.png)

ペルソナ数および例示数とMauveスコアの関係

さらに、出力時に複数のペルソナを混ぜると多様性が高まりますが、多く混ぜすぎると応答の一貫性が損なわれる可能性もあり、調整が必要になります。

![](https://ai-data-base.com/wp-content/uploads/2025/04/AIDB_88247_9.png)

複数ペルソナ混合時の出力性能比較

### 視覚的な分析からも見える傾向

生成されたテキストをベクトル空間に埋め込み、可視化した分析も行われています。

その結果、本手法の出力は、実データと同じような広がりやクラスタ構造を持っていることが確認されています。これは、特定の観点だけに偏ることなく、多様な視点をカバーした出力になっていることを意味します。

一方、比較対象となった他の手法では、出力が一部の領域に集中してしまうケースが目立ちました。分布全体をカバーしきれないという傾向は、応答の多様性にも影響を与えていると考えられます。

![](https://ai-data-base.com/wp-content/uploads/2025/04/AIDB_88247_7-1024x232.png)

生成データの多様性を示す埋め込み可視化

### 応用できる場面を考えてみる

このアプローチの設計をそのまま再現する必要はありません。ただ、考え方や工夫のポイントは、さまざまな実務の場面で取り入れることができます。

たとえば、新しいサービスや製品に対して、多様なユーザーがどのような反応を示すかをシミュレーションしたいとき。あるいはマーケティングメッセージを検討する際に、異なる層の受け止め方を想像してみたいとき。

さらに、データが少ない領域で合成データによってトレーニングを補完したり、複数の視点をもったSNS投稿や記事を作成したりする場面でも、この発想は応用可能です。

大切なのは、「多様性のある出力を得るには、どのような視点をどう組み合わせるべきか」という問いを自分で持つことです。本手法の設計は、そのためのひとつの具体例にすぎません。考え方さえ理解できれば、手元にあるLLMとプロンプトだけでも、似たアプローチを試すことができます。

## まとめ

本記事では、LLMの出力に現実の集団が持つばらつきや多様性を反映させる方法について、一つの研究をもとに整理してきました。紹介したアプローチ（研究内では *Mixture of Personas* と呼ばれています）は、単一のペルソナに頼らず、複数の視点と応答例を動的に組み合わせる構成をとっています。

こうした仕組みを通じて、「それらしい一つの答え」ではなく、「集団としての傾向」を表現する出力が得られる可能性があることが、実験でも示されています。さらに、生成されたデータは学習用データとしての質も備えており、他のモデルへの転用にも一定の柔軟性があることが確認されました。

前述したように、この構成をそのまま再現しなくても、得られた知見の一部をプロンプト設計に取り入れることはできます。複数の視点を設定する、例示の扱い方を工夫する、入力との対応関係を意識する…そうした設計のひとつひとつが、出力の多様性や現実性に直結します。

LLMを使って集団の声を捉えたいと考えるとき、何を組み合わせ、どう調整するかという視点そのものが、設計の鍵になるかもしれません。

**参照文献情報**

- タイトル：Mixture-of-Personas Language Models for Population Simulation
- URL： [https://doi.org/10.48550/arXiv.2504.05019](https://doi.org/10.48550/arXiv.2504.05019)
- 著者：Ngoc Bui, Hieu Trung Nguyen, Shantanu Kumar, Julian Theodore, Weikang Qiu, Viet Anh Nguyen, Rex Ying
- 所属：Yale University, The Chinese University of Hong Kong

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[LLM研究の拡大と分野別動向　約1万6000件の論文から主要トピックを抽出](https://ai-data-base.com/archives/88439)

[LLMに「分析を任せる」とはどういうことか　自然な問いかけからインサイトを得る](https://ai-data-base.com/archives/88313)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)