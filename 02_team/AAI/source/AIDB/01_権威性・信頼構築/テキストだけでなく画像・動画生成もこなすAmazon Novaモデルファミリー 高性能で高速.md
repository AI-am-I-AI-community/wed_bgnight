---
title: "テキストだけでなく画像・動画生成もこなすAmazon Novaモデルファミリー 高性能で高速"
source: "https://ai-data-base.com/archives/80001"
author:
  - "[[AIDB Research]]"
published: 2024-12-05
created: 2025-06-13
description: "本記事では、Amazonが開発したLLM「Nova」ファミリーの特徴と技術的アプローチを紹介します。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、Amazonが開発したLLM「Nova」ファミリーの特徴と技術的アプローチを紹介します。

Novaは、テキスト処理から画像・動画生成まで対応可能なマルチモーダルモデルで、異なるサイズのモデルを用意することで、用途や予算に応じた柔軟な選択を可能にしています。

200言語以上のデータを活用しながら、段階的な学習プロセスを採用することで、実用性の高いシステムとして設計されています。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80001-1024x576.jpg)

**発表者情報**

- 機関：Amazon Artificial General Intelligence

## 背景

企業や組織が独自のLLMを開発・展開する動きが加速しています。最近では、マルチモーダル処理や長文脈理解など、より高度な機能を備えたモデルの開発競争が激化している状況にあります。

このような状況下で今回新たにAmazonがLLMを開発しました。

開発された『Nova』モデル群は、性能と実用性のバランスを重視した設計思想を持っています。3つの異なるサイズで展開し、用途や予算に応じた選択を可能にしています。また200以上の言語データを活用した多言語対応を実現し、15の主要言語に重点を置いています。またテキスト処理だけでなく画像生成や動画生成にも対応しています。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80001_f1-1024x545.png)

Novaモデルファミリーの全体構成。各モデルの入出力関係と、それぞれが処理できるデータタイプを示す

研究者らは今回、Novaファミリーの基本的な性能だけでなくエージェント性能、長文コンテキスト処理性能、専門的なドメイン性能を豊富なベンチマークで網羅的に評価し結果をまとめています。  
新しいモデルが登場する際に、現在はどのようなベンチマークが使用されるのかといった観点でも興味深い内容になっています。

さらに、画像生成や動画生成においても中立的な評価を行い報告しています。

その結果、性能だけでなく、ユーザー体験に直接影響する生成速度などの側面でも優れていることが示唆されました。

## Amazon Nova Pro、Lite、Microの評価

### 基本的な能力

まずはAmazon Novaモデルのコア性能を評価するため、テキストとマルチモーダルの両方について、一連の公開ベンチマークを用いた評価が行われました。

#### テキストタスク性能

一般知識、推論、言語理解、多言語性、指示追従などの分野での評価で使用されたベンチマークを以下に並べます。

（１）MMLU (大規模マルチタスク言語理解)  
STEM、人文科学、社会科学の57の科目分野をカバーする多肢選択式問題のベンチマークです。法律、物理学、数学、コンピュータサイエンス、歴史などが含まれ、小学生から高度な専門家レベルまで難易度は様々であり、世界知識と問題解決能力の両方に焦点が当てられています。0-shot Chain-of-Thought (CoT)でプロンプトが実施され、全科目の [正解率](https://ai-data-base.com/archives/25930 "正解率") の平均が算出されました。

（２）ARC-C (AI2推論チャレンジ)  
3年生から9年生までの理科の試験から集められた多肢選択式問題のデータセットです。0-shot CoTでプロンプトが実施され、正解率が算出されました。

（３）DROP (段落上での離散推論)  
クラウドソーシングで作成された読解データセットであり、参照テキストの複数の入力位置から推論して操作することが求められます。0-shot CoTでプロンプトが実施され、 [F1スコア](https://ai-data-base.com/archives/26112 "F1スコア（F値）") が算出されました。

（４）GPQA (大学院レベルのGoogle-Proof質問回答)  
生物学、物理学、化学分野のPhD取得者または取得予定者の専門家によって作成された、非常に高度な多肢選択式問題ベンチマークです。0-shot CoTでプロンプトが実施され、メインセットでの正解率が算出されました。

（５）MATH  
アメリカン数学コンペティション(AMC 10、AMC 12)、アメリカ数学招待試験(AIME)などの数学コンペティションから集められた問題を含む数学問題解決ベンチマークです。0-shot CoTでプロンプトが実施され、MATH5kセットでの正解率が算出されました。

（６）GSM8K (小学校数学8K)  
8,500問の高品質で多様な小学校数学問題からなるベンチマークです。複数のステップの推論を必要とする基本的な数学問題解決能力が評価されます。0-shot CoTでプロンプトが使用され、1,319サンプルのテストセットでの正解率が算出されました。

（７）IFEval (指示追従評価)  
モデルが「キーワードを少なくとも3回使用する」といった「検証可能な指示」に従う能力を評価するベンチマークです。自然言語による検証可能な指示を1つ以上含む25種類のプロンプト、合計541プロンプトから構成されます。緩い制約の下での指示レベルの正答率が算出されました。

（８）BBH (Big-Bench Hard)  
アルゴリズムタスクからカジュアルな論理タスク、単語の並べ替え、映画のレコメンドまでをカバーする23の多様な科目で構成される総合的なベンチマークです。タスクには多肢選択と自由生成の両方が含まれます。科目全体のマクロ平均正解率が算出されました。

表には、Nova Pro、Nova Lite、Nova Microを含む各モデルの性能評価結果がまとめられています。なおパブリックモデルについては、Claude、Gemini、OpenAI、Llamaファミリーの公式技術レポートやウェブサイトから入手できる最高スコアが参照されています。ベンチマークのコア性能について、Amazon Nova Pro、Lite、Microは全ての評価項目で優れた結果を示しており、中でもNova MicroとLiteは数学、推論、指示追従のベンチマークで際立った性能を発揮しています。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80001_t1-edited.png)

また、Novaモデルの翻訳機能も評価されています。使用されたのは、842の異なるウェブ記事から構成される機械翻訳用ベンチマークFlores（Flores200としても知られる）です。英語と非英語言語間の翻訳能力が評価されます。平均で21単語程度の長さの文章について、0-shotの条件で、英語からと英語への両方向で評価が実施されました。評価言語セットには、アラビア語、ドイツ語、スペイン語、フランス語、ヒンディー語、イタリア語、日本語、韓国語、ポルトガル語、ヘブライ語、トルコ語、簡体字中国語、ロシア語、オランダ語が含まれています。

翻訳機能の定量的な評価結果をまとめたものが下の表です。Nova Pro、Lite、Microはいずれも、翻訳の品質指標であるspBLEUとCOMET22スコアにおいて高いスコアを示しています。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80001_t2-1024x595.png)

#### マルチモーダル性能

Amazon Novaモデルのマルチモーダル機能が、自然画像理解、グラフや図表を含む文書の理解、テキスト理解、動画における時間的推論など、さまざまな観点で検証されました。

各ベンチマークの目的と特徴を以下に示します。

（１）MMBU  
大学レベルの30の異なる分野から収集された多肢選択式および自由記述式の質問を含むベンチマークです。評価にはChain-of-Thought（CoT）プロンプティングが使用され、正確性で測定されます。

（２）ChartQA  
3種類のグラフ（棒グラフ、折れ線グラフ、円グラフ）に関する2,500の質問が含まれており、視覚的、論理的、算術的な推論能力が求められます。テストセットでの緩和された正確性で評価されます。

（３）DocVQA  
文書分析と認識能力、特に [光学文字認識](https://ai-data-base.com/archives/26261 "光学文字認識（OCR）") （ [OCR](https://ai-data-base.com/archives/26261 "光学文字認識（OCR）") ）の性能が検証されます。1940年から2020年にかけての様々な産業の文書から集められた5,349の質問で構成され、 [正規化](https://ai-data-base.com/archives/26401 "正規化") レーベンシュタイン類似度（ANLS）で評価されます。

（４）TextVQA  
自然画像における文字読み取り能力（ [OCR](https://ai-data-base.com/archives/26261 "光学文字認識（OCR）") ）に特化した5,000のサンプルで構成されています。検証セットでの重み付き正確性で評価されます。

（５）VATEX  
多様な人間の活動をカバーする動画キャプション生成のベンチマークです。約10秒の長さの動画を含む公開テストセットで評価され、CIDErスコアが使用されます。

（６）EgoSchema  
長時間の動画に関する質問応答ベンチマークであり、特徴的な「証明書の長さ」（人間が動画の説明を確認するのに要する時間）を持ちます。動画は幅広い自然な人間の活動を収録しており、人間が作成した多肢選択式の質問-回答ペアが付属しています。

表に、画像理解と動画理解に関する定量的な評価結果がまとめられています。Nova ProとLiteはすべてのベンチマークで高いスコアを達成しており、中でもにChartQAでの図表理解とVATEXでの動画理解において、他のモデルと比較して1位または2位の性能を示しています。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80001_t3-1024x491.png)

### エージェント性能

Nova Pro、Lite、Microは、エージェントとして機能する能力を備えています。ツールやAPI群の活用、ユーザーのリクエストと過去の会話履歴の理解、ツール使用の要否判断、そして使用するツールの選択といった一連の処理がエージェントによって行われます。その後、ツールが呼び出され、結果が評価され、ユーザーとのコミュニケーションが取られます。

今回、テキスト理解とビジュアル推論の両方が必要とされるエージェンティックワークフローについて評価が実施されました。テキスト理解の評価には、Berkeley Function Calling Leaderboard（BFCL）ベンチマークが使用され、実際のアプリケーションにおける関数呼び出しとオーケストレーション能力がテストされました。ビジュアル推論については、画像理解を必要とする関数呼び出しの正確性を評価する3つのベンチマークが使用されました。

Nova ProとLiteの両モデルによって、これらの難易度の高いベンチマークで新たな最高水準が達成されました。

#### テキストベースのエージェント性能

下の表に、Berkeley Function Calling Leaderboardベンチマークの定量的な結果が示されています。Gorillaプロジェクトから発展したBFCLベンチマークでは、ユーザーの自然言語リクエストに基づいて、実世界の関数やツールを正確に呼び出し、利用する能力が評価されます。Novaモデルは、抽象構文木（AST）、実行、関連性、非関連性の各指標、および総合スコアにおいて優れた性能を示しました。また、Nova LiteとMicroは、比較対象のモデルの中で最も低いレイテンシーを達成しています。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80001_t4-1024x478.png)

#### マルチモーダルのエージェント性能

Nova ProとLiteは、マルチモーダル入力に対するネイティブサポートが提供されており、エージェンティックワークフローにも対応しています。

そこでウェブサイトのナビゲーションによって実世界のタスクを解決する必要がある3つの異なるベンチマークで評価が実施されました。ウェブサイトは通常スクリーンショットとして表現され、標準的なウェブブラウザでレンダリングされたすべてのスタイル要素とビジュアルデータが正確に伝えられます。

以下、使用されたベンチマークの説明です。

（１）VisualWebBench  
キャプション生成、質問応答、 [OCR](https://ai-data-base.com/archives/26261 "光学文字認識（OCR）") 、アクション予測、グラウンディングなど、ウェブブラウジングに関連する7つのコアタスクが含まれています。100以上のウェブサイトから12のドメインにわたる1,536サンプルで全モデルが評価され、個々のコアタスクの異なる指標の平均が最終的な評価指標として使用されています。

（２）MM-Mind2Web  
オリジナルのMind2Webベンチマークをマルチモーダル化した拡張版です。エージェントによって要素が選択され、3つの基本的なアクション（クリック、入力、選択）のいずれかが選択され、一部のアクションには値も設定される必要があります。パーサンプルのステップ正確性のマイクロ平均が報告されており、要素とアクションの選択、および予測された値がすべて正しい場合にのみ、エージェントは成功とみなされます。

（３）GroundUI-1K  
Mind2Webを含む複数の既存データセットで構成され、それらがグラウンディングタスクとして再利用されています。幅広いドメインのウェブサイトのスクリーンショットと指示が与えられ、マルチモーダルエージェントは目的のUI要素の2D位置を予測するように求められます。予測された2D位置が正解の境界ボックス内にある場合、エージェントは正解とされます。評価には1,000サンプルが使用されます。

下の表に、他の公開されている結果とともに、マルチモーダルエージェントワークフローに関する結果が示されています。NovaのLiteとProの両モデルは、強力なビジュアル推論とエージェント機能を実証し、3つのベンチマークすべてで高いスコアを達成しています。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80001_t5-1024x541.png)

### 長文コンテキスト性能

Nova Pro、Lite、Microの長文コンテキスト処理能力が評価されました。長時間の複数ターンの会話、検索された文書のリストに関する推論、長時間の動画の理解など、多くのタスクにおいて重要となる能力です。それぞれのモデルが扱える文脈長は、Microが128kトークン、LiteとProが300kトークンです。以下のベンチマークで長文脈性能が評価されました。

（１）テキストニードル・イン・ザ・ヘイスタック（NIAH）  
先行研究に従い、広範な文脈（「ヘイスタック」）内から特定の情報（「ニードル」）をモデルが位置特定する能力が評価されました。このテストでは、32kから始まる様々な長さの入力文脈に対するモデルの性能が測定され、正確な情報取得能力が評価されます。

（２）SQuALITY  
文学作品のストーリーに基づくクエリベースの要約に焦点を当てたタスクであり、大きな文脈から関連する要約を生成する能力が評価されます。

（３）LVBench  
このマルチモーダルベンチマークには、テレビシリーズ、スポーツ、放送、監視映像などの様々なドメインからのYouTube動画に関する質問が含まれています。99の動画と1,549の質問で構成され、推論、イベント理解、要約など6つの異なるタイプのタスクがカバーされています。

下の表に、テキストおよびマルチモーダルの長文脈ベンチマークの結果が示されています。長時間の動画に関する質問応答タスクでは、Nova ProとLiteの両方がLVBenchデータセットにおいて他のモデルを上回る堅固な性能を示しました。Novaモデルは、テキストとマルチモーダルの両方の理解が必要なユースケースにおいて、あらゆる深さからの情報検索において一貫して優れた性能と信頼性を示しています。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80001_t6.png)

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80001_f2-1024x422.png)

各Novaモデルの長文脈処理における性能を示したヒートマップ

### 特定ドメインへの専門性

以上のような基本的な性能に加えて、特定の専門分野やドメインにおけるモデルの性能が評価されました。多岐にわたる性能分析の中から、ソフトウェアエンジニアリング、財務分析、検索拡張生成（RAG）の3つのドメインについてベンチマーク評価が行われました。

#### ソフトウェアエンジニアリング

Pythonのコーディングタスクであるコード生成能力は、HumanEvalによって評価されました。164の独自のプログラミング問題と単体テストが含まれています。言語理解、アルゴリズム、基本的な数学的能力が評価され、その一部はシンプルなソフトウェアの面接問題に相当する難易度が設定されています。

#### 財務分析

財務データを理解する能力は、FinQAを用いて評価されました。S&P 500企業の収益報告書から抽出された8,281の財務に関する質問-回答ペアで構成される、専門家によって [アノテーション](https://ai-data-base.com/archives/26297 "アノテーション") が付けられたデータセットです。表形式と非構造化テキストの両方から情報を抽出し、関連する財務知識を用いて正確に計算を行う能力が評価されます。0-shot CoT設定での後処理後の正確性の平均が報告されています。

#### 検索拡張生成（RAG）

RAG能力は、CRAGベンチマークのタスク1のセットアップを使用して評価されました。各入力質問に対して、5つの事前選択されたHTMLページが外部知識として考慮されます。CRAGの公式リポジトリで使用される標準的な検索アプローチに従い、BeautifulSoupを使用してHTMLタグが除去された後、テキストは1000文字以下のチャンクに分割され、sentence- [transformer](https://ai-data-base.com/archives/26535 "Transformer") s/all-MiniLM-L6-v2モデルを使用して文章がエンコードされます。同じモデルで質問もエンコードされ、類似度が最も高い上位20チャンクがモデル推論の入力コンテキストとして使用されます。

モデルの回答と期待される回答の比較には、gpt-4-turbo-2024-04-09による判定が行われました。表には、Nova Pro、Lite、Microと選択された公開モデルのRAGに関する性能が示されています。合計2,706の検証セットとテストセットの例に対する正解率が報告されています。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80001_t7-1024x723.png)

### ランタイムパフォーマンス

ランタイムパフォーマンスとは、プログラムやシステムがどれくらい効率的に動作するかを示す指標です。ユーザーが実際にプログラムを使用している時のパフォーマンスを指すため、ユーザー体験に直接影響します。

Nova Pro、Lite、Microのランタイムパフォーマンスは、最初のトークンまでの時間（TTFT）、出力トークン毎秒（OTPS）、そして合計応答時間で評価されました。

（１）TTFT  
APIリクエストが送信されてから最初のトークンを受信するまでの時間が秒単位で測定されます。

（２）OTPS  
最初のトークン以降の出力トークンの生成速度（トークン/秒）を示し、推論時の全体的なスループットと効率性を反映します。

（３）合計応答時間  
与えられた入力-出力プロンプト長に対して、入力プロンプトの送信から生成シーケンスの終了までの全体的な所要時間が秒単位で測定されます。モデルのユーザー体験全体が表現されます。

#### 測定結果

下記の図に、1000トークンの入力と100トークンの出力を用いた場合のTTFT、OTPS、合計応答時間が、Nova Pro、Lite、Microモデルと他の公開モデルについて示されています。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80001_f3_2-1024x401.png)

Nova Micro、Lite、Proは、それぞれ同等の能力を持つモデル群と比較して最速のモデルの一つとして位置付けられています。3つのNovaモデルはすべて、最先端のランタイムパフォーマンスを実証しており、多くの実世界のユースケースにおいてスムーズで応答性の高いユーザー体験が提供されることが示唆されています。

## Amazon Nova Canvasの評価

今回開発されたモデルは画像生成能力を持ち、「Amazon Nova Canvas」と名付けられています。

### 自動評価指標

ImageRewardとText-to-Image Faithfulness（TIFA）という2つの自動評価指標が使用されました。それぞれ以下の特徴があります。

（１）ImageReward  
人間の選好と予測スコアを整合させた標準化された報酬モデルから生成されるスコアです。スコアの計算には、MSCOCO-2014検証セットから無作為に抽出された10,000件のプロンプトが使用されました。

（２）TIFA  
生成された画像と入力テキストの忠実度を視覚的質問応答（VQA）を通じて測定する参照フリーな指標です。評価セットとしては、MSCOCO、DrawBench、PartiPrompts、PaintSkillデータセットから [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") された4,000件のプロンプトを含むTIFA-v1.0ベンチマークが使用されています。

DALL.E 3、Stable Diffusion 3 Medium、Stable Diffusion 3.5 Large、Flux（SchnellとPro）などの他の公開モデルとの比較結果が表に示されています。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80001_t8.png)

### 人間による評価

A/Bテストによる評価が実施されました。

評価用プロンプトセットは、実際の画像モデルの使用事例を反映した約1,000件のプロンプトで構成されています。MSCOCO、Drawbench、OpenParti、DALL.E 3 Eval、DOCCIなどのデータセットからのプロンプトが含まれ、人物、風景、自然のシーン、室内環境、創造的なテーマ、芸術的なテーマなど、幅広いカテゴリーがカバーされています。

評価の品質を確保するため、いくつかのプロンプトがランダムに選択され、モデルの品質に関する追加データポイントを得るために繰り返し評価されました。

各プロンプトを使用して、Amazon Nova Canvasと他のモデルから画像が生成されました。Nova Canvasからの画像生成にはランダムなシードが使用され、すべての画像は1,000×1,000ピクセルの解像度で生成されました。

評価においては、人間の評価者に以下の2つの側面について画像の選好が尋ねられました。

（１）テキストと画像の整合性  
モデルの指示追従能力を測定します。

（２）画像品質  
評価者の全体的な選好を定量化します。

#### 評価結果

表には、Amazon Nova CanvasとOpenAI DALL.E 3およびGoogle Imagen 3との比較における対比評価の結果が、勝率、同率、敗率を含めて示されています。勝率は、Nova Canvasが他のモデルより好まれたサンプルの割合を反映しています。同率（tie：タイ）となっている場合は、人間の評価者が2つのモデル間に知覚可能な差を見出せなかったということです。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80001_t9-1024x150.png)

この結果から、Nova Canvasは他のモデルに対しても競争力があることが示唆されています。

## Amazon Nova Reelの評価

今回開発されたモデルには動画生成機能もあり、Amazon Nova Reelと呼ばれています。

### 人間による評価指標

Nova Reelの評価は、生成された動画に対する人間のフィードバックを主軸として、動画品質と動画の一貫性という2つの主要な軸で実施されました。評価者には2つの動画が横並びで表示され、評価している指標について、より優れている動画を選択するか、同等と判断した場合は同点とマークするように求められました。動画は720p解像度で生成され、生成時には異なるランダムシードが使用されました。

#### 動画品質

動画品質の評価は、以下の4つの主要な要素で構成されました。

（１）画像品質  
個々のフレームの視覚的な魅力。解像度、シャープさ、オブジェクトの明瞭さ、全体的な構図などが評価されます。

（２）モーション品質  
フレーム間の動きの流動性。フリッカリング、歪み、急激な変化のない、自然で現実的な動きの表現が評価されます。

（３）画像とテキストの整合性  
各フレームがプロンプトにどれだけ忠実か、エンティティの存在や属性、空間的関係、色などの静的な視覚的詳細が評価されます。

（４）モーションとテキストの整合性  
エンティティのアクションの正確さ、カメラの動き、属性の時間的変化など、動的な要素のプロンプトへの忠実度が評価されます。

また、モーションの度合い、エンティティのサイズ、創造的な構図、一般的な動画の好ましさなど、全体的な魅力に影響を与える要因も考慮されています。

#### 動画の一貫性

動画全体を通じたサブジェクトと背景の時間的な整合性も評価されました。エンティティのサイズ、形状、外観の維持や、予期せぬ変形や変化のない背景の安定性が含まれます。この軸において高いスコアは、動画の継続時間を通じて前景と背景の要素間に信頼できる空間的関係が維持されていることを意味します。

### データセットの構成と実装

#### 構築方法

動画生成の様々な側面を捉えるため、多様なプロンプトが慎重にキュレーションされました。プロンプトは以下の6つの広範なカテゴリーに分類されます。

（１）人物とアクティビティ  
（２）動物  
（３）自然の風景と景観  
（４）室内シーン  
（５）オブジェクトのインタラクション  
（６）創造的なシーンとアクティビティ

#### モーション関連の評価方法

プロンプトセットは、生成された動画におけるモーションのテキストとの整合性を評価する上で重要な、様々なモーション関連の側面をカバーするように構造化されています。

（１）カメラモーション  
モデルがカメラの動きに関する指示にどの程度忠実に従えるかを評価するため、様々なカメラモーションを含むプロンプトが含まれています。

（２）動的な属性  
サブジェクトまたは背景が時間とともに状態や形状を変化させる場合の、モデルの生成能力が評価されます。

（３）モーションバインディング  
特定の動きやアクションの組み合わせが要求される場合に、モデルが複雑で協調的なモーションを生成できるかを評価します。

キュレーションされたプロンプトセットは約700のプロンプトで構成されています。すべてオープンソースのベンチマークから収集されました。

### 実験環境と品質保証

品質の高い一貫した偏りのない評価を実現するため、以下のような厳密な手続きが採用されました。

#### アノテーション品質の管理プロセス

評価者には詳細なガイドラインが提供され、各評価項目における判断基準が包括的に説明されました。さらに、専門家が提供した例を用いて評価者のトレーニングが実施され、各バッチの [アノテーション](https://ai-data-base.com/archives/26297 "アノテーション") は抜き取り検査の対象とされました。

#### 評価の信頼性向上

結果の信頼性をさらに高めるため、コンセンサス投票システムが導入されました。各動画比較について3名の異なる評価者から [アノテーション](https://ai-data-base.com/archives/26297 "アノテーション") が収集され、多数決方式で最終的な判定が決定されました。

#### パフォーマンス評価結果

Runway MLのGen3 AlphaやLuma Labsのバージョン1.6など、最先端のモデルとの対比較が実施されました。評価結果は、勝率、同率、敗率の形式で報告されています。勝率は、Nova Reelが他のモデルより好まれたサンプルの割合を示しています。同率は、評価者が2つのモデル間に知覚可能な差を見出せなかったケースを表しています。

下の表には、Gen3-AlphaおよびLuma1.6との比較における対比評価の結果が示されています。動画の一貫性において、Nova ReelはGen3 Alphaに対して67.0%、Luma 1.6に対して74.7%の勝率を達成し、サブジェクトと背景の整合性において優れた性能を示しました。動画品質においても、Gen3 Alphaに対して56.4%、Luma 1.6に対して51.1%の勝率を記録しています。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80001_t10-1024x189.png)

## 責任あるAIへの取り組み

Amazonは、責任あるAI（RAI）への取り組みを、公平性、説明可能性、プライバシーとセキュリティ、安全性、制御可能性、真実性と堅牢性、ガバナンス、透明性という8つの基本的な次元に基づいて進めていると主張しています。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80001_t11-1024x351.png)

### RAI設計目標と実装

報告によると、RAI（責任あるAI）の各次元は、データ収集から事後デプロイメントの実行時緩和まで、モデル開発ライフサイクル全体を通じて詳細な設計目標に落とし込まれているとのことです。目標は、関連する法規制、自主的なフレームワーク、顧客へのコミットメントに基づいて設定され、複数のステークホルダーによる内部調整プロセスを経ているとされています。

また、モデルの能力向上（データ量、モデルサイズ、 [アーキテクチャ](https://ai-data-base.com/archives/26562 "アーキテクチャ") の革新による）に伴うリスク増大が認識されており、ホワイトハウスのAI安全保障に関する自主的なコミットメントへの署名、英国とソウルでのAI安全サミットへの参加、G7 AI広島プロセス行動規範への準拠など、様々な取り組みが進められているとされています。

### RAI目標への準拠確保

各RAI次元への準拠を測定・確保するために、以下の方法を採用していると述べられています。

（１）モデル行動を支配する次元（安全性、公平性、真実性と堅牢性、制御可能性、プライバシーとセキュリティ）  
事前学習データのキュレーションと、教師付き微調整（SFT）および人間からのフィードバックによる [強化学習](https://ai-data-base.com/archives/26125 "強化学習") （RLHF）を用いたモデルの調整を実施。

（２）実行時の入出力モデレーション  
最初と最後の防衛線として機能させ、新たに特定された脅威やモデル調整のギャップに迅速に対応。

（３）厳密なガバナンス方法論  
設計段階からRAIを組み込んだ製品開発プロセスを実施。

### 評価とレッドチーミング

RAIの評価には、BOLD、RealToxicityPrompts、MM-SafetyBenchなどの公開ベンチマークと、動的に更新される独自のベンチマークの両方が用いられていると報告されています。さらに、内部レッドチーミング、第三者および専門家によるレッドチーミング、自動化されたレッドチーミングという3つのアプローチを組み合わせた包括的な評価戦略が採用されているとのことです。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80001_f4-1024x652.png)

Novaモデルの安全性評価に使用された攻撃テクニック（attack techniques）の分類体系を示した図

## まとめ

本記事では、新しく発表されたNovaモデル群のテクニカルレポートを分析しました。

性能評価においては、従来のテキスト処理能力の評価指標であるMMLUやARC-C、DROPなどに加え、マルチモーダル処理能力を測定するMMUMやChartQA、DocVQAなど、多岐にわたるベンチマーク評価が実施されています。多くの指標で注目すべきスコアを達成しているだけでなく、実行速度に関しても優れているようです。

なお、安全性への取り組みについては、複数の専門機関との連携による評価体制の構築など、体系的なアプローチが見られます。

今後主に使用されるモデルの一つとなる可能性があるため、このような性能や特徴を覚えておくことが役に立つかもしれません。

**参照文献情報**

- タイトル：The Amazon Nova Family of Models: Technical Report and Model Card
- URL： [https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card](https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card)
- 著者：不明
- 所属：Amazon Artificial General Intelligence

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[実際の企業データからなるtext-to-SQLベンチマーク「Spider 2.0」と専門エージェント『Spider-Agent』](https://ai-data-base.com/archives/79831)

[実在する人間1052人の態度と行動をAIでモデル化　インタビューベースのエージェントが人間の回答を85%再現](https://ai-data-base.com/archives/80107)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)