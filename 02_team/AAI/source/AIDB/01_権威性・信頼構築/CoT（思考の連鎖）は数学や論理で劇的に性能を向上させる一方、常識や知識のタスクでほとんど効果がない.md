---
title: "CoT（思考の連鎖）は数学や論理で劇的に性能を向上させる一方、常識や知識のタスクでほとんど効果がない"
source: "https://ai-data-base.com/archives/75942"
author:
  - "[[AIDB Research]]"
published: 2024-09-24
created: 2025-06-13
description: "本記事では、LLMにおける思考の連鎖（Chain-of-Thought, CoT）プロンプティングの効果を包括的に評価した研究を紹介します。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、LLMにおける思考の連鎖（Chain-of-Thought, CoT）プロンプティングの効果を包括的に評価した研究を紹介します。

研究者たちは、100以上の論文を対象とした分析と、14のモデルを用いた20のデータセットでの独自の評価を行いました。CoTがどのようなタスクで効果的なのか、そしてなぜ効果があるのかを明らかにすることを目的としています。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75942-1024x576.jpg)

**参照論文情報**

- タイトル：To CoT or not to CoT? Chain-of-thought helps mainly on math and symbolic reasoning
- 著者：Zayne Sprague, Fangcong Yin, Juan Diego Rodriguez, Dongwei Jiang, Manya Wadhwa, Prasann Singhal, Xinyu Zhao, Xi Ye, Kyle Mahowald, Greg Durrett
- 所属：The University of Texas at Austin, Johns Hopkins University, Princeton University

**本記事の関連研究**

- [LLMの推論能力を戦略的に向上させる新しいプロンプト手法『SCoT』](https://ai-data-base.com/archives/75505)
- [反復学習でCoTによる推論性能を向上させる手法 Metaとニューヨーク大学による研究](https://ai-data-base.com/archives/69296)
- [CoTの推論ステップ数がLLMの推論能力に及ぼす影響を詳細に検証した結果](https://ai-data-base.com/archives/62364)

## 背景

LLMの推論能力を引き出す方法として、CoT手法が広く使われるようになりました。CoTを使うと、人間が理解しやすい説明を作り出せると同時に、複雑な問題を解くときに途中の計算をしやすくなります。

しかし、CoTがどんな種類の課題で本当に役立つのかは、詳しくはよくわかっていませんでした。そこで今回研究者たちは、100以上の論文を詳しく調べ、さらに14種類のモデルと20の異なるデータセットで新たに評価を行いました。

これらの調査でわかったのは、CoTが特に効果を発揮するのは、数学や論理に関する課題だということです。それ以外の種類の課題では、CoTの効果はあまり大きくありませんでした。

この結果を受けて研究者たちはさらに詳しく調べ、最終的に二つのことが明らかになりました。

以下では、まずCoTとはそもそもなにか？という段階から詳しく紹介します。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75942_figure1-1024x484.jpg)

CoTと直接回答の性能差を示し、数学や記号推論タスクでCoTが最も効果的であることを示す

## CoTについての背景

### 推論タスクとは

まず、推論タスクについて説明しましょう。

推論タスクとは、質問と答えのペアです。質問は言葉の組み合わせで作られており、答えは質問によって決まる選択肢の中から選ばれます。答えの形は様々で、「はい」か「いいえ」、数字、選択肢から選ぶもの、質問の中に出てきた名前など、いろいろあります。

推論能力を試すベンチマークには色々あり、用途に応じて使い分けます。ただしBiGGen Benchというデータセットは少し特殊で、長い文章の回答をLLMが採点します。

### プロンプティング

次に、LLMの使い方を説明します。

LLMは、文章の続きを予測するのが得意です。通常は、質問を含む指示（プロンプト）を与えて、LLMに回答を作ってもらいます。その後、LLMの出力から必要な答えの部分を取り出します。

### 直接回答とCoTの違い

LLMの答え方には2種類あります。

すぐに答えだけを言う方法を直接回答と呼び、一方で考え方の過程も含めて答える方法がCoTです。

どちらの場合も、LLMの出力から正しい形の答えを取り出す必要があります。CoTの場合は、推論ステップの中から最終的な答えを見つける作業が追加で必要になります。

LLMに答えてもらう時の指示の仕方はそれぞれで異なり、直接回答を求めるプロンプトは「すぐに答えを言ってください」などになります。それに対してCoTを求めるプロンプトは「順を追って考えてください（Let’s think step by step）」などです。

なお、LLMは大抵の場合、この指示通りに答えてくれますが、時々違う答え方をすることもあります。

### 記号的推論について

最後に、記号的推論というものについて説明します。

記号的問題とは、決まったルールで解ける問題のことです。

例えば、「12 × 4」という計算問題は記号的問題です。一方、「晴れた日に川のどこで水を汲めるか」という問題は、決まったルールがないので非記号的問題です。

記号的な問題と非記号的な問題の間には、はっきりとした境目がありません。両方の特徴を持つ問題もあります。

ここまでの説明は、以下の研究の内容を理解するためにとても重要な話ですのでよく覚えてください。

## 文献から分かったこと

まず研究者らは、CoTと直接回答の性能を比べた論文を調べました。

### 論文の選び方

まず、ICLR 2024、EACL 2024、NAACL 2024から、全部で4,642本の論文が集められました。その中から、”CoT”、”chain-of-thought”、”chain of thought”という言葉が2回以上出てくる論文516本が選ばれました。

そのあと、CoTと直接回答を比べている論文だけを選ぶように絞込みが行われました。画像も扱うモデル、CoTで特別な訓練をしたモデル、複雑なCoTの使い方、外部ツールを使うシステムは除外されました。

結果として、110本の論文から1,218の実験結果が集められ、264のデータセットがカバーされました。

さらに、集められた実験は14の種類に分けられました。タスクの説明を基に分類されたので、結果の良し悪しは考慮されませんでした。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75942_table1-1024x481.png)

分析で用いたタスクカテゴリーの一部とその説明

### 分かったこと

下の図に、様々なタスクでのCoTの効果が示されています。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75942_figure2-1024x788.jpg)

異なるタスクカテゴリーにおけるCoTの性能向上を示し、数学や論理的推論タスクでの効果が高いことを強調している

主な発見は以下の通りです。

（１）CoTが最も効果的だった分野

- 記号やアルゴリズムを使う問題（平均14.2ポイント改善）
- 数学の問題（平均12.3ポイント改善）
- 論理的な問題（平均6.9ポイント改善）

これら3分野での平均点は、CoTを使うと56.9点でCoTを使わないと45.5点でした。

（２）それ以外の分野での平均点

CoTを使うと56.8点で、CoTを使わないと56.1点でした。これほど小さな改善は、CoTの成功とは見なされません。しかもCoTは計算量が多いため、公平に比べるには計算量を同じにする必要があるという点も見逃せません。

### 数学以外でCoTは役に立つのか

さきほどの図の右側には、数学や論理以外でCoTが効果的だった10の例外が示されました。しかし例外と言っても、何らかの形で論理や数学に関係しているのです。

例えばBIG-bench Hard（BBH）にはアルゴリズムや計算、論理的な考えが必要な問題が多く含まれていました。また法律の議論は文脈を理解する必要がありますが、実は論理的な考えも必要です。

ただし、本当の意味でいくつかの例外もありました（例：ScienceQA=科学に関する質問応答や対話の評価）。

## 実験から分かったこと

今回、研究者たちは先行研究をまとめるだけでなく、自分たち自身が実験も行いました。

### 実験の準備

実験では、20種類のデータセット、14種類のモデルを使用しました。またプロンプトも、ヒントなし（ゼロショット）とヒントあり（フューショット）の2パターンが使われました。

なお、英語のモデルだけが選ばれ、一般的な推論テストで評価された、指示に従うよう調整されたLLMが中心に据えられました。

またデータセットは、記号を使わないもの、少し使うもの、たくさん使うものなど、幅広く選ばれました。答え方の幅も広く、選択式、短い文で答える、自由に答えるなど様々でした。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75942_1-1024x452.png)

実験で使用したモデル、データセット、プロンプト戦略の一覧

### ヒントなしのCoTはどんな時に効果的なのか

結論から言って、主に数学（MATHやGSM8K）や論理（ContextHubやMuSR）を必要とする問題で改善が見られました。

常識や言葉の理解、読解力を問う問題では、CoTと直接回答の間に大きな違いは見られませんでした。一方で、数学や記号を使う問題では大きな改善が見られました。例えば、MATHで41.6%、GSM8kで66.9%も良くなりました。

記号を少し使う問題（ContextHubやMuSR Murder Mysteries）では、ある程度の改善が見られました。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75942_2-1024x528.jpg)

推論カテゴリーごとのCoTの性能向上と、個々のデータセットでの性能

### 答え方の形式はCoTの効果に影響するのか

この点はあまり影響しないことが分かりました。自由に答える問題では、事前に計画を立てたり、正しい答えについて考えすぎたりすると、かえって答えにくくなる可能性が指摘されました。

例を挙げると、MuSiQueデータセットで試された短い答えを求める問題では、複数のステップがはっきりしており、全体的にCoTによる改善は見られませんでした。

一方、BiGGen Benchは自由に答える問題で、LLMが採点役を務めます。CoTを使うと少し良くなりました。

### 知識、柔軟な推論、常識の分野での改善は意味があるのか

ほとんどの場合、意味のある改善は見られませんでした。例外はMMLU、StrategyQA、MuSRです。

これら3つの分野の13のデータセットで、改善に意味があるかどうかが調べられたところ、約38%（58件）で意味のある改善が見られました。そのうちの半分近く（26件）がMMLUとMMLU Proに集中していました。

### MMLUとMMLU Proの詳しい分析

MMLUとMMLU Proは様々な分野を含むため、詳しく調べられました。すると、CoTが最も効果を発揮したカテゴリの多くが数学に関係していました（例：小学校の数学、高校の数学）。

そして数学以外のカテゴリ（例：ビジネス）でも、実は数学的な計算が必要な問題が多く含まれていました。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75942_3-1-1024x213.png)

Llama 3.1モデルでのMMLUとMMLU Proの上位3つのサブカテゴリーにおけるCoTの効果

研究者たちは、質問や答えに「=」記号が含まれるかどうかを手がかりに、CoTの効果を分析しました。すると、「=」を含む質問や答えでCoTが最も効果を発揮していました。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75942_4-1024x368.jpg)

等号（”=”）を含む問題とそうでない問題でのCoTの性能差

以上の結果はCoTが主に数学に関連する問題でMMLUとMMLU Proに役立っていることを示しています。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75942_3-1024x213.png)

## CoTの”形式的推論”における強みと弱み

最後に、CoTが記号を使う問題でどのように機能するかが詳しく調べられました。

### 記号的推論の2つの段階

記号を使う問題の多くは、2つの段階に分けられると考えられます。

まずは計画を立てる段階。問題文から必要な情報が取り出され、解き方の設計図のようなものが作られます。

次に実行する段階。設計図を基に、順番に従って計算が行われ、最終的な答えが導き出されます。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75942_5-1024x407.jpg)

GSM8Kデータセットに対する異なるプロンプト変形の例

### 比較された5つの方法

研究者たちは、以下の5つの方法を比べました。

1. ヒントを与えて直接答えを求める方法
2. ヒントを与えてCoTで解く方法
3. 計画を立てて直接答えを出す方法
4. 計画を立ててCoTで解く方法
5. 計画を立てて外部の計算ツールで解く方法

テストされた問題は、数学（GSM8KとGSM8K-Hard）と論理的な推論（ContextHubとFOLIO）です。

### 分かったこと

主な発見は以下の通りです。

計画を立てるだけでは、性能はあまり良くなりませんでした。CoTや計画を立ててCoTで解く方法が良い結果を示しました。

しかし途中の計算過程を追跡することで、最も大きな改善が見られました。特に数学の多い問題でこの傾向が強く現れました。

ただし、CoTや計画を立ててCoTで解く方法は、ほとんどの場合、計画を立てて外部の計算ツールで解く方法には及びませんでした。LLMは、計算ツールと比べると、計算の実行と追跡に限界があることが示されました。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75942_6-1024x535.png)

数学と論理的推論データセットに対する異なるプロンプト変形の性能を比較

### 結論

これらの結果から、以下のことが分かります。

まず、どんな問題でも、解き方の詳しい説明（計画）があれば役立つ可能性があります。

しかし、CoTが直接答えを求めるより良い結果を出すのは、計算の追跡が多く必要な場合だけです。

そして計算ツールが使える場合、計算ツールはCoTよりも常に良い結果を出します。ただしCoTは、計算ツールほどは完全ではありませんが、広い範囲で活用できるという利点をもちます。

そこで研究者たちは、可能な場合にはLLMを計算ツールと組み合わせて使うことを提案しています。

## まとめ

本記事では、CoTの性能を文献の分析と実験を通じて調べた研究を紹介しました。

研究者らは、CoTが主に数学や記号を用いる論理タスクで大きな改善をもたらすことを発見しました。他のタイプのタスクでは、CoTの効果は限定的でした。また、CoTの主な利点は問題を解くための中間段階を追跡する能力にあることが分かりました。ただし計算ツールを使用する方が正確さは増します。

研究者らは、CoTが多くの自然言語タスクで改善をもたらすためには、プロンプトベースのCoTを超えて、検索、エージェント間の相互作用、より洗練されたファインチューニングモデルなど、新しいパラダイムに移行する必要があると結論づけています。

- 参照論文URL： [https://arxiv.org/abs/2409.12183](https://arxiv.org/abs/2409.12183)
- プロンプトと出力のデータ： [https://huggingface.co/collections/TAUR-Lab/cot-analysis-project-66bbb9e5e0156e65059895f5](https://huggingface.co/collections/TAUR-Lab/cot-analysis-project-66bbb9e5e0156e65059895f5)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[医療のような専門分野におけるLLMの性能は「知識グラフと再ランキングの併用」で大幅に向上（東京大学Irene Li氏）](https://ai-data-base.com/archives/75999)

[LLMの「自己対話」により複雑な問題の解決能力を飛躍的に向上させる手法『Iteration of Thought』](https://ai-data-base.com/archives/76134)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)