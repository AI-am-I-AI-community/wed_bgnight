---
title: "LLMは人間のような「共感的な対話」ができるか？実行プロンプトと検証結果"
source: "https://ai-data-base.com/archives/73786"
author:
  - "[[AIDB Research]]"
published: 2024-08-05
created: 2025-06-13
description: "本記事では、LLMを用いた「共感的な応答」に関する研究を紹介します。研究者らはLLMの共感的な対話能力を実証的に調査し、現状の改善方法を提案しています。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、LLMを用いた「共感的な応答」に関する研究を紹介します。

研究者らはLLMの共感的な対話能力を実証的に調査し、現状の改善方法を提案しています。従来の課題であった”ユーザーの感情理解”と”適切な応答”についての新たな可能性を示しています。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_73786-1024x576.jpg)

**参照論文情報**

- タイトル：Harnessing the Power of Large Language Models for Empathetic Response Generation: Empirical Investigations and Improvements
- 著者：Yushan Qian, Wei-Nan Zhang, Ting Liu
- 所属：Harbin Institute of Technology

## 背景

人と人とのコミュニケーションにおいて、お互いの気持ちを理解し合うことは「共感的な対話」と呼ばれ、社会をよりよくする上で欠かせないものと言われています。  
AIの研究者たちは、コンピューターにも人間のような共感能力を持たせようと努力してきました。

これまでの研究では、比較的小さな規模の言語モデルを使って、共感的な返事ができるようにトレーニングする試みが行われてきました。しかし、LLMが登場したことで、状況が大きく変わりました。

LLMは膨大な情報を学習しており、人間の言葉をよく理解し、適切な返事をすることができます。最近では人間からのフィードバックを活用した新しい学習方法によって、さまざまな場面で人間らしい対話ができるようになりました。

しかし、LLMが本当に共感的な対話をできるのかについては、まだ十分に研究されていません。そこで、研究者たちは、LLMが共感的な返事をどれくらい上手に生成できるのか、そしてそれをさらに改善するにはどうすればいいのかを調べようとしています。LLMと人間のコミュニケーションがより自然で温かいものになることを目指した研究です。

以下で詳しく紹介します。

下記はLLMによる共感的対話の例です。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_73786_1-1024x674.jpg)

人と人の会話

```js
「お金があればなぁ。そしたら彼女はクラブで彼ではなく、僕と一緒に座っているのに。」

「クラブは正しいタイプの女の子を見つけるにはあまり良い場所じゃないよ。」
```

人とAIの会話

```js
「お金があればなぁ。そしたら彼女はクラブで彼ではなく、僕と一緒に座っているのに。」

「君が好きな人が他の誰かと時間を過ごしているのを見るのは辛いよね。でも、お金だけが人の関心を引く唯一の方法ではないと思うよ。彼女と話して、彼女をもっとよく知る努力をしてみたらどうかな。」
```

研究者らは、AIであれば時間や場所を問わず話し相手になれると言います。

## 手法

本研究では、LLMに”良い聞き手”になってもらうことを目指しています。そこで、「話者」と「聞き手」の交互の発言からなる対話コンテキストを基に、聞き手の役割を果たす手法が開発されました。

そして、共感的応答生成のためのプロンプトテンプレートと3つの改善手法が試されました。下の図が全体像を示しています。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_73786_2-1024x482.jpg)

共感的対話生成におけるLLMのための提案手法の全体的な アーキテクチャ と流れ

### 共感的応答生成のためのプロンプトテンプレート

今回は、LLMのコンテキスト内学習の能力に注目し、ファインチューニングなしで共感的対話タスクを実行する可能性が探られました。大量の訓練データを必要としないため手軽な方法です。そして、ゼロショットとフューショットコンテキスト内学習の両方でLLMの性能が調査されました。

プロンプトの影響を考慮し、一貫したスタイルのプロンプトテンプレートが設計されました。テンプレートは以下の要素で構成されています。

1. タスク定義
2. ガイドライン指示
3. 例示（オプション）
4. 対話コンテキスト

実験では、例示の数を変えた3つの設定（0-shot、1-shot、5-shot）が試され、例示の数がLLMの性能にどのような影響を与えるかが調査されました。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_73786_9-1024x383.png)

プロンプトテンプレート

**3つの改善手法**

```js
タスクの定義：
これは共感的な対話タスクです。最初のワーカー（スピーカー）は感情ラベルを与えられ、その感情を感じたときの状況を自分で記述します。その後、スピーカーはその状況を第二のワーカー（聞き手）に会話形式で伝えます。スピーカーの感情ラベルと状況はリスナーには見えません。聞き手は会話の中で他人の感情をできるだけ認識し、受け入れるべきです。

ガイドラインの指示：
あなたは聞き手の役を担い、既存の文脈に基づいて適切な反応をしてください。聞き手の次の応答のみを提供すればよいです。

例：
以下は既存の対話文脈です：インスタンス 1:（トレーニングセットからの完全な対話）

対話コンテキスト：
スピーカー: U₁ リスナー: U₂ ...... スピーカー: Uₙ₋₁

その他：
改善方法のための追加の内容。
```

### 発展的な手法

以下3つの方法が考案されました。

#### 1\. 意味的に類似したコンテキスト内学習

LLMの性能をさらに向上させるため、テストセットの対話コンテキストに意味的に近い訓練セットのインスタンスを選択する手法が提案されました。  
対話コンテキストを長い文に連結し、文エンコーダーを使用してベクトル表現を生成します。そして、コサイン類似度を用いて意味の類似性を測定します。

つまり、テストデータに意味的に近いデータを選んで例示として使用する方法です。より関連性の高い例を用いてLLMの推論を導くことで、性能向上を目指しています。

#### 2\. 二段階対話生成による改善

共感的対話では、話者の感情とその背景となる状況の理解が重要です。そこで、より深い理解に基づいた応答をするために二段階の対話生成プロセスが提案されました。  
第一段階でLLMはユーザーの感情状態と状況を推測し、第二段階ではその推論結果を基に最終的な応答を生成します。

つまり、LLMを2回使用します。最初に感情と状況を推測し、次にその推測結果を用いて応答を生成します。すると、より深い理解に基づいた応答生成を可能になります。

#### 3\. 知識ベースによる改善

対話履歴だけでは十分な情報が得られない場合があるため、外部知識の活用が提案されました。 [ATOMIC20\_20](https://arxiv.org/abs/2010.05953) と [COMET](https://arxiv.org/abs/1906.05317) を使用して、対話コンテキストに関連する常識的推論が生成されます。さらに、これらの推論を動的に対話コンテキストに組み込むアルゴリズムが開発されました。LLMがより豊富な背景知識を基に応答を生成できるようにする手法です。

## 実験セットアップ

### データセット

[EMPATHETICDIALOGUES](https://github.com/facebookresearch/EmpatheticDialogues) がベンチマークデータセットとして採用されました。英語による多ターンの共感的対話から構成されています。各対話には感情ラベル（全32種類）と、その感情に対応する状況が付与されています。対話の流れとしては、話し手が自身の状況について語り、聞き手がその感情を理解し適切に応答するという形式が取られています。

### 比較モデル

最新の先行研究モデルとLLMの性能が比較されました。比較対象となったモデルは以下の通りです。

1. MoEL：複数の感情特化デコーダーを使用し、適切な感情応答を生成する [Transformer](https://ai-data-base.com/archives/26535 "Transformer") ベースのモデル
2. MIME：感情の極性に基づくクラスタリングと感情模倣を活用した共感的対話生成モデル
3. EmpDG：ユーザーフィードバック、対話レベルおよびトークンレベルの感情を利用する対話生成モデル
4. EC：対話コンテキストの感情原因を特定し、ゲート機構を用いて共感的応答を生成するモデル
5. EmpHi：潜在的な共感意図の分布を理解し、暗黙的・明示的な意図表現を統合するモデル
6. KEMP：常識や感情語彙などの外部知識を活用して感情を理解・表現する対話生成モデル
7. CEM：常識知識を活用し、感情的・認知的側面を組み合わせて共感的表現を強化するモデル
8. CASE：常識認知グラフと感情概念グラフを用いて、ユーザーの認知と感情を粗粒度・細粒度で整合させるモデル
9. BlenderBot：複数のスキルを持つオープンドメインチャットボットで、共感的対話にも適用可能

### 評価指標

自動評価と人手評価の両方が実施され、可能な限り多くの指標が選択されました。

#### 自動評価

主な自動評価指標として、以下が採用されました。

- Distinct-n (Dist-1/2)：応答の多様性を測定する
- BERTscore (P\_BERT, R\_BERT, F\_BERT)：BERTの事前学習済み埋め込みを利用して、候補文と参照文の単語をコサイン類似度でマッチングする
- BLEU-n (B-2/4)：生成された応答とゴールデン応答の類似性と関連性を測定する

また、一部のベースラインモデルが感情分類を学習プロセスの一部として行っているため、感情予測精度（Acc）も報告されています。

#### 人手評価

テストデータセットから無作為に100の対話が [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") されました。対話コンテキストとモデルによって生成された応答が提示され、3人の評価者（多数決ルール）が以下の4つの観点から1から5のスコアを付与しました。

1. 共感性（Emp）：ユーザーの感情と経験の理解度、適切な表現をしているか
2. 一貫性（Coh）：応答の文脈との一貫性と関連性があるか
3. 情報量（Inf）：応答に含まれる価値ある情報の量
4. 流暢さ（Flu）：応答の読みやすさ

さらに、異なるモデル間を直接比較するA/Bテストも実施されました。評価者は、2つの異なる手法によって生成された応答のペアを提示され、上記4つの観点に基づいてより優れた応答を選択しました。

### 実装の詳細

OpenAIのGPTファミリーがLLMとして使用されました。gpt-3.5-turboモデル、GPT-3 davinciおよびGPT-3.5の別バージョン（text-davinci-003）もテストされました。出力の決定性を高めるため、温度パラメータは0に設定されました。

データセットは、訓練セット：検証セット：テストセットが8:1:1の比率で分割されました。公平な比較のため、すべての最先端モデルのパラメータ設定は、それぞれの初期論文やコードで推奨されている設定に合わせられました。

## 結果と分析

### 基本的な結果

プロンプトテンプレートを用いたLLM（とコンテキスト内学習）とベースラインの自動評価結果が下の表に示されています。本手法は既存の最先端ベースラインを大きく上回り、すべての自動評価指標で顕著な改善が見られました。中でも、多様性の面で優れた結果が得られました。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_73786_3-1024x814.png)

LLMとベースラインの自動評価結果の比較

Dist-1/2指標（多様性の測定）では、LLMはそれぞれ51.8%と92.7%の改善を達成し、多様な言語表現（主に単語と二語連鎖）においてLLMの大きな優位性が示されました。BERTScoreとBLEUに関しては、LLMはそれぞれ平均2.1%と26.95%の改善を達成しました。LLMが文脈から学習する能力が未知の特定のタスクに迅速に適用できることを示しています。

また、例示の数が多様性のパフォーマンスと正の相関関係にあることが観察されました。例示の追加がLLMの言語習慣に影響を与える可能性を示唆しています。

人間による評価では、自動評価指標のほとんどで最高のパフォーマンスを示したChatGPT+5-shotが代表として選ばれました。人間による評価結果とA/Bテストの結果が以下2つの表にそれぞれ示されています。ChatGPTはすべての側面でベースラインを大きく上回り、共感的で一貫性があり、情報量の多い応答を生成する能力が優れていることが実証されました。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_73786_4-1024x625.png)

ChatGPTと競合するベースラインに関する人間評価の結果

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_73786_6-1024x441.png)

人間によるA/Bテストの結果（側面ごと）

さらに、ベースラインのスコアが以前の研究よりも低くなっていることが注目されました。これは、ChatGPTの共感的対話における優れたパフォーマンスが相対的に評価基準を引き上げたためと考えられます。A/Bテストでは、70%以上のケースで人間の評価者がChatGPTによって生成された応答を好むという結果が得られ、この見解が裏付けられました。

流暢さについては、既存のモデルによって生成された応答がすでに流暢であるため、モデル間に大きな差は見られませんでした。

### 改善手法の結果

LLMに対する高度な探索の実験結果が下記に示されています。全体として、提案された3つの改善方法によって生成された応答は、人間のA/Bテストにおいてすべての側面で元のChatGPTによって生成された応答よりも好ましく評価されました。これらの結果は、文脈内の例示の選択、二段階の対話生成、文脈に関連する知識の強化の有効性を検証しています。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_73786_5-1024x294.png)

高度な探索に関する自動評価の結果

自動評価では、意味的に類似した文脈内学習（Similar ICL）の改善方法が最も優れたパフォーマンスを示しました。これは、ほとんどの自動評価指標が正解に近い応答を好む傾向があるためと考えられます。しかし、より多くの思考や情報を導入することで、人間が好む適切な応答であっても、正解から逸脱する可能性があります。

さらに、正しく推論された感情や状況が生成された応答に与える影響を検証するため、二段階の対話生成の変形実験が行われました。最初の段階でのモデルの思考出力を真の感情と状況で個別に置き換えることで、BERTScoreとBERT指標の両方が向上しましたが、多様性が失われる結果となりました。

### ケーススタディ

下の表に、5つの競合するベースラインとLLMの提案手法によって生成された応答が示されています。ほとんどのベースラインはユーザーの感情を理解していますが、単純な慰めの応答（「大丈夫になるよ」）しか提供していないことが観察されます。中ではBlenderbotはより多くの情報を含む応答を生成していますが、理由や提案を示さずにユーザーのアイデアを支持するにとどまっています。他のベースラインと比較して、今回提案された手法はユーザーの感情を十分に理解し、より共感的で一貫性があり、情報量の多い応答を生成しています。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_73786_7-1024x506.png)

ベースラインとLLMから生成された応答の例

意味的に類似した文脈内学習の方法（+SS ICL）は、関連するインスタンスから学習することで、ユーザーの悲しい感情を和らげるための追加の提案を提供しています。

二段階の対話生成の方法（+Two-stage）は、推論されたユーザーの感情と状況をより具体的に応答に反映しています。

知識ベースとの組み合わせ方法（+Knowledge）は、常識的推論に基づいて関連性の高い共感的な応答を生成しています。

```js
文脈
スピーカー: 理想の女性が他の人を好きだと思います。それでとても悲しいです。
リスナー: おお、それはお気の毒に。彼女に話しかけてみましたか？
スピーカー: 彼女が1ヶ月間国外にいるので、彼女が戻ってきたら話すつもりです。

EmpHi：きっと彼女は大丈夫だよ。
KEMP：君ならきっとうまくいくよ！
CEM：まあ、きっと大丈夫だよ。
CASE (SOTA)：彼女は大丈夫だと思うよ。
Blenderbo：それはいい考えだね。きっと何とかなるよ。
ChatGPT：いいプランだね。自分の気持ちをちゃんと伝えることは大事だよ。うまくいくといいね。
+ SS ICL： いいプランだね。彼女に自分の気持ちや心配を伝えることは大切だよ。その間は、自分が楽しくなれることに集中してみて。
+ Two-stage：理想の彼女とのことについて悲しんでるのはかわいそうだね。こういう状況って、特に相手が外国にいるときは、乗り越えるのが大変だと思うよ。彼女が戻ってきたら、どんなふうに話を進めるか考えたことある？
+ Knowledge：大変だね。でも、彼女が戻ってきたときに話しかける予定なんだね、それはいいことだと思うよ。うまく話せて、気持ちがはっきりして落ち着けるといいね。
```

### LLMによる人間の評価者のシミュレーション分析

LLMが共感的応答の生成で優れたパフォーマンスを示したことから、他のモデルのパフォーマンスを評価するためにLLMを人間の評価者のシミュレーションに使用できるかどうかが検討されました。人間の評価者と比較して、後者はコストが低く、時間の消費も少ないという利点があります。そこで、GPT-4を評価者として採用し、同じ設定でA/Bテストが実施されました。

人間の評価者とGPT-4のパフォーマンスを評価するために、スピアマン [相関係数](https://ai-data-base.com/archives/26481 "相関係数") とケンドールのタウ [相関係数](https://ai-data-base.com/archives/26481 "相関係数") が使用されました。なおスピアマン [相関係数](https://ai-data-base.com/archives/26481 "相関係数") は、2つのデータセットの間の関係を調べる方法です。データが「どれだけ一緒に上がったり下がったりするか」を確認するために使います。一方、ケンドールのタウ [相関係数](https://ai-data-base.com/archives/26481 "相関係数") も、2つのデータセットの関係を調べますが、データの「並び順」に注目しています。順位がどれだけ一致しているかを見るために使います。

結果は下の表に示されています。GPT-4は共感の側面で人間の評価者との最高の相関を達成したことが観察されました。  
すべての側面でGPT-4と人間の評価者との間にかなり良好なスピアマン [相関係数](https://ai-data-base.com/archives/26481 "相関係数") とケンドールのタウ [相関係数](https://ai-data-base.com/archives/26481 "相関係数") が得られ、共感の側面で最高の相関が達成されました。つまり、LLMが人間の評価者をシミュレートする可能性が示唆されています。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_73786_8-1024x412.png)

人間評価者とGPT-4の間の異なる側面におけるスピアマン 相関係数 とケンドールのタウ

## まとめ

本記事では、LLMの共感的応答生成能力を調査し、その改善方法を提案する研究を紹介しました。

いくつかの実験結果により、研究者らが提案した基本的な手法および3つの改善方法の有効性が確認されました。

今後は、共感表現の文化的差異などを考慮した研究が期待されています。

- 参照論文URL： [https://arxiv.org/abs/2310.05140](https://arxiv.org/abs/2310.05140)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[画像と「動画」の中にあるものを認識する『SAM 2（Segment Anything 2）』をMetaが開発](https://ai-data-base.com/archives/73710)

[LLMベースの万能エンジニアを構築する『OpenHands（旧OpenDevin）』プラットフォーム](https://ai-data-base.com/archives/73891)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)