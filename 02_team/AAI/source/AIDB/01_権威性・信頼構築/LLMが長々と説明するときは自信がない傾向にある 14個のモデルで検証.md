---
title: "LLMが長々と説明するときは自信がない傾向にある 14個のモデルで検証"
source: "https://ai-data-base.com/archives/78828"
author:
  - "[[AIDB Research]]"
published: 2024-11-20
created: 2025-06-13
description: "本記事では、LLMが「答えに自信がない時ほど言葉を重ねてしまう」という興味深い現象について、最新の研究成果を紹介します。人間にも見られる特徴でありながらLLMの性能や効率性に大きな影響を与えていることが明らかになってきました。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、LLMが「答えに自信がない時ほど言葉を重ねてしまう」という興味深い現象について、最新の研究成果を紹介します。

人間にも見られる特徴でありながらLLMの性能や効率性に大きな影響を与えていることが明らかになってきました。

ペンシルベニア州立大学の研究チームは、14の最新LLMを対象に包括的な分析を行い、この現象の本質に迫りました。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78828-1-1024x576.jpg)

**参照論文情報**

- タイトル：Verbosity ≠ Veracity: Demystify Verbosity Compensation Behavior of Large Language Models
- 著者：Yusen Zhang, Sarkar Snigdha Sarathi Das, Rui Zhang
- 所属：Penn State University

**本記事の関連研究**

- [LLMにおける長文処理能力の進化を調査 Claude 3.5は情報の流れを追跡するスキルに長ける](https://ai-data-base.com/archives/78379)
- [直感に頼るようなタスクだとLLMに「ステップバイステップで考えて」は逆効果](https://ai-data-base.com/archives/78145)
- [LLMの「知っているのに嘘をつく」幻覚と「知らないから間違える」幻覚の違い](https://ai-data-base.com/archives/78047)

## 背景

LLMには、人間と同様に、答えに自信が持てない時ほど必要以上に言葉を重ねて説明してしまう傾向があることが観察されています。このような冗長な回答は、ユーザーの理解を妨げ、効率を下げる原因となっています。また、不要な単語を余分に生成することで、LLMサービスの応答時間が長くなったりコストが増加したりする問題も引き起こしています。

これまでには、LLMの生成する文章の冗長さに着目した研究や、LLMが不確実な状況でどのように振る舞うかについての研究、 [強化学習](https://ai-data-base.com/archives/26125 "強化学習") を使ってLLMの応答の長さを最適化する研究などが行われてきました。また、LLMの不確実性を数値化する手法や、複数のLLMを効率よく使い分ける方法についても研究が進められてきました。

しかし、LLMのこの「答えに自信がない時ほど言葉を重ねてしまう」という現象そのものを定義し、なぜそうなるのかを探り、改善する方法を提案した研究はこれまでありませんでした。そこで今回ペンシルバニア州立大学の研究者らでは、この現象を「簡潔に書くよう指示されているにもかかわらず、情報を失うことなく短く書き直せるような回答を生成してしまう行動」と定義し、調査することにしました。

研究者らは既存の長文質問応答データセットと推論ベースの言語理解データセットを組み合わせて新しい評価基準を作成し、14の最新のLLMについて詳しい分析を実施しました。その結果、さまざまな興味深い事実が浮かび上がってきました。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78828_1-1024x327.jpg)

簡潔な回答と冗長な回答の比較。1つ目は簡潔で正確、2つ目と3つ目は質問の繰り返しや曖昧さを含む冗長な回答を示している

## 「冗長性の補償」の定義と研究アプローチ

私たちは、答えに自信がないとき、必要以上に言葉を重ねてしまう傾向があります。「とりあえず色々な答えを言ってみて、どれかが当たっているといいな」という心理が働くためです。

実は、LLMにも同じような傾向があることが発見されました。これを「冗長性の補償」と呼んでいます。この問題は二つの点で好ましくありません。

- 利用者にとっては、無駄に長い回答は理解を妨げ、時間の無駄になります
- システムにとっても、余計な処理が必要になり、コストと時間がかかります

そこで今回の研究では、LLMの冗長性の補償について詳しく調べ、それを改善する方法を探ることにしました。

### 研究の進め方

まず、LLMの冗長性を以下のような方法で調べることにしました。

データセットには、元となる文章と、それについての質問、そして正解が用意されています。LLMはこれらを読み込み、「できるだけ簡潔に答えてください」という指示とともに回答を作り出します。これを「簡潔な質問応答」と呼んでいます。

LLMには一度に処理できる文章の長さに制限があるため、長い入力文章は適切な長さに区切って与えられます。

ある回答が「冗長」かどうかは、その内容を変えることなく、もっと短く言い換えられるかどうかで判断します。これを自動的に判定する仕組みがあり、冗長な場合は1、そうでない場合は0という値を出します。

### 性能との関係

冗長な回答をする傾向には、回答の質にも影響があることがわかっています。これを調べるために、2つの物差しが使われています。

1. 簡潔な回答の平均点から、冗長な回答の平均点を引いた値です。もし冗長さが回答の質に関係ないのなら、この値は0になるはずです。
2. 上記の差を全体の点数で割った値です。異なるデータセットや異なるLLM同士を公平に比較できます。

### 不確実性との関係

人間が答えに自信がないときに言葉を濁したり回りくどい表現をしがちなように、LLMの冗長な回答も、答えに対する不確実さと関係があると考えられています。この関係を調べるため、LLMの回答がどれくらい迷いを含んでいるのかを数値化して分析しています。

### 改善方法

一つのLLMで簡潔で正確な回答を得るのは難しいため、複数のLLMを組み合わせる方法が考え出されました。まず性能の低いLLMで回答を作り、それが冗長だった場合は、より性能の高いLLMに切り替えていくという仕組みです。これにより、無駄な言葉を減らしながら、より質の高い回答を得ることができます。

## 実験のセットアップ

### データセットの構築

データセット作成には2つの重要な原則に従ったとのことです。

1つ目は、サンプルの質を高く保つことです。質問は人手で注釈付けされた既存のデータセットから選ばれ、明確な答えがあるものに限定しています。また、はい/いいえ型、正誤判定型、選択式の質問は除外し、自由な回答を必要とするものだけが採用されました。

2つ目は、LLMにとって適度な難しさを持たせることです。もし [正解率](https://ai-data-base.com/archives/25930 "正解率") が100%に近いと、モデルは確信を持って答えてしまい、冗長性の現象が観察しにくくなります。そのため、知識を問う問題と推論を必要とする問題という2種類の問題が用意されました。

### 知識を問う質問応答

長い文章から知識を抽出する能力を試すため、4つのデータセットが用意されました。

まず「Qasper」は、 [NLP](https://ai-data-base.com/archives/26319 "自然言語処理（NLP）") （ [自然言語処理](https://ai-data-base.com/archives/26319 "自然言語処理（NLP）") ）の論文についての質問で構成され、平均4,120語程度の文章を扱います。

次に「Lon [gB](https://ai-data-base.com/archives/26343 "勾配ブースティング") ench」は、複数のデータセットを組み合わせたもので、平均9,522語程度の文章を含みます。

「NarrativeQA」は本や映画の台本についての質問で、平均70,340語という最も長い文章を扱います。

最後に「NQ30」は30個の文書の中から必要な情報を見つけ出す必要がある質問で、平均3,602語程度の文章を使用します。

### 推論を必要とする質問応答

MMLUデータセットが改変して使用されました。選択肢をヒントとして使い、自由な形式で回答を生成する必要があるように設計されています。

### 実験の条件

すべてのデータセットについて、正解が4語以下の質問のみ使用されました。人手でサンプルを確認したところ、4語という制限が、簡潔さと説明の十分さのバランスが取れる長さだとわかったためです。

各データセットは最大500サンプルとし、それを超える場合はランダムに500サンプルを選びました。モデルの性能評価には [再現率](https://ai-data-base.com/archives/26095 "再現率") を使い、カスケードモデルの評価には [F1スコア](https://ai-data-base.com/archives/26112 "F1スコア（F値）") が採用されていいます。

### 使用したモデル

実験には14種類のLLMが使用されました。Mistral、Mixtral、Llama、Gemmaといったオープンソースのモデルと、GPT、Claude、Geminiというクローズドソースのモデルです。

すべてのモデルには「できるだけ簡潔に、可能なら一つのフレーズで回答してください」という共通の指示が与えられて実験が行われました。

## 結果と分析

### 冗長性補償の発生頻度

すべてのモデルとデータセットにおいて、冗長性補償の振る舞いが観察されました。平均すると、mistral-7bでは74.19%の回答が冗長だと判断されました。最も良い結果を示したのはllama3-70bで、冗長な回答は13.62%に抑えられました。

また、7つのオープンソースモデルの平均は39.80%であり、これはクローズドソースモデルの28.96%と比べて明らかに高い値であることが示されました。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78828_2-1024x509.jpg)

オープンソースモデル(a)とクローズドソースモデル(b)における冗長性補償の頻度。全モデルで冗長性が見られ、llama3-70bが平均して最も低い頻度を示した

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78828_3-1024x245.jpg)

5つのデータセットにおける冗長性補償行動の人手による分類結果。モデルとデータセットによって異なるパターンを示している

### 冗長性補償の5つのパターン

冗長な回答のパターンを人手で分類したところ、5つの種類に分けられることが明らかにされました。

1. 正確な回答を避けた表現が使われる
2. 質問文の一部を繰り返したり、関係のない情報が含まれる
3. 正解を含むことを期待して複数の答えが並べられる
4. 必要以上に詳しい説明が加えられる
5. 不必要な形式的な表現が使われる

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78828_4-1024x155.png)

5つの冗長性補償タイプの具体例

パターンの出現頻度は、モデルやデータセットによって大きく異なることが示されました。例えば、gemini-1.5-flashはMMULデータセットでは質問の繰り返し（67.86%）が多く、Qasperデータセットでは列挙（47.62%）が主なパターンとなっています。

一方、llama-3-80bはQasperデータセットにおいて、詳細な説明（32.87%）が主なパターンとして観察されました。結論として、データセットやモデルによって冗長性の現れ方に大きな違いがあることが明らかにされました。

### 冗長性補償と性能の関係

ほとんどのデータセットとタスクにおいて、冗長な回答と簡潔な回答の間で性能に明確な差が見られることが明らかにされました。知識ベースの質問と推論ベースの質問の両方で確認されています。

注目すべき点として、ほとんどのケースで冗長な回答の方が性能が低くなることが示されました。例えば、llama3-70bではQasperデータセットにおいて27.61%もの性能差が観察されました。

モデル別に見ると、gemini-pro-1.0が最も小さな性能差（平均7.92）を示し、gemma-2-27bが最も大きな差（平均19.15）を示すことが明らかにされました。しかし、すべてのモデルにおいて性能と冗長性の間の関係を完全に切り離すことはできず、この点の改善が急務であることが示されました。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78828_5-1024x378.png)

短文（Qasper）、中文（Lon gB ench）、長文（NarrativeQA）データセットにおける冗長vs簡潔な回答の正確性の比較

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78828_6-1024x474.png)

NQ30とMMLUデータセットにおける冗長vs簡潔な回答の正確性の比較

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78828_7-1024x622.png)

モデルの能力（ELOスコアとコンテキスト長）とδの 相関係数

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78828_8-1024x180.png)

Chain-of-Thought生成における正確性の差異を示す結果

### モデル性能と冗長性の関係

モデルの能力と冗長性の関係を調べるため、2つの観点から分析が行われました。

1つ目は一般的な性能で、これはChatBot Arenaのスコアを用いて評価されました。2つ目は長い入力を処理する能力で、これは文脈ウィンドウサイズの対数を用いて測定されました。

分析の結果、Qasper、Lon [gB](https://ai-data-base.com/archives/26343 "勾配ブースティング") ench、NarrativeQAのデータセットでは、強い負の相関が観察されました。モデルの性能が高くなるほど、冗長性の影響が小さくなることを示しています。

一方で、MMLUとNQ30のデータセットでは、明確な相関は見られませんでした。このことから、単にモデルを強化したり文脈ウィンドウを拡大したりするだけでは、冗長性と性能の関係を完全に解決することはできないことが示唆されました。

### 不確実性との関連

図に示されるように、すべての4つのモデルにおいて、回答の長さが増えるほど不確実性が高まることが観察されました。中でも回答が3トークンを超えるあたりから、不確実性が急激に上昇することが明らかにされました。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78828_9-1024x187.jpg)

全データセットで平均した不確実性スコア。生成される出力の長さが増えるほど不確実性が増加することを示している

これらの結果から、2つの重要な点が示されました。1つ目は、LLMが長い回答を生成する際には、より大きな不確実性を抱えているということです。2つ目は、冗長性補償が発生する場合、LLMは簡潔な回答を生成する場合と比べて、より大きな不確実性を持っているということです。

### カスケードモデル選択による冗長性の軽減

カスケードモデル選択とは、複数のLLMを性能の低いものから順に使っていく仕組みです。

1. まず性能の低い（計算コストの安い）LLMで回答を生成させます
2. その回答が冗長だと判定された場合、次に性能の高いLLMを試します
3. 簡潔な回答が得られるか、もしくは最も性能の高いLLMまで試し終わるまで、これを繰り返します

この方法が優れているのは、簡単な質問には単純なモデルで対応でき、難しい質問には自動的により強力なモデルが使われるため、コストと質のバランスが取れるからです。実験では、MistralとGPT-4を組み合わせた場合、冗長な回答の割合が63.81%から16.60%まで減少するという良好な結果が得られました。他にも、弱いモデルと強いモデルの両方で観察されました。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78828_10-1024x443.png)

異なるカスケードモデルの組み合わせによる冗長性補償の頻度

### LLMルーティングへの応用

カスケードモデル選択は、LLMルーティング（適切なモデルの選択）にも応用されました。図5に示されるように、異なるデータセットと3つのルーティング設定での性能が検証されました。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78828_11-1024x555.jpg)

1サンプルあたりの平均コストとF-1スコアの関係。提案手法が全データセットでベースラインを上回ることを示している

実験の結果、すべてのモデル、データセット、設定において、ルーティングの性能がベースラインを上回ることが示されました。特筆すべき点として、GemmaからGemini-1.5へのルーティングでは、両方の個別モデルの性能を上回る結果が得られました。

以上の結果から、ルーティングアルゴリズムがすべての設定で性能を改善し、より少ないコストで強いモデルの性能を超えることができることが示されました。

## まとめ

本記事では、LLMにおける冗長な回答の特徴と、その背後にある不確実性との関連を分析したペンシルベニア州立大学の研究を紹介しました。

研究チームは、LLMの冗長な回答を5つのタイプに分類し、すべてのモデルでこの現象が高い頻度で発生していることを明らかにしました。また、モデルが不確実性を感じているときほど冗長な回答をする傾向があることも確認されました。

これらの問題に対して、研究チームはカスケードモデル選択アルゴリズムという単純ながら効果的な手法を提案しています。この手法を使うと、例えばMistralモデルではQasperデータセットにおける冗長な回答の頻度を63.81%から16.16%まで低減できることが示されました。今後は、この研究成果をもとに、より効率的で正確なシステムの開発が進むことが期待されます。

- 参照論文URL： [https://arxiv.org/abs/2411.07858](https://arxiv.org/abs/2411.07858)
- コード： [https://github.com/psunlpgroup/VerbosityLLM](https://github.com/psunlpgroup/VerbosityLLM)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[LLMプロジェクト開発に必要な新しい概念「AgentOps」とは](https://ai-data-base.com/archives/78733)

[Claude 3.5 Computer Useのケーススタディ集　示唆される「GUIエージェントの夜明け」](https://ai-data-base.com/archives/78895)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)