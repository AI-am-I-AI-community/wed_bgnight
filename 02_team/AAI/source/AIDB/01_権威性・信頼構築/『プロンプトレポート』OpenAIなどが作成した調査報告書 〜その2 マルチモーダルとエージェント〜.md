---
title: "『プロンプトレポート』OpenAIなどが作成した調査報告書 〜その2 マルチモーダルとエージェント〜"
source: "https://ai-data-base.com/archives/71094"
author:
  - "[[AIDB Research]]"
published: 2024-06-18
created: 2025-06-13
description: "前回に引き続き、「プロンプトレポート」の紹介記事です。メリーランド大学、OpenAI、スタンフォード大学、Microsoftなどの研究者らが、プロンプト技術の体系的な理解を提供することを目的に作成した調査報告書です。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

[前回](https://ai-data-base.com/archives/70953) に引き続き、「プロンプトレポート」の紹介記事です。メリーランド大学、OpenAI、スタンフォード大学、Microsoftなどの研究者らが、プロンプト技術の体系的な理解を提供することを目的に作成した調査報告書です。

[その3　プロンプトエンジニアリングのケーススタディ](https://ai-data-base.com/archives/71186) はこちら。

![](https://ai-data-base.com/wp-content/uploads/2024/06/AIDB_71094-1024x576.jpg)

**参照論文情報**

- タイトル：The Prompt Report: A Systematic Survey of Prompting Techniques
- 著者：Sander Schulhoff, Michael Ilie, Nishant Balepur, Konstantine Kahadze, Amanda Liu, Chenglei Si, Yinheng Li, Aayush Gupta, HyoJung Han, Sevien Schulhoff, Pranav Sandeep Dulepet, Saurav Vidyadhara, Dayeon Ki, Sweta Agrawal, Chau Pham, Gerson Kroiz, Feileen Li, Hudson Tao, Ashay Srivastava, Hevander Da Costa, Saloni Gupta, Me [gan](https://ai-data-base.com/archives/26269 "敵対的生成ネットワーク（GAN）") L. Rogers, Inna Goncearenco, Giuseppe Sarli, Igor Galynker, Denis Peskoff, Marine Carpuat, Jules White, Shyamal Anadkat, Alexander Hoyle, Philip Resnik
- 所属：University of Maryland, OpenAI, Stanford, Microsoft, Vanderbilt, Princeton, Texas State University, Icahn School of Medicine, ASST Brianza, Mount Sinai Beth Israel, Instituto de Telecomunicações, University of Massachusetts Amherst

## 背景

プロンプティングは、主に英語のテキストで最も広く使用されています。他の言語やモダリティ（情報の形式）でのプロンプティングには、技術や工夫が必要となると考えられています。

本記事では、以下の内容をお伝えします。

- マルチモーダルプロンプティングの技術と応用例
- エージェントの概念と活用方法
- LLMを用いた評価フレームワークの構築手法

なお、本「プロンプトレポート」は非常に重厚な資料であるため、本メディアでは3部作にわたって内容を紹介しています。

第一回目の記事は [こちら（重要な用語と各種プロンプト手法について）](https://ai-data-base.com/archives/71093)

## 多言語プロンプティング

英語以外の言語、特にデータが少ない言語では、生成AIの出力品質が劣る傾向があります。生成AIが主に英語データで学習されているためです。そこで、様々な多言語プロンプティング技術が開発されています。

![](https://ai-data-base.com/wp-content/uploads/2024/06/AIDB_71094_1-1024x883.png)

#### （１）入力を英語に翻訳する

最もシンプルな多言語プロンプティング戦略の一つです。非英語の入力を英語に翻訳することで、生成AIにコンテンツを理解しやすくします。

#### （２）思考連鎖を多言語に拡張

CoTの発展系として下記の手法が考案されています。

Cross-Lingual Thought (XLT) Prompting: 役割割り当て、言語間思考、CoTなど6つの指示から成るプロンプトテンプレートを用いる手法。

Cross-Lingual Self Consistent Prompting (CLSP): 異なる言語で推論パスを構築し、同一質問に回答するアンサンブル手法。

#### （３）コンテキスト内学習の多言語への適用

同様にコンテキスト内学習を発展させた以下の手法が考案されています。

X-InSTA Prompting: 分類タスクにおいて、入力文と文脈内の例示を整列させる手法。意味的整列、タスクベース整列、両者の組み合わせの3アプローチを検討。

In-CLT (Cross-lingual Transfer) Prompting: ソース言語とターゲット言語両方で文脈内例示を作成する手法。多言語LLMの言語間認知能力を刺激し、タスク性能を向上させる。

#### （４）多言語での文脈内エグゼンプラーの選択

コンテキスト内における例示の選択は、生成AIの多言語性能に大きく影響します。通常、元のテキストに意味的に類似した例示が重要ですが、異なる例示が有効な場合もあります。

#### （５）プロンプトテンプレートの言語選択

多くの場合、英語のプロンプトテンプレートの方が効果的です。生成AIが主に英語データで学習されているためと考えられます。

#### （６）機械翻訳へのプロンプティングの応用

以下の手法が考案されてきました。

**Multi-Aspect Prompting and Selection (MAPS)  
**高品質の出力を確保するために、人間の翻訳プロセスを模倣する手法。ソース文からの知識マイニング（キーワードとトピックの抽出、翻訳例の生成）から始まり、この知識を統合して複数の可能な翻訳を生成し、その中から最良のものを選択する。

**Chain-of-Dictionary (CoD)  
**ソースフレーズから単語を抽出し、辞書から自動的に複数の言語での意味のリストを作成する手法。これらの辞書フレーズをプロンプトの前に付け、翻訳時にそれらを使用するようLLMに求める。

**Dictionary-based Prompting for Machine Translation (DiPMT)  
**CoDと同様に機能するが、ソースとターゲットの言語での定義のみを与え、フォーマットが若干異なる手法。

**Decomposed Prompting for MT (DecoMT)  
**ソーステキストをいくつかのチャンクに分割し、Few-Shotプロンプティングを使用して個別に翻訳する手法。次に、これらの翻訳とチャンク間のコンテキスト情報を使用して、最終的な翻訳を生成する。

**Interactive-Chain-Prompting (ICP)  
**翻訳対象のフレーズにある曖昧さについて、LLMにサブクエスチョンを生成させることで、翻訳の曖昧さに対処する手法。その後、人間がこれらの質問に答え、システムはこの情報を含めて最終的な翻訳を生成する。

**Iterative Prompting  
**初めにLLMに下書き翻訳を作成させる手法。自動検索システムまたは直接的な人間のフィードバックから得られる監督シグナルを統合することでさらに洗練される。

## マルチモーダルプロンプティング

生成AIモデルがテキスト以外の情報を扱うようになり、それに伴い新たなプロンプティング技術が登場しています。従来のテキストベースの手法を応用したものだけでなく、画像や音声といった異なる種類の情報を活用した手法も含まれます。

![](https://ai-data-base.com/wp-content/uploads/2024/06/AIDB_71094_2-1024x340.png)

#### （１）画像プロンプティング

写真、図面、テキストのスクリーンショットなどのデータを含む形式です。画像を含むプロンプト、または画像生成のためのプロンプトを指します。

一般的なタスクには、画像生成、キャプション生成、画像分類、画像編集などがあります。

#### （２）プロンプト修飾子（Prompt Modifiers）

結果の画像を変更するためにプロンプトに追加される単純な単語です。例えば、「キャンバスに」「明るいシーン」などがよく使用されます。

#### （３）ネガティブプロンプティング（Negative Prompting）

ユーザーはプロンプト内の特定の用語に重みを付け、モデルにそれらの用語を重視させる（逆に重視しないようにする）ことができます。例えば、「余分な指」に負の重みを付けると、解剖学的に正確な手を生成しやすくなります。

#### （４）マルチモーダルコンテキスト内学習

テキストベースのコンテキスト内学習（ICL）の成功を受け、研究が進んでいます。

**Paired-Image Prompting  
**画像変換のタスクに適用される手法です。例えば、昼の景色の画像と、それに対応する夜の景色の画像のペアを複数用意します。ペアをモデルに提示することで、「昼の景色を夜の景色に変換する」というタスクをデモンストレーションします。そして、新しい昼の景色の画像をモデルに与えると、モデルは学習したデモンストレーションに基づいて、その画像を夜の景色に変換します。

**Image-as-Text Prompting  
**画像をテキストベースのプロンプトに組み込む手法です。まず、画像をテキストで説明する記述（キャプション）を生成します。例えば、「森の中の小さな家」という画像があれば、「この画像には、緑豊かな森の中に佇む小さな木造の家が写っています」というようなキャプションを生成します。そして、このキャプションをプロンプトの一部として使用することで、画像の情報をテキストベースのプロンプトに自然に組み込むことができます。

#### （５）マルチモーダルCoT

画像を含む数学の問題のプロンプトに「ステップバイステップで解いてください」というテキストの指示を添える方法です。  
様々なドメインに適用することが可能です。

#### （６）音声プロンプティング

音声モダリティにもプロンプティングが拡張されています。実験では、一部のオープンソース音声モデルはICLを実行できない結果も得られていますが、基本的には音声ベースのICLも有効と示されています。

音声プロンプティングはまだ初期段階ですが、今後、様々な技術が提案されることが期待されています。

#### （７）動画プロンプティング

テキストから動画への生成、動画編集、動画からテキストへの生成など、動画モダリティにもプロンプティングが拡張されています。

#### （８）セグメンテーションプロンプティング

[セマンティック](https://ai-data-base.com/archives/26143 "セマンティック") セグメンテーションなどの [セグメンテーション](https://ai-data-base.com/archives/26353 "セグメンテーション") にもプロンプティングが使用されています。

#### （９）3Dプロンプティング

3Dオブジェクト合成、3Dサーフェイステクスチャリング、4Dシーン生成（3Dシーンのアニメーション化）など、3Dモダリティにもプロンプティングが使用されています。

## プロンプティングのさらなる拡張

プロンプティング技術はより複雑になってきており、外部ツールへのアクセスや、出力の有効性を判断する高度な評価アルゴリズムを組み込むようになってきました。以下ではエージェントと評価という2つの主要なトピックについて説明します。

### エージェント

本論文でエージェントは以下のように定義されています。

> 生成AI（通常はLLM）のシステムがユーザーの目標を達成するために、外部のシステムと対話する行動を取ること

LLMの能力向上に伴い、企業や研究者はLLMが外部システムを利用できるようにする手法を模索しています。LLMが数学的計算や推論、事実確認などの分野でまだ課題を抱えているためです。エージェントのような振る舞いをさせるにはプロンプトやプロンプトチェーンの工夫が必要です。

![](https://ai-data-base.com/wp-content/uploads/2024/06/AIDB_71094_3-1024x453.png)

#### （１）ツール使用エージェント

生成AIエージェントにとって重要な要素がツールの使用です。ツールはエキスパートやモジュールとも呼ばれます。記号的ツール（例：電卓、コードインタプリタ）と神経的ツール（例：別のLLM）があります。

#### （２）Modular Reasoning, Knowledge, and Language（MRKL）System

エージェントの最もシンプルな定式化の1つです。複数のツールへのアクセスを提供するLLMルーターが含まれており、天気や現在の日付などの情報を取得するために複数の呼び出しを行い、情報を組み合わせて最終的な応答を生成します。Toolformer、Gorilla、Act-1など複数の手法が提案されています。

#### （３）Self-Correcting with Tool-Interactive Critiquing（CRITIC）

まず外部呼び出しなしでプロンプトに応答を生成し、次に同じLLMがこの応答に対して考えられるエラーを批評します。最後に、インターネット検索やコードインタプリタなどのツールを使用して、応答の一部を検証または修正します。

#### （４）コード生成エージェント

以下の手法が提案されています。

**Program-aided Language Model（PAL）  
**問題をPythonインタプリタに送信されるコードに直接変換し、答えを生成します。

**Tool-Integrated Reasoning Agent（ToRA）  
**PALに似ていますが、単一のコード生成ステップではなく、問題を解決するために必要な限り、コードと推論のステップを交互に行います。

**TaskWeaver  
**ユーザーのリクエストをコードに変換するPALに似ていますが、ユーザー定義のプラグインも利用できます。

#### （５）観測ベースのエージェント

一部のエージェントは、おもちゃの環境と対話することで問題を解決するように設計されています。プロンプトに挿入された観測結果を受け取ります。

#### （６）Reasoning and Acting（ReAct）

問題を解決するために、思考を生成し、行動を取り、観測結果を受け取る手法です（このプロセスを繰り返します）。プロセスを通して得られた手法は、過去の思考、行動、観測の記憶を持つようにプロンプトに挿入されます。

ReActを基にした手法がReflexionで、内省のレイヤーが追加されています。行動と観測の軌跡を取得し、成功/失敗の評価が与えられます。次に、何をしたのか、何が問題だったのかを内省します。内省は、作業記憶としてプロンプトに追加され、プロセスが繰り返されます。

#### （７）生涯学習エージェント

環境と継続的に相互作用しながら、新しい知識やスキルを獲得し続けることができるエージェントのことで、現実世界における生涯学習のプロセスに似ています。Minecraftを舞台にしたLLMエージェントの研究では、エージェントがゲーム内の様々なタスクをこなしながら、新しい能力を身につけていく様子が観察されています。

つまり、Minecraftでのエージェントの行動は、現実世界で生涯学習が必要とされる状況に応用できる可能性を示唆しています。

#### （８）Voyager

自ら学習目標を設定し、その目標を達成するために必要なアクションを自律的に計画・実行し、得られた知識を長期記憶として蓄積するエージェントフレームワークです。例えば、「Webデザインについてもっと学ぶ」という目標を立て、その目標を達成するためにWebデザインに関する記事を読んだり、関連するツールを使ってみたりします。そして、得られた知見を長期記憶に保存し、後から必要に応じて取り出せるようにします。

エージェントが自律的に情報を収集し、学習していく必要がある現実世界のタスク（ペネトレーションテストやユーザビリティテストなど）に応用できると考えられています。

#### （９）Ghost in the Minecraft（GITM）

与えられたタスクを自律的に分割し、サブタスクをこなすことで最終的な目標を達成するエージェントフレームワークです。

例えば、「ダイヤモンドの剣を作る」というタスクが与えられたとします。このタスクを「ダイヤモンドを集める」「棒を作る」「ダイヤモンドと棒を組み合わせて剣を作る」というサブタスクに分割します。そして、これらのサブタスクを1つずつこなしていくことで、最終的にダイヤモンドの剣を作ることができます。その際、GITMはMinecraftの知識ベース（アイテムの作り方など）や過去の経験（どこでダイヤモンドを見つけられるかなど）を活用しながらタスクを遂行します。

#### （１０）検索拡張生成（RAG）

LLMによる文章生成において、関連する情報を外部から検索し、その情報を生成プロセスに活用する手法です。例えば、「アルバート・アインシュタインの生涯について教えてください」というプロンプトが与えられたとします。RAGでは、まずアインシュタインに関する情報がウェブ上（あるいはデータベース上）から検索されます。検索で得られた情報がプロンプトに挿入されることで、より詳細で正確なアインシュタインの伝記を生成することができます。

#### （１１）Verify-and-Edit

LLMが生成した複数の文章を比較・検証し、最も整合性の高い文章を選択・編集することで、文章の質を向上させる手法です。

1. まずLLMに同じトピックで複数の文章を生成させます。
2. 次に、それぞれの文章について、トピックに関連する情報を外部から収集します。
3. そして、収集した情報を基に各文章を評価し、最も整合性の高い文章を選択します。
4. 選択した文章に対しては、外部情報を使ってさらに内容を拡充します。

#### （１２）Demonstrate-Search-Predict

質問応答タスクにおいて、質問を段階的に分解し、各段階で必要な情報を検索・統合することで回答を生成する手法です。

1. まず、与えられた質問を複数のサブクエスチョンに分割します。
2. 次に、各サブクエスチョンに対して関連する情報を検索し、回答を生成します。
3. 最後に、各サブクエスチョンの回答を統合することで、元の質問に対する最終的な回答を生成します。

一連のプロセスを実現するために、Few-Shotプロンプティングが用いられます。

#### （１３）Interleaved Retrieval guided by Chain-of-Thought（IRCoT）

複雑な質問応答タスクにおいて、検索とChain-of-Thought（CoT）を交互に活用することで、質問に対する回答を導出する手法です。

1. まず、与えられた質問に対してCoTを用いて推論ステップを生成します。
2. 各推論ステップにおいて、必要な情報を外部から検索します。
3. 検索で得られた情報を基に、次の推論ステップを生成します。

つまり検索とCoTを交互に繰り返すことで、質問に対する最終的な回答を導き出します。検索はCoTの推論ステップを補助するために使われ、CoTは検索すべき情報を特定するために使われています。

#### （１４）Iterative Retrieval Augmentation

長文生成タスクにおいて、反復的に検索を行うことで生成文章の品質を向上させる手法です。以下の3つのステップを繰り返します。

1. 文章の内容を示唆する短い文（クエリ文）を生成する。
2. クエリ文を基に、関連する情報を外部から検索する。
3. 検索で得られた情報を利用して、次の文章を生成する。

上記のステップを繰り返すことで、文章全体として一貫性のある、詳細な内容を生成することができます。

ここで重要なのは、各ステップで生成されるクエリ文が、単に元の文章のタイトルを使うよりも、検索に適したキーワードを含んでいるという点です。

### 評価

情報抽出・推論能力、ユーザー意図の理解力を活用して、LLMを評価器として使用することが注目されています。例えば、LLMにエッセイを評価させたり、以前のLLMの出力を評価したりすることが可能です。

堅牢な評価器を構築する上で重要な4つの評価フレームワークの構成要素があります。

1. プロンプティング技術
2. 評価の出力形式
3. 評価パイプラインのフレームワーク
4. その他いくつかの方法論

![](https://ai-data-base.com/wp-content/uploads/2024/06/AIDB_71094_4-1024x650.png)

#### （１）プロンプティング技術

評価タスクにおいては、どのようなプロンプティング技術を使うかは非常に重要です。プロンプトを設計する際には、以下のような一般的なテクニックが役立ちます。

**コンテキスト内学習  
**評価タスクに関連する例示をプロンプトに含めることで、LLMが評価基準を理解しやすくなります。例えば、「このように、文法的に正しく、内容も明確な文章は高評価となります。\[例示\]」といった具合です。

**役割ベースの評価  
**LLMに特定の役割（例：厳しい先生、優しい友人など）を与えてから評価をさせると、多様な視点からの評価が得られます。また、複数のLLMに異なる役割を与え、評価対象について議論させる（マルチエージェント設定）ことで、より洞察に富んだ評価が期待できます。

**思考連鎖（Chain-of-Thought）プロンプティング  
**LLMに評価の思考プロセスを段階的に示させることで、評価の精度が向上します。例えば、「まず文章の文法をチェックし、次に内容の論理性を確認し、最後に全体的な印象を評価する」といった指示を与えるイメージです。

**モデル生成ガイドライン  
**評価基準があいまいだと、LLMによる評価がブレやすくなります。そこで、LLMにガイドラインの生成をプロンプトで促し、評価基準を明確化することも有効です。例えば、「高評価の文章の特徴を3つ挙げてください」といった指示で、評価のポイントを具体化できます。

#### （２）出力形式

LLMからの出力形式を工夫することで、評価の精度を高めることができます。

**スタイリング  
**XMLやJSONなどの構造化された形式で出力させると、評価結果が解釈しやすくなります。

**リニアスケール（例：1-5）  
**1〜5点などの数値スケールで評価を出力させるシンプルな方法。LLMに「3点」のように具体的な点数を出力させたり、「3.5点」のように連続値を出力させたりできます。

**[バイナリ](https://ai-data-base.com/archives/26314 "バイナリ") スコア  
**YesかNoの [バイナリ](https://ai-data-base.com/archives/26314 "バイナリ") 形式で評価を出力させる方法。シンプルな2択の評価に適しています。

**リッカート尺度  
**「強く同意する」から「強く反対する」までの5段階評価など、リッカート尺度形式で出力させる方法。LLMにリッカート尺度の各レベルの意味を理解させることが重要です。

#### （３）評価のフレームワーク

評価タスクのためのフレームワークも提案されています。

**LLM-EVAL  
**評価基準（変数のスキーマ）、スコアの範囲、評価対象のコンテンツをプロンプトに含めるシンプルなフレームワーク。

**G-EVAL  
**LLM-EVALに加え、プロンプト内で自動的に思考連鎖ステップを生成し、最終的なプロンプトに組み込むフレームワーク。各ステップの重要度に応じて評価結果に重みづけします。

**ChatEval  
**複数のLLMに異なる役割を割り当て、評価対象について議論させるマルチエージェント評価フレームワーク。

#### （４）その他の方法論

評価スコアの算出方法には、以下のようなバリエーションがあります。

**明示的スコアリング  
**LLMが直接評価スコアを出力する方法。

**暗黙的スコアリング  
**LLMの予測の信頼度、出力の生成尤度、説明（エラー数のカウントなど）、プロキシタスクでのパフォーマンスから間接的にスコアを算出する方法。

また、評価の効率を高めるためのテクニックもあります。

**バッチプロンプティング  
**複数の評価対象を一度にプロンプトに含めて評価する方法。ただし、 [バッチサイズ](https://ai-data-base.com/archives/26582 "バッチサイズ") が大きいと評価精度が下がることも。

**ペアワイズ評価  
**複数の評価対象を一度にプロンプトに含めて評価する方法。ただし、 [バッチサイズ](https://ai-data-base.com/archives/26582 "バッチサイズ") が大きいと評価精度が下がることも。

以上のように、LLMを評価タスクに活用する際には、プロンプトの設計、出力形式、評価フレームワークの選択など、様々な工夫が必要になります。タスクの特性をふまえながら適切な手法を組み合わせることが、評価の成功の鍵を握っていると言えますね。

## まとめ

本記事では、OpenAIらの調査報告書「プロンプトレポート」に基づき、プロンプティング技術の多言語・マルチモーダルへの拡張、そしてエージェントや評価フレームワークの導入といった動向を紹介しました。

多言語プロンプティングは、英語以外の言語でのAIの性能向上に不可欠であり、翻訳や言語間の知識伝達などに貢献しています。マルチモーダルプロンプティングは、画像や音声といった様々な種類の情報を扱うことを可能にし、AIの応用範囲を大きく広げています。

エージェントは、AIが外部システムと連携し、複雑なタスクを解決できるようにする技術です。評価フレームワークは、AIの出力の質を評価し、改善に役立てるための仕組みです。これらの技術は、プロンプティングをより実用的なツールへと進化させています。

次の記事ではシリーズの最後としてプロンプトにおける課題とベンチマークに関する内容を紹介します。

- 参照論文URL： [https://arxiv.org/abs/2406.06608](https://arxiv.org/abs/2406.06608)
- プロジェクトページ： [https://trigaten.github.io/Prompt\_Survey\_Site/](https://trigaten.github.io/Prompt_Survey_Site/)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[『プロンプトレポート』OpenAIなどが作成した調査報告書　〜その1　重要な用語と各種プロンプト手法〜](https://ai-data-base.com/archives/70953)

[『プロンプトレポート』OpenAIなどが作成した調査報告書　〜その3　プロンプトエンジニアリングのケーススタディ〜](https://ai-data-base.com/archives/71186)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)