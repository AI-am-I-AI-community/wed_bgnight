---
title: "ハーバード大学とGoogleの研究者ら、LLMチャットボットを総合的に評価するデータセットの作り方を報告（作成されたデータセットも公開）"
source: "https://ai-data-base.com/archives/76713"
author:
  - "[[AIDB Research]]"
published: 2024-10-08
created: 2025-06-13
description: "本記事では、RAGシステムの性能を総合的に評価するための新しい手法「FRAMES」を紹介します。RAGシステムは複雑な質問に対して関連情報を検索し、適切な回答を生成する能力が求められます。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、RAGシステムの性能を総合的に評価するための新しい手法「FRAMES」を紹介します。

RAGシステムは複雑な質問に対して関連情報を検索し、適切な回答を生成する能力が求められます。

今回ハーバード大学とGoogleの研究者らは、事実の正確性、情報検索能力、複雑な推論能力を同時に評価するための考え方を整理しました。また、一般的な内容に対応した質問セットを作成しました。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_76713-1024x576.jpg)

**参照論文情報**

- タイトル：Fact, Fetch, and Reason: A Unified Evaluation of Retrieval-Augmented Generation
- 著者：Satyapriya Krishna, Kalpesh Krishna, Anhad Mohananey, Steven Schwarcz, Adam Stambler, Shyam Upadhyay, Manaal Faruqui
- 研究機関：ハーバード大学、Google

**本記事の関連研究**

- [RAG-LLMシステムへのユーザークエリは4つのレベルに分類できる　最も複雑なのは「隠れた根拠からの推論が必要なクエリ」Microsoftによる研究](https://ai-data-base.com/archives/76241)
- [ロングコンテキストLLM台頭の今もRAGを使用する理由](https://ai-data-base.com/archives/75289)
- [RAGで検索文書の要約を活用したクエリ書き換えが検索精度を大幅に向上させる　AWS報告](https://ai-data-base.com/archives/74922)
- [100個の事例を分析して明らかになったLLM-RAGアプリケーション「19の欠陥パターン」](https://ai-data-base.com/archives/73120)

## 背景

多くの企業がLLMを活用したRAG（検索拡張生成）システムの導入を検討しています。大量の社内文書や専門知識を活用し、質問に対して的確な回答を生成する仕組みが求められているためです。

そしてRAGシステムを効果的に運用するには、性能を適切に評価することは不可欠です。  
しかしここで課題となるのが、既存の評価方法の多くが単一の側面（例：情報検索の精度や回答の事実性）にのみ焦点を当てていることです。

そこで今回研究チームは新たな評価フレームワーク「FRAMES」を開発しました。以下の特徴を持ちます。

1. 事実の正確性、情報検索能力、複雑な推論能力を同時に評価する
2. 複数の情報源から段階的に情報を収集し、統合する能力を測定する
3. 過去のデータと現在の状況を適切に関連付ける能力を評価する
4. 定量的・定性的な分析を要する質問を設計する

今回研究者らが実際に開発したのは一般的なテーマの質問データセットですが、その設計思想は独自のRAGシステム評価に応用できる可能性が高いです。

以下で本研究を詳しく紹介します。

## FRAMES

研究者らは、RAGシステムの包括的な評価を目的としたデータセット「FRAMES」の作成方法を整理しました。

「FRAMES」の大きな特徴はまず、RAGシステムの3つの重要な要素を同時に評価できる点にあります。

1. 事実性（回答の正確さと信頼性）
2. 検索能力（必要な情報を効果的に収集する能力）
3. 推論能力（収集した情報を基に適切な結論を導き出す能力）

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_76713_1-1024x410.jpg)

FRAMESと他のデータセットの特徴比較表

### データセットの作成プロセス

今回研究者らが作成したのは特定の分野に特化はしていない824問からなる質問セットです。以下のプロセスを経て作成されました。

**（１）LLMによる質問生成の試行**

最初にLLMを用いて質問の自動生成を試みましたが、約30%の質問に事実誤認や幻覚が含まれるなどの問題が発生しました。

**（２）人間の専門家による質問の作成と検証**

そのため、最終的には人間の専門家によって質問が作成され、厳密な品質チェックが行われました。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_76713_2-900x1024.png)

人間の専門家に対して与えられた指示

上記のように、RAG評価セットを作成する際にはLLMと人間のハイブリッドアプローチが有効です。LLMを使って大量の質問案を生成し、その後、業界専門家がレビューと修正を行うことで、効率的に質の高い評価セットを作成できるケースが多くあります。

### データセットの特徴

研究者らはデータセットが以下の特徴を備えるようにしました。

**特徴１：多様な情報源**

FRAMESは各質問の回答に2〜15の異なるWikipedia記事からの情報が必要となるように設計されました。

**特徴２：複数のステップ**

約64%の質問が3つ以上の記事からの情報を必要とするように作られました。

**特徴３：多様な推論タイプ**

数値計算、表形式データの解釈、複数の制約条件の考慮、時系列分析、後処理などさまざまな種類の推論が必要とされます。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_76713_3-1024x694.png)

FRAMESで使用される異なる推論タイプの説明（数値推論、表形式推論、複数制約、時間的推論、後処理の5タイプ）

なお、業務上のプロセスも多くの場合、複数の情報源や段階的な意思決定を必要とします。

### 品質管理のための取り組み

FRAMESの品質を維持するために以下のような工夫が施されました。

1. Wikipediaの情報に基づく正確性の確認
2. 時間経過による変化を考慮した質問の明確化
3. 単純な yes/no 回答を避け、推測による正解を防止
4. Wikipediaを情報源とすることで、データの信頼性を確保

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_76713_4-1-1024x307.png)

FRAMESの質問分布

なお、上記を例えば組織用RAGの評価セット作成する際の品質管理に応用するとした場合は、以下のように置き換えることができるかもしれません。

1. 組織内の正式文書や信頼できる外部ソースを基準とした正確性の確認
2. 業界動向や法規制の変化を考慮した質問設計
3. 具体的な解決策や分析を要求する質問設計
4. 承認された情報源のみを使用し、データの信頼性を担保

## 実験

研究者らはFRAMESデータセットを用いて、最新LLMの性能評価を行いました。

### シングルステップの評価

**評価方法**

まずはモデルに質問を1回だけ与え、その応答の評価が行われました。以下の3つのアプローチが試されました。

（１）単純なプロンプト  
質問をそのままモデルに与え、検索なしで回答を生成させる

（２）BM25検索拡張プロンプト  
質問に関連する上位n個のWikipedia記事をBM25（Best Matching 25）アルゴリズムで検索し、それらを質問と共にモデルに与える

※なおBM25とは、検索クエリに最も適合する文書を見つけ出すための順位付けアルゴリズムです。 [tf-idf](https://ai-data-base.com/archives/26539 "TF-IDF") （単語の出現頻度と逆文書頻度）の概念を発展させたものと考えられています。

（３）オラクルプロンプト  
質問生成時に人間が使用したすべての関連Wikipedia記事を質問と共にモデルに与える

**実験結果**

結果は次の通りでした。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_76713_5-1024x573.jpg)

テストセットにおけるGemini-Pro-1.5-0514の各推論タイプごとの精度

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_76713_6-1024x201.png)

異なるモデルの精度パフォーマンス

- 単純プロンプト：Gemini-Pro-1.5-0514モデルで約40%の [正解率](https://ai-data-base.com/archives/25930 "正解率")
- BM25検索拡張プロンプト（2記事）：約45%の正解率
- BM25検索拡張プロンプト（4記事）：約47%の正解率
- オラクルプロンプト：約72%の正解率

ここから得られる考察は以下の通りです。

まず単純プロンプトから検索拡張プロンプトへの移行で正解率が上昇していることから、検索の重要性が示されました。

また、オラクルプロンプトでも約28%の誤りがあり、その80%が数値計算、表形式データ解釈、後処理に関連してました。完全に情報が与えられても完璧にはならないということです。

なお、複数の制約条件や時間的推論を要する質問では比較的高い性能を示したが、数値計算や表形式データの解釈では課題が残ったことから、推論タイプによる性能差が大きいことが読み取れます。

### マルチステップの評価

シングルステップ評価の結果を踏まえ、研究チームはより複雑な評価手法としてマルチステップ評価を実施しました。

マルチステップとは、モデルに複数回の推論と検索の機会を与え、段階的に回答を生成させるLLMの使い方です。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_76713_7-1024x435.jpg)

**評価方法**

マルチステップ評価の手法は以下の通りです。

1. 質問に基づいてk個の検索クエリを生成
2. 各クエリに対して上位n\_docs個のWikipedia記事をBM25スコアに基づいて検索
3. 検索された記事を文脈に追加
4. このプロセスをn回繰り返す
5. 最終的に、蓄積された文脈を使用して質問に回答

**実験結果**

実験は特別な指示なしでマルチステップ検索を実行するパターンとモデルに効率的な検索戦略を立てるよう指示するパターンの二通りで行われました。

結果は次の通りでした。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_76713_8-1024x523.jpg)

ステップ数(n)とステップごとのクエリ数(k)を変更した際のパフォーマンス向上を示す

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_76713_9-1024x699.jpg)

テストセットにおけるGemini-Pro-1.5-0514の各推論タイプごとの精度。多段階検索計画の効果を示す

- バニラ設定：(k, n, n\_docs) = (5, 5, 2)の場合、正解率が約45%から約52%に向上
- 検索計画指示付き設定：(k, n, n\_docs) = (5, 5, 10)の場合、正解率が約66%まで向上（オラクル性能の約73%に近づく）
- 複数の制約条件や時間的推論を要する質問で大幅な改善
- 数値計算タスクでは、オラクル性能を上回る結果も

結果から得られる考察は以下の通りです。

まず、複数回の検索と推論のサイクルにより、モデルはより適切な情報を蓄積し、複雑な質問に対する回答精度を向上させることができました。

また、効果的な検索計画の指示により、モデルは必要な情報をより効率的に収集し、性能を大幅に向上させることができました。

さらに、計算コストとのトレードオフが示唆されています。マルチステップアプローチは高い性能を示しましたが、複数回の推論が必要となるため、計算コストと応答時間が増加します。  
実際の運用においてリソース効率と回答の質のバランスを考慮する際の参考になるかもしれません。

## まとめ

本記事では、RAGシステムの総合的な評価を目的とした新しいデータセット「FRAMES」の研究を紹介しました。RAGシステムの評価において、事実の正確性、情報検索能力、推論能力を同時に測定することの重要性を示す結果が得られています。

FRAMESデータセットは、複雑な多段階推論を必要とする質問を含んでおり、最先端のモデルでさえ難しいと感じる課題を提示しています。研究結果から、モデルの性能向上には反復的な検索と段階的な推論が効果的であることが明らかになりました。

FRAMESは一般的な知識に基づいた質問セットであり、そのまま企業特有のRAGシステムの評価に適用できるわけではありません。しかしRAGシステムの評価において考慮すべき重要な側面を示しており、企業や開発者が自社のシステムを評価する際の参考になる可能性があります。

実際のアプリケーションに適用する際には、各システムの特性や要件に応じたカスタマイズが必要となることに留意してください。

- 参照論文URL： [https://arxiv.org/abs/2409.12941](https://arxiv.org/abs/2409.12941)
- データセット： [https://huggingface.co/datasets/google/frames-benchmark](https://huggingface.co/datasets/google/frames-benchmark)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[100万体のLLMエージェントによるシミュレーションを実験できる環境が登場](https://ai-data-base.com/archives/76640)

[高解像度な深度マップを高速生成するモデル『Depth Pro』Appleが公開](https://ai-data-base.com/archives/76790)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)