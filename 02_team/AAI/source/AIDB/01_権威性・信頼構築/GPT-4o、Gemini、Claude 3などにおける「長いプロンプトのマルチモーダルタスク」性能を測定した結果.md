---
title: "GPT-4o、Gemini、Claude 3などにおける「長いプロンプトのマルチモーダルタスク」性能を測定した結果"
source: "https://ai-data-base.com/archives/69354"
author:
  - "[[AIDB Research]]"
published: 2024-05-21
created: 2025-06-13
description: "有望なマルチモーダルモデルが多く登場する一方で、モデルの能力を測定するためのベンチマークが不足しています。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

有望なマルチモーダルモデルが多く登場する一方で、モデルの能力を測定するためのベンチマークが不足しています。そこで今回研究者らは、情報検索能力と妨害要因の排除能力、そして現実世界の条件に近い長いコンテキスト処理性能を測定するための新しいベンチマークデータセットを作成し、実験しました。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69354-1024x576.jpg)

**参照論文情報**

- タイトル：MileBench: Benchmarking MLLMs in Long Context
- 著者：Dingjie Song, Shunian Chen, Guiming Hardy Chen, Fei Yu, Xiang Wan, Benyou Wang
- 所属：The Chinese University of Hong Kong, Shenzhen Research Institute of Big Data

**本記事の関連研究** ：

- [スタンフォード大学の研究者ら、GPT-4oとGemini1.5 Proで「マルチモーダルモデルにおける『Many-Shot』の効果」を検証](https://ai-data-base.com/archives/69211)
- [マルチモーダルLLMにおけるハルシネーション（幻覚）の原因と対策](https://ai-data-base.com/archives/68720)
- [マルチモーダルLLMにおける欠点と原因を明らかにする調査研究の結果](https://ai-data-base.com/archives/68367)
- [LLMに心の目を与える『Visualization-of-Thought』プロンプティング　マルチモーダルモデルに匹敵する空間推論性能を達成](https://ai-data-base.com/archives/67128)

## 背景

マルチモーダルの大規模言語モデルが優れた性能を示しています。それに伴い、モデルの性能評価のためのベンチマークも登場してきました。その多くは、一般的な能力や特定のタスクにおける能力について測るものです。単一の画像と短いテキストで構成されるものが多く、現実世界の複雑さや多様性を捉えきれていないという問題点が指摘されています。

複数の画像を扱うタスクを評価するベンチマークも存在しますが、サンプルごとに提供される画像数が限られていたり、時系列のキャプション生成タスクに特化していたりと、まだ課題があります。

複数の画像を扱い、かつ長いコンテキストを扱う場合におけるハルシネーションの発生は危惧されるものであり、その点における評価が足りていません。

こうした背景を受けて、研究者らはMILEBENCHという新しいベンチマークを作成しました。マルチモーダルモデルの長いコンテキスト処理能力をテストするために特別に設計されたベンチマークです。「診断評価」と「現実的評価」の2つの異なる評価セットが用意されています。長いコンテキストでのタスク完了能力をテストするものです。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69354_1-1024x512.jpg)

マルチモーダルLLMの性能は、データセットの画像数によって変動する。オープンソースのマルチモーダルLLMは、画像数が増えると顕著な性能低下を示す。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69354_2-1024x453.png)

現在のベンチマークにおける画像数と単語数の分布の可視化。MILEBENCHのサンプルあたりの単語数と画像数の範囲と平均は、従来を大幅に上回っている。

## MILEBENCHの評価体系

MILEBENCHは、「現実的評価」と「診断評価」で構成されています。現実的評価では、マルチモーダルモデルが長いコンテキストを理解してタスクを実行する能力が試されます。診断評価では、コンテキストから情報を取り出す、つまり情報検索能力と妨害要因の排除能力が測定されます。

### 現実的評価の詳細

タスクは（１）時系列の複数画像タスクと（２） [セマンティック](https://ai-data-base.com/archives/26143 "セマンティック") な複数画像タスクの2つのグループに分類されます。

**（１）時系列の複数画像タスク**

マルチモーダルモデルが時間的に関連する複数の画像間の時間的関係を見抜く能力がテストされます。現実世界のシナリオにおける予測能力が重視されるタスクです。

タスクの具体的内容

1. 一連の画像に基づいて、物体やキャラクターの行動を解釈し予測する
2. 一連の画像の中で物体を識別し理解する
3. 空間的・方向的な概念の理解をテストする
4. 画像シーケンス内の論理的推論に焦点を当てる

**（２）セマンティックな複数画像タスク**

マルチモーダルモデルが時間的には無関係だが意味的には相互に関連する複数の画像を処理する能力が問われます。

タスクの具体的内容

1. モデルがマルチモーダルな知識を統合して単一または複数ホップの推論タスクを行う
2. 画像に直接埋め込まれた豊富なテキスト情報の処理と理解を要求する
3. 視覚的な関係性の理解と推論に焦点を当てる
4. 主に視覚データと自然言語の対話理解を含む
5. マルチ画像情報を用いて空間環境を認識する

### 診断評価の詳細

[自然言語処理](https://ai-data-base.com/archives/26319 "自然言語処理（NLP）") 分野の「Needle in a Haystack（干し草の山の中の針）」タスクと [コンピュータビジョン](https://ai-data-base.com/archives/26602 "コンピュータビジョン") 分野の「画像検索」タスクがマルチモーダル形式に変換されて用いられます。

下記は、分類法とマルチモーダルの長いコンテキストの例を示しています。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69354_3-1-1024x555.jpg)

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69354_6.png)

タスク分布

### データ収集とレビュー

データは、既存のデータセットからの抽出と、新タスク用の合成データの作成という2つの方法で収集され、コンテキスト長の異なる6,440のサンプルが集められました。

品質を保証するため、オープンソースのデータセットについては10%のデータを手動で検証し、独自に作成したデータセットについては全データを手動で検証するというレビュープロセスが実施されました。結果、アノテータ間の一致度は95%以上と高く、エラー率は1%未満に抑えられました。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69354_5.png)

本データセットの主な統計情報

## 評価実験

上記データセットMILEBENCHを用いて、複数のマルチモーダルモデルを対象とした大規模な評価実験が行われました。非公開モデル（GPT-4VやGemini 1.5など）、オープンソースモデル（Mantis、Qwen-VL-7B、LLaMA-VID、Valleyなど）で合計22のモデルが評価されました。なお、NVIDIA A100 [GPU](https://ai-data-base.com/archives/26570 "GPU") を使用してゼロショット設定で評価されました。

### 主な実験結果

非公開モデルであるGPT-4oが診断評価と現実的評価の両方で他のモデルを上回る性能を示しました。ただし、それでも完璧とは言えない結果だったことが注目されます。

また、公開されているマルチモーダルモデルの多くは長いコンテキストのタスクで苦戦することが明らかになりました。MantiとQwen-VL-7Bは現実的評価と診断評価でそれぞれ平均47.5%と37.2%のスコアを記録し、比較的高い性能が確認されました。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69354_7-1024x647.jpg)

### エラー分析

モデルの欠点をさらに調査するため、エラー分析が実施されました。

空間理解タスクでは、GPT-4Vは応答を拒否し、他のモデルは質問に正しく答えることができませんでした。複数画像のQAデータでの学習が不足していることが関係している可能性があると推察されます。  
視覚的関係推論タスクでは、Qwen-VL-Chatとvalleyが画像の違いの認識と指示の遵守に苦労していました。こちらの原因は視覚能力が低解像度であることが原因かもしれないと述べられています。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69354_8-1024x595.jpg)

空間理解タスク（上）と視覚的関係推論タスク（下）におけるエラーケースの2つの例。

### 画像数による性能への影響

研究者らは、画像数の異なるデータセットでのマルチモーダルモデルの性能を調査するため、データセットを画像数に基づいて「Few」、「Medium」、「Many」の3つのレベルに分類しました。その結果、ほとんどのモデルは画像数が増えるにつれて性能が大幅に低下することが明らかになりました。多くのモデルが単一の画像でのみ学習されているため、複数の画像を含むテストデータへの一般化が不十分であることが原因だと考えられます。

しかし、GPT-4V、GPT-4o、Gemini 1.5、Claude 3 Opus、Qwen-VL-Chatなどの一部のモデルは、おそらく複数の画像を用いた学習を行っているため、「Medium」レベルでは性能が向上しました。ある程度の画像数の増加は、タスク完了に必要な情報を提供できるためだと推測されます。ただし、これらのモデルでも「Many」レベルになると性能が低下しており、複数の画像を含む文脈のモデリングにはさらなる改善の余地があることが示唆されました。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69354_9.png)

様々な画像数レベルでの平均性能

また研究者らは、「Needle in a Haystack」タスクで最も高い性能を示した非公開モデルと公開モデルを選んで分析を行いました。長いテキストを用いた「Needle in a Haystack」タスクにおいては、モデルが文脈の中央に位置する「針」を見つけるのに苦労する「Lost in the Middle」現象が以前から指摘されているためです。この現象がマルチモーダルな文脈でも起こるかどうかを調べられました。

その結果、GPT-4Vはマルチモーダルな長い文脈でも「Lost in the Middle」現象を示さず、両タスクで99%以上の高い性能を達成しました。一方、Qwen-VL-Chatは、特に画像を用いたタスクにおいて、ある程度の「Lost in the Middle」現象を示しました。長い文脈を扱う能力の高さが、このリスクを大幅に軽減できることを示唆しています。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69354_10-1024x590.png)

Needle in a haystackにおける深さと文脈長の変化による結果の可視化

また研究者らは、MILEBENCHの現実的評価における9つのタスクについて、全てのモデルの性能を分析し、異なるタスク間の相関を計算しました。その結果、視覚的関係推論を除いて、同じカテゴリ内のタスク（時系列の複数画像タスクまたはセマンティックな複数画像タスク）は高い相関を示しました。視覚的関係推論（セマンティックタスクの3つめ）は難易度が高く、モデル間のスコア差が小さかったため、他のタスクとの相関が低くなったと考えられます。

また、視覚的ナビゲーションと空間的位置特定タスクは、一人称視点から世界を理解するなどの特殊な認知スキルを必要とするため、他のタスクとの相関が低くなったと推測されます。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69354_12-1024x563.png)

Combined-image Setでの実験結果

## まとめ

本記事では、マルチモーダルモデルの長いコンテキストにおける能力を評価するために特別に設計された初のベンチマーク「MILEBENCH」を提案した研究を紹介しました。

MILEBENCHは、診断評価と現実的評価の2つの評価セットを用意することで、マルチモーダルモデルの長いコンテキストへの適応能力とこれらのコンテキストでのタスク完了能力を体系的に評価します。実験結果から、一部のモデルが印象的なパフォーマンスを示したものの、マルチモーダルモデルの能力向上には更なる研究が急務であることが明らかになりました。

今後の研究の方向性としては、長いコンテキストのマルチモーダルモデルの開発と、MILEBENCHのより大きなコンテキストや他のモダリティへの拡張が挙げられます。これらの取り組みは、マルチモーダルモデルがますますマルチモーダル化する世界により適応できるようにするのに役立つでしょう。

マルチモーダルモデルの発展は、複雑な現実世界のタスクを自動化する上で大きな可能性を秘めています。MILEBENCHのような取り組みを通じて、マルチモーダルモデルの能力向上が加速され、私たちの日常生活やビジネスにも大きなインパクトをもたらすことが期待されます。

- 参照論文URL： [https://arxiv.org/abs/2404.18532](https://arxiv.org/abs/2404.18532)
- プロジェクトページ： [https://milebench.github.io/](https://milebench.github.io/)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[反復学習でCoTによる推論性能を向上させる手法 Metaとニューヨーク大学による研究](https://ai-data-base.com/archives/69296)

[ファインチューニングがLLMの幻覚（ハルシネーション）に与える影響　Googleなどによる検証結果](https://ai-data-base.com/archives/69421)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)