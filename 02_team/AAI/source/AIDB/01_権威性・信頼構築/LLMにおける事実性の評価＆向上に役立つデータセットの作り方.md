---
title: "LLMにおける事実性の評価＆向上に役立つデータセットの作り方"
source: "https://ai-data-base.com/archives/80376"
author:
  - "[[AIDB Research]]"
published: 2024-12-10
created: 2025-06-13
description: "本記事では、LLMが抱える「ハルシネーション」問題に対応するために開発された、事実性評価用データセット生成手法を紹介します。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、LLMが抱える「ハルシネーション」問題に対応するために開発された、事実性評価用データセット生成手法を紹介します。  
元テキストから抽出した”事実に関する主張”を微妙に書き換えて異なる情報を生成することで、LLMが正・誤を見分ける能力を評価できるようにするといった方法論です。  
研究者らは実際にこの方法論を用いてWikipediaデータをもとに新しいデータセットを構築し、本アイデアの有用性を実証しました。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80376-1024x576.jpg)

**発表者情報**

- 研究者：Alessandro Scirè et al.
- 研究機関：Babelscape, Sapienza University of Rome

## 背景

LLMは、ハルシネーションと呼ばれる、事実に基づかない内容を生成してしまうという問題を抱えています。LLMはあたかも人間が書いたかのような流暢なテキストを生成するため、ユーザーがその内容を鵜呑みにしてしまう可能性があり、ハルシネーションは深刻な問題となっています。

これまでに行われてきた事実性評価研究では、生成されたテキストが、例えばニュース記事や書籍などのソース文書と一致しているかを検証していました。しかし、現実世界のように様々な種類のテキストが混在する状況には対応できていませんでした。また、検証に使うソース文書が常に存在するという前提にも無理があります。

有力なプロジェクトには [FEVER (Fact Extraction and VERification)](https://fever.ai/) があり、開発者らはWikipediaから抽出した文章を少し改変してデータセットを作りました。185,445件もの”事実に関する主張”を、それが正しいか、間違っているか、情報不足かを判断するためのものです。しかし、FEVERは個別の事実の真偽を判定することに特化しており、現実世界のテキストのように、複数の事実が複雑に絡み合った文章全体を評価するには不向きでした。

さらに、FACTORやFELMといった「LLM正しいテキストと間違ったテキストを自動生成する」フレームワークも考案されてきました。事実性評価のためのデータを作るためです。しかし生成されるデータセットは規模が小さく、十分ではありませんでした。

そこで、研究者たちは、現実世界の複雑なテキストを評価できる、より大規模で汎用的な、新しい事実性評価手法の開発に挑むことになりました。

本研究で示されている方法論を応用すると、独自のチャットボットを作成する際に「LLMが正しい答えを述べられるかどうかをチェックする」作業に役立つかもしれません。

研究のポイント

1. 元の文章から細かい主張を抜き出し、それをほんの少し書き換えて間違った情報も作り出す方法論を考案した
2. Wikipediaをもとに「幅広いトピックをカバーしている正しい文と間違った文のペア」を何万組も用意した大規模なデータセットを開発し、誰でも使えるようにした

以下で詳細を紹介します。

## 「事実性評価データセット生成」の方法論

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80376_1-1024x687.png)

主張の抽出（factual claims）と改ざん（falsified claims）を行うプロセスを示す。元の文、抽出された主張、改ざんされた主張、生成された事実的な文、非事実的な文がどのように作られるかを視覚的に説明。

研究者らは、LLMの事実性を評価するためのデータセット開発の方法論を以下のようにまとめています。

### ”事実に関する主張”の抽出プロセス

まず、資料（本研究ではWikipedia）の各ページからランダムに文章（パッセージ）を [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") します。次に、LLMを用いて、選択されたパッセージから原子的な”事実に関する主張”が抽出されます。それ以上分割する必要がなく、自己完結していて、真偽を検証できる基本的な情報単位のことです。

抽出時には以下の制約が設けられています。

- 15単語以内の短い”事実に関する主張”
- 元のテキストの論理的な流れを維持
- 代名詞を避け、名詞を主語として使用

例えば、以下のようなパッセージが入力された場合、

```js
アマゾンの熱帯雨林は、アマゾニアとしても知られており、南米のアマゾン盆地の大部分を覆う、アマゾンバイオームの湿潤広葉樹林である。この地域は9カ国に属する領土を含み、ブラジルは熱帯雨林の60％を占めている。
```

以下のような”事実に関する主張”が生成されます。

1. アマゾンの熱帯雨林はアマゾニアとしても知られている
2. アマゾンバイオームの湿潤広葉樹林である
3. 南米のアマゾン盆地の大部分を覆っている
4. この地域は9カ国に属する領土を含む
5. ブラジルは熱帯雨林の60％を占めている

### ”事実に関する主張”の改ざんプロセス

次に、抽出された”事実に関する主張”の中から一つを選び、事実誤認を導入する”改ざん処理”を実施します。この改ざんは、検出を困難にするため、以下の条件で行われます。

- 日付、年、数字、人名、場所名、組織名などの変更は避ける
- 重要な事実を微妙に改変する
- 単純な否定変換は使用しない

例えば、前述の例で抽出された”事実に関する主張”「ブラジルは熱帯雨林の60％を占めている」が選択された場合、「森林の大部分はペルーに含まれている」という改ざんされた”事実に関する主張”が生成されます。

### テキストペアの生成プロセス

#### （１）事実テキストの生成

事実性評価タスクの難易度を上げるため、元の文章（本研究ではWikipedia）をそのまま使用せず、言い換え生成を行うことが提案されています。抽出された”事実に関する主張”を基に、元のテキストと同じ意味を持つ新しいテキストが生成されます。このとき、以下の点が考慮されます。

- 元のテキストの事実を完全にカバー
- 抽出された”事実に関する主張”の順序を維持
- 元の表現とは異なる言い回しを使用

生成例として、「アマゾニアとして広く知られるアマゾンの熱帯雨林は、アマゾンバイオーム内に位置する湿潤広葉樹林であり、南米のアマゾン盆地の重要な部分を覆っている。この広大な地域は9カ国にまたがり、ブラジルは熱帯雨林の60％を占めている。」のようになります。

#### （２）非事実テキストの生成

非事実テキストは、改ざんされた”事実に関する主張”を含む”事実に関する主張”セットを用いて生成されます。以下の特徴を持つテキスト生成を行います。

- 事実テキストとほぼ同一の構造
- 改ざんされた部分のみが異なる
- 検証タスクの混乱要因を非事実部分に限定

生成例は、「アマゾニアとして広く知られるアマゾンの熱帯雨林は、アマゾンバイオーム内に位置する湿潤広葉樹林であり、南米のアマゾン盆地の重要な部分を覆っている。この広大な地域は9カ国にまたがり、ペルーは熱帯雨林の60％を占めている。」のようになります。

## 今回実際に開発されたベンチマークデータセットの作成手順

研究者らはWikipediaをもとにLLMの事実性を評価するためのベンチマークデータセットを実際に作成し、「LLM-OASIS」名付けました。エンドツーエンドの事実性評価システムのトレーニングと評価を可能にするものです。

なお、今回実際に作られたデータセットを「LLM-OASIS」と呼ぶのであり、事実性評価用データセットを生成する方法論そのものを「LLM-OASIS」と呼ぶわけではありません。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80376_2-edited.jpg)

LLM-OASISデータセット作成の具体的なプロセス

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80376_3.png)

LLM-OASISデータセットの規模（ページ数、パッセージ数、抽出された主張の数など）や、生成された事実的・非事実的テキストの長さに関する統計情報

### 人間による評価

自動生成されたデータの品質を評価し、手順を厳密に評価するため、研究者らは5人の専門言語学者に依頼し、パイプラインの各タスク（”事実に関する主張”抽出、”事実に関する主張”改ざん、事実テキスト生成、非事実テキスト生成）について1,750件のインスタンスを検証しました。

#### タスク（１）　”事実に関する主張”抽出

アノテーターはWikipediaの文章と、モデルMによって抽出された”事実に関する主張”のリストを受け取りました。アノテーターの仕事は、各”事実に関する主張”が対応する文章内で適切に表現されているか（つまり、同じ意味を持っているか）、また原子性を持っているかを検証することでした。

モデルは、このタスクにおいて96.78%の精度を達成しました。また、Fleiss’κスコアは0.81であり、アノテーター間で高い一致が見られました。

#### タスク（２）　”事実に関する主張”改ざん

このタスクでは、アノテーターは元の”事実に関する主張”と改ざんされた”事実に関する主張”のペアを受け取りました。アノテーターの仕事は、各”事実に関する主張”が適切に改ざんされているか（つまり、矛盾する意味を持っているか）を検証することでした。

GPT-4は、このタスクにおいて98.55%の精度を達成しました。また、Fleiss’κスコアは0.84であり、アノテーター間でほぼ完全な一致が見られました。

#### タスク（３）　事実テキストと非事実テキストの生成

アノテーターは元の（または改ざんされた）”事実に関する主張”のリストと、GPT-4によって生成された事実（または非事実）テキストを受け取りました。アノテーターの仕事は、各”事実に関する主張”が生成されたテキスト内で正しく表現されているかを検証することでした。

事実テキスト生成タスクでは、90.36%の精度と0.73のFleiss’κスコアが測定されました。非事実テキスト生成タスクでは、89.2%の精度と0.72のFleiss’κスコアが測定されました。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80376_4.png)

モデルの生成結果を人間の評価者が確認した結果（例えば、主張の抽出精度が96.78%）や、評価者間の一致度（Fleiss’ κ）

### ゴールドベンチマーク

研究者らは、人間による [アノテーション](https://ai-data-base.com/archives/26297 "アノテーション") の結果を用いて、モデル評価のためのゴールドスタンダードベンチマークを構築しました。高品質なデータを確保するため、いずれかの [アノテーション](https://ai-data-base.com/archives/26297 "アノテーション") 段階でいずれかのアノテーターによってエラーとしてマークされなかったインスタンスのみを保持しました。

このデータを用いた以下の2つの評価タスクが提案されました。

#### タスク１：エンドツーエンドの事実性評価

与えられたテキストに事実誤認が含まれているかどうかを判断するタスクです。モデルは、入力された文章に対して、True（事実誤認なし）またはFalse（事実誤認あり）の [バイナリ](https://ai-data-base.com/archives/26314 "バイナリ") ラベルを出力する必要があります。

このタスクでは、事実テキストと非事実テキストのみが入力文章として使用されます。元のテキストは、LLMの事前学習中にすでに学習されている可能性があるため、除外されます。

#### タスク２：根拠に基づく”事実に関する主張”検証

与えられた根拠を用いて、個々の”事実に関する主張”を事実または非事実として分類するタスクです。このアプローチでは、”事実に関する主張”がすでにテキストから抽出されていることを前提としており、検証対象となるテキスト全体ではなく、個別の文に焦点を当てることでタスクを簡素化しています。モデルは、入力された”事実に関する主張”と対応する根拠となる文章に対して、True（”事実に関する主張”は根拠によって裏付けられている）またはFalse（”事実に関する主張”は根拠によって裏付けられていない）の [バイナリ](https://ai-data-base.com/archives/26314 "バイナリ") ラベルを出力する必要があります。

このタスクでは、抽出された”事実に関する主張”とその対応する非事実バージョンに焦点を当て、事実テキストを根拠として使用します。元のテキストと非事実テキストは、前者はLLMの事前学習中にすでに学習されている可能性があり、後者は現実世界の知識と矛盾するため、除外されます。

## ベンチマークデータセットを用いたLLMの事実性評価方法

従来の事実性評価は個々の”事実に関する主張”の検証に焦点を当てていましたが、今回想定されているのは「自然言語の生のテキストの事実性を評価する」といった現実的なシナリオです。

### 事実性評価システムの構成

研究者らが提案している事実性評価システムは、以下3つのサブタスクから構成されます。

1. ”事実に関する主張”抽出
2. 証拠検索
3. ”事実に関する主張”検証

最後に、各”事実に関する主張”の検証結果を集約して、テキスト全体の事実性を判断します。

#### ”事実に関する主張”抽出

入力テキストから原子的な”事実に関する主張”を抽出します。抽出に使用されるモデルは、すでに作られたトレーニングデータを用いて学習されます。本研究では、Wikipediaの原文と、GPT-4 APIによって抽出された”事実に関する主張”のペアを用いて、 **T5base** モデルがファインチューニングされました。

#### 証拠検索

抽出された”事実に関する主張”を検証するための証拠となる文章を、知識ベースから検索します。ここで使用されるモデルもトレーニングデータを用いて学習されます。

本実験では **[Dense Passage Retrieval (DPR)](https://github.com/facebookresearch/DPR)** の手法を用いて、 **E5base** モデルをファインチューニングします。E5baseモデルは、”事実に関する主張”と文章の両方を密ベクトル表現に変換し、それらの内積を用いて文章をランク付けします。

#### ”事実に関する主張”検証

抽出された”事実に関する主張”と検索された証拠を比較し、各”事実に関する主張”の事実性を評価します。

すでに構築されたデータセットを用いて、”事実に関する主張”、証拠、ラベルのトリプレットからなるデータセットを構築します。ラベルは、

- 前提が仮説を含意する (ENT)
- 中立である (NEUT)
- 矛盾する (CONTR)

のいずれかを示します。

本実験では、DeBERTa-v3largeモデルがファインチューニングされました。モデルは、”事実に関する主張”と証拠を入力として受け取り、ENT、NEUT、CONTRのいずれかのラベルを出力します。

## 今回作られたデータセット「LLM-Oasis」で行われた実験

研究者らは、LLMの事実性評価に関する大規模な実験を、実際に作成した「LLM-Oasis」によって実施しました。

実験では、研究チームが構築したLLM-OASISデータセットを活用し、テキストの事実性を評価するための2つのタスクが設定されました。

（１）エンドツーエンドの事実性評価タスク  
テキスト全体の事実性を評価するタスクです。バランスド精度(balanced accuracy)を評価指標として使用します。

（２）証拠に基づく主張の検証タスク  
個々の主張の事実性を証拠文書と照らし合わせて評価するタスクです。

また、実験対象のモデルとしては以下が使用されました。

- GPT-4
- GPT-3.5
- Llama 3
- Mistral
- 研究チームが独自に開発した検証モデル（開発アプローチは前述の通り）

データセットは80:20の比率で訓練データと検証データに分割され、全ての主張・事実テキスト・非事実テキストが同一の分割に含まれるよう配慮されました。

また、外部知識を活用した場合の性能変化も検証するため、RAGを用いた実験も実施されました。検索には研究チームが開発した検索モジュールが使用され、上位30件の関連文書が参照されました。

## 実験結果の概要

### エンドツーエンド事実性評価タスクの結果

#### 証拠検索モジュールの性能

研究者らは、まず証拠検索の性能を詳細に評価しました。微調整を施したE5baseモデルは、Recall@30（上位30件の検索結果における [再現率](https://ai-data-base.com/archives/26095 "再現率") ）で0.95という高い性能を達成しました。微調整前の同モデルの0.52から大幅な改善を示しています。

#### モデル別の性能比較

エンドツーエンド評価タスクでは、以下のような結果が得られました。

外部知識なしの場合

- GPT-4o: 60.75%
- Llama 3: 53.22%
- Mistral: 51.73%
- GPT-3.5: 51.16%

RAGを導入した場合

- 研究チーム開発モデル: 69.24%
- GPT-4o: 68.02%
- その他のモデル: 51-54%程度

なお、研究チームが開発した1Bパラメータの小規模モデルが、GPT-4oを含む大規模モデルを上回る性能を示したことは注目に値します。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80376_5.png)

提案手法とLLMベースラインモデルの、エンドツーエンドでの事実性評価タスクにおける性能比較

### 証拠に基づく”事実に関する主張”検証タスクの結果

このタスクでは、全体的により高い性能が観察されました。

- 研究チーム開発モデル: 93.30%
- GPT-4o: 90.78%
- Llama 3: 76.63%
- GPT-3.5: 75.56%
- Mistral: 64.37%

研究者らは、このタスクでの高い性能について、以下の3つの要因を考えています。

1. 単一の主張を検証する単純なタスク設定
2. 正確な証拠の提供
3. より小さなコンテキスト（平均100トークン）での処理

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80376_7.png)

”事実に関する主張”単位での証拠に基づく事実性検証タスクの性能を比較

以上の結果は、事実性評価という複雑なタスクにおいて、適切に設計された小規模モデルが大規模モデルと競争可能であることを示唆しています。

## まとめ

本記事では、LLMの事実性評価のための新しいデータセット生成方法と、その方法論に基づき実際に開発されたデータセット「LLM-OASIS」について紹介しました。

方法論の核となるのは、ドキュメントから抽出した情報を基に、事実的な文と非事実的な文のペアを体系的に生成するアプローチです。(1)原文からの”事実に関する主張”の抽出、(2)”事実に関する主張”の改変による非事実情報の生成、(3)パラフレーズによる事実テキストの生成、(4)非事実テキストの生成、という4段階のパイプラインが提案されました。

研究チームは、この方法論の有効性を検証するため、81,000以上のWikipediaページを用いてデータセットを構築し、複数の大規模言語モデルによる評価実験を実施しました。その結果、生成された事実/非事実のペアは、GPT-4oでさえも完全な識別が困難な質の高いものであることが確認されています。

この方法論が多様な分野や多言語に展開されることが期待されます。

**参照文献情報**

- タイトル：Truth or Mirage? Towards End-to-End Factuality Evaluation with LLM-Oasis
- URL： [https://arxiv.org/abs/2411.19655](https://arxiv.org/abs/2411.19655)
- 著者：Alessandro Scirè, Andrei Stefan Bejgu, Simone Tedeschi, Karim Ghonim, Federico Martelli, Roberto Navigli
- 所属：Babelscape, Sapienza University of Rome

## 理解度クイズ（β版）

1\. 今回提案された事実性評価のアプローチは何ですか？

ドキュメントから抽出した情報を基に、体系的なプロセスで事実的・非事実的テキストのペアを生成する新しいアプローチを提案しています。

解説を見る

2\. ”事実に関する主張”改変プロセスの特徴として正しいものは？

本研究では、単純な否定や数値の変更ではなく、微妙な意味の改変を行うことで、より本質的な事実性評価の課題に取り組んでいます。

解説を見る

3\. 研究チームが開発した事実性評価システムの特徴は？

研究チームは、”事実に関する主張”の抽出、証拠の検索、そして検証という3段階の処理パイプラインを構築し、より体系的な事実性評価を実現しています。

解説を見る

4\. 事実性評価における「証拠に基づく主張検証」の特徴は？

このタスクでは、個々の主張を明示的に抽出し、それぞれに対して適切な証拠を照合することで、より正確で説明可能な事実性評価を実現しています。

解説を見る

5\. 本研究の主要な技術的貢献は？

本研究の主要な貢献は、Wikipediaから体系的に事実/非事実ペアを生成する手法を確立し、事実性評価のための大規模データセット構築を可能にしたことです。

解説を見る

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[OpenAI o1モデルファミリー登場　その特徴の全貌](https://ai-data-base.com/archives/80187)

[LLMの開発トレンドに新たに見出された『密度化の法則』および『能力密度』の概念](https://ai-data-base.com/archives/80454)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)