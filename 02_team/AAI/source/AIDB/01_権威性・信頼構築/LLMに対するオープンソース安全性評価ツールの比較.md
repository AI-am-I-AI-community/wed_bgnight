---
title: "LLMに対するオープンソース安全性評価ツールの比較"
source: "https://ai-data-base.com/archives/77301"
author:
  - "[[AIDB Research]]"
published: 2024-11-01
created: 2025-06-13
description: "本記事では、LLMの安全性を自動的にチェックする「スキャナー」と呼ばれる新しい技術分野の包括的な分析をご紹介します。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、LLMの安全性を自動的にチェックする「スキャナー」と呼ばれる新しい技術分野の包括的な分析をご紹介します。

富士通の研究チームは、Garak、Giskard、PyRIT、CyberSecEvalという4つの主要なオープンソースツールを詳細に調査し、それらの設計原理から実践的な性能評価まで体系的にまとめました。この調査は、まだ発展途上にあるLLMセキュリティ評価ツールの現状と課題を明らかにし、より効果的な活用に向けた指針を示しています。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77301-1-1024x576.jpg)

**参照論文情報**

- タイトル：Insights and Current Gaps in Open-Source LLM Vulnerability Scanners: A Comparative Analysis
- 著者：Jonathan Brokman, Omer Hofman, Oren Rachmil, Inderjeet Singh, Rathina Sabapathy, Aishvariya Priya, Vikas Pahuja, Amit Giloni, Roman Vainshtein, Hisashi Kojima
- 所属：Fujitsu Research of Europe

**本記事の関連研究**

- [IBMから日本語対応の商用可能オープンソースLLM「GRANITE 3.0」公開　8Bから](https://ai-data-base.com/archives/77349)
- [オープンソースモデルでも力を合わせればGPT-4oに匹敵することを示す「Mixture-of-Agents（MoA）」アーキテクチャ](https://ai-data-base.com/archives/71419)
- [Apple開発のオープンソースLLM「OpenELM」](https://ai-data-base.com/archives/68614)
- [強くて軽いモデルPhi-3の評価結果　Microsoftの論文（テクニカルレポート）より](https://ai-data-base.com/archives/68184)

## 背景

LLMの普及に伴い、人々の生産性は大きく向上しつつありますが、同時にLLMに起因するセキュリティ上の様々な脆弱性も明らかになってきました。例えば訓練データに内在するバイアスの問題や、悪意のあるプロンプトに対する脆弱性などが重要な課題です。

LLMの脆弱性研究は大きく2つの流れに分かれています。1つは脆弱性の種類や評価方法を体系的に整理する調査研究、もう1つはLLMの特定のセキュリティ上の弱点を深く掘り下げる研究です。

これらの基礎研究を踏まえ、最近では「レッドチーミング」というアプローチが重視されるようになってきました。レッドチーミングとは、実際の攻撃者になりすまして模擬攻撃を行い、システムの弱点を見つけ出す手法です。

LLMのセキュリティを高めるため、このレッドチーミングを自動化するツールが次々と開発されています。ツールの中でも、LLMの脆弱性を分析する「スキャナー」というツールが新しく登場し、注目を集めています。しかし、効果や信頼性、使い方に関する知識は十分に蓄積されていません。個々のスキャナーやレッドチーミングのベストプラクティスに関する報告は存在するものの、スキャナーを選択・導入する際の意思決定に役立つ実務報告は見当たらないのが現状です。

そこで今回研究者らは、LLMの脆弱性分析のためのスキャナーを網羅的に調査しました。以下は調査アプローチと調査結果です。まずは、「スキャナー」とは一体何か？という点からお伝えします。

## スキャナーの基本的な仕組み

LLMの脆弱性スキャナーは、比較的最近になって開発されたツールです。テスト対象となるLLMが入力として与えられ、そのLLMの脆弱性を特定するものです。

### スキャナーのアーキテクチャ

スキャナーの中核となる仕組みは、「アタッカー」と「評価者」というペアが組み合わされて使用されることにあります。アタッカーは、LLMに対して意図的に問題のある応答を引き出すために質問（プロンプト）を投げかけます。一方、評価者は、そのような攻撃が成功したかどうかを判定する役割を担っています。

### 攻撃の種類

攻撃方法は大きく2つに分類されます。

一つ目は静的攻撃で、あらかじめ用意された問題のあるプロンプトのデータセットが使用されます。

二つ目はLLMベースの攻撃で、攻撃用のLLMが、リアルタイムで問題のあるプロンプトを生成します。この場合、LLMには特定の要件リストなどの追加情報が与えられることがあります。

### 評価の方法

評価方法もまた、2つのアプローチに分けられます。

一つ目は、LLMの応答の中に特定の文字列やパターンが含まれているかどうかが確認される静的評価です。正規表現によるパターンマッチング、完全一致、単語一致などの手法が含まれます。

二つ目は、評価用のLLMが応答の内容が問題を含んでいないかを判断するLLMベースの評価です。攻撃に使用されたプロンプトや、あらかじめ定められた要件なども考慮されます。

### 攻撃カテゴリーの統一

脆弱性スキャナーの比較のため、攻撃を4つの基本カテゴリーに分類されました。

- ジェイルブレイク攻撃（モデルの制限を回避しようとする攻撃）
- コンテキストと継続の攻撃
- 勾配ベースの攻撃
- コード生成攻撃

## スキャナーの選定基準と対象

### 選定の基本方針

スキャナーの選定では、3つの重要な基準が設けられました。

第一に、脆弱性テストの質の高さが重視されました。実際の状況を想定した包括的なテストスイートが不可欠とされ、十分な文書化と研究に基づいた攻撃手法が信頼性の指標として採用されました。

第二に、進化し続ける脅威に対応できる定期的な更新性が求められました。サイバーセキュリティの脅威は日々変化しており、数ヶ月前に効果的だったテストが現在では役に立たなくなる可能性が考慮されました。

第三に、オープンソースであることと、活発なコミュニティの存在が重要視されました。コミュニティの活動が、プロジェクトの長期的な持続可能性を支えると考えられました。

### 選定されたスキャナー

15個の候補の中から、以下の4つのスキャナーが特に優れていると判断されました。

#### （１）Garak

[https://github.com/leondz/garak](https://github.com/leondz/garak)

2024年初頭にリリースされたGarakは、広範な脆弱性への対応と頻繁な更新により、急速に人気を集めました。その攻撃手法は、学術研究に裏付けられていることが特徴とされています。

#### （２）Giskard

[https://github.c](https://github.com/Giskard-AI/giskard) [om/Giskard-AI/giskard](https://github.com/Giskard-AI/giskard)

Giskardは、活発なコミュニティを持つオープンソースのスキャナーとして知られています。コード貢献、脆弱性に関する議論、ベストプラクティスの共有など、幅広い活動が行われています。

#### （３）PyRIT

[https://github.com/Azure/PyRIT](https://github.com/Azure/PyRIT)

Microsoftによって開発されたPyRIT（Python Risk Identification Tool for Generative AI）は、2024年3月にリリースされました。LLMベースの攻撃と評価戦略に重点を置いて、継続的な進化を遂げています。

#### （４）CyberSecEval

[https://meta-llama.github.io/PurpleLlama/](https://meta-llama.github.io/PurpleLlama/)

Metaによって開発されたこのスキャナーは、LLMが生成するコードの脆弱性検出を専門としながら、自然言語における脆弱性にも対応しています。

### Garakの詳細

Garakのテストスイートは、20種類以上の特定の攻撃-評価ペアを備え、確立された研究に基づくジェイルブレイク攻撃に特に力を入れています。静的な攻撃と評価手法が主に採用されています。

なお「テストスイート」とは、特定のシステムやソフトウェアを検証するための一連のテストケースやテスト項目の集合を指します。

GarakでスキャンするとJSONとHTML形式の両方でレポートが生成され、JSONレポートには各テストの詳細な情報が含まれます。さらに、成功した攻撃のみを記録する「hitlog」も提供されています。非技術者向けのHTML形式では、より広い視点からの概要が提示されます。

Garakの特筆すべき機能として、NvidiaのNeMo Guardrailsとの統合が挙げられます。そのために防御機能の有無によるLLMの脆弱性評価の比較が可能となっています。例えば、GPT-3.5モデルでは、防御設定なしの場合は76.1%、高度な保護設定では92.6%の保護率が達成されるなど、Guardrailsの効果が実証されています。

### Giskardの詳細

Giskardのテストスイートには、9つの攻撃-評価ペアが含まれており、静的方式とLLMベースの方式が組み合わされています。幻覚、有害なコンテンツ、ステレオタイプ、情報漏洩などの広範な問題に対応する機能が備えられています。

特徴的なのは、コンテキストベースのメカニズムです。対象モデルの説明と、多くの場合、安全性要件のリストがコンテキストに含まれます。要件は攻撃ごとに生成され、その攻撃に対する堅牢なモデルの期待される動作が指定されます。

最終的にユーザーフレンドリーなHTMLレポートが生成され、攻撃タイプごとに失敗したケースが分類されます。また、プロンプト、応答、重要度、攻撃成功の理由などの情報が含まれます。

### PyRITの詳細

PyRITは完全にLLMベースのフレームワークを採用し、非常に柔軟な実装が特徴とされています。アタッカーと評価者のLLMの指示に直接アクセスできる点が、他のスキャナーとは異なります。

PyRITには2つの攻撃アプローチが実装されています。

1. 単一ターン攻撃（一般的なLLMベースの攻撃と同様の手法）
2. マルチターン攻撃（対象のLLMと連続的な対話を行い、定義された目標が達成されるまで続けられる攻撃。より高い成功率）

評価用のLLMは、マルチターン攻撃において二重の役割を果たします。攻撃の成功判定に加えて、対話を継続すべきかどうかの判断も行います。評価エンジンには4つの戦略が用意され、二値的な判定（成功/失敗）から、スコアベクトル（1から5の段階評価や0から1の連続値）まで、様々な出力形式が提供されます。

カスタム攻撃戦略の作成が可能で、特定の脆弱性をターゲットにしたテストシナリオが作成できます。また、評価者の指示を修正することで、バイアス、ヘイトスピーチ、倫理的違反などの特定の分野に焦点を当てた評価が可能です。

### CyberSecEvalの詳細

CyberSecEvalは、LLMが生成するコードの脆弱性分析に特化した静的テストスイートを提供します。主に安全でないコーディング手法の検出に焦点が当てられ、悪意のあるコードの生成や自然言語によるジェイルブレイク攻撃の評価も行われます。

安全でないコーディング手法のテストには、2つの主要な戦略が採用されています。

- 自動補完シナリオ（安全でない実践の前の10行のコードをLLMに提示し、リスクのあるコードが再現されるかを確認する）
- 指示ベースアプローチ（安全でない実践を自然言語の指示に変換し、LLMがその指示に基づいて安全でない実践を再現するかを評価する）

評価セッション終了時には、2種類のレポートが生成されます。

1. 様々な攻撃の成功率を要約した統計レポート
2. 各攻撃とLLMの対応する応答を記録した詳細な応答レポート

### 重複する特徴について

以下に、各ツールの特徴が共通している部分を列挙します。

GarakとGiskardでは、人気のオープンソースGuardrailsソリューションがすぐに使用できる形で統合されています。

PyRITとGiskardでは、攻撃成功の評価に関する説明が提供されます。

Giskardのみが、例題テンプレートと非英語の例を通じて、他言語での脆弱性露呈能力が提供されています。

GiskardとPyRITでは攻撃のカスタマイズが可能ですが、そのアプローチは大きく異なります。PyRITではアタッカーLLMのシステムプロンプトを完全に制御できる一方、Giskardでは事前定義されたプロンプトとユーザー入力を組み合わせる、より構造化されたアプローチが採用されています。

現時点では、CyberSecEvalとGarakのみが、LLMが生成するコードのセキュリティを評価するための特別なテスト機能を提供しています。

## 定量的な比較結果

スキャナーの性能は、主に2つの重要な観点から評価されました。カバレッジ（包括性）と評価機能の有効性です。

包括性は、実世界の脅威をどれだけ幅広くシミュレートできるかによって判断されます。攻撃の種類の多様性、各タイプの攻撃インスタンスの数、そしてLLMからエラーを引き出す効果（有効性）が測定されます。

信頼性は、評価機能がどれだけ効果的に働くかで判断されます。様々な攻撃シナリオにおいて、脆弱性を正確に検出できる能力が評価されました。

### 評価対象

4つのLLMが評価対象として選ばれました。

- MetaのLLaMA 3
- CohereのCommand-R
- OpenAIのGPT-4o
- Mistral AIのMistral Small

各スキャナーの攻撃の質を評価するため、一連の攻撃が実施され、各スキャナーの評価機能を使用して攻撃成功率（ASR）が測定されました。しかし、評価機能自体にもエラーの可能性があるため、その誤差範囲（MOE）も評価する必要がありました。

スキャナーの評価には本来の「正解」が存在しないため、1000件以上の攻撃応答が手動で注釈付けされ、信頼できる基準が確立されました。この手動注釈作業では、各攻撃の目的を十分に理解し、モデルの応答を分析することで攻撃の成功が判定されました。

### 主な発見

Garakは最も広範な攻撃の種類を提供し、ほとんどの場合、攻撃インスタンスの数も最も多いことが明らかになりました。また、Garakの攻撃は最も高い品質を示し、コンテキストと継続攻撃での約20%から安全でないコード攻撃での約70%まで、様々な成功率が確認されました。

しかし、評価機能の誤差測定では、Garakを含むすべてのスキャナーの評価機能に問題があることがわかりました。その中ではPyRITのLLMベースの評価機能が最も信頼性が高く（誤差が最小）、一方でGarakでは最大26%の誤差が見られ、これは成功した攻撃の37%が誤って検出されたことを意味します。

### 評価機能の課題

静的評価機能とLLMベース評価機能の両方に課題が見られました。

静的評価においては文字列マッチングを使用する方式では、単純な句読点の違いでも誤分類が発生することがありました。

LLMベース評価では、複雑な文脈をより適切に処理できる一方で、時として予測不可能な動作を示し、無関係な理由付けを提供することがありました。

図で示されているように、GiskardとPyRITのLLMベース評価機能が最も高い信頼性を示しました。CyberSecEvalの信頼性の低さは、安全でないコードの識別という野心的な試みに起因すると考えられます。Garakについては、その大規模なデータは静的評価から LLMベース評価への移行に有益であると考えられます。また静的重視のスキャナーが攻撃の有効性の面で明確な優位性を持つことも示しています。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77301_1-1024x295.png)

## 組織のニーズに合わせたスキャナーの選択に向けて

スキャナーの選択は、組織特有のビジネスリスクによって大きく影響を受けると考えられています。

例えば、HR、営業、マーケティング、社内データ分析など、多様なユースケースを扱う大企業のレッドチームグループでは、すぐに使える包括的なテストスイートが好まれます。一方、単一製品に焦点を当てる企業では、特定のニーズに応じて動的に適応できるカスタマイズ可能なソリューションが重視されます。

### 各スキャナーの推奨用途

#### Garak

最も広範なテストスイートが提供されており、多様なユースケースを扱うレッドチームグループに適していると評価されています。ただし、静的な攻撃データセットに重点が置かれているため、カスタマイズ性には制限があります。NvidiaのNeMo Guardrailsとの統合により、追加の安全層の設定が可能とされています。

#### Giskard

静的手法とLLMベースの手法の両方を用いた柔軟な攻撃生成を求めるユーザーに最適です。LLMベースの攻撃のカスタマイズが簡単かつ効果的に行えることが特徴です。そのため、最小限の手動介入で動的なオンライン環境に合わせたテストスイートの作成が可能です。また、Guardrailsによる安全性強化機能も含まれています。

#### PyRIT

最もカスタマイズ可能なテストスイートが提供され、LLMベースの攻撃に重点が置かれています。アタッカーと評価者のLLMの両方の指示を編集できる完全なアクセスが許可されており、高い柔軟性が実現されています。ただし、プロンプトエンジニアリングの十分な知識が必要とされます。そのため、外部の知識に頼るのではなく、社内で独自にテストスイートを作成することに重点を置くレッドチームに適しています。また、比較的高い成功率を示す高度なマルチステップ攻撃も実装されています。

#### CyberSecEval

コード生成LLMのレッドチーミングに特化しており、コード関連のセキュリティ問題を露呈するように設計されたテストスイートが提供されています。そのため、自動生成コードの完全性が重要なソフトウェアとサイバーセキュリティ分野のレッドチームグループに特に価値があるとされています。

### 現在のスキャナーの課題

現在、スキャナーの評価機能の信頼性に重要な問題が見つかっています。評価機能とは、スキャナーが「攻撃が成功したかどうか」を判断する部分です。この機能の問題は、スキャナーごとに異なる独自のテスト方法を採用しているため、一つのデータセットでは適切な評価ができないことにあります。

この問題に対処するため、今回研究チームは約1000件の事例を含む新しいデータセットを作成しました。このデータセットを使って、各スキャナーが攻撃の成功を正しく判断できているかどうかを詳しく調べました。その結果、すべてのスキャナーの評価機能が十分な堅牢性を持っていないことが明らかになりました。

こうした問題を解決するためには、今後3つの方向性があると思われます。ただし、ユーザーが行う努力ではなく、プロバイダーに求められる内容がほとんどです。

まず第一に、スキャナーの性能を公平に比較するための「物差し」となる新しい仕組みを作ることが必要です。日々進化するLLMの弱点に対応できるよう、定期的に更新される評価用データが含まれます。

次に、評価機能そのものの改善が提案されています。例えば単純な文字列の一致を確認する方法（静的評価）と、LLMを使って判断する方法（LLMベース評価）の両方の良いところを組み合わせる方法が推奨されています。静的評価は単純で制御しやすく、LLMベース評価は文脈を理解する力に優れているため、これらを組み合わせることで、より正確な評価が期待できます。

最後に、脆弱性スキャナーの品質を保証するための基準作りが提案されています。スキャナーが最低限満たすべき効果と信頼性のレベルを定めるものです。

## まとめ

本記事では、LLMの脆弱性を調べるためのオープンソースのスキャナーに関する初めての包括的な比較研究を紹介しました。研究者らは、Garak、Giskard、PyRIT、CyberSecEvalという4つの有望なスキャナーについて、共通の設計原理と独自の特徴を明らかにしています。

彼らはは約5,000件の攻撃テストを実施し、各スキャナーの効率性と信頼性を詳細に評価しました。また、スキャナーの評価精度を検証するための1,000サンプルのデータセットも作成しています。

組織がLLMシステムのセキュリティ対策を検討する際の参考となるだけでなく、今後のスキャナー開発における課題も示されました。

- 参照論文URL： [https://arxiv.org/abs/2410.16527](https://arxiv.org/abs/2410.16527)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[プレイヤーの行動に応じてゲームを自動生成する技術　Googleなどが開発](https://ai-data-base.com/archives/77790)

[LLMが自分で「より賢いLLMの作り方」を発見するSelf-Developingフレームワーク（NEC 石橋陽一氏）](https://ai-data-base.com/archives/77965)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)