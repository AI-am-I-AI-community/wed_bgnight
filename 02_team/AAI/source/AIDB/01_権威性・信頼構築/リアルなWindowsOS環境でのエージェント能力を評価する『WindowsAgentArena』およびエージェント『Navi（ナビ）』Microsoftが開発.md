---
title: "リアルなWindowsOS環境でのエージェント能力を評価する『WindowsAgentArena』およびエージェント『Navi（ナビ）』Microsoftが開発"
source: "https://ai-data-base.com/archives/75765"
author:
  - "[[AIDB Research]]"
published: 2024-09-18
created: 2025-06-13
description: "この記事では、Microsoftの研究チームが開発した新しいエージェント評価環境「WindowsAgentArena」と、それを使って開発・評価されたマルチモーダルエージェント「Navi」を紹介します。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

この記事では、Microsoftの研究チームが開発した新しいエージェント評価環境「WindowsAgentArena」と、それを使って開発・評価されたマルチモーダルエージェント「Navi」を紹介します。

WindowsAgentArenaは、実際の Windows オペレーティングシステム内で動作するエージェントの性能を測定するための総合的なベンチマークです。  
Azureクラウド上で完全に並列化可能なため、これまで数日かかっていた評価プロセスを約 20 分で完了できるようになり、エージェントの開発サイクルが大幅に短縮されて迅速な改良ができるようになりました。

研究チームは、この新しい環境を活用して「Navi」というマルチモーダルエージェントを開発しました。Naviの性能評価の結果や、開発の過程で得られた知見は、今後のOS操作エージェント研究にとって重要なヒントとなるものです。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75765_top2-1024x576.jpg)

**参照論文情報**

- タイトル：Windows Agent Arena: Evaluating Multi-Modal OS Agents at Scale
- 著者：Rogerio Bonatti, Dan Zhao, Francesco Bonacci, Dillon Dupont, Sara Abdali, Yinheng Li, Justin Wagle, Kazuhito Koishida, Arthur Bucker, Lawrence Jang, Zack Hui
- 所属：Microsoft, Carnegie Mellon University, Columbia University

## 背景

LLMをコンピューターエージェントとして活用できる可能性が注目されています。最近のLLMは画像の説明文を作成したり視覚的な推論を行ったりするマルチモーダルな能力が向上したことで、エージェントとしての基礎ができてきたのです。

しかし、現実の人間が行うワークフローの複雑さは、これまでのテスト環境では十分に捉えられていないという課題がありました。私たちは日常的に、複数のプログラムを切り替えたり、アプリケーションの設定を変更したり、グラフィカルインターフェースとコマンドラインインターフェースを行き来しながら複雑な作業を行っています。

この問題に対応するため、さまざまなベンチマークが開発されてきました。しかし、今までのベンチマークは特定のモダリティやドメインに限定されていたり、評価に長時間を要するという問題がありました。

そこで今回研究者らは、Windowsに焦点を当てることで、最も一般的なコンピューターOS（市場シェア73%）におけるエージェントの性能評価を可能にする「WindowsAgentArena」を開発しました。

WindowsAgentArenaは初期条件と自動実行ベースの評価基準を備えたさまざまなタスクセットを提供し、人間の操作記録に従うのではなく、タスク完了に対して報酬を与える仕組みを採用しています。完全にスケーラブルで、Azure仮想マシン上のセキュアなDockerコンテナにデプロイ可能です。その結果、これまで数日かかっていたベンチマーク評価を、わずか20分程度で完了できるようになったとのことです。

さらに研究者らはこの環境を応用して、WindowsOSでの操作に強みを持つエージェント「Navi」を開発しました。

以下で研究全体の詳細を紹介します。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75765_1-1024x267.png)

本ベンチマークの概念図。実際のWindows OS環境を包含するベンチマークスイートで、エージェントが様々なアプリケーションやウェブドメインと対話できること、Azure仮想マシンで並列評価が可能であることを示す

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75765_2-1024x414.png)

AIエージェント評価プラットフォーム/ベンチマークの比較表

## WindowsAgentArenaの環境について

### タスク定義

WindowsAgentArenaの環境では、エージェントがタスクをどのように実行するかを定義しています。エージェントは、ユーザーからの指示や画面上の情報をもとに、適切な操作を行います。エージェントが行う操作には、マウスのクリックやキーボード入力、プログラムの起動など、さまざまな行動が含まれます。

エージェントはタスクを達成するために、環境とやり取りを繰り返します。エージェントが環境とやり取りを行うプロセスは、タスクが完了するか、エージェントが終了を宣言するまで続きます。タスクを成功させると報酬が与えられ、失敗すると報酬は得られません。

### 観測空間

エージェントが取得できる情報は次のとおりです。以下の情報をもとに、エージェントは環境を理解し、次に取るべき行動を判断します。

（1）タスクの指示（ユーザーの目標を示すテキスト）

（2）現在アクティブなウィンドウのタイトル

（3）開いているすべてのウィンドウやアプリのリスト

（4）クリップボードの内容

（5）画面上の文字情報（ [OCR](https://ai-data-base.com/archives/26261 "光学文字認識（OCR）") による取得）

（6）操作可能な画面要素のリスト（位置や内容などの情報を含む）

（7）画面の画像

- 前のステップの画面画像
- 現在の画面画像
- 特定の要素に枠線が表示された注釈付き画像

（8）過去の操作履歴

（9）後で使用するためのメモ機能

### 行動空間

WindowsAgentArenaでは、エージェントが取れる行動として次のものがあります。

1. Pythonコードを使った自由な操作
2. 用意された関数を使った操作

また、マウスの移動やクリック、キーボードでの入力、プログラムの起動、アプリの切り替えなど、さまざまな操作を行います。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75765_3.png)

WINDOWSAGENTARENAのComputer classアクション。GUI、キーボード、OSに関連する機能が含まれる。

そして行動を組み合わせることで、ユーザーの目的の達成を目指します。

### 実行に基づく報酬評価

タスクの成功や失敗は、後処理のスクリプトを使用して評価します。タスクの種類に応じて評価方法は異なり、次のような方法があります。

- システムやアプリの設定を確認する
- ファイルの内容をチェックする
- Webを利用して結果を評価する

評価を通して、エージェントがタスクを正しく完了したかを判断し、適切な報酬を与えます。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75765_4-1024x581.jpg)

データ操作、ウェブナビゲーション、アプリ設定など、タスク評価スクリプトの例。タスクの報酬Rは、エージェント実行後のシステムの最終状態に基づいて計算され、複雑な現実世界のタスクの評価を可能にする

### Windows OS向けのタスク選定

WindowsAgentArenaの初期リリースには、154のさまざまなタスクが含まれており、一般的なWindowsユーザーが日常的に行う操作をカバーしています。

1. ドキュメント編集やスプレッドシートの操作（LibreOffice Calc／Writer）
2. インターネットの閲覧（Microsoft Edge、Google Chrome）
3. システム設定やファイル操作（File Explorer、Settings）
4. コーディング（Visual Studio Code）
5. 動画の再生（VLC Player）
6. ユーティリティの使用（Notepad、Clock、Paint）

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75765_5-1.png)

11のプログラム/アプリケーションにおけるタスクの内訳

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75765_6-1.png)

タスクをドメイン、難易度、完了に必要なステップ数で分類

なお、各タスクはJSON形式の設定ファイルで定義されており、設定ファイルは次の要素で構成されています。

- 自然な言葉での指示
- 初期設定に必要な手順
- タスク評価に必要な情報の取得方法
- 評価のスタイルと方法（例えばファイルの比較を行うPythonスクリプトなど）

### 開発基盤

WindowsAgentArenaのインフラは、ローカル環境でもクラウドでも柔軟に動作するよう設計されています。Azure上の仮想マシンを利用することで、大規模な並列評価も可能です。

システムの中心には、Windows11の仮想マシンをホストするDockerコンテナがあります。コンテナ内には、タスクを管理するクライアントプロセスやエージェント、評価用のスクリプトが配置されています。

仮想マシンは、エージェントが操作を行う主要な環境となります。PythonのFlaskサーバーがコンテナと仮想マシンの間をつなぎ、クライアントからのコマンドを仮想マシンで実行し、観測結果やファイルをクライアントに返します。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75765_7-1024x358.png)

ローカルおよびクラウドデプロイメントの設定比較。小規模なローカルテストと大規模なクラウド並列化のために設計

ライセンスの関係上、事前に構築されたWindows11のスナップショットは提供されていませんが、オープンソースの手順に従ってMicrosoftのサーバーからトライアル版をダウンロードし、ベンチマーク用に自動で準備するスクリプトが用意されています。

## ベースライン結果と分析

### Windowsナビゲーション用エージェント『Navi』

研究チームは、Windows環境内で自律的に操作できる新たなマルチモーダルエージェント「Navi」を開発しました。Naviの主な特徴は以下のとおりです。

1. 思考連鎖プロンプティング手法の活用

Naviは、コンピューターの現在の状態、自身の過去の行動、そして次に取るべき最適な行動を推論するよう指示されます。

1. 多様な入力情報の活用

下記の情報を入力として使います。

- 現在のフォアグラウンドウィンドウのタイトル
- 開いているすべてのウィンドウやブラウザタブのタイトル
- 現在の画面の表現
1. 画面表現の処理方法

研究チームは、エージェントへの入力として画面表現を処理するため、以下の方法を検討しました。

- UIA（ユーザーインターフェース自動化）ツリーの解析
- DOMツリーの解析（ブラウザのみ）
- [OCR](https://ai-data-base.com/archives/26261 "光学文字認識（OCR）") （ [光学文字認識](https://ai-data-base.com/archives/26261 "光学文字認識（OCR）") ）
- アイコンや画像の検出
- OmniParser（マルチ要素検出用の専用モデル）

最終的に、複数の方法を組み合わせることで、画面の詳細な表現を取得し、エージェントの理解力を向上させています。

1. プロンプトの構成

エージェントへの完全なプロンプトは、以下の要素で構成されています。

- タスクの指示
- 行動空間の説明
- エージェントの過去の行動履歴
- コンピューターのクリップボードの内容
- 変数や思考を保存できるメモリブロック
- Set-of-Marks（SoM）で注釈付けされた画像
- 前の状態のスクリーンショット

※ [Set-of-Marks（SoM）](https://arxiv.org/abs/2310.11441) とは、マルチモーダルLLM用に考案された、効果的な視覚的プロンプティング手法です。平たく言えば画像に注釈を加える手法です。モデルの理解が格段によくなると検証されています。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75765_8-1024x225.jpg)

独自のピクセルベースのローカルモデルに基づくSet-of-Marksの例。 OCR （青）、アイコン検出（緑）、画像検出（赤）

1. エージェントの出力

画面理解と長期的なタスク計画に関連する質問に回答した後、エージェントは次の行動を示すPythonコードを出力します。

### WindowsAgentArena ベースライン結果

研究チームは、異なるSoMと推論モデルを用いてNaviのバリエーションを比較しました。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75765_9-1024x565.png)

エージェントの成功率。タスクカテゴリ、モデル、入力モダリティタイプでグループ化

主な観察結果と洞察は以下のとおりです。

1. 人間のパフォーマンスとの大きな差

最高性能のエージェント（UIA + OmniParser + GPT-4V-1106）は成功率19.5%であるのに対し、人間のパフォーマンスは成功率74.5%でした。

この差はカテゴリーによって異なります。エージェントは、テキスト中心のインターフェース（Webブラウザ、Windowsシステム）に関するタスクでは比較的良好なパフォーマンスを示しましたが、キーボードショートカットやアイコンに依存するタスク（Office、Windowsユーティリティ）では劣っていました。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75765_10-1024x573.jpg)

成功したエピソードの例。UIAと独自モデルを組み合わせて画面解析。エージェントはマウスとキーボード機能を使用してウェブページのPDFをデスクトップに保存。

1. 正確なSet-of-Marks（SoM）の重要性

視覚的プロンプト技術の品質が、エージェントのパフォーマンスに大きな影響を及ぼすことが判明しました。高品質のUIAマーカーをピクセルベースの要素検出器に追加することで、パフォーマンスが大幅に向上しました。

結果を以下に並べます。

- OmniParserで57%向上
- オープンソースモデルで52%向上
- 専用ピクセルモデルで15%向上（GPT-4V-1106使用時）
1. 視覚と言語の不一致による失敗

エージェントの一般的な失敗原因は、テキスト出力と画面の視覚的理解を正確に一致させられなかったことでした。この問題は、視覚言語モデル（VLM）の訓練データ分布と、OS上での数百の小規模マーカーを含むタスクとのミスマッチによるものと考えられます。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75765_11-1024x459.jpg)

Windows OSエージェントの一般的な失敗例。(a) SoMの境界ボックスマーキングの不正確さによる問題。(b) モデルのビジュアル-言語アライメントのエラー

1. ベースモデル間のパフォーマンス差

Phi3-V、GPT-4o-mini、GPT-4o、GPT-4V-1106の間で大きなパフォーマンス差が見られました。GPT-4V-1106が最も優れた性能を示し、多くのカテゴリーでGPT-4oの成功率の2倍以上を達成しました。

### Mind2Web ベンチマークにおける追加結果

Naviの性能と堅牢性を異なる環境で評価するため、研究チームは [Mind2Webベンチマーク](https://osu-nlp-group.github.io/Mind2Web/) でも評価を行いました。結果は以下のとおりです。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75765_12-1024x279.png)

さまざなモダリティと入力の組み合わせによるMind2Webの評価結果

1. 最先端のパフォーマンスを達成

Naviは、オリジナルのSeeActエージェントと比較して、最先端のパフォーマンスを記録しました。

1. 最適な入力の組み合わせ

画像とDOMのSoMプロンプティングの組み合わせが、エージェントのパフォーマンス向上に最も効果的であることが判明しました。これは、WindowsAgentArenaでUIAツリーとピクセルベースのマーカーを組み合わせた結果と一致しています。

## 考察

以上の結果に基づき、研究チームは汎用OSエージェントの開発に関するいくつかの重要な議論点を提起しています。以下にその主なポイントを記載します。

### 完全自律型エージェント vs. 人間の関与を含むエージェント

研究チームは自律型エージェントに焦点を当てていますが、人間の関与を組み込むことで、パフォーマンスと効果を向上させる可能性があると指摘しています。

例えばエージェントが質問アクションを選択してユーザーから追加の情報や直接の介入を求めることで、タスク達成の確実性を高めます。

ただしコストが増加する可能性があり、評価やベンチマークがより困難になることがあります。また、人間の関与が必要となる場合があります。

### 汎用エージェント vs. 特化型エージェント

現代の多くのエージェントは、汎用的な知識を持つ大規模モデルに基づいています。しかし、研究チームはOSエージェントを「エージェントのエージェント」として扱う新たな方向性を提案しています。

特定のドメイン向けに微調整された専門のサブエージェントを使用することで、各領域に特化したエージェントが協調し、高度なタスク遂行ができると期待されます。汎用性を維持しつつ、複雑なタスクをより効率的に処理できる可能性があります。

### 模倣学習 vs. 強化学習

エージェント開発における主要な課題の一つは、モデルのトレーニングやチューニングに必要な正解行動データの不足です。これはロボティクス研究でも同様の問題に直面しています。

例えば [強化学習](https://ai-data-base.com/archives/26125 "強化学習") は、不完全な行動データを活用してモデルを改善する手法として有望です。しかし強化学習においてはタスク完了などを基準とした適切な報酬目的関数を定義する必要があります。

そこで研究チームは、WindowsAgentArenaを活用して、エージェントの強化学習トレーニング用データを大規模に生成する方向性を有望と見ています。

### 「最適な」行動空間とは

研究チームは自由形式の行動を持つ完全自律型エージェントに焦点を当てていますが、あらかじめ定義された行動関数やスキルライブラリを使用するエージェントの可能性も検討しています。

厳密な行動のルールを使用することで、エージェントの実行精度を高めることができます。エラーは主にエージェントの計画立案と意思決定から生じます。

このアイデアを実行する上ではルールを組み合わせる際の判断が重要となりますが、エージェントの行動をより制御しやすく、予測可能にします。

### 安全性とセキュリティ

AIエージェントの設計プロセスにおいて、倫理的ガイドラインと責任あるAI活用の原則を遵守することは極めて重要です。研究チームは、「ユーザーはAIの行動を理解し、指示し、診断し、必要に応じて上書きする能力を持つべき」そして「ユーザーのプライバシーを尊重し、公平性を確保し、社会にポジティブな貢献をするAI技術の開発と継続が求められる」と念を押しています。

## まとめ

この記事では、Windows上でのLLMエージェントの性能を測るための「WindowsAgentArena」というツールを紹介しました。

「WindowsAgentArena」には154種類の様々な課題があり、LLMエージェントに計画を立てさせたり、画面を理解させたり、ツールを使わせたりする実際的な作業が含まれています。特徴的なのは、Azureを使って、従来なら数日かかる評価を約20分で終えられることです。

さらに研究チームは「Navi」という新しいLLMエージェントも開発しました。ただし、NaviをWindowsAgentArenaで試したところ最高で19.5%の成功率であり、人間の74.5%にはまだ及びません。

WindowsAgentArenaは無料で公開されています。WindowsAgentArenaを活用して今後のLLMエージェント研究が進むことが期待されています。

- 参照論文URL： [https://arxiv.org/abs/2409.08264](https://arxiv.org/abs/2409.08264)
- プロジェクトページ： [https://microsoft.github.io/WindowsAgentArena/](https://microsoft.github.io/WindowsAgentArena/)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[ノーコードでLLMマルチエージェントを操る『AUTOGEN STUDIO』Microsoftが新開発](https://ai-data-base.com/archives/75716)

[単純に生成回数を増やすとLLMの性能が大幅に向上する「推論時のスケーリング則」](https://ai-data-base.com/archives/75838)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)