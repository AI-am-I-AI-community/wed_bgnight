---
title: "プロンプトに例を多く載せるほど、どんなタスクでも性能が上がるのか？DeepMindによる『Many-shot Learning』の実験結果"
source: "https://ai-data-base.com/archives/67883"
author:
  - "[[AIDB Research]]"
published: 2024-04-19
created: 2025-06-13
description: "プロンプトに例示を含めることにより新しいタスクを学習させられる「コンテキスト内学習（In-context Learning、ICL）」が注目を集めています。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

プロンプトに例示を含めることにより新しいタスクを学習させられる「コンテキスト内学習（In-context Learning、ICL）」が注目を集めています。

これまでの研究は数ショットで行われてきましたが、今回Googleの研究者らは、「多ショット学習（Many-shot Learning）」の可能性を探っています。最新のLLMの長いコンテキストウィンドウを活用し、数百から数千もの例を用いた実験を行ったのです。

多様なタスクにおける性能向上や、人間のデータに依存しない新しい学習法など、多ショットの効果と特性が詳細に分析されました。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_67883-1024x576.jpg)

**参照論文情報**

- タイトル：Many-Shot In-Context Learning
- 著者：Rishabh Agarwal, Avi Singh, Lei M. Zhang, Bernd Bohnet, Stephanie Chan, Ankesh Anand, Zaheer Abbas, Azade Nova, John D. Co-Reyes, Eric Chu, Feryal Behbahani, Aleksandra Faust, Hugo Larochelle
- 所属：Google DeepMind

**本記事の関連研究** ：

- [LLMの思考の流れに沿ってプロンプトを与えるか否かで30%以上精度が変化する　DeepMindが報告](https://ai-data-base.com/archives/64551)
- [CoTの推論ステップ数がLLMの推論能力に及ぼす影響を詳細に検証した結果](https://ai-data-base.com/archives/62364)
- [LLMに敢えて間違わせてルールを覚えさせるプロンプト手法　Google DeepMindなどが考案](https://ai-data-base.com/archives/64057)
- [GPT-4やGeminiなどさまざまなLLMで、プロンプトの入力が長くなるにつれて推論性能に顕著な低下が見られる](https://ai-data-base.com/archives/64873)

## 背景

LLMのコンテキスト内学習においては、プロンプトで提供されるわずか数例から新しいタスクを学習することができると示されています。パラメータの更新は一切必要ないため、非常に便利な特性です。

しかし数ショット（数個の例）で効果が出ている一方、多ショットだとどうなるのか？Googleの研究者らはそう疑問を持ちました。これまで多ショットの研究はほとんどされてきていません。

最近LLMの文脈ウィンドウ（LLMが一度に処理できるトークン化された入力の量）が拡大してきたため、数百から数千もの例を用いた実験が可能です。例えば2024年2月にリリースされたGemini 1.5 Proでは、文脈長が100万トークンにまで拡大しました。  
うまくいけば多ショットによってLLMがより多様なタスクに適応でき、有用性が増すのかもしれません。

研究者らは、プロンプトにおける例示の数を増やすことが、LLMの性能にどのような影響を与えるかを体系的に評価しました。

タスクとしては、機械翻訳、要約、計画、報酬モデリング、数学的問題解決、科学的質問応答、アルゴリズム的推論など、多様な種類が試されました。

さらに、人間が例を用意する代わりにモデルが例を生成する挑戦的な実験も行われました。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_67883_1-1024x413.png)

多ショットICLと少ショットICLのタスクパフォーマンスの比較（本研究の総括的な図1）

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_67883_2-1024x352.png)

各タスクの最高性能と最大ショット数のコンテキスト長（本研究の総括的な図2）

## 例示数を単純に増やす実験の結果

研究者らは、Gemini 1.5 Proモデルを用いて、例示数を増やすことによるICLの性能への影響を多様なタスクにおいて評価しました。

### タスク1：低リソース言語への機械翻訳

研究チームはまず、事前学習では不十分な知識しか得られない可能性のある、「英語から低リソース言語（話者が少ない言語）への機械翻訳タスク」に焦点を当てました。コンテキスト例の数を増やすことによる性能の変化を評価した結果、少ショットから多ショットへの移行により、クルド語で4.5％、タミル語で1.5％の性能向上が見られました。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_67883_3-1024x321.png)

機械翻訳におけるショット数の増加に伴う性能向上

特筆すべきは、多ショットの結果、Google 翻訳の性能を上回ったことです。

（編集部注：横軸に注目です。最大で1024個（2の10乗）もの例を用いてコンテキスト内学習を行っています。）

### タスク2：要約タスク

次に要約タスクにおける、LLMの能力変化を観察しました。異なる種類のトピックにわたっての実験が行われています。

XSumデータセット（226,711 件のニュース記事で構成されている要約タスクのためのデータセット）の例を多ショットで使用しました。

その結果、多ショットICLは、XSumおよびXLSumでファインチューニングされた要約特化モデル（PEGASUSとmT5）に非常に近い性能を達成しました。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_67883_4-1024x338.png)

要約タスクにおけるショット数の増加に伴う性能変化

### タスク3：物流計画

研究者らは、多ショットICLが常識的な計画能力を向上させることができるかどうかを検証するために、物流ドメインのベンチマークを使用しました。荷物を飛行機などで運ぶ計画能力を試すものです。

結果、コンテキスト例の数が増えるにつれて、成功率が大幅に向上することが示されました。最先端の既存手法におけるスコアには及ばないものの、多ショットICLがLLMの常識的な計画能力を向上させる可能性が示唆されました。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_67883_5.png)

計画タスクにおけるショット数の増加に伴う成功率の変化

### タスク4：コード検証

研究チームは、GSM8Kデータセットを用い、コードの正確性をチェックするタスクの実験にも取り組みました。

その結果はやや複雑なものでした。

16以上のコンテキスト例で「性能」は大幅に向上しました。一方で、正解と不正解のソリューションに対する「確信度」は例示が増えると分離されることが示されました。不正解に対する確信度は下がっていってしまいます。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_67883_6-1024x320.png)

コード検証タスクにおけるショット数の増加に伴う性能と確信度の変化

## 人間による例示からの脱却を実験

多ショットICLは、高品質な例に頼っており、ほとんどの場合は例は人間による手製です。しかし、複雑すぎる問題や新しい課題などに対して、必ずしも人間による高品質な例が得られるとは限りません。

そこで、研究者らは、この問題に対処するための2つのアプローチを探求しました。「強化ICL」と「教師なしICL」です。

### 強化ICLとは

すでにファインチューニングにおいては、人間製のデータよりもモデル生成データの方がタスク性能向上に役立つケースが報告されています。

そこで今回研究者らは、コンテキスト内学習においてもモデル生成の例を使用しました。例を生成する方法は以下の通りです。

1. Few-shotまたはゼロショットのCoTプロンプトを使用
2. 各問題に対して複数の例を [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング")
3. 正しい答えが得られた例を選ぶ
4. 問題と正解のペアをまとめる

なおモデル生成による例で行う強化ICLの問題点は、CoTの推論ステップが正しいとは限らない、つまり正解を得ている例だとしても推論過程が誤っている恐れがあることです。そういったデータをファインチューニングやプロンプトを行うと、通常はパフォーマンスが低下します。

（しかし、結論的には、モデル生成の例は人間の例以上の効果をもたらすことになりました。後述を参照）

### 教師なしICLとは

研究者らはさらに一歩進んで、多ショットにおいて例の中から根拠（正解と正解に至る道筋）を完全に取り除き、問題のみでモデルにプロンプトを与えるという、教師なしICLを実験することにしました。

以下の3つの要素で構成されています。

1. 「以下のような質問が提示されます：」などの前置きを書く
2. 未解決の入力または問題のリストを並べる
3. 望ましい出力形式のためのゼロショットの指示またはFew-shotプロンプト

要するに、問題と正解ペアの多ショットではなく、問題情報のみを例として多ショットで与えるという実験です。

（編集部注：このテーマだけでも1本の論文になりそうなくらい興味深い設定です。）

この実験が芳しい結果を得ると期待された一つの理由は、LLMの事前知識の豊富さにあります。LLMがタスクを解くために必要な知識をすでに持っている場合、プロンプトに挿入された情報はタスクに必要な知識を絞り込むのに役立つ可能性があります。

教師なしICLは広く適用できるはずですが、事前知識が枯渇している可能性が高いタスク（例えば、低リソースの機械翻訳）では、うまくいかないかもしれません。

### 数学問題タスクで実験

研究者らは、高校数学の問題で構成されている [Hendrycks MATH](https://github.com/hendrycks/math) データセットを用いて、強化ICLと教師なしICLを評価しました。

教師なしICLでは、未解決の問題の後に4ショットプロンプトを追加しました。比較のため、MATHセットからの人間が書いた解法（正解）を使用したICLも評価しました。

下の図（左）に示すように、MATH500において、強化ICLと教師なしICLは、少ショットと多ショットの両方で、正解の解法を用いたICLを上回りました。

また、GSM8Kへの転用（右の図）では、MATHプロンプトを用いた強化ICLが、少なくとも25ショットで、正解のMATH解法を用いたICLや教師なしICLを上回りました。つまりモデル生成の解法を例とするテクニックが役立つ可能性を示唆しています。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_67883_7-1024x356.png)

数学的問題解決における強化ICLと教師なしICLの性能比較

### 科学的質問応答タスクで実験

生物学、物理学、化学の大学院レベルの推論に焦点を当てた多肢選択式のQAベンチマーク「 [GPQA](https://github.com/idavidrein/gpqa) 」でも実験されました。

強化ICLでは、ゼロショットプロンプトを使用して複数の正解例を生成し、129問を解きました。

下の図に示すように、正解例を用いた平均テスト精度は、5ショットから125ショットにかけて大幅に向上し、最高性能の125ショットプロンプトは、最先端のClaude-3 Opusに匹敵する精度に迫りました。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_67883_8-1024x293.png)

GPQAにおける強化ICLと教師なしICLの性能比較

興味深いことに、強化ICLの結果は、GPQAにおいて、25ショットまではモデル生成の例がデータセットで用意されたもともと正解を例とするよりも優れていることを示唆しています。しかし、それ以上のショット数では同等の性能をもたらしています。

そして教師なしICLは、ショット数に応じて正解の例を用いたICLよりも優れた性能を示すことがありますが、一般的に強化ICLよりも劣っていました。

### アルゴリズム推論タスクでも実験

研究者らは、 [BIG-Bench Hard](https://github.com/suzgunmirac/BIG-Bench-Hard) の8つのタスクを選択し、150の問題からなるデータセットでを使用しました。標準的な3ショットCoTプロンプトをで、問題ごとに10の論拠を [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") しました。正確性に基づいて例をフィルタリングし、3〜100の（問題、論拠）のペアを含むプロンプトに配置しました。そして100の問題でパフォーマンスを評価しました。

下の図に示すように、強化ICLは、ほぼすべてのタスクにおいて、標準的な3ショットCoTプロンプトを大幅に上回りました。また、8つのタスクのうち7つで、ショット数が増えるほどパフォーマンスが単調に向上しました。いくつかのタスクでは、強化ICLは、データ量を統制した場合でも、人間が書いた3ショットプロンプトを上回りました。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_67883_9-1024x367.png)

BIG-Bench Hardにおける強化ICLの性能

なお、強化ICLにおいてプロンプトに使用された「例」は、問題と単純な正解だけでなく、正解に至る道筋も含められました。そのため、モデル生成の「道筋」に誤りが含まれていると強化ICLに悪影響が出ると懸念されていました。しかし結果として、強化ICLは優れた成果を出しました。

## 多ショット文脈内学習の分析

研究者らは、Few-shotから多ショットになるとモデルの振る舞いがどのように変化するかを調査しました。

### 事前学習の偏りを克服

これまで、どんなにコンテキスト内学習を行ったとしても事前学習によるバイアスを変えることは難しいと報告されてきました。しかしコンテキスト長に限界があった時代の実験による結果のため、常識が覆る可能性があります。

本研究では、Financial PhraseBank（FP）センチメント分析（映画レビューの [感情分析](https://ai-data-base.com/archives/26497 "感情分析") ）データセットを用いて以下のようなラベルの付け方を試しました：

研究者らは、事前学習の好みに挑戦するラベルの関係を調べました：

- 反転ラベル：本来のラベル（ネガティブ、ニュートラル、ポジティブ）を逆順にする。学習済みの感情の傾向と矛盾するようにあえて仕向けます。
- 抽象ラベル：感情とは無関係なラベル（A, B, C）を使う。既存の感情との関連性を取り除くため。

その結果、Few-shotでは、置換ラベルを使った精度が本来のラベルよりもかなり低くなりました。Few-shot学習では事前学習のバイアスを克服するのが難しいことを示唆しています。

しかし、多ショットになるにつれ、反転ラベルと抽象ラベルの精度が大幅に向上し、本来のラベルに近づいていきました。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_67883_10-1024x300.png)

センチメント分析における事前学習の偏りの克服

また、本来のラベルでは、予測したラベルへの確信度がショット数とともに着実に高まりました。一方、反転ラベルでは、事前学習の偏りを克服する過程で、確信度が一旦下がってから急激に上昇し、一定になりました。

つまり、十分な例示数があれば、言語モデルは事前学習による思い込みを克服できるようです。

### 数学的なタスクを多ショット学習で解けるか

研究者らは、数値を入力とする抽象的な数学の関数を、多ショットで解けるかどうかを調べました。特に、以下の2つのタスクに注目しました。

1. 高次元の線形分類：
	- N次元のベクトルとそのラベルからなるデータセットを作る。
	- もう1つのN次元ベクトルをランダムに選び、それを決定境界とする。
	- この境界より上のN次元の点をK個、下の点をK個、モデルに例示する。
	- 新しいN次元の点が、境界より上か下かをモデルに予測させる。 （決定境界やしきい値はモデルに伝えない）
2. パリティ関数：
	- 20桁の2進数列に、1の数が奇数か偶数かを判定させる。

高次元の線形分類では、多ショット学習はランダムな予測よりもはるかに高い精度を達成し、機械学習の強力な手法であるk-nearest neighbors（最も近いk個のデータの多数決でクラスを予測する機械学習アルゴリズム）とほぼ同等の性能を示しました。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_67883_11-1024x320.png)

高次元の線形分類におけるショット数の増加に伴う性能変化

パリティ関数では、例示数を8192まで増やすと、精度が一貫して向上しました。これは、はるかに多くの例を最初から学習したGPT-2という言語モデルを上回る性能です。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_67883_12-1024x305.png)

20桁のシーケンスパリティタスクにおけるショット数の増加に伴う性能変化

Many-shot Learningは、自然言語以外の数学的なタスクにも適用できる可能性が示唆されました。

### Many-shot Learningは例示の順序に敏感か？

Few-shotでは、プロンプト内の例示の順序が性能に大きく影響することがあります。研究者らは、多ショットでもこの影響が続くかどうかを調べました。

数学の問題集から50問を選び、その順序を10通りにランダムに並べ替得る実験を行いました。そして、別の500問からなるテストセットで性能を評価しました。

その結果、数学の分野によって性能のばらつきが大きいことがわかりました。驚くべきことに、ある分野で優れた順序が、別の分野では不十分な結果につながることもありました。例えば、幾何学で最高の順序が、数論では低い性能となったのです。

このように分野ごとの変動は大きいものの、全体の平均性能の変動は比較的小さくなりました。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_67883_13.png)

MATHにおける例の順序に対する多ショットICLの感度

### 確信度は性能の指標になるか

先行研究では、プロンプトの長さが増えるほど、正解に対するモデルの確信度が下がることが確認されています。

本研究でも、科学的質問応答（GPQA）、数学の問題解決（MATH）、算数の文章題（GSM8K）において、多ショット学習でこの傾向を確認しました。

しかし、確信度とタスクの性能には必ずしも相関はないことに注意しなければいけません。例えば、MATHとGPQAの [正解率](https://ai-data-base.com/archives/25930 "正解率") は125ショット以降に下がっていますが、確信度の増加はみられません。

また、強化ICLや教師なしICLを使った確信度の変化は、通常のICLに比べて傾きが小さいことがわかりました。

さらに、モデルが生成した解答の方が正解よりもしばしば高い性能をもたらすにもかかわらず、正解を使った学習の確信度はモデル生成の解答よりもずっと低いことが観察されました。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_67883_14-1024x317.png)

多ショットICLにおける負の対数尤度の傾向

## まとめ

本記事では、LLMに多くの例を与えるMany-shot Learningの可能性と特性を探った研究を紹介しました。

研究者らは、機械翻訳、要約、計画、報酬モデリング、数学的問題解決、科学的質問応答、アルゴリズム的推論など、多様なタスクにおいて実験を行いました。その結果、多ショットによる性能の大幅な向上を発見しました。さらに人間が生成した高品質な正解データの入手が困難な問題では、モデルによる例データの生成や、問題のみを多ショットで与える教師なし手法が有効であることも発見しました。

また、多ショット学習は事前学習の偏りを克服し、LLMでは通常難しい非自然言語タスクの学習を可能にすることを明らかにしました。

LLMのコンテキストウィンドウが長くなるのは今後の技術的な進展に従ってあらゆるモデルで起こりうることなので、こうした研究報告は有益なものとなる可能性があります。

- URL： [https://arxiv.org/abs/2404.11018](https://arxiv.org/abs/2404.11018)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[Appleが開発　スマホに特化したマルチモーダルLLM『Ferret UI』](https://ai-data-base.com/archives/67840)

[LLMにおける、長いコンテキストから欲しい情報を見つけ出す「needle-in-a-haystack（干し草の中の針）」テスト結果とプロンプト例](https://ai-data-base.com/archives/68016)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)