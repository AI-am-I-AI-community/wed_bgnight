---
title: "『プロンプトレポート』OpenAIなどが作成した調査報告書 〜その1 重要な用語と各種プロンプト手法〜"
source: "https://ai-data-base.com/archives/70953"
author:
  - "[[AIDB Research]]"
published: 2024-06-17
created: 2025-06-13
description: "メリーランド大学、OpenAI、スタンフォード大学、Microsoftなどの研究者らは、プロンプト技術の体系的な理解を提供することを目的に「プロンプトレポート」と命名した調査報告書を作成しました。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

メリーランド大学、OpenAI、スタンフォード大学、Microsoftなどの研究者らは、プロンプト技術の体系的な理解を提供することを目的に「プロンプトレポート」と命名した調査報告書を作成しました。

![](https://ai-data-base.com/wp-content/uploads/2024/06/AIDB_70953-1024x576.jpg)

データセットから得られたすべてのテキストベースのプロンプティング技術の一覧。

**参照論文情報**

- タイトル：The Prompt Report: A Systematic Survey of Prompting Techniques
- 著者：Sander Schulhoff, Michael Ilie, Nishant Balepur, Konstantine Kahadze, Amanda Liu, Chenglei Si, Yinheng Li, Aayush Gupta, HyoJung Han, Sevien Schulhoff, Pranav Sandeep Dulepet, Saurav Vidyadhara, Dayeon Ki, Sweta Agrawal, Chau Pham, Gerson Kroiz, Feileen Li, Hudson Tao, Ashay Srivastava, Hevander Da Costa, Saloni Gupta, Me [gan](https://ai-data-base.com/archives/26269 "敵対的生成ネットワーク（GAN）") L. Rogers, Inna Goncearenco, Giuseppe Sarli, Igor Galynker, Denis Peskoff, Marine Carpuat, Jules White, Shyamal Anadkat, Alexander Hoyle, Philip Resnik
- 所属：University of Maryland, OpenAI, Stanford, Microsoft, Vanderbilt, Princeton, Texas State University, Icahn School of Medicine, ASST Brianza, Mount Sinai Beth Israel, Instituto de Telecomunicações, University of Massachusetts Amherst

## 背景

生成AIの分野では、開発者もユーザーも、”プロンプティング”や”プロンプトエンジニアリング”を用いて生成AIとやり取りを行います。プロンプティングおよびプロンプトエンジニアリングは広く研究されている一方で、分野が新しいために用語の定義が矛盾していたり、体系的な理解が不足していたりします。そこでOpenAIなどの研究者らは、プロンプティング技術の分類法を作成し、プロンプトに関する構造化された理解を確立しようと試みています。

この調査報告書に含まれる内容は以下7つの大きなカテゴリーに分けられています。

1. **コアプロンプティング技術  
	**テキストベースの基本的なプロンプティング技術
2. **多言語技術  
	**複数の言語のテキストデータに対するプロンプティング技術
3. **マルチモーダル技術  
	**動画、音声などのマルチメディアを処理するためのプロンプティング技術
4. **エージェント  
	**コアプロンプティング技術を使用することが多いエージェントシステム
5. **評価  
	**プロンプトやエージェントの出力評価
6. **安全性  
	**プロンプティング全般で考慮すべき安全性の課題
7. **セキュリティ  
	**プロンプティング全般で考慮すべきセキュリティ上の懸念事項

本記事ではまず、プロンプトとはそもそも何か？という問いを出発点に、体系的にプロンプトの用語や手法を見ていきます。なお、調査報告書は膨大であり本記事だけでは網羅しきれないため、シリーズ記事となります（完結済み）。

[その2　マルチモーダルとエージェント](https://ai-data-base.com/archives/71094)  
[その3　プロンプトエンジニアリングのケーススタディ](https://ai-data-base.com/archives/71186)

![](https://ai-data-base.com/wp-content/uploads/2024/06/AIDB_70953_1.png)

プロンプティングの7つの中核カテゴリーの相互関係を示した図

## プロンプトとは何か？

プロンプトとは、生成AIモデルへの入力であり、出力を導くものです。テキストだけでなく、画像、音声、その他のメディアがプロンプトの役割を担います。例えば「テーブルの上のものを全て説明してください」というテキストと、同時に添えられた写真は両方プロンプトです。

### プロンプティングの歴史

自然言語のプロンプトを使って言語モデルの振る舞いや応答を引き出すというアイデアは、GPT-3やChatGPTの時代以前に遡ります。GPT-2ではすでに「プロンプト」という概念が使用されています。

一方、「プロンプトエンジニアリング」という用語自体は、最近になって登場したものです。ただし、この用語を使わずにプロンプトエンジニアリングのプロセスを実行していた論文は観測されています。

最初期のプロンプティングに関する論文の中には、現在とは少し異なる方法でプロンプトを定義しているものがあります。例えば、2020年ごろにはタスクとプロンプトを分けて考えられることもありました。最近では、タスクの記述も含めてLLMに渡される文字列全体をプロンプトと呼んでいます（本論文を含む）。

### プロンプトテンプレートについて

プロンプトは、”プロンプトテンプレート”を使って構築されることがよくあります。プロンプトテンプレートとは、1つ以上の変数を含む関数で表され、変数に情報（通常はテキスト）を代入することでプロンプトが生成されるものです。次の図では、下段の例がプロンプトテンプレートです。

![](https://ai-data-base.com/wp-content/uploads/2024/06/AIDB_70953_0.png)

テンプレートによって生成されたプロンプトは、テンプレートのインスタンス（具体例）とも呼ばれます。

例えば、ツイートを二値分類するタスクにプロンプティングを適用する場合は、以下のようなプロンプトテンプレートを使用できます。

```js
ツイートをポジティブまたはネガティブに分類してください：
{TWEET}
```

データセット内の各ツイートが、テンプレートの別々のインスタンスに挿入され、結果として得られるプロンプトが、推論のためにLLMに与えられます。

### プロンプティングの用語集

プロンプティングの分野では、用語の使用が急速に発展しています。現状では、用語の意味が理解しづらかったり、矛盾していたり、混同されていたりします（例えば、「ロールプロンプト」と「ペルソナプロンプト」など）。そこで今回研究者らは、用語の定義を行っています。

主要な用語の定義は以下の通りです。

**プロンプティング  
**プロンプトを生成AIに提供し、生成AIがそれに応じて応答を生成するプロセス。

**プロンプトチェーン  
**連続して使用される2つ以上のプロンプトテンプレート。最初のプロンプトテンプレートで生成されたプロンプトの出力が、2番目のテンプレートのパラメータとして使用され、すべてのテンプレートが使い尽くされるまで続きます。

**プロンプティング技術  
**「プロンプトをどのように作成・構成・運用するか」についての設計ノウハウやベストプラクティスの集合体。

**プロンプトエンジニアリング  
**使用しているプロンプティング技術を修正または変更することによって、プロンプトを反復的に開発するプロセス。

![](https://ai-data-base.com/wp-content/uploads/2024/06/AIDB_70953_3.png)

プロンプトエンジニアリングのプロセスを示した図。データセットに対する推論、パフォーマンス評価、プロンプトテンプレートの修正を繰り返す。

**プロンプトエンジニアリング技術  
**プロンプトを改善するための反復戦略。

**エグゼンプラー（exemplar）  
**モデルに示されるタスクの完了例。後述するFew-shot promptingなどで使用する例示の内容を指す。

![](https://ai-data-base.com/wp-content/uploads/2024/06/AIDB_70953_2-1024x646.jpg)

プロンプティングの主要な用語の階層構造を示した図。

なお、下記は本文ではなく付録部分に示された（著者らいわく）「それほど頻繁には登場しない用語」の説明集です。

**コンテキストウィンドウ  
**LLMが処理できるトークンの空間を指します。コンテキストウィンドウには最大長（コンテキスト長）が存在します。

**プライミング（Priming）  
**会話の残りの部分に特定の指示を与える初期プロンプトをモデルに与えることを指します。ユーザーとのインタラクション方法に関するロールやその他の指示が含まれる場合があります。システムプロンプトまたはユーザープロンプトで行います。

**会話型プロンプトエンジニアリング  
**生成AIとの会話の過程で行われるプロンプトエンジニアリングを指します。ユーザーは生成AIに出力の改良を求めることになります。これに対して、（会話型でない）プロンプトエンジニアリングは、会話を継続するのではなく、生成AIに完全に新しいプロンプトを送信することで行われることが多いです。

**プロンプトベース学習（Prompt-Based Learning）  
**プロンプティング関連の技術を使用するプロセスを指します。プロンプトのファインチューニングの文脈で多く使用されます（定義が曖昧なため、本論文ではこの用語は用語集以外で使用していません）。

**プロンプトチューニング  
**通常は勾配ベースの更新を介して、プロンプト自体の重みを直接最適化することを指します。プロンプトファインチューニングとも呼ばれます。そのため、”プロンプトエンジニアリング”とは区別すべきとのことです。

**ユーザープロンプト（User Prompt）  
**ユーザーから提供されるプロンプトです。最も一般的なプロンプトの形式であり、通常、消費者向けアプリケーションにおける「プロンプト」とはユーザープロンプトを指しています。

**アシスタントプロンプト（Assistant Prompt）  
**LLMの出力をもとにしたプロンプトです。ユーザーとの会話履歴の一部はモデル自身にフィードバックされることがあるためです。

**システムプロンプト（System Prompt）  
**ユーザーとのインタラクションのための高レベルな指示をLLMに与えるために使用されます。※すべてのモデルがこれを持っているわけではありません。

**ハードプロンプト（Hard Prompt）  
**LLMの知っている語彙に直接対応するトークンのみを含むプロンプトです。

**ソフトプロンプト（Soft Prompt）  
**語彙に対応しないトークンを含む可能性のあるプロンプトです。LLMが知らない語彙を使用する場合、本来はファインチューニングすることが望ましいですが、それができない場合にソフトプロンプトを与えることになります。

**プレフィックス（Prefix）  
**予測されるトークンがプロンプトの末尾に来る方式です。通常、GPTスタイルの最新モデルで使用されます。与えられたプロンプトの続きを予測する形でトークンが生成されていく（＝出力）ということです。下記のクローズと同様、ユーザーが選択するテクニックの話ではなく、原理に関連する用語です。

**クローズ（Cloze）  
**モデルによって予測されるトークンがプロンプトの途中のどこかにある「埋めるべきスロット」として提示されます。例：「私は毎朝 \[　\] を食べます。」通常、BERTのような初期のトランスフォーマーモデルで使用されている方式です。

## 文献に基づくプロンプティング技術の調査結果

次に研究者らは、文献のレビューを通して、プロンプティング技術を調査して分類しました。

### レビューのプロセス

文献のレビューは、PRISMA（Preferred Reporting Items for Systematic Reviews and Meta-Analyses）プロセスに基づいて行われました。PRISMAとはレビューの透明性と再現性を確保するための国際的なガイドラインです。主なデータソースはarXiv、Semantic Scholar、ACLで、プロンプティングに関連する44のキーワードを使用してデータベースを検索しました。

#### データ収集パイプライン

データ収集は、人間とLLMによるレビューの両方で行われました。

1. まず、arXivから単純なキーワードとブール規則（※）に基づいて論文を取得し、初期サンプルとしました。
2. 次に、人間のアノテーターがarXivセットから1,661件の論文のサンプルにラベルを付けました。
3. 300件の論文は2人のアノテーターによって独立にレビューされ、92％の一致率（Krippendorff’s α = Cohen’s κ = 81％）が得られました。
4. 次に、GPT-4-1106-previewを使用してプロンプトを開発し、残りの論文を分類しました。

最終的に、人間とLLMによる [アノテーション](https://ai-data-base.com/archives/26297 "アノテーション") を組み合わせることで、1,565本の論文が選定されました。

※ブール規則とは、検索式の中で AND、OR、NOT などの論理演算子を使って、検索条件を組み合わせる方法のことです。

![](https://ai-data-base.com/wp-content/uploads/2024/06/AIDB_70953_4.png)

PRISMAレビュープロセスの流れを示した図。4,247件のレコードから1,565件の関連レコードを抽出。

### テキストベースのプロンプティング技術

以下では58種類のテキストベースのプロンプティング技術が6つの主要カテゴリーに分類され、その分類法が提示されています。一部の技術は複数のカテゴリーに適合する可能性もありますが、最も関連性の高い単一のカテゴリーに配置されています。

![](https://ai-data-base.com/wp-content/uploads/2024/06/AIDB_70953_5-1024x437.png)

データセットから得られたすべてのテキストベースのプロンプティング技術の一覧。

データセットから得られたすべてのテキストベースのプロンプティング技術の一覧。

#### 1\. コンテキスト内学習（ICL）

コンテキスト内学習（In-Context Learning、ICL）は、重みの更新やモデルの再学習を必要とせずに、プロンプト内の例示やタスク関連の指示によって生成AIにスキルやタスクを学習させる能力を指します。ただし、「学習」という言葉は誤解を招く可能性があります。ICLは単にタスクの指定に過ぎず、学習されるスキルが新しいものである必要はなく、すでに学習データに含まれている可能性もあります。

またICLの一種であるFew-Shotプロンプティングは、少数の例（エグゼンプラー）のみで生成AIにタスクを完了させる方法です。

![](https://ai-data-base.com/wp-content/uploads/2024/06/AIDB_70953_2-4.png)

ICLにおけるFew-shot promptingの例。簡単な足し算の例示を示している。

![](https://ai-data-base.com/wp-content/uploads/2024/06/AIDB_70953_2-5.png)

ICLの指示プロンプトの例。テキストから特定のパターンの単語を抽出するようにLLMに指示している。

![](https://ai-data-base.com/wp-content/uploads/2024/06/AIDB_70953_2-6.png)

トレーニングデータに含まれている知識を用いたICLの例。新しいスキルの学習ではなく、既存の知識の利用。

##### Few-Shotプロンプティングの設計

プロンプトのエグゼンプラー（要するに例示）を選択するのは難しいことです。LLMのパフォーマンスはエグゼンプラーに大きく依存し、加えて一般的なLLMのコンテキストウィンドウに収まるエグゼンプラーの数は限られています。エグゼンプラーの選択や順序など、出力品質に重要な影響を与える6つの設計上の決定事項が下記に整理されています。

![](https://ai-data-base.com/wp-content/uploads/2024/06/AIDB_70953_8-1024x248.png)

Few-shotプロンプトを作成する際の6つの主要な設計上の決定事項と、それぞれの設計例を示した図。

それぞれの内容を日本語でまとめると以下のようになります。すべて但し書きが含まれています。

1. エグゼンプラーの量（Exemplar Quantity）  
	可能な限り多くのエグゼンプラーを含めることが推奨されます。ただし、タスクによってはエグゼンプラーの数が多すぎると逆効果になる場合もあります。
2. エグゼンプラーの順序（Exemplar Ordering）  
	エグゼンプラーの順序をランダムにすることが推奨されます。ただし、タスクによっては特定の順序が効果的な場合もあります。
3. エグゼンプラーのラベル分布（Exemplar Label Distribution）  
	エグゼンプラーのラベル分布をバランスよく提供することが推奨されます。ただし、タスクによっては不均衡なラベル分布が効果的な場合もあります。
4. エグゼンプラーのラベル品質（Exemplar Label Quality）  
	エグゼンプラーが正しくラベル付けされていることを確認することが推奨されます。ただし、タスクによっては不正確なラベルが性能に大きな影響を与えない場合もあります。
5. エグゼンプラーの形式（Exemplar Format）  
	エグゼンプラーの形式を統一することが推奨されます。ただし、タスクによっては特定の形式が効果的な場合もあります。
6. エグゼンプラーの類似性（Exemplar Similarity）  
	テストサンプルと類似したエグゼンプラーを選択することが推奨されます。ただし、タスクによってはより多様なエグゼンプラーが効果的な場合もあります。

### 2\. ゼロショット

Few-Shotプロンプティングとは対照的に、ゼロショットプロンプティングではエグゼンプラー（例示）が一切使用されません。スタンドアロンのゼロショット技術と、Chain of Thoughtなどの他の概念と組み合わせたゼロショット技術の2種類が存在します。ゼロショットプロンプティングの中にも以下のように多くの手法があります。

#### （１）ロールプロンプティング（ペルソナプロンプティング）

プロンプト内で生成AIに特定の役割が割り当てられます。例えば、「マドンナ」や「旅行ライター」のように振る舞うように促すことができます。オープンエンドなタスクでより望ましい出力が生成されたり、場合によってはベンチマークでの精度が向上したりします。

参考： [タスクに応じてロールプレイさせるとChatGPTなどLLMの推論能力は普遍的に向上する](https://ai-data-base.com/archives/54536)

#### （２）スタイルプロンプティング

プロンプトに目的のスタイル、トーン、ジャンルを指定することで、生成AIの出力を調整することができます。（同様の効果は、ロールプロンプティングでも達成可能です。）

**（３）エモーションプロンプティング**

人間にとって心理的に関連性の高いフレーズ（例：「これは私のキャリアにとって重要です」）をプロンプトに組み込むことで、ベンチマークやオープンエンドなテキスト生成におけるLLMのパフォーマンスが向上する可能性があります。

参考： [「自分を信じて限界を超えてください」など感情をグッと込めた指示プロンプトが添えられると、ChatGPTなどのLLMのパフォーマンスは向上する](https://ai-data-base.com/archives/58158)

#### （４）System 2 Attention（S2A）

まずLLMにプロンプトを書き直させ、質問に関係のない情報を削除します。次に、新しいプロンプトをLLMに渡して、最終的な応答を取得します。

#### （５）SimToM

複数の人物やオブジェクトが登場する複雑な質問を扱います。与えられた質問に対して、ある人物が知っている事実の集合を確立し、それらの事実のみに基づいて質問に答えようとします。プロンプトに含まれる無関係な情報の影響を排除するのに役立ちます。

#### （６）Rephrase and Respond（RaR）

最終的な答えを生成する前に、質問を言い換えて拡張するようLLMに指示します。例えば、「質問を言い換えて拡張し、回答してください」というフレーズを質問に追加します。1回のパスで行うこともできますし、新しい質問を別途LLMに渡すこともできます。複数のベンチマークで改善が示されています。

参考： [ユーザープロンプトをLLMが言い換えて、LLM自身が理解しやすくする手法『RaR』](https://ai-data-base.com/archives/51160)

#### （７）Re-reading（RE2）

質問を繰り返すだけでなく、「質問をもう一度読んでください：」というフレーズをプロンプトに追加します。これは非常にシンプルな手法ですが、特に複雑な質問に対する推論ベンチマークの改善が示されています。

#### （８）Self-Ask

与えられたプロンプトに対してフォローアップの質問が必要かどうかを最初に決定するようLLMにプロンプトを与えます。必要な場合は、LLMがこれらの質問を生成し、それらに答えた後、元の質問に答えます。

### 3\. 思考生成プロンプティング

問題解決の際にLLMに推論を明示させる一連の手法が、思考生成プロンプティングと呼ばれています。

#### （１）Chain-of-Thought（CoT）プロンプティング

Few-Shotプロンプティングを活用して、LLMが最終的な答えを出す前に思考プロセスを表現するよう促す手法です。LLMの数学や推論タスクのパフォーマンスが大幅に向上することが示されています。

#### （２）ゼロショットCoTプロンプティング

最もシンプルなパターンで、エグゼンプラーは含まれません。代わりに、「一歩一歩考えてみましょう」のような思考を誘発するフレーズがプロンプトに追加されます。他にも、「正しい答えを出すために、一歩一歩論理的に考えてみましょう」や「まず論理的に考えてみましょう」などのフレーズが提案されています。タスクに依存しないため魅力的だとされています。

#### （３）Step-Back Prompting

推論を始める前に関連する概念や事実について高レベルの質問をLLMに尋ねるCoTの変種です。PaLM-2LとGPT-4の両方で、複数の推論ベンチマークのパフォーマンスを大幅に改善することが示されています。

参考： [LLMにまず前提から尋ることで出力精度を向上させる『ステップバック・プロンプティング』と実行プロンプト](https://ai-data-base.com/archives/56671)

#### （４）Analogical Prompting

CoTを含むエグゼンプラーを自動生成する手法で、SG-ICLに似ています。数学的推論やコード生成タスクでの改善が示されています。

#### （５）Thread-of-Thought（ThoT）Prompting

CoT推論のための思考誘発文を改良したものです。「一歩一歩考えましょう」の代わりに、「このコンテキストを段階的に管理可能な部分に分けて、要約と分析を行いながら進めていきましょう」というフレーズが使用されます。大規模で複雑なコンテキストを扱う質問応答やリトリーバルタスクで効果を発揮します。

#### （６）Tabular Chain-of-Thought（Tab-CoT）

LLMに推論をマークダウンのテーブルとして出力させるゼロショットCoTプロンプトです。表形式の設計により、LLMは出力の構造、ひいては推論自体を改善することができます。

#### （７）Few-shot CoTプロンプティング

思考の連鎖を含む複数のエグゼンプラーがLLMに提示されます。パフォーマンスが大幅に向上する可能性があります。

#### （８）Contrastive CoT Prompting

LLMに推論の仕方を示すために、正しい説明と間違った説明の両方を含むエグゼンプラーがCoTプロンプトに追加されます。算術推論や事実に基づく質問応答などの分野で大幅な改善を示しています。

#### （９）Uncertainty-Routed CoT Prompting

複数のCoT推論パスを [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") し、多数派が一定のしきい値（検証データに基づいて計算）を超えている場合はそれを選択する手法です。超えていない場合は、貪欲に [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") を行い、その応答を選択します。GPT4とGemini Ultraの両方で、MMLUベンチマークの改善を示しています。

#### （１０）Complexity-based Prompting

CoTに2つの主要な変更が加えられています。第一に、質問の長さや必要な推論ステップ数などの要因に基づいて、複雑なエグゼンプラーを選択して [アノテーション](https://ai-data-base.com/archives/26297 "アノテーション") とプロンプトに含めます。第二に、推論時には複数の推論連鎖（回答）を [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") し、一定の長さのしきい値を超える連鎖の中で多数決を行います。これは、より長い推論は回答の質が高いことを示唆しているという前提に基づいています。実験により3つの数学的推論データセットで改善が示されています。

#### （１１）Active Prompting

まずいくつかのエグゼンプラーやトレーニング用の質問からスタートし、LLMにそれらを解かせます。次に、不確実性（この場合は不一致）を計算し、不確実性が最も高いエグゼンプラーを人間のアノテーターに書き直させます。

#### （１２）Memory-of-Thought Prompting

テスト時にFew-Shot CoTプロンプトを構築するために、ラベルなしのトレーニングエグゼンプラーを活用します。テスト前に、CoTでラベルなしのトレーニングエグゼンプラーに対して推論を行います。テスト時には、テストサンプルに類似したインスタンスを検索します。この手法は、算術、常識、事実推論などのベンチマークで大幅な改善を示しています。

#### （１３）Automatic Chain-of-Thought（Auto-CoT）Prompting

ゼロショットプロンプトを使用して、思考の連鎖を自動的に生成します。テストサンプル用のFew-Shot CoTプロンプトを構築するために使用されます。

### 4\. 問題分解プロンプティング

複雑な問題をより単純な部分問題に分解することにフォーカスした研究も数多く行われてきました。生成AIにとってだけでなく、人間にとっても効果的なアプローチですね。分解手法の中には、単純に分解を誘発する指示をするだけのものもありますが、問題を明示的に分解することで、LLM の問題解決能力をさらに向上させることができます。

#### （１）Least-to-Mostプロンプティング

まずLLMにプロンプトを与えて、与えられた問題を解決せずに部分問題に分解します。次に、モデルの応答をプロンプトに追加しながら、最終的な結果に到達するまで部分問題を順次解決していきます。記号操作、構成的一般化、数学的推論を含むタスクで大幅な改善が示されています。

#### （２）Decomposed Prompting

LLMに特定の関数の使い方を示すFew-Shotプロンプトを与えます。これらの関数には、文字列の分割やインターネット検索などが含まれ、しばしば別のLLM呼び出しとして実装されます。これを受けて、LLMは元の問題を部分問題に分解し、それらを異なる関数に送ります。一部のタスクでLeast-to-Mostプロンプティングを上回る性能を示しています。

#### （３）Plan-and-Solveプロンプティング

「まず問題を理解し、解決計画を立てましょう。次に、その計画を実行し、問題を一歩一歩解決しましょう」という改良版のゼロショットCoTプロンプトで構成されています。複数の推論データセットにおいて、標準的なゼロショットCoTよりも堅牢な推論プロセスを生成します。

#### （４）Tree-of-Thought（ToT）

初期問題から始めて、複数の可能な手順を思考（CoTからの）の形で生成することで、木構造の探索問題を作成します。各ステップが問題解決にどの程度寄与しているかを（プロンプティングを通して）評価し、どのステップを継続するかを決定した後、さらに思考を重ねていきます。探索と計画を必要とするタスクで効果的です。

#### （５）Recursion-of-Thought

通常のCoTと似ていますが、推論の連鎖の途中で複雑な問題に遭遇するたびに、その問題を別のプロンプト/LLM呼び出しに送ります。この処理が完了した後、その回答が元のプロンプトに挿入されます。このように、再帰的に複雑な問題を解くことができ、最大文脈長を超えるような問題にも対応できます。算術やアルゴリズムのタスクで改善が示されています。

#### （６）Program-of-Thoughts

Codexのような LLM を使用して、推論ステップとしてプログラミングコードを生成します。コードインタープリターがこれらのステップを実行して最終的な答えを得ます。数学やプログラミング関連のタスクで優れていますが、意味的推論タスクではあまり効果的ではありません。

#### （７）Faithful Chain-of-Thought

自然言語と記号言語（例えばPython）の両方を使用したCoTを生成します。これはProgram-of-Thoughtsと似ていますが、タスクに応じて異なるタイプの記号言語を使用する点が異なります。

#### （８）Skeleton-of-Thought

並列化による回答速度の向上に重点を置いています。与えられた問題に対して、LLMに回答のスケルトン（ある意味で解決すべき部分問題）を作成するようプロンプトを与えます。次に、並行してこれらの質問をLLMに送り、すべての出力を連結して最終的な応答を得ます。

### 5\. アンサンブルプロンプティング

生成AIにおけるアンサンブルとは、複数のプロンプトを使用して同じ問題を解決し、それらの応答を集約して最終的な出力を生成するプロセスを指します。多くの場合、最終的な出力を生成するために、最も頻度の高い応答を選択する多数決方式が用いられます。  
LLMの出力のばらつきを減らし、多くの場合、精度を向上させますが、最終的な答えに到達するために必要なモデル呼び出しの回数が増えるというコストがかかります。

#### （１）Demonstration Ensembling

訓練セットから異なるエグゼンプラーのサブセットを含む複数のフューショットプロンプトが作成されます。次に、それらの出力が集約されて最終的な応答が生成されます。

#### （２）Mixture of Reasoning Experts（MoRE）

異なる推論タイプに特化した異なるプロンプトを使用して、多様な推論エキスパートのセットが作成されます（例えば、事実推論にはリトリーバル拡張プロンプト、マルチホップと数学推論にはCoT推論、常識推論には生成された知識プロンプトを使用）。すべてのエキスパートの中から、一致スコアに基づいて最良の答えが選択されます。

#### （３）Max Mutual Information Method

様々なスタイルとエグゼンプラーを含む複数のプロンプトテンプレートが作成され、プロンプトとLLMの出力の間の相互情報量を最大化するテンプレートが最適なものとして選択されます。

#### （４）Self-Consistency

複数の異なる推論パスが同じ答えにたどり着く可能性があるという直感に基づいています。この手法では、まず温度を0以外に設定して多様な推論パスを引き出し、LLMに複数回プロンプトを与えてCoTを実行します。次に、生成されたすべての応答に対して多数決を行い、最終的な応答を選択します。  
算術、常識、記号推論のタスクで改善が示されています。

#### （５）Universal Self-Consistency

Self-Consistencyと似ていますが、多数の応答をプログラム的にカウントするのではなく、すべての出力をプロンプトテンプレートに挿入して多数の答えを選択する点が異なります。自由形式のテキスト生成や、同じ答えが異なるプロンプトによって少しずつ異なる形で出力される場合に役立ちます。

#### （６）Meta-Reasoning over Multiple CoTs

Universal Self-Consistencyと似ていますが、まず与えられた問題に対して複数の推論の連鎖（必ずしも最終的な答えではない）を生成します。次に、これらの連鎖をすべて単一のプロンプトテンプレートに挿入し、そこから最終的な答えを生成します。

#### （７）DiVeRSe

与えられた問題に対して複数のプロンプトを作成し、それぞれにSelf-Consistencyを適用して複数の推論パスを生成します。推論パスの各ステップに基づいてスコアを付け、最終的な応答を選択します。

#### （８）Consistency-based Self-adaptive Prompting（COSP）

エグゼンプラーのセットに対してゼロショットCoTとSelf-Consistencyを実行し、高い一致度のサブセットを選択して最終的なプロンプトのエグゼンプラーとして含めることで、フューショットCoTプロンプトを構築します。そして再び、最終プロンプトでSelf-Consistencyを実行します。

#### （９）Universal Self-Adaptive Prompting（USP）

COSPの成功を踏まえ、それをすべてのタスクに一般化することを目的としています。USPは、エグゼンプラーを生成するために未ラベルデータを使用し、それらを選択するためのより複雑なスコアリング関数を使用します。さらに、USPではSelf-Consistencyは使用されません。

#### （１０）プロンプトパラフレーズ

全体的な意味を維持しながら、元のプロンプトの言い回しを一部変更することで、プロンプトを変換します。これは、アンサンブル用のプロンプトを生成するために使用できるデータ拡張手法と言えます。

### 6\. 自己批判プロンプティング

生成AIシステムを構築する際、LLMに自身の出力を批評させると有用な場合があります。単なる判断（例えば、この出力は正しいか）である場合もあれば、LLMにフィードバックを提供するよう促し、そのフィードバックを使用して回答を改善する場合もあります。

#### （１）Self-Calibration

まずLLMにプロンプトを与えて質問に答えさせます。次に、質問、LLMの回答、および回答が正しいかどうかを尋ねる追加の指示を含む新しいプロンプトが構築されます。これは、LLMを適用する際の信頼度レベルを判断したり、元の回答を受け入れるか修正するかを決定したりする際に役立ちます。

#### （２）Self-Refine

LLMの最初の回答に基づいて、同じLLMにフィードバックを提供するようプロンプトを与え、そのフィードバックに基づいて回答を改善するよう促す反復的なフレームワークです。この反復プロセスは、停止条件（例えば、最大ステップ数に達した）が満たされるまで続けられます。Self-Refineは、推論、コーディング、生成タスクなど、様々なタスクで改善が示されています。

#### （３）Reversing Chain-of-Thought（RCoT）

まずLLMに生成された回答に基づいて問題を再構成するようプロンプトを与えます。次に、元の問題と再構成された問題の間の詳細な比較を生成し、矛盾がないかどうかを確認します。これらの矛盾は、LLMが生成された回答を修正するためのフィードバックに変換されます。

#### （４）Self-Verification

Chain-of-Thought（CoT）を使用して複数の候補解を生成します。次に、元の質問の特定の部分をマスクし、質問の残りの部分と生成された解に基づいて、LLMにそれらを予測させることで、各解のスコアを付けます。8つの推論データセットで改善が示されています。

#### （５）Chain-of-Verification（COVE）

まずLLMに与えられた質問に対する答えを生成させます。次に、その答えの正当性を検証するのに役立つ関連質問のリストを作成します。各質問はLLMによって回答され、すべての情報がLLMに与えられて最終的な修正された答えが生成されます。様々な質問応答とテキスト生成のタスクで改善が示されています。

参考： [LLMの出力から誤り（ハルシネーション）を減らす新手法『CoVe（Chain-of-Verification）』と実行プロンプト](https://ai-data-base.com/archives/55711)

#### （６）Cumulative Reasoning

まず質問に答える際の潜在的なステップをいくつか生成します。次に、LLMにそれらを評価させ、これらのステップを受け入れるか拒否するかを決定します。最後に、最終的な答えに到達したかどうかを確認します。到達していれば、プロセスを終了しますが、そうでない場合は繰り返します。論理推論タスクと数学的問題で改善が示されています。

### プロンプティング技術の使用状況

多数のテキストベースのプロンプティング技術が存在しますが、研究や業界で実際に一般的に使用されているのはそのうちの一部に過ぎません。技術の使用状況は、他の論文におけるその技術の引用数を測定することで間接的に評価されました。その結果、Few-ShotプロンプティングとChain-of-Thoughtプロンプティングが最も多く引用されていることが明らかになりました。これは、他の技術の普及率を理解するための基準として役立ちます。

#### ベンチマーク

プロンプティング技術の研究では、新しい技術を提案する際、複数のモデルやデータセットでベンチマークを行うことが一般的です。これは、技術の有用性を証明し、モデル間での転移性を調べるために重要です。本研究では、どのベンチマークデータセットとモデルが使用されているかを定量的に調査しました。最もよく使用されているモデルはGPT-3、BERT、GPT-4で、最もよく使用されているデータセットはGSM8K、MMLU、BBHでした。

![](https://ai-data-base.com/wp-content/uploads/2024/06/AIDB_70953_9.png)

論文内で言及された生成AIモデルの引用数のグラフ。

![](https://ai-data-base.com/wp-content/uploads/2024/06/AIDB_70953_10.png)

論文内で言及されたデータセットの数のグラフ。

### プロンプトエンジニアリング

プロンプティング技術の調査に加えて、プロンプトを自動的に最適化するために使用されるプロンプトエンジニアリング技術も検討されました。プロンプトエンジニアリング技術のセットは、プロンプティング技術に比べてかなり少ないため、勾配更新を使用する手法も一部取り上げられました。

#### （１）メタプロンプティング

メタプロンプティングとは、プロンプトやプロンプトテンプレートを生成または改善するようLLMにプロンプトを与えるプロセスです。

#### （２）AutoPrompt

パラメータが凍結されたLLM（Frozen LLM）と、いくつかの「トリガートークン」を含むプロンプトテンプレートが使用されます。トークンの値は、学習時に逆伝播によって更新されます。これはソフトプロンプティングの一種です。

#### （３）Automatic Prompt Engineer（APE）

エグゼンプラーのセットを使用してゼロショットの指示プロンプトが生成されます。複数の可能なプロンプトが生成され、それらにスコアが付けられ、最高のプロンプトのバリエーションが作成されます（例えば、プロンプトパラフレーズを使用）。望ましい結果が得られるまで、プロセスが繰り返されます。

#### （４）Gradientfree Instructional Prompt Search（GrIPS）

APEと似ていますが、開始プロンプトのバリエーションを作成するために、削除、追加、スワップ、パラフレーズなどのより複雑な一連の操作を使用します。

#### （５）Prompt Optimization with Textual Gradients（ProTeGi）

多段階のプロセスを通じてプロンプトテンプレートを改善するユニークなアプローチです。まず、入力のバッチをテンプレートに通し、その出力、正解、プロンプトを別のプロンプトに渡して、元のプロンプトを批評します。これらの批評から新しいプロンプトが生成され、バンディットアルゴリズムを使用して1つが選択されます。APEやGRIPSなどの手法よりも改善が示されています。

### （６）RLPrompt

凍結されたLLMに未凍結のモジュールが追加されます。このLLMを使用してプロンプトテンプレートが生成され、データセットに対してテンプレートのスコアが付けられ、Soft Q-Learningを使用して未凍結のモジュールが更新されます。興味深いことに、文法的にナンセンスなテキストが最適なプロンプトテンプレートとして選択されることがよくあります。

#### （７）Dialogue-comprised Policy-gradient-based Discrete Prompt Optimization（DP2O）

おそらく最も複雑なプロンプトエンジニアリング技術で、 [強化学習](https://ai-data-base.com/archives/26125 "強化学習") 、カスタムプロンプトスコアリング関数、プロンプトを構築するためのLLMとの会話が含まれます。

以上のように多くのプロンプティング技術が存在します。下の図は関連論文の引用数のグラフです。

![](https://ai-data-base.com/wp-content/uploads/2024/06/AIDB_70953_11-414x1024.jpg)

上位25論文のほとんどがプロンプティング技術に関するもの。

### アンサーエンジニアリング

アンサーエンジニアリングとは、LLMから正しい答えを取り出すための方法を探る作業です。アンサーエンジニアリングとプロンプトエンジニアリング（プロンプトの設計）は別物ですが、密接に関連しています。実際には、両者を同時に進めることが多いでしょう。必要性を理解するために、「ヘイトスピーチかどうか」を判定する2値分類タスクを例に考えてみましょう。

```js
これは「ヘイトスピーチ」それとも「ヘイトスピーチではない」ですか？
{TEXT}
```

{TEXT}には、判定対象のテキストが入ります。このプロンプトに対し、LLMは次のように様々な答え方をしたとします。

- 「これはヘイトスピーチです」
- 「ヘイトスピーチ。」
- 「人種について悪い言葉を使っているので、ヘイトスピーチに当たります」

上記の答えは、全て「ヘイトスピーチである」という同じ判定を示していますが、表現が統一されていません。こうしたバラつきがあると、LLMの出力を一貫して解釈するのが難しくなります。プロンプトを工夫することで多少は改善できますが、完璧とは言えません。そこで、アンサーエンジニアリングの出番となるわけです。

アンサーエンジニアリングでは、次の3つの要素を考えます。

1. アンサー空間（answer space）： 取りうる答えの範囲。タスクに応じて「はい/いいえ」だけだったり、特定の単語の集合だったりします。
2. アンサー形状（answer shape）： 答えの形式。単語なのか、文章なのか、あるいは画像や動画といった別の形式なのかを決めます。
3. アンサー抽出器（answer extractor）： LLMの出力から答えの部分を取り出すルール。プログラムで定義することもあれば、別のLLMを使うこともあります。

![](https://ai-data-base.com/wp-content/uploads/2024/06/AIDB_70953_12.png)

アンサーエンジニアリングの3つの設計決定事項（アンサーの形状、空間、エクストラクタの選択）を示した、LLMの出力例への注釈付き図。

アンサー抽出器の一例として、バーバライザー（verbalizer）があります。これは、LLMの出力を事前に定義したラベルに変換するルールです。

例えば、先ほどの「ヘイトスピーチかどうか」の例で、LLMが「+」「-」という記号で答えを出力するとします。バーバライザーを使えば、「+」なら「ヘイトスピーチ」、「-」なら「ヘイトスピーチではない」といったふうに、記号をラベルに変換できます。

## まとめ

本記事では、プロンプティングに関する調査報告論文「プロンプトレポート」の一部を紹介しました。

上記では、プロンプティングの概念整理、手法の分類、歴史的背景、用語の定義が行われています。また、技術の使用状況やベンチマーク、発展的なトピックにも言及しています。

次回はより発展的な内容に触れていきます。

- 参照論文URL： [https://arxiv.org/abs/2406.06608](https://arxiv.org/abs/2406.06608)
- プロジェクトページ： [https://trigaten.github.io/Prompt\_Survey\_Site/](https://trigaten.github.io/Prompt_Survey_Site/)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[包括的なRAG評価ベンチマーク『CRAG』Metaなどが開発](https://ai-data-base.com/archives/70850)

[『プロンプトレポート』OpenAIなどが作成した調査報告書　〜その2　マルチモーダルとエージェント〜](https://ai-data-base.com/archives/71094)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)