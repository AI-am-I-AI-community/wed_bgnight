---
title: "Self-Reflection（自己反省）がLLMのパフォーマンスに与える影響を網羅的に調査"
source: "https://ai-data-base.com/archives/75649"
author:
  - "[[AIDB Research]]"
published: 2024-09-13
created: 2025-06-13
description: "この記事では、LLMが自分自身の行動を反省して振り返る機能を持つことでどのような効果があるかについての研究を紹介します。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

この記事では、LLMが自分自身の行動を反省して振り返る機能を持つことでどのような効果があるかについての研究を紹介します。

研究者たちは9種類のLLMと8種類の自己反省手法を使い、さまざまな分野の1,000問のテストで「問題を解く能力」がどれだけ良くなるかを調べました。

単に問題をもう一度解いてみるような簡単な方法から、詳しく説明を加えるような複雑な方法まで、さまざまなタイプの自己反省の効果を分析し、どの方法が一番効果的かを見つけ出そうとしました。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75649-1024x576.jpg)

**参照論文情報**

- タイトル：Self-Reflection in LLM Agents: Effects on Problem-Solving Performance
- 著者：Matthew Renze, Erhan Guven
- 所属：Johns Hopkins University

**本記事の関連研究**

- [人間のような内省メカニズムをLLMに導入することの効果 Google DeepMindなどが検証](https://ai-data-base.com/archives/72194)
- [LLMから「LLMエージェント」へ　ソフトウェアエンジニアリングにおける今後の展開](https://ai-data-base.com/archives/74375)
- [Sakana AIが科学研究自動化フレームワーク『The AI Scientist』開発](https://ai-data-base.com/archives/74257)
- [LLMベースの万能エンジニアを構築する『OpenDevin』プラットフォーム](https://ai-data-base.com/archives/73891)
- [Appleが「LLMエージェントの評価」に特化したベンチマーク『MMAU』を開発　5領域5能力で測る](https://ai-data-base.com/archives/73656)

## 背景

LLMベースのエージェント（LLMエージェント）の開発が進んでいます。LLMエージェントは複数の手順が必要な問題を解くこと、ウェブブラウザや検索エンジン、プログラムを実行するツールなども使えることが期待されています。

しかし、LLMエージェントには課題もあります。知識に限りがあったり、推論を間違えたり、実際にはない情報を出力したり、あまり意味のない繰り返しをしたりすることがあります。このような問題を改善するために、さまざまな能力が追加されたエージェントが設計されてきました。例えば、「考えの流れを示す方法」や「外部の記憶を使う方法」、「フィードバックから学ぶ方法」などが考案されてきました。

フィードバックから学ぶ方法については、フィードバックが自分の中から来るか外からくるか、数値や言葉のどちらで表されるか、モデルの訓練時や出力を作る時、出力した後のどのタイミングで学ぶかなど、さまざまな観点から研究が行われています。  
そして、出力した”後”に学ぶ方法として、「何度も改善を繰り返す方法」や「複数のモデルで話し合う方法」、「自己反省」などがあります。

「自己反省」は、LLMエージェントが自分の思考を管理する戦略の一つとして注目されています。一部の研究では、LLMは自己反省を行うことで自らの間違いを見つけて直せることが分かっています。より詳しくは「LLMは推論の間違いを見つけることはできないが、外からのフィードバックを基に直せる可能性もある」と指摘されています。つまり、おそらく考えの間違いは正せないが、答えは修正できるということです。

そこで今回研究者らは、これまでの研究を踏まえて、LLMエージェントの問題解決性能を上げるために「自己反省」がどのように役立つかを調べることにしました。そして、自己反省のプロセスをいくつかの要素に分け、それぞれの要素がエージェントの全体的な性能向上にどのくらい貢献するかを明らかにしました。

GPT-4やLlama 2 70B、Gemini 1.5 Proなどのさまざまな種類のLLMや、数学、科学、医学などのさまざまな問題分野で、自己内省がどのような効果をもたらすかについて細かく調査しています。

以下で詳しく紹介します。

## 研究手法

### データセット

この研究では、ARC、AGIEval、HellaSwag、MedMCQAなどの有名なLLMベンチマークから多肢選択式の問題が抽出されました。

データは標準フォーマットに変換され、10個のデータセットから各100問がランダムに選ばれ、合計1,000問からなる多分野試験が作成されました。

下の表には、この多分野試験の作成に使用された問題セットの詳細が示されています。各問題セットの出典、対象分野、問題数、ライセンスなどの情報が記載されています。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75649_1-1024x313.png)

### モデル

今回の実験では、GPT-4、Llama 2 70B、Google Geminiなど、9種類の人気の高いLLMが評価されました。なお、モデルは全て、Microsoft、Anthropic、Googleが提供するクラウドベースのAPIを通じてアクセスされました。

各LLMの特徴を比較すると、例えばGPT-4、Gemini 1.5 Pro、Claude Opusなどは、パラメータ数が非常に多い強力なLLMですが、GPT-3.5やLlama 2 7Bなどの小規模なモデルと比較すると、トークンあたりのコストが大幅に高くなります。

下の表には、実験に使用されたLLMの詳細が示されています。各モデルの名前、開発元、リリース日、ライセンスタイプなどの情報が記載されています。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75649_2.png)

### エージェント

研究では、8種類の自己反省型LLMエージェントが調査されました。自身の思考の流れ（Chain of Thought、CoT）を振り返り、自己反省を生成して問題を再解答することが期待されているエージェントたちです。

各エージェントは、独自の自己反省タイプを持ちます。

（１）再試行タイプ  
不正解だったことを伝えられ、単純に再挑戦する

（２）キーワードタイプ  
各種エラーに関するキーワードのリストを受け取る

（３）アドバイスタイプ  
改善のための一般的なアドバイスのリストを受け取る

（４）説明タイプ  
エラーを犯した理由の説明を受け取る

（５）指示タイプ  
問題解決のための順序付きの指示リストを受け取る

（６）解答タイプ  
問題の段階的な解答を受け取る

（７）複合タイプ  
上記6種類の自己反省を全て含む

（８）未編集タイプ  
上記6種類の自己反省を含むが、正解が削除されていない

未編集タイプのエージェントは「完全な情報」を持つエージェントであり、自己反省によるパフォーマンス向上の理論的な最大値を示すために使用されます。

一方で、自己反省機能を持たないエージェントがスコアの下限を示すベースラインに据えられました。標準的なプロンプトエンジニアリングを用いて、自己反省なしでどの程度の性能を発揮できるかを示します。

自己反省型エージェントは、ベースラインのエージェントと同様のプロンプトエンジニアリング技術を使用しますが、再解答の前に自己反省を行います。再解答時には、自己反省の内容がプロンプトに挿入され、エージェントが過去の誤りから学習できるようになっています。

なお、未編集エージェントを除く全ての自己反省型エージェントでは、正解のラベルや説明が自己反省から削除されています。

### 実験プロセス

実験は以下の手順で行われました。

1. ベースラインエージェントが1,000問全てに解答する
2. 正解した問題はベースラインエージェントのスコアに加算される
3. 不正解だった問題は、自己反省を行うためのキューに追加される
4. 不正解だった各問題について、自己反省型エージェントが問題、不正解の解答、正解を振り返る
5. 正解を外部フィードバック信号として使用し、8種類の自己反省フィードバックが生成される
6. 自己反省テキストから正解のラベルや説明が削除される（未編集エージェントを除く）
7. 不正解だった各問題について、自己反省型エージェントが自己反省テキストを用いて再解答する
8. 全エージェントのスコアが計算され、ベースラインエージェントと比較・分析される

なお本実験は、時間とコストを節約するため、バッチ処理として実装されました。概念的には複数のステップを持つエージェントをシミュレートしていますが、技術的には一連のバッチ処理として実装されています。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75649_3.png)

自己反省実験の流れを示す図。問題回答、反省、答えの編集、再回答のステップを図示

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75649_4.png)

バッチ処理を表現するアルゴリズム

### 評価指標

主な評価指標として、 [正解率](https://ai-data-base.com/archives/25930 "正解率") （正解数÷問題総数）が使用されました。ただし、実験コスト削減のため、ベースラインエージェントが正解した問題については自己反省型エージェントによる再解答は行われませんでした。代わりに、自己反省型エージェントの正解再解答スコアがベースラインエージェントのスコアに加算され、自己反省型エージェントの新たな合計スコアとされました。

### 分析手法

自己反省型エージェントのスコアをベースラインエージェントと比較する際、マクネマー検定が用いられて統計的有意性が判定され、p値が報告されました。

マクネマー検定では、2つの対応のある結果セットの不一致ペアの数が比較されます。検定統計量を計算するため、2×2の分割表が作成されます。セルaには両エージェントが不正解だった件数、セルdには両方が正解だった件数、セルbには不正解-正解のペア数、セルcには正解-不正解のペア数（この場合は常に0）が入れられます。

マクネマーの検定統計量は以下の式で計算されます。

χ² = (b – c)² / (b + c)

ここで、bとcは2×2分割表の不一致ペアを表します。

## 結果

### エージェント別パフォーマンス

分析の結果、さまざまなタイプの自己反省型エージェントが、ベースラインエージェントを上回るパフォーマンスを示したことが明らかにされました。全てのLLMにおいて、全ての自己反省タイプで統計的に有意なパフォーマンスの向上が見られました（p < 0.001）。

この傾向を示す具体例として、GPT-4の結果が提示されています。

下の図では、GPT-4を用いた各エージェントの正解率が示されています。全ての自己反省タイプが、多肢選択式問題の解決精度を向上させていることが視覚的に確認できます。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75649_5-1024x498.png)

ベースラインエージェントの正解率が79%であるのに対し、最も単純な「再試行」エージェントでも83%まで向上しています。

また「解答」や「複合」エージェントでは93%という高い正解率が達成されています。

下の表には、GPT-4を用いた各エージェントの詳細な数値分析結果が示されています。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75649_8.png)

ベースラインからの正解率の増加、検定統計量、p値などが記載されており、全ての自己反省タイプで統計的に有意な改善が確認できます。

### モデル別パフォーマンス

テストされた全てのLLMにおいて、全ての自己反省タイプで同様の正解率の向上が見られました。全てのケースで、パフォーマンスの改善は統計的に有意でした（p < 0.001）。

下の図は、モデルとエージェントタイプ別の正解率をプロットしたものです。この図から、全てのLLMで自己反省エージェントによる改善パターンが類似していることが分かります。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75649_6-1024x505.png)

例えば、今回実験した中で最も性能の高いモデルであるClaude 3 Opusでは、ベースラインの正解率が79.2%であるのに対し、「解答」エージェントでは93.9%まで向上しています。一方、比較的小規模なモデルであるLlama 2 7bでも、ベースラインの29.7%から「説明」エージェントで45.7%まで向上しています。

下の表には、全てのモデルとエージェントタイプにおける正解率の詳細な数値が示されています。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75649_9-1024x308.png)

この表から、モデルの規模や種類に関わらず、自己反省が一貫してパフォーマンスを向上させていることが確認できます。

### テスト別パフォーマンス

問題領域（試験の種類）によって、自己反省の効果の大きさに違いが見られたことが報告されています。

一部の問題領域では自己反省による大幅な性能向上が見られた一方で、他の領域ではその効果が比較的小さいものでした。例えば、LSAT-AR（分析的推論）試験で最も大きな改善が見られました。一方、SAT英語試験などでは、効果が比較的小さいものでした。

下の図は、GPT-4における試験とエージェントタイプ別の正解率をプロットしたものです。この図から、問題領域によって自己反省の効果に大きな違いがあることが視覚的に確認できます。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75649_7-1024x501.png)

LSAT-AR試験では、ベースラインの正解率が33%であるのに対し、「解答」エージェントでは76%まで向上しています。またSAT英語試験では、ベースラインが既に93%と高く、「解答」エージェントでも97%とわずかな向上にとどまっています。

下の表には、GPT-4における試験とエージェントタイプ別の詳細な正解率が示されています。この表から、問題の難易度や領域によって自己反省の効果が異なることが確認できます。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75649_10-1024x305.png)

以上の結果は、自己反省が全般的にLLMエージェントの問題解決能力を向上させる一方で、その効果の大きさはモデルの種類や問題の性質によって異なることを示しています。中でも、難易度の高い問題や複雑な推論を要する問題において、自己反省の効果が顕著に表れる傾向が見られています。

## 考察

### 結果の解釈

研究結果から、全ての種類の自己反省がLLMエージェントのパフォーマンスを向上させることが明らかになりました。テストされた全てのLLMで観察されたのです。

より多くの情報を含む自己反省タイプ（例：指示、説明、解答）は、限られた情報しか持たない自己反省タイプ（例：再試行、キーワード、アドバイス）よりも高いパフォーマンスを示しました。未編集エージェントとその他の自己反省型エージェントの正解率の差は、自己反省から直接的な答えの漏洩を効果的に防いでいることを示しています。

しかし、指示、説明、解答、複合エージェントが生成するフィードバックの構造は、直接答えを与えることなく、間接的に正解へのガイダンスを提供していることが明らかです。

興味深いことに、再試行エージェントも全てのLLMで有意にパフォーマンスを向上させました。このことから、エージェントが以前に間違いを犯したという知識だけでも、問題の再解答時のパフォーマンスを向上させる効果があることが分かります。この現象については、エージェントが2回目の試行でより慎重になるか、あるいは再解答の思考の流れに基づいて2番目に可能性の高い答えを選択している可能性が考えられます。この点についてはさらなる調査が必要です。

### 研究の限界

本研究には複数の限界があります。

まず、作成されたLLMエージェントは単一ステップの問題のみを解決しています。実際のLLMエージェントの価値は、複雑な多段階の問題を解決する能力にあるため、この実験は自己反省型LLMエージェントの潜在能力を完全に示すものではありません。

次に、APIエラーが結果に若干の誤差を生じさせた可能性があります。これらのエラーは主に、質問内容がコンテンツセーフティフィルターを作動させた際に発生しました。多くの場合、エージェントの正解率報告に1%未満の誤差を生じさせた程度ですが、一部のモデルでは最大2.8%の誤差が生じた可能性があります。

さらに、トップパフォーマンスのLLMは、ほとんどの試験で90%以上の正解率を達成しました。その結果、トップスコアの増加が100%（満点）の上限付近で団子状態になっており、パフォーマンスの向上を正確に評価することが難しくなっています。より高難度の試験を使用することで、この問題を解決できる可能性があります。

最後に、全てのモデルとエージェントにおいて、LSAT-AR（分析的推論）試験が最も難しく、同時に自己反省による効果も最も大きかったです。この1つの試験による大きなパフォーマンス向上が、全試験の集計結果を歪めている恐れがあります。より均一な難易度の試験セットを使用することで、この偏りを解消できる可能性があります。

### 研究の意義

実用的な観点からは、本研究はエージェントAIシステムを構築するAIエンジニアにとって意味のある知見をもたらしています。環境からのエラー信号に基づいて自身の間違いを自己反省できるエージェントは、将来的に同様の間違いを避けることを学習できます。エージェントが同じ間違いを無限に繰り返す「非生産的ループ」に陥るという一般的な問題の防止にも役立つでしょう。

理論的な観点からは、LLMにおけるメタ認知を研究するAI研究者にとって意味を持ちます。LLMが自身の思考の流れを自己反省できるのであれば、他の類似のメタ認知プロセスもLLMのパフォーマンス向上に活用できる可能性があります。

### 今後の研究方針

今後の研究方針として、以下の5点が提案されています。

（１）より複雑な問題セットを用いた実験の反復  
LSAT-AR試験と同程度かそれ以上の難易度の問題を使用することで、自己反省によるパフォーマンス向上をより明確に示すことができます。

（２）多段階問題を用いた実験  
エージェントが各ステップ後に環境からフィードバックを受け取り、エラー修正のための外部信号として使用する様子を観察すべきです。長期的な問題における自己反省の潜在能力も示すことができます。

（３）外部ツールへのアクセスを提供した実験の反復  
例えば、Pythonインタープリターからのコンパイルエラーや検索エンジンからの低ランクの検索結果に対して、エージェントがどのように適応するかを確認します。ツールからのエラー信号が自己反省にどのように役立つかを観察できます。

（４）外部メモリを持つエージェントでの実験の反復  
実世界のエージェントは、自己反省を保存し、類似（ただし必ずしも同一ではない）問題に遭遇した際にRAGを用いて取り出す必要があります。

（５）より広範なLLM、エージェントタイプ、問題領域における自己反省の調査  
自己反省の効果をより詳細に調べ、自己反省型LLMエージェントの潜在的な強みについてさらなる経験的な証拠を得るための研究が必要です。

## まとめ

この記事では、LLMベースのエージェントが反省によって問題を解く能力がどのように変わるかを調べた研究について紹介しました。

研究者たちは、さまざまなLLMに多くの選択問題を解かせ、間違えた答えを出したあとでエージェントに自分の間違いについて考えさせました。すると、どのような方法で自分を振り返っても、問題を解く能力が良くなることが分かりました。

中でも、詳しい説明や問題の解き方を含む自己反省が最も効果的で、バックボーンLLMの種類や問題の分野によらず有効でした。

研究者たちは、今回の発見がAIエージェント開発者や、AIが自分の思考をどのように理解しているかを研究する人々にとって役立つと考えています。

今後の研究では、より複雑な問題を使って、自己反省がどのような効果をもたらすかを調べることが提案されています。将来的にはエージェントの能力をさらに向上させる方法が見つかるかもしれません。

- 参照論文URL： [https://arxiv.org/abs/2405.06682](https://arxiv.org/abs/2405.06682)
- コードとデータ： [https://github.com/matthewrenze/self-reflection](https://github.com/matthewrenze/self-reflection)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[100人以上の研究者が実験参加　LLMは人間より優れた研究アイデアを思いつくのか？](https://ai-data-base.com/archives/75562)

[ノーコードでLLMマルチエージェントを操る『AUTOGEN STUDIO』Microsoftが新開発](https://ai-data-base.com/archives/75716)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)