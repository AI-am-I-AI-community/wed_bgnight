---
title: "「LLMはプロンプトから新しいタスクを学べるのか？」 という根本的な問いに対する3つの仮説を検証"
source: "https://ai-data-base.com/archives/74020"
author:
  - "[[AIDB Research]]"
published: 2024-08-08
created: 2025-06-13
description: "本記事では、LLMの文脈内学習（In-context learning, コンテキスト内学習）の仕組みに関する研究を紹介します。文脈内学習とは、LLMが少数の例示から新しいタスクを学習し実行する能力を指します。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、LLMの文脈内学習（In-context learning, コンテキスト内学習）の仕組みに関する研究を紹介します。文脈内学習とは、LLMが少数の例示から新しいタスクを学習し実行する能力を指します。

研究者らは今回、LLMが新しいタスクを学習するメカニズムを解明するために、3つの仮説を検証しました。そしてLLMの学習能力の限界を探りました。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74020-1024x576.jpg)

**参照論文情報**

- タイトル：What Do Language Models Learn in Context? The Structured Task Hypothesis
- 著者：Jiaoda Li, Yifan Hou, [Mri](https://ai-data-base.com/archives/26447 "磁気共鳴画像（MRI）") nmaya Sachan, Ryan Cotterell
- 所属：ETH zurich

**本記事の関連研究**

- [LLMのプロンプトに数百から数千の例を含める超長尺のコンテキスト内学習（In-context learning）とファインチューニングの性能比較](https://ai-data-base.com/archives/68564)
- [Claude 3などのLLMはコンテキスト内学習によって線形回帰・非線形回帰問題タスクもこなす](https://ai-data-base.com/archives/67496)
- [RAGとLong-Contextの比較、そしてハイブリッドで活用する新しい方法](https://ai-data-base.com/archives/73468)
- [ロングコンテキストはRAGもText to SQLも解決するか　Googleがケーススタディを実施](https://ai-data-base.com/archives/71486)

## 背景

LLMは、与えられた例示からタスクを学習し実行する能力、すなわち文脈内学習を示すと言われています。文脈内学習は、コード生成や教育、医療など幅広い分野で活用されています。しかし、文脈内学習がどのようなメカニズムで機能しているのかについては見解が分かれています。

文脈内学習の謎を解明するため、これまで研究者たちによってさまざまな仮説が提唱されてきました。仮説は大きく3つに分類されます。

1つ目の仮説は、「新しいことを学んでいるわけではなく、既に知っているタスクを識別しているだけ」というものです。つまり、LLMは訓練段階で多くのタスクを学習し、使用時には、与えられた例を見て、『これはどのタスクだろう？』と判断し、そのタスクを実行するのだという考え方です。

2つ目の仮説は、「LLMは訓練段階で「学び方」そのものを学習し、使用時には、「学び方」を使って新しいタスクを学習する」という考えです。LLMが本当の意味で新しいことを学べるという考え方です。

3つ目の仮説は、上記2つの中間的な考え方とも言えるもので「LLMは訓練段階で基本的なタスクを学習し、使用時には基本タスクを組み合わせて、新しく複雑なタスクを作り出す」という内容です。

今回、3つの仮説のどれが正しいのか、あるいは全て間違っているのかを確かめるべく、研究者らは一連の実験を行いました。

そして文脈内学習の本質や能力、限界についての新たな洞察が得られました。

下の図は3つの仮説を図解したものです。事前に学んだ通りのタスクしか行わないのか、組み合わせて新たなタスクを行えるのか、それともタスクの単純な組み合わせは行えるのかを比較しています。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74020_1.png)

## 仮説1の検証

まず一つ目の仮説は、「LLMは新しいことを学んでいるわけではなく、既に知っているタスクを識別しているだけ」といった内容です。仮説1を検証するために以下のような実験が行われ、結果が得られました。

### 実験設定

実験では「レスポンス変更タスク（RA）」という新しい手法が使用されました。

レスポンス変更タスク（RA）は、既存のタスクを基にして新しい形式のタスクを作り出す手法です。元のタスクの入力部分はそのままに、出力（レスポンス）の部分だけを変更します。変更は特定の規則や関数を用いて行われ、例えば「ポジティブ」を「ポル」に置き換えるといった具合です。

レスポンス変更タスク（RA）を使用する目的は、言語モデルが未知のタスクにどれだけ適応できるかを調査することです。モデルは訓練時に見たことのない形式のレスポンスに直面しますが、それでも正しく分類できるかどうかが試されます。そのため、柔軟性や汎用学習能力が必要とされます。

そして、実験では、テキスト分類に関する3つのデータセットが使用されました。

1. 顧客レビュー（CR）  
	（製品に対する顧客のレビューデータセット。主に製品やサービスに対する短い意見文で構成されており、 [感情分析](https://ai-data-base.com/archives/26497 "感情分析") のタスクによく使用される）
2. スタンフォード感情ツリーバンク（SST-2）  
	（映画レビューに基づいた [感情分析](https://ai-data-base.com/archives/26497 "感情分析") のデータセット）
3. AG News  
	（ニュース記事の分類データセット。カテゴリは世界、スポーツ、ビジネス、科学技術のいずれか。タイトルと短い説明文が含まれており、テキスト分類タスクでよく使用される）

3つのデータセットに対して、通常の文脈内学習（ICL）とRAタスクを用いたICL（RA-ICL）の性能が比較されました。

実験を行う前の段階では、通常の文脈内学習のほうがRAタスクを用いた文脈内学習よりも優れた性能を示すと予想されていたと考えられました。通常の文脈内学習は、モデルが事前学習時に類似したタスクに触れている可能性が高いため、より馴染みのあるパターンを扱っていると考えられます。一方、RA-ICLは意図的に変更された未知のレスポンスパターンを扱うため、より難しいタスクだと予想されるためです。

### 結果

実験結果は以下のとおりでした。

まず、文脈内学習における例示が短い場合、RA-ICLの性能はランダム予測と同程度でしたが、長さが増すにつれて性能が向上し、通常の文脈内学習と同等の性能に達しました。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74020_3-1024x247.png)

データセットにおける通常の文脈内学習とRA-ICLの性能比較。デモンストレーション長さLの変化に対する性能を示す

また、モデルサイズが大きくなるほど、通常の文脈内学習とRA-ICLの両方の性能が向上しました。最小のモデル（LLaMA2-7B）でさえ、RA-ICLでランダム予測を大きく上回る性能を示しました。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74020_4.png)

異なるモデルサイズ（7B、13B、70B）での通常の文脈内学習とRA-ICLの平均性能比較

実験結果は、仮説1の予測と矛盾しています。LLMは、事前学習時に観察されていない可能性が高いRAタスクを文脈内で学習できることが示されましたためです。

つまりLLMは、単に事前学習時に観察されたタスクを選択しているだけではなく、新しいタスクを文脈内で学習する能力を持っていることが示唆されます。

## 仮説2の検証

次に、仮説2「LLMは訓練段階で「学び方」そのものを学習し、使用時には、この「学び方」を使って新しいタスクを学習する」が検証されました。

### 一つ目の実験

仮説2を検証するため、新たな概念として「プロンプト変更タスク（PA）」が導入されました。既存のタスクのプロンプト部分を変更するタスクです。もし仮説2が正しければ、モデルは新しいタスクを「その場で」学習できるはずです。つまり、入力（プロンプト）が変更されても、出力（レスポンス）との関係性を学習できるはずだという考えです。

実験では、以下の手法が比較されました。

1. 通常の文脈内学習
2. レスポンス変更タスク文脈内学習（RA-ICL）
3. プロンプト変更タスク文脈内学習（PA-ICL）
4. プロンプト変更タスクに対する [ロジスティック回帰](https://ai-data-base.com/archives/26336 "ロジスティック回帰（LR）") （PA-LR）

なおPA-LRは、PAタスクが学習可能であることを確認するためのベースラインとして使用されました。

実験結果は以下の通りでした。

まず、 [ロジスティック回帰](https://ai-data-base.com/archives/26336 "ロジスティック回帰（LR）") モデルは、PAタスクをある程度学習できることが示されました。  
次にRA-ICLにおいては、LLMは、例示の長さに関わらず、常にランダム予測と同程度またはそれ以下の性能しか示しませんでした。対照的に、RA-ICLでは80%を超える高い性能が達成されました。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74020_5.png)

3つのテキスト分類タスクにおける各設定（通常ICL、RA-ICL、PA-ICL、PA-LR）の性能比較

実験結果は、仮説2の予測と一致しません。PAタスクとRAタスクが同様に学習されるはずだという予測に反して、両者の間に大きな性能差が観察されました。

### 二つ目の実験

LLMのメカニズムにおける研究では、LLMが勾配降下法（機械学習でよく使われる最適化手法）を使って [線形回帰](https://ai-data-base.com/archives/26362 "線形回帰") （シンプルな予測モデル）を学んでいるという考えがあります。

そこで、研究者たちは非常にシンプルな実験を考案しました。入力（プロンプト）と出力（レスポンス）をそれぞれ単一のトークンに限定することで、タスクを [線形回帰](https://ai-data-base.com/archives/26362 "線形回帰") 問題として扱えるようにしたのです。

実験では2つの手法が比較されました。1つ目は文字列変換関数を用いたICL（τg-ICL）で、要するに通常の文脈内学習の方法です。2つ目は [線形回帰](https://ai-data-base.com/archives/26362 "線形回帰") （τg-Linear）で、同じデータを使って訓練された単純な機械学習モデルです。

実験の結果、τg-Linearは大多数の関数を完璧に学習できましたが、τg-ICLの性能は平均が低く、分散が大きいものでした。さらに、両者の性能間に有意な相関は見られませんでした。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74020_6-1024x180.png)

τg-LinearとτgICLの性能の平均と分散、およびそれらの 相関係数 を示す

この実験結果も、仮説2の妥当性に疑問を投げかけています。LLMは、事前学習時に獲得した学習アルゴリズムを用いて新しいタスクを学習しているのではなく、より複雑なメカニズムが関与している可能性が示唆されます。

## 仮説3の検証

最後に仮説3「LLMは訓練段階で基本的なタスクを学習し、使用時には基本タスクを組み合わせて、新しく複雑なタスクを作り出す」の検証が行われました。

### 一つ目の実験

まず研究者たちはレスポンス変更タスク（RA-ICL）と文字列変換関数を用いたICL（τg-ICL）の性能を比較しました。目的は、二つのタスク間に何らかの関連性があるかを探ることでした。

実験の結果、RA-ICLとτg-ICLの性能間に統計的に意味のある正の相関が見つかりました。相関の強さは中程度で、0.34から0.51の範囲でした。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74020_7-1024x304.png)

CR、SST-2、AG Newsデータセットにおける、RA-ICLとτg-ICLの性能の相関関係を示す

この発見は非常に興味深いものです。なぜなら、RAタスクが実際には二つの基本的なタスク、つまりgとτの組み合わせによって学習されている可能性を示唆しているからです。仮説3が正しい可能性を支持するものと言えるでしょう。

### 二つ目の実験

次に、研究者たちは「自然な」関数という新しい概念を導入しました。ランダムな文字列変換ではなく、直感的で事前学習データに含まれている可能性が高い関数です。同義語、反義語、キーワードという3種類の関数が使用されました。

実験結果はまたもや非常に興味深いものでした。LLMは同義語とキーワード関数をほぼ完璧に学習しました。反義語関数はやや難しかったものの、それでもランダムな関数よりも明らかに学習が容易でした。統計的な分析によって、これらの自然な関数がランダムな関数よりも有意に学習しやすいことが確認されました。この結果もまた、LLMが事前学習時に獲得した知識を効果的に活用できることを示唆しています。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74020_8.png)

### 三つ目の実験

最後の実験では、研究者たちは自然な関数、特に同義語関数を繰り返し適用することで、一見ランダムに見える関数を作成しました。複雑なタスクが実際には基本的なタスクの組み合わせで構成されている可能性を探るためでした。

実験の結果、LLMは、高次の同義語関数を90%以上の [F1スコア](https://ai-data-base.com/archives/26112 "F1スコア（F値）") で学習することができました。一見無関係に見える単語の対応関係でも、LLMが理解し学習できることを示しています。ただし、同義語の次数が上がるにつれて、LLMの性能に有意な低下が見られました。タスクの複雑さが増すにつれて、LLMの学習が徐々に困難になることを示唆しています。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74020_9-1024x435.png)

“positive”と”negative”の同義語の階層的な図。同義語の階層が高くなるにつれて、元の単語との関連性が薄れていくことを示す

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74020_10-1024x302.png)

異なる階層の同義語に対するLLaMA2-70Bの学習性能。同義語の階層が高くなるにつれて性能が低下する傾向を示す

### 仮説3に対する実験結果のまとめ

実験結果は全体的に、LLMが基本的なタスクを組み合わせて複雑なタスクを学習するという仮説3を強く支持するものです。

## まとめ

本記事では、LLMの文脈内学習能力に関する研究を紹介しました。

研究者たちは3つの仮説を検証し、LLMが事前学習時に観察されなかったタスクを学習できることを示しました。また、LLMが基本的なタスクを組み合わせて新しいタスクを学習している可能性が示唆されました。

最終的に、仮説3「LLMは訓練段階で基本的なタスクを学習し、使用時には基本タスクを組み合わせて、新しく複雑なタスクを作り出す」という考え方が最も裏付けられた結果となりました。

今後もLLMの原理に関する研究が進み、能力の謎が解明されることが期待されます。

- 参照論文URL： [https://arxiv.org/abs/2406.04216](https://arxiv.org/abs/2406.04216)
- データ： [https://github.com/eth-lre/LLM\_ICL](https://github.com/eth-lre/LLM_ICL)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[漫画を台本に変換するモデル『Magi v2』オックスフォード大学の研究グループが開発](https://ai-data-base.com/archives/73876)

[OpenAIがGPT-4oの評価を発表。音声性能が高く、それゆえのリスクも](https://ai-data-base.com/archives/74097)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)