---
title: "LLMを擬人化することは開発や評価にどんな影響を及ぼすか"
source: "https://ai-data-base.com/archives/84526"
author:
  - "[[AIDB Research]]"
published: 2025-02-18
created: 2025-06-13
description: "本記事では、LLMを「人間らしいもの」として捉える考え方が、研究や開発、評価にどのような影響を与えているのかを取り上げます。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、LLMを「人間らしいもの」として捉える考え方が、研究や開発、評価にどのような影響を与えているのかを取り上げます。

近年、LLMの振る舞いを人間の思考や認知と重ねて理解しようとする傾向が強まっており、これが研究手法や開発方針、評価基準にも影響していると指摘されています。

LLMを人間のように扱うことは研究の進歩を促す一方で、誤解や偏りを生む可能性があるため、より適切に理解・運用するための新しい枠組みが求められています。

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_84526_thum2-1024x576.png)

参照論文情報は記事の下部に記載されています。

**本記事の関連研究**

- [LLMエージェント間で観察された人間のような「意見の二極化」](https://ai-data-base.com/archives/82487)
- [LLMエージェントに人間のような欲求を持たせてシミュレーションする手法](https://ai-data-base.com/archives/80804)
- [実在する人間1052人の態度と行動をAIでモデル化　インタビューベースのエージェントが人間の回答を85%再現](https://ai-data-base.com/archives/80107)

## 背景

LLMの研究において、人間の思考や認知と重ね合わせて考える傾向が強まっています。これには、知能を再現しようとする試みが長年続けられてきた背景も関係しており、自然な流れとして根づいてきたようです。

その中で、LLMの性能を評価する過程で「人間らしさ」を基準にする場面が増えていると指摘されています。例えば、モデルの誤りを「幻覚」と表現したり、あたかも人格があるかのような説明がなされることがあります。

このような表現の使われ方には、LLMがまるで意識や意図を持っているかのように錯覚させる側面があると考えられます。その結果、研究や技術の発展の方向性が特定の枠組みに縛られたり、利用者がLLMを誤解したまま活用してしまう恐れが生じています。

研究者らは、現在のようにLLMに過剰な人間らしさを投影することはモデルの本質を見誤る要因になると考えています。そして、より適切な理論や評価方法を確立する必要があると議論されています。

そこで今回オックスフォード大学とスタンフォード大学の研究者らはこの問題を深く掘り下げるため、LLMに対する既存の認識を見直し、別の視点から新たな可能性を探る作業に取り組みました。

以下で詳しく紹介します。

| **「背景」のサマリー**      1\. LLM研究では、人間の認知と重ねて考える傾向が強まり、性能評価にも「人間らしさ」が基準として使われる場面が増えている   2\. しかし、このような表現はLLMに意識や意図があると誤解させる恐れがあり、技術の発展や利用者の理解に影響を与える可能性がある   3\. オックスフォード大学とスタンフォード大学の研究者は、LLMへの過剰な擬人化が本質を見誤る要因になると指摘し、新たな評価方法の確立を目指している |
| --- |

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_84526_1.png)

LLM開発・運用サイクルでの人間的思考の影響を体系化した概念図

## 広がるLLMの擬人化表現

現研究において、LLMについての表現方法が大きく変化してきています。人々は、まるでLLMが人間であるかのように表現する傾向を強めているのです。

研究チームは、膨大な数の論文を収集し、独自の分析手法を用いて調査を行いました。論文中でLLMがどれほど人間のように描写されているかを、客観的な方法で測定したのです。

### 擬人化表現の多さを数値化

研究では「AnthroScore」という測定手法が導入されました。たとえば「LLMは回答を間違えることがある。彼女は誤情報を広めているかもしれない」といった文章における擬人化表現を自動的に検出します。

分析結果から、以下の実態が明らかになりました。

- 研究論文の要旨全体の約30%に擬人化された記述が含まれている
- LLM関連の論文に限ると、その割合は40%を超える
- 研究分野によって擬人化の度合いに違いがある
- 時間の経過とともにこの傾向が強まっている

論文の執筆者自身が意図しないうちに、LLMを「人格を持つ存在」として扱う傾向が強まっている可能性を示唆しています。

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_84526_2.png)

2023年から2024年にかけてのarXiv論文要旨で計測された人間的表現の増加傾向

### 分野による違い

言語学分野の主要な論文集であるACL Anthologyの分析結果からは、興味深い発見がありました。

- 10年前には5%程度だった擬人化の割合が、直近では11%にまで増加
- LLMの解釈や倫理、対話システムといった、人間との関わりが深い領域では擬人化の表現が多く出現
- 伝統的な言語学の研究では擬人化の頻度が低い傾向

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_84526_3.png)

2007年から2022年のACL Anthologyにおける人間的表現の歴史的推移

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_84526_4.png)

NLP の各サブ分野で観察された人間的表現の分布比較

この傾向の背景には、LLMを扱う研究が人間の思考を模倣することや、その社会的影響を論じることと深く関わっているという事情があります。研究の主題に人間の行動や心理が関与するほど、無意識のうちにLLMを人間のように表現する機会が増えると考えられます。

### 擬人化表現の傾向から見えてくるもの

定量的な分析は、研究者たちのLLMに対する無意識的な捉え方を浮き彫りにしました。数年という短期間で、論文における擬人化表現が急増している事実は、研究者たちの意識変化を如実に反映しているといえます。そうした表現が適切かどうかについては、慎重な検討が必要です。

| **「広がるLLMの擬人化表現」のサマリー   **   1\. LLMに関する研究論文では、人間的な表現が増加しており、その傾向を定量的に測定するためにAnthroScoreという指標が用いられた   2\. 分析の結果、LLM関連の論文では擬人化の割合が40％を超え、時間の経過とともにこの傾向が強まっていることが確認された   3\. 擬人化が進むことで研究者や一般ユーザーの認識に影響を与える可能性があり、今後はより慎重な表現が求められるようになると考えられる |
| --- |

## 人間らしさを前提とすることが与える影響

LLMの研究開発においては、人間の思考や行動を基準とする見方が幅広く採用されています。人間の認知過程に照らし合わせることで、LLMの動作原理を理解しやすくなるという利点がみられます。ただし、研究者たちからは、人間的な見方に過度にとらわれることで、LLMの本質的な特徴を見逃したり、新たな可能性を制限したりする懸念が指摘されています。

### 学習過程における影響

研究開発の現場では、人間の学習方法に基づいたアプローチが広く採用されてきました。例えば、文章を人間が理解しやすい単位で区切ったり、推論過程を自然言語で段階的に示したりする手法は、確かな成果を上げています。

しかし最近の研究からは、人間の認知とは異なるアプローチでも優れた結果が得られることが明らかになってきました。例えば、文章をバイト単位で処理する方法や、人間には直感的でない推論方法でも、高い性能を実現できることが示されています。

人間のように思考過程を言語化する「チェーン・オブ・ソート」などの手法は、一見効果的に見えます。しかしながら、最新の研究では、むしろ学習データ上のパターンを強化しているだけである可能性が指摘されています。例として、意味を持たないランダムな文字列を用いた場合でも推論性能が向上するという現象が報告されています。

こうした知見から、研究者たちは人間的な学習方法にとらわれない新しいアプローチの重要性を認識しています。LLM独自の特性を活かした多様な学習手法の開発が、今後の研究課題として浮かび上がってきているのです。

### LLMの制御における人間価値観の組み込み

LLMの制御においても、人間の価値観や倫理観を組み込もうとする試みが数多く行われています。RLHFやConstitutional AIといった技術は、まさに学習済みモデルに人間の好みを反映させ、出力内容を制御することを目指しています。

人間の価値観を取り入れることは、確かに多くの利点をもたらすと考えられています。しかしその一方で、望ましくない人間的な性質まで学習してしまうリスクも指摘されています。

また、利用者がLLMをあたかも感情や人格を持つ存在のように扱ってしまう事態も懸念されています。実際のところ、人間らしさを意図的に付与したつもりでも、LLMは単に学習データのパターンに基づいて、相手を褒めるような応答を選択しているだけかもしれないのです。

研究者たちは現在、人間的な倫理観や推論を直接移植する代わりに、技術的な制御の枠組みを強化する方向性を提案しています。例えば、制御理論を応用して出力範囲を制限したり、モデルの内部構造を可視化して望ましくない出力を抑制したりする手法が検討されています。

人間の道徳観を模倣することだけが唯一の解決策ではないとの認識が広まりつつあるのです。

### LLMの能力評価における人間基準の問題点

LLMの性能評価には、MMLUやGSM8Kといった人間向けの試験が広く活用されてきました。問題を正確に解く能力を測定するには、一見するとわかりやすい基準だと考えられたためです。

さらに、人間と同等の成績を収めるケースが増加したことで、LLMが人間と同程度の思考能力を獲得したとの見方も広まりつつありました。

しかしながら、こうした評価手法には重要な問題が潜んでいることが明らかになってきています。たとえば、問題文のわずかな書き換えや出題形式の変更によって、成績が大きく変動してしまうケースが報告されています。

また、同じ試験を繰り返し受けさせると、問題の傾向だけを学習してしまい、真の能力向上とは異なる形で点数が上昇するという現象も確認されています。

研究者たちは、データの出現頻度、複数回のやり取りにおける文脈の扱い、予測の不確実性など、人間とは異なるLLM独自の特性に着目した評価基準の必要性を指摘しています。実際に、動的に更新されるベンチマークの開発や、詳細な誤り分析の導入といった新しい評価手法の確立に向けた取り組みが進められています。

人間基準の評価に過度に依存することは、LLMの潜在的な長所や課題を見落とすリスクをはらんでいます。研究コミュニティでは、LLMの本質的な能力をより正確に把握するため、多角的な評価アプローチの開発が模索されています。

### 人間的解釈の限界と新たな視点

LLMが誤った情報を出力する現象は、一般に「ハルシネーション」と呼ばれています。しかしながら、実際のLLMは単に単語を確率的に推定しているだけであり、人間のような記憶や意図を持っているわけではないという指摘がなされています。

一部の研究者たちは、誤情報と見なされる出力であっても、創造的な文脈では新たなアイデアの源となり得ると論じています。

さらに利用者への過度な賞賛は「サイコファンシー」と表現されていますが、実態は入力テキストを模倣した結果に過ぎない可能性が高いとされています。同様に、一見すると欺瞞的に見える振る舞いについても、学習データにある対話パターンの再現であり、意図的な策略ではないと解釈されています。

研究者たちは、LLMに人間的な責任や道徳性を求めることで、むしろ誤解が生じやすくなると警鐘を鳴らしています。擬人化的な解釈を避け、LLMの内部構造や学習過程に基づいた統計的・構造的な理解を深めることが重要だと指摘されています。

### ユーザーインターフェースの課題

LLMとのやり取りには、一般的にチャット形式のインターフェースが採用されています。

チャットは人間にとって馴染みやすい一方で、あたかも人との会話であるかのような錯覚を生みやすく、LLMの本質的な理解を妨げる可能性が指摘されています。曖昧な指示や不明確な入力に対して、予期せぬ応答が返されるケースも報告されています。

専門家たちは、LLMの特性を活かした新しいインターフェースの可能性を提言しています。例えば、構造化された質問テンプレートや選択式のプロンプトなど、人間の対話を模倣するのではなく、LLMの機能を効果的に引き出す設計が模索されています。

自然な対話の親しみやすさを保ちながら、システムの動作原理を利用者に分かりやすく示す方法の開発が進められています。

| **「人間らしさを前提とすることが与える影響」のサマリー   **   1\. LLMの学習方法や評価基準に人間の思考や価値観が前提として組み込まれることで、研究や開発の方向性が特定の枠に縛られる可能性が指摘されている   2\. 人間の試験をそのまま適用する評価方法ではLLMの本質を正しく理解できないリスクがあり、また、倫理的調整では擬人化が誤解を生む要因となるため、新たな評価・制御手法の必要性が高まっている   3\. チャット形式のインターフェースは直感的だが、LLMが人間のように思考しているという錯覚を生みやすく、利用者が誤解しないための透明性の高い設計が求められている |
| --- |

### LLMの研究開発における提言

人間の認知科学から得られる知見は重要ですが、LLM固有の特性を理解するための新しい視点も欠かせないことが指摘されています。人間的な比喩が誤解を招く場合もあるため、多様な学問領域の知見を組み合わせた研究アプローチが推奨されています。

### 提言１：LLMの本質を捉える新しい概念枠組みの構築

LLMを理解する上で、心理学や認知科学の知見を超えた新たな分析枠組みの確立が求められています。

たとえば「teleological approach」はLLMと人間の評価基準の違いを明確にする手法として注目されています。また、「role-play」や「agent model」といった概念は、LLMを人間とは異なるシステムとして捉える視点を提供しています。

### 提言２：擬人化がもたらす影響の包括的な分析

研究者たちは、人間的な表現の単なる言い換えにとどまらず、その背後にある前提や仮定を深く掘り下げる必要性を強調しています。

ハルシネーションやサイコファンシーといった用語の背景にある人間的な思考の枠組みを見直し、研究テーマや手法を広く再検討することが提言されています。

### 提言３：学際的アプローチの重要性

制御理論、人間工学、ソフトウェア工学など、多様な分野の知見を取り入れることで、LLMのフィードバック・ループや安全性の検証が大きく前進すると期待されています。

人間的なアプローチだけでは見落としがちな側面も、複数の理論的視点を導入することで適切に理解できるようになるでしょう。

人間との類似性を持ちながらも独自の設計原理を備えたLLMの研究には、こうした多角的なアプローチが不可欠だと考えられています。

| **「LLMの研究開発における提言」のサマリー   **   1\. LLMの特性を正しく理解するためには、人間の認知科学だけに頼らず、新たな概念を構築し、LLM独自の振る舞いを分析する視点が求められている   2\. 擬人化表現の修正だけでは問題の本質を見落とす恐れがあり、研究の枠組みや手法そのものを批判的に見直すことが重要とされている   3\. 制御理論や人間工学など多分野の知見を取り入れることで、LLMの特性を適切に評価し、安全で効果的な活用を目指すことが提案されている |
| --- |

## 人間的アプローチの意義も忘れない

人間らしさで比喩することがLLM研究を推進する重要な原動力となってきたという見方も根強く存在しています。

人間の脳や心の仕組みを模倣することで、新しい技術が発展してきた歴史的経緯を踏まえると、人間の思考プロセスから学ぶことには大きな意義があるとされています。実際に、人間の言語理解を模倣するアプローチは、会話システムや言語生成の分野で目覚ましい成果を上げてきました。

一部の研究者たちは、LLMの出力に人間的な特徴が見られることを自然な帰結として捉えています。人間が作成した膨大なテキストデータを学習材料としている以上、人間の言葉遣いや表現様式が反映されるのは避けられないと指摘されています。

むしろ、人間的な用語や概念を用いることで、利用者にとってシステムがより理解しやすくなるという利点も強調されています。研究分野全体を見渡すと、人間的なアプローチがLLMの発展を大きく後押ししてきた事実は広く認められています。

しかしながら、そうした傾向に伴う潜在的な問題点にも目を向けるのが今回の主題です。人間の視点から得られる示唆を活用しつつも、LLMの用途や応用分野に応じて、独自のシステムとして捉え直す柔軟な姿勢が求められているのです。

## まとめ

本記事では、LLMの研究において人間らしさを前提とする見方がもたらす影響を検討した研究を紹介しました。

人間の認知を参照することでLLMの理解が進む一方で、擬人化による誤解や研究の方向性の偏りが懸念されています。こうした課題に対し、LLMを独立したシステムとして捉える新たな評価手法や分析の枠組みが求められています。

研究の進展に伴い、多分野の視点を取り入れる必要性も指摘されており、今後の議論が注目されます。LLMの特性を適切に理解するための手法や考え方の整理は、引き続き重要な課題となると予想されます。

**参照文献情報**

- タイトル：Thinking beyond the anthropomorphic paradigm benefits LLM research
- URL： [https://doi.org/10.48550/arXiv.2502.09192](https://doi.org/10.48550/arXiv.2502.09192)
- 著者：Lujain Ibrahim, Myra Cheng
- 所属：University of Oxford, Stanford University

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[LLM専用の「新しい言葉」を導入　Google DeepMind](https://ai-data-base.com/archives/84361)

[「LLM活用で文書作成」社会でどこまで導入されている](https://ai-data-base.com/archives/84626)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)