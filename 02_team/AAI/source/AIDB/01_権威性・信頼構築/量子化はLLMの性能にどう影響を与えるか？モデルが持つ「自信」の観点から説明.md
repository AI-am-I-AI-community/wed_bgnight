---
title: "量子化はLLMの性能にどう影響を与えるか？モデルが持つ「自信」の観点から説明"
source: "https://ai-data-base.com/archives/68518"
author:
  - "[[AIDB Research]]"
published: 2024-05-02
created: 2025-06-13
description: "LLMは多大な計算コストとメモリーを必要とするため、モデルを軽量なものに変える量子化手法が注目を集めています。今では、大きなモデルが発表されたと同時に量子化モデルが有志によって作成されるこも多くなっています。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

LLMは多大な計算コストとメモリーを必要とするため、モデルを軽量なものに変える量子化手法が注目を集めています。今では、大きなモデルが発表されたと同時に量子化モデルが有志によって作成されるこも多くなっています。

しかし量子化は、モデルの性能低下やバイアスの増幅を引き起こすことが懸念されています。また、モデルの予測確率分布（簡単に言うとモデルの自信）がどう変化するのかは、十分な検討がなされていません。

そこで今回研究者らは量子化前後のLLMを比較し、量子化がモデルの確信度に与える影響を調査しました。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_68518-1024x576.jpg)

**参照論文情報**

- タイトル：When Quantization Affects Confidence of Large Language Models?
- 著者：Irina Proskurina, Luc Brun, Guillaume Metzler, Julien Velcin
- 所属：Université de Lyon

**本記事の関連研究** ：

- [LLMを軽くする効果的な剪定手法『SliceGPT』](https://ai-data-base.com/archives/63622)
- [小さなLLMを多数組み合わせることで、単一の巨大モデルに匹敵する可能性](https://ai-data-base.com/archives/64708)
- [1.1Bパラメータの小さなモデルを巨大データ（約3兆トークン）で訓練したモデル『TinyLlama』が、比較的優秀な性能を発揮](https://ai-data-base.com/archives/61914)
- [強くて軽いモデルPhi-3の評価結果　Microsoftの論文（テクニカルレポート）より](https://ai-data-base.com/archives/68184)

## 背景

LLMの優れた性能の裏には、数億から数千億に及ぶパラメータを持つ巨大なネットワークが存在します。推論時の計算コストと記憶容量が大きく必要であるため、実用においてはコストやメモリ削減の工夫が重要となっています。

そこで注目されているのが量子化技術です。量子化は、学習済みモデルの重みをより少ないビット数で表現することで、モデルを圧縮する手法の一つです。

従来の量子化研究では、主に以下の評価指標が用いられてきました。

1. 推論の高速化率
2. 重みの近似精度
3. 性能低下幅

しかしモデルの「予測確率分布」に与える影響については十分な検討がなされていません。

モデルの予測確率分布は、簡単に言うと、モデルが各クラス（ラベル）に対してどの程度の確信を持っているかを表す指標です。例えば、二値分類問題では、モデルは「はい」と「いいえ」のそれぞれに対して0から1の間の確率を出力します。この確率の分布が予測確率分布です。  
モデルが高い確信度を持つ場合は実際に正解である割合も高く、低い確信度の場合は正解である割合も低くなります。つまり、予測確率分布は、モデルの予測の信頼性を反映していると考えられています。

そのため、予測確率分布の変化を調べることで、量子化による性能低下をより深く理解できると期待できす。

そこで今回研究者らは、量子化前後のLLMの予測確率分布に着目し、以下の分析を行いました。

1. 量子化がLLMのキャリブレーションと確信度に与える影響の調査
2. 量子化前後のLLMの確信度の整合性評価
3. 量子化による性能低下の原因（量子化前の確信度の観点から説明）

なおキャリブレーションとは、モデルの予測確率が真の確率をどの程度反映しているかを表す指標です。

## 研究デザイン

量子化前後のLLMの予測確率分布を比較するために、以下の方法論が採用されています。

### 量子化手法

研究者らは、事前学習済みのLLMに対して、GPTQ（OPTQ）と呼ばれる量子化手法を適用しました。入力データに基づいて各層の重みを反復的に量子化する手法で、以下の利点があります。

1. 重みの近似誤差を最小化できる
2. 様々なビット数で量子化したモデルを保存できる
3. [GPU](https://ai-data-base.com/archives/26570 "GPU") を用いて推論を大幅に高速化できる

量子化というのは、モデルの重みを表現するのに必要なビット数を減らすことです。ビット数が少ないほど、モデルを圧縮できます。今回の研究では、4ビットに量子化しました。重みを表現するのに4つの0と1の組み合わせを使うということです。

なお量子化には、モデルを適切に圧縮するために、訓練データの一部を使う必要があります。今回の研究では、 [C4というデータセット](https://huggingface.co/datasets/c4) を使いました。C4データセットは、ウェブ上から収集された大量のテキストデータです。研究者たちは、C4データセットからランダムに選んだ128個の文章（シーケンス）を使って、量子化を行いました。

### 評価指標

量子化前後のモデルの性能を評価するために、以下の指標が用いられました。

1. 精度（Acc.）：モデルの予測が正解ラベルと一致する割合
2. キャリブレーション誤差（CE）：モデルの予測確率と実際の精度の乖離度合い

キャリブレーション誤差は、2値分類問題ではExpected Calibration Error（ECE）を、多クラス分類問題ではAdaptive Calibration Error（ACE）を使用しました。

研究者たちは、量子化がモデルの予測の仕方にどのような影響を与えるのかを調べるために、2つの特別なケースに注目しました。

1つ目は、モデルが正解を選ばないケースです。モデルは正解に対してあまり自信を持っていません。つまり、モデルは「この答えが正しいと思うけど、自信はない」と考えているわけです。その結果、モデルは正解を選ばずに、別の答えを選んでしまうのです。

2つ目は、モデルが間違った答えを選ぶケースです。こちらののケースでは、モデルは間違った答えに対して過剰に自信を持っています。つまり、モデルは「この答えは絶対に正しい！」と考えているのに、その結果、モデルは間違った答えを選んでしまう場合です。

研究者たちは、これらのケースを調べるために、2つの指標を測定しました。1つは、モデルが間違った答えを選んだときの自信の度合い（Conf\_err）です。もう1つは、モデルが正解に対してどれだけ自信を持っているか（Conf\_true）です。

## 実験

### データセット

研究者らは、以下の6つの常識推論タスクを用いて、量子化前後のLLMの性能を評価しました。

1. ARC EASY：科学的知識を問う読解問題
2. BOOLQ：自然言語で与えられた質問に対して「はい」か「いいえ」で答える問題
3. PIQA：物理的常識を問う選択式問題
4. HELLASWAG：文章の続きを予測する問題
5. OBQA（OpenBookQA）：科学的知識を問う選択式問題
6. XSTORY-EN：物語の続きを予測する問題

上記はすべて、LLMの言語理解能力を様々な側面から評価するものです。例えば、BOOLQは読解能力を、PIQAは物理的常識の理解を、HELLASWAGは文脈の理解を問うタスクです。

### モデル

以下の4つのLLMファミリーが実験に使用されました。

1. BLOOM：5億6000万から71億のパラメータを持つモデル
2. OPT：1億2500万から130億のパラメータを持つモデル
3. Mistral-7B：71億のパラメータを持つモデル
4. LLaMA-7B：71億のパラメータを持つモデル

それぞれパラメータ数が異なるだけでなく、事前学習に使用されたデータセットも異なります。BLOOMは多言語データセットで学習されたモデルであり、LLaMAは主に英語のデータセットで学習されたモデルといった具合です。

### 実験の目的

以下の二つが主な狙いです。

1. モデルファミリー間で、量子化による性能変化を比較する
2. モデルのスケール（パラメータ数）によって、量子化による性能変化がどのように異なるかを調べる

## 実験結果

研究者らは、一連の実験を通じて、量子化がLLMの性能に与える影響を多角的に分析しました。量子化前後のキャリブレーション誤差、予測エントロピー、最大の確信度変化が生じたケース、モデル間の分布の差異についてなど。

分析のポイントそれぞれについて簡単に述べます（一部、前述した内容と同じ）

- キャリブレーション誤差は、モデルの予測確率と実際の [正解率](https://ai-data-base.com/archives/25930 "正解率") の差を表す指標です。キャリブレーション誤差が小さいほど、モデルの予測確率は信頼できると言えます。
- 予測エントロピーは、モデルの予測がどの程度確信を持っているかを表す指標です。エントロピーが大きいほど、モデルは予測に自信を持っていないことを意味します。
- 確信度の変化とは、量子化前後で、モデルの予測確率がどれほど変わったかです。変化したモデルほど量子化の影響を最も受けやすいと考えられます。
- モデル間の分布の差異については、予測確率分布の違いで、差異が大きいほど、量子化による影響が大きいと言えます。

結果、モデルファミリーやスケールによって量子化の影響が異なることが明らかになりました。詳細は以下に示します。

### キャリブレーションへの影響

下記表に示されているように、量子化後のモデルでは、量子化前から存在していたキャリブレーション誤差がさらに増幅される傾向が見られました。なお、モデルファミリーやタスクに関わらず一貫して観察されました。LLaMA-7Bでは、HELLASWAG  
タスクにおいて量子化前のキャリブレーション誤差が約10%も増加しました。また、HELLASWAGタスクにおける性能の低下が、BOOLQやPIQAタスクと比べて顕著でした。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_68518_2-1024x434.png)

### 確信度への影響

次に下記の表は、パラメータ数が同程度の4つのモデルの結果を示しています。すべてのモデルにおいて、量子化前後で誤答に対する過剰な確信度（約0.95）が観察されました。さらに、量子化後は正解ラベルに対する確信度が統計的に有意に低下することが明らかになりました。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_68518_3.png)

また、下記に示されるように、量子化後のモデルではエントロピーが増加しました。量子化によって答えの選択における不確実性が増大したことを示唆しています。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_68518_5-1024x697.png)

### 確信度変化の大きなケース

下の図は、HELLASWAGタスクにおけるBLOOMとOPTモデルの確信度変化を示しています。量子化前の確信度が低いサンプルほど、量子化による影響が大きいことがわかります。一方、量子化前のモデルが高い確信度を示したサンプルでは、量子化による影響が小さいことが観察されました。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_68518_1.png)

モデル間の分布の差異

また次の図は、量子化前後のモデル間の確信度分布の差異を、Jensen-Shannon距離を用いて示しています。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_68518_4.png)

モデルのスケールが大きくなるほど、量子化前後の分布の差異が小さくなる傾向が見られました。この傾向は、LLaMAを除くすべてのモデルファミリーで一貫して観察されました。LLaMAは、同程度のスケールの他のモデルとは異なる振る舞いを示しました。

実験結果の全体から、量子化がLLMの性能に与える影響が、モデルファミリーやスケールによって異なることがわかります。また、量子化前のモデルの確信度が低いサンプルほど、量子化による影響を受けやすいことが明らかになっています。

結論を改めてまとめると以下になります。

1. 量子化後のモデルは、量子化前と比べてキャリブレーション誤差が増大し、予測の信頼性が低下する。
2. 量子化後のモデルは、正解ラベルに対する確信度が統計的に有意に低下する。
3. 量子化による性能変化の度合いは、モデルのファミリー（BLOOM, OPT, Mistral, LLaMAなど）やスケール（パラメータ数）によって異なる。
4. 量子化前のモデルの確信度が低いサンプルほど、量子化による影響を受けやすい。

## まとめ

本記事では、LLMの量子化が、モデルの確信度とキャリブレーションに与える影響を調査した研究を紹介しました。研究者らは、量子化後のモデルでキャリブレーション誤差が増大し、正解ラベルに対する確信度が統計的に有意に低下することを明らかにしました。また、量子化による性能変化は、モデルファミリーやスケールによって異なることが示されました。

LLMの量子化は、推論の高速化や省メモリ化に欠かせない技術となっています。本研究で得られた知見を活用することで、LLMの実用性を高めることができるかもしれません。

- URL： [https://arxiv.org/abs/2405.00632](https://arxiv.org/abs/2405.00632)
- GitHub： [https://github.com/upunaprosk/quantized-lm-confidence](https://github.com/upunaprosk/quantized-lm-confidence)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[LLMに対して、「人間には意味が分からない滅茶苦茶な文」でプロンプトを送る手法『LM Babel』](https://ai-data-base.com/archives/68433)

[Apple開発のオープンソースLLM「OpenELM」](https://ai-data-base.com/archives/68614)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)