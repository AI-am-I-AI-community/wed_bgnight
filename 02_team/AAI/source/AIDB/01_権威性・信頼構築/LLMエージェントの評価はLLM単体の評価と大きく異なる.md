---
title: "LLMエージェントの評価はLLM単体の評価と大きく異なる"
source: "https://ai-data-base.com/archives/72074"
author:
  - "[[AIDB Research]]"
published: 2024-07-03
created: 2025-06-13
description: "本記事では、LLMエージェントの評価方法に関する研究を紹介します。LLMエージェントとは、複雑なタスクを自律的に遂行するシステムを指しています。その特性から、LLMエージェントの評価にはLLMの評価とは異なる課題があります。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、LLMエージェントの評価方法に関する研究を紹介します。

LLMエージェントとは、複雑なタスクを自律的に遂行するシステムを指しています。その特性から、LLMエージェントの評価にはLLMの評価とは異なる課題があります。

研究者らは、現在の評価手法の問題点を指摘し、LLMエージェントの能力をより正確に測定するための方法論を提示しています。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_72074-1024x576.jpg)

**参照論文情報**

- タイトル：AI Agents That Matter
- 著者：Sayash Kapoor, Benedikt Stroebl, Zachary S. Siegel, Nitya Nadgir, Arvind Narayanan
- 所属：Princeton University

## 背景

近年、LLMエージェントと呼ばれる「LLMを基盤とした複合的なAIシステム」が注目を集めています。LLM単体よりも高度なタスクをこなすことがその特徴です。例えば、コマンドラインの操作やウェブ上での複雑な作業など、より実践的な課題に取り組めると期待されています。

そんなLLMエージェントの性能を評価するため、様々なベンチマーク（性能評価基準）が開発されてきました。プログラミングやウェブ操作など、多岐にわたる分野でのエージェントの能力を測定します。しかし、既存のベンチマークには以下のような問題点があることが分かってきました。

1. 多くのベンチマークが正確さのみを重視し、計算コストや効率性を考慮していない
2. モデル開発者（研究者）向けの評価基準と、実際のユーザー向けの評価基準が明確に区別されていない
3. 多くのベンチマークでは、適切なテストデータ（ホールドアウトセット）が用意されていない
4. 評価方法が統一されていないため、研究結果の再現が困難になっている

実際の使用場面で役立つLLMエージェントの開発を進めるには、上記の課題をクリアする必要があります。

そこで今回研究者らは、解決策を提示しています。以下で詳しく説明します。

## LLMエージェントの評価はコスト重視

### 精度を追求するとコストがかさむ

LLMを複数回使用し、その結果の多数決を取ることで、モデルの精度が大幅に向上することが分かっています。例えば数学（GSM-8K、MATH）、チェス、一般知識（MMLU）など、様々な分野のベンチマークで効果を示しています。

LLMエージェントが動作する環境で、解答の正誤を即座に確認できる仕組みがある場合、繰り返し挑戦することでさらに顕著な性能向上が見られます。例えば、プログラミングコードを生成するAIシステムであるAlphaCodeの場合、初回の試行（ゼロショット）ではほぼ0%だった [正解率](https://ai-data-base.com/archives/25930 "正解率") が、1,000回の再試行で15%以上、100万回の再試行で30%以上に達しました。

上記のように、計算リソースを増やせば増やすほど、理論上は無限に精度を向上させられる可能性があります。中でも、プログラミングコンテストのような環境では、テストケースで解答の正誤を判定できるため、正解が得られるまで何度でも試行できてしまいます。

研究者たちは、プログラミング能力を評価するHumanEvalベンチマークでも同様の現象を確認しました。つまり、試行回数を増やすほど、正解率が向上したのです。

このような状況では、精度だけを追求すると、計算コストが際限なく膨らむ危険性があります。しかし、LLMエージェントの評価では、精度とコストのバランスを考慮することが不可欠です。単純に再試行を繰り返すだけで精度が向上してしまうため、コストを適切に管理した評価が重要になります。

### コストと精度のトレードオフ

精度とコストの関係を明確に理解するためには、パレート曲線という手法が有効です。複数の目標（この場合は精度の最大化とコストの最小化）を同時に最適化する際に用いられる手法です。

研究者たちは、HumanEvalというプログラミング能力評価ベンチマークを用いて、以下の3つのLLMエージェントを評価しました。

1. LDB
2. LATS
3. Reflexion

上記のエージェントは、生成されたコードを実行し、テストに失敗した場合には様々な方法で改善を試みるように設計されています。例えば、デバッグ、別の解決策の探索、失敗の原因分析（「リフレクション」と呼ばれる）などが行われます。

なお比較のため、以下のようなシンプルな手法も評価に含められました。

1. GPT-3.5とGPT-4モデル（追加の処理なしで直接使用）
2. リトライ戦略：テスト失敗時に最大5回まで再試行
3. ウォーミング戦略：リトライと同様だが、徐々にモデルの温度（ランダム性）を上げる
4. エスカレーション戦略：安価なモデルから始め、失敗時により高性能なモデルへ段階的に切り替え

評価の結果、以下のような意外な発見がありました。

1. 最先端と言われるエージェント [アーキテクチャ](https://ai-data-base.com/archives/26562 "アーキテクチャ") は、シンプルなベースライン手法を性能面で上回ることができなかった
2. エージェント間でコストに大きな差が見られ、同程度の精度でも、コストが100倍近く異なる場合もあった。
3. 計画立案、振り返り、デバッグなどの複雑な手法（「システム2アプローチ」と呼ばれる）が性能向上に寄与しているという明確な証拠は見つからなかった

下記で詳しく述べます。

### コストと精度のトレードオフ調査結果と考察

HumanEvalベンチマークにおいては、「最先端」と呼ばれるLLMエージェントの [アーキテクチャ](https://ai-data-base.com/archives/26562 "アーキテクチャ") はシンプルなベースライン手法を上回りませんでした。研究者らが導入した「ウォーミング戦略」と呼ばれるシンプルな手法が、最も高性能なエージェント [アーキテクチャ](https://ai-data-base.com/archives/26562 "アーキテクチャ") と同等の精度を達成しました。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_72074_1.png)

シンプルなベースラインが最先端のエージェントよりもパレート改善を提供していることを示す図

さらに注目すべき点として、これまでの研究では、研究者らが提案した最後の3つのシンプルなベースライン（リトライ、ウォーミング、エスカレーション）とエージェント [アーキテクチャ](https://ai-data-base.com/archives/26562 "アーキテクチャ") を比較した例が見当たらないことが指摘されています。

またエージェント間で、コストに大きな差が見られました。同程度の精度を達成しているにもかかわらず、コストが最大で100倍近く異なるケースが観察されました。しかし手法を提案している論文では、実行コストが主要な評価指標として報告されていませんでした。

例えば、ReflexionとLDBは「ウォーミング戦略」よりも50%以上コストがかかり、LATSに至っては50倍以上のコストがかかることが示されました。コストの大部分はGPT-4の呼び出しによるものであり、モデルのコストが変動しても、これらの比率は安定していると考えられます。

一方で、「エスカレーション戦略」は、LDB（GPT-3.5）よりも精度が高く、コストは半分以下であることが明らかになりました。

これまでの研究では、シンプルなベースラインとの比較が十分に行われていなかったため、計画立案、振り返り、デバッグなどの複雑な手法（「システム2アプローチ」と呼ばれる）が性能向上に寄与しているという誤った認識が広まっていましたが、実はコード生成におけるシステム2アプローチの有用性には疑問が残るということですね。

ただし、研究者らは、HumanEvalよりも難しいプログラミングタスク（例：SWE-bench）では、システム2技術が有用である可能性も示唆しています。

しかし全体を通して言えることは、要するにLLMエージェントの評価においてコストの観点は非常に重要であるということです。再試行のような科学的意義の低い方法でも精度が向上してしまうため、精度だけでは技術の良し悪しを正確に把握できません。

## コストと精度を両方最適化する方法論

今回研究者らは、LLMエージェントの性能評価において、精度とコストを同時に最適化する新しいアプローチを提案しています。

1. DSPyフレームワークを修正して、精度とコストの同時最適化を可能にする
2. HotpotQAのトレーニングセットから100サンプルをランダムに選択し、最適化用データセットとする
3. 残りの50サンプルを開発セット（検証用）として使用する
4. トレーニングセットの半分（50サンプル）を使用して、成功予測を生成するフューショット例の候補を収集する
5. Optunaライブラリを使用して、精度の最大化とプロンプトトークン数の最小化を同時に行うパラメータ探索を実装する
6. パラメータ探索では、以下の要素を最適化する
	- a) エージェントパイプライン内の各モジュールの温度
	- b) フューショット例の数
	- c) 特定の例の選択
	- d) フォーマット指示を追加するかどうか
7. Optunaが16回の試行を行い、パレート最適なエージェント設計を探索する
8. 開発セットで最高の精度を示したプログラムを、同時最適化モデルとして選択する
9. 選択されたモデルをテストセット（200サンプル）で評価し、精度とコストを測定する
10. GPT-3.5とLlama-3-70Bの両方のモデルでこのプロセスを繰り返す
11. 結果を従来のDSPy実装と比較し、精度とコストのトレードオフを分析する

また、パレート曲線（複数の目標を同時に最適化する手法）を用いて精度とコストの関係を視覚化します。

### 固定コストと変動コスト

LLMエージェントの運用コストは、固定コストと変動コストに分けられます。

固定コストは、エージェントの設定（温度やプロンプトなど）を最適化する際に一度だけ発生します。

一方、変動コストはエージェントが実行されるたびに発生し、処理するテキストの量に応じて変動します。エージェントの使用頻度が増えるほど、変動コストの影響が大きくなります。

同時最適化アプローチにより、上記二つのコストのバランスを調整することができます。初期の最適化に多くのリソースを投資することで、長期的には変動コストを削減できます。例えば、より効果的な例示（フューショット）を見つけることで、精度を維持しながらコストを抑えられます。

### 評価実験のセットアップ

本手法の有効性を示すため、DSPy（大規模言語モデルを使用したタスク自動化のためのフレームワーク）が修正され、HotpotQA（複数の文書から情報を統合して回答する質問応答タスク）ベンチマークで評価されました。

評価では、5つの異なるエージェント設計が比較されました。

1. 最適化なしのベースラインモデル
2. 出力フォーマットの指示を追加したモデル
3. 効果的な例示を含むモデル
4. ランダム検索最適化を使用したモデル
5. 精度とコストを同時に最適化したモデル

情報検索にはColBERTv2という高性能な検索モデルが使用され、エージェントの性能は正解文書の取得率で評価されました。最適化と評価には、HotpotQAのデータセットからそれぞれ100サンプルと200サンプルが無作為に選ばれました。

さらに、GPT-3.5とLlama-3-70Bという二つの異なる言語モデルを用いて評価が行われ、モデル間での比較も可能になりました。

このようにして、精度とコストの同時最適化がLLMエージェントの性能向上にどのように寄与するかが分析されました。

### 実験結果

DSPyの使用は精度を向上させましたが、同時にコストも増加しました。しかし、同時最適化手法を適用することで、このコスト増加が抑制されました。

GPT-3.5モデルでは、同時最適化手法により、従来のDSPy実装と比較して同程度の精度を維持しながら、変動コストが53%削減されました。Llama-3-70Bモデルでも同様に、41%のコスト削減が達成されました。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_72074_2.png)

同時最適化が精度を維持しながらコストを大幅に削減することを示す図

固定コストと変動コストのバランスを調整することを考慮した結果、HotPotQAタスクでは、両モデルとも約1,350回の実行後に、同時最適化モデルの総コストが従来のDSPy実装を下回ることが明らかになりました。

実世界の大規模タスクでは、変動コストが固定コストを大きく上回る傾向があります。LLMエージェントが数百万回使用される場合、変動コストは固定コストの何倍もの規模に達する可能性があります。

なお同時最適化アプローチによる設計の最適化に若干の固定コストがかかりますが、エージェントが数千回使用される場合、その影響は無視できるレベルとなります。

今後、他のタスクや異なるモデルでも同様の最適化手法が適用されることが望ましいとされています。

## モデル評価と下流タスク評価は別

LLMエージェントの評価には、主に2つの異なる目的があると提案されています。「モデル評価」と「下流評価」です。

モデル評価はLLM開発者や研究者が行う科学的な分析であり、下流評価は実際のアプリケーション開発者が製品選択に用いる実用的な評価です。2つの評価目的の違いが十分に認識されていないと、LLMエージェントの実行コスト考慮方法に混乱が生じます。

モデル評価では、時間経過によるコスト変動や、異なるモデル間の公平な比較を考慮して、ドル建てのコストを避ける傾向があります。代わりに、モデルのパラメータ数（モデルの複雑さを示す指標）や学習に使用された計算量などが指標として用いられます。

一方、下流評価では実際のコストが重要な基準となります。モデル評価では避けられていた時間経過によるコスト変動も、下流評価では重要な要素として考慮されます。

しかし、下流評価でコストを測定する際にはいくつかの課題があります。

1. 提供者によって同じモデルの料金が異なる可能性
2. API呼び出しのコストが急に変更される可能性
3. モデル開発者の決定によるコスト変動（例：一括API呼び出しの料金設定）

上記の問題に対処するため、評価結果をカスタマイズ可能にする仕組みが有効です。例えば、ユーザーが自身の使用する提供者の最新価格を入力し、コストと精度のトレードオフを再計算できるインターフェースなど。

モデル評価と下流評価の違いがベンチマーク設計にも影響を与えることが、NovelQAベンチマークの例を通じて示されました。  
NovelQAは、長いコンテキストウィンドウを持つLLMを評価するために設計されたベンチマークで、中身は小説データです。小説の長さは5万語から100万語以上に及び、各小説には5〜100の質問が用意されています。

NovelQAベンチマークは、小説の内容を一度に入力し、全ての質問に一括で回答するという方法でLLMを評価します。モデル評価には適していますが、下流評価ではそうでもありません。実際のユースケースでは、ユーザーは質問を個別に行う可能性が高く、その場合、小説の内容を毎回再処理する必要があります。そのため実際のコストは大幅に増加します。

結論として、モデル評価と下流評価の目的の違いを明確に認識し、それぞれに適した評価方法を採用するのが重要です。中でも下流評価では、実際のコストを考慮することが不可欠です。今後は、評価目的に応じた別個のベンチマーク、もしくはモデル評価ベンチマークの変種を開発することがベストです。

## エージェントのベンチマークに潜むショートカット

ベンチマークにショートカット（近道）が存在すると、実世界での性能を正確に反映しない可能性があります。

ショートカットとはエージェントがベンチマークの特定の特徴やパターンに依存して高いパフォーマンスを発揮することを指します。今回、それは [過学習](https://ai-data-base.com/archives/26427 "過学習") によって起こることが多いと捉えられています。

ショートカットを不可能にすることは、ベンチマーク開発者の責任だと考えられています。個々のエージェントをチェックするよりも、ショートカットを許さないベンチマークを設計する方が容易だからです。

### 過学習

多くのエージェントベンチマークは数百サンプル程度の小規模なものが多く、テストサンプルに直接最適化されてしまう危険性があります。LLM単体の訓練データ汚染よりも深刻な問題とされています。

[過学習](https://ai-data-base.com/archives/26427 "過学習") を防ぐため、適切なホールドアウトセット（テストデータ）が不可欠です。しかし、驚くべきことに、多くのエージェントベンチマークにはホールドアウトセットが含まれていません。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_72074_3-1024x214.png)

一般性のレベルに基づく適切なホールドアウトの概要

[過学習](https://ai-data-base.com/archives/26427 "過学習") の問題は、エージェントの目的や、ベンチマーク作成者が求める一般性のレベルによって異なる形で現れます。今回研究者らは、エージェントの一般性に応じてベンチマークのレベルを次のように分類しました。

1. 分布特異的ベンチマーク  
	特定のタスク（例：米国の小学校レベルの数学問題）に限定され、分布の変化を考慮しない
2. タスク特異的ベンチマーク  
	特定のタスク（例：航空券の予約）に限定されるが、分布の変化を考慮しない
3. ドメイン一般ベンチマーク  
	特定のドメイン（例：ウェブブラウジング）内の任意のタスクを測定する
4. 汎用ベンチマーク  
	異なるドメイン間でのエージェントの精度を測定する

研究者らは、エージェントの一般性のレベルが高いほど、訓練セットとホールドアウトセットの差異を大きくすべきだと提案しています。例えば、ドメイン一般ベンチマークでは、ホールドアウトセットに訓練セットとは異なるタスクを含める必要があります。

### WebArenaベンチマークによるケーススタディ

WebArenaは、ウェブ上でのエージェントの能力を評価するために設計されたベンチマークです。ウェブサイトのナビゲーション、スクロール、適切なウェブ要素の選択など、多様な能力が評価されます。

以下のような様々なウェブサイトのクローンが含まれています。

1. GitLab
2. Reddit
3. Wikipedia
4. OpenStreetMaps
5. Eコマースプラットフォーム
6. コンテンツ管理システム

さらに、計算機とスクラッチパッドという2つのツールも用意されています。

812の異なるタスクが含まれており、ウェブサイトとの対話が求められます。例えば、「ナイアガラの滝から60km以内の運転距離にある米国の国際空港の住所をすべて見つける」や「ニューヨーク市に関連するサブレディットに質問を投稿する」といったタスクが設定されています。

ただしWebArenaはいくつかの課題も指摘されています。

1. ウェブサイトの変更に対するエージェントの頑健性を評価することが難しい
2. 未知のタスクに対するエージェントの性能を評価するためのテストセットが用意されていない

#### STeP エージェントの分析

WebArenaのリーダーボードで首位を占めるSTeP エージェントの性能が分析されました。このエージェントは35.8%の精度を示し、次点のエージェントを10ポイント以上上回っています。

分析の結果、STeP エージェントがWebArenaに含まれる特定のタスクを解決するためのポリシーをハードコードしていることが明らかになりました。例えば、Redditのユーザープロフィールに移動するタスクでは、現在のベースURLに ‘/user/user\_name’ を追加するという固定的な方法が使用されています。

このアプローチには以下のような問題があります。

1. ウェブサイトのURL構造が変更された場合、エージェントが機能しなくなる可能性がある
2. WebArena以外のタスクに対応できない可能性が高い

上記のケーススタディからは、現在のエージェントベンチマークには改善の余地があることが示唆されます。

### ヒューマンインザループ

LLMエージェントが任務を遂行する際の人間の関与の度合いは、エージェントの性能評価において重要な要素です。

データ分析タスクを例に、人間の関与の度合いを整理してみます。

1. 最小限の関与  
	チャットボットを使ってデバッグなどの補助的なタスクを行う
2. 中程度の関与  
	エージェントにデータ可視化のコードを書かせ、実行させる。人間は結果が明らかにおかしい場合のみ介入する
3. 最大限の関与  
	データセットと課題（例：不動産データベースを使用してプール所有が物件価値に与える影響を特定する）を与え、因果推論の方法を含むすべての側面でエージェントに完全な自律性を与える

現在の（人間の関与の度合いに対する）評価方法は主に2つの極端なケースに焦点を当てています。

1. チャットボットが質問に正確に答える能力の評価（例：MMLU）
2. エージェントが監督なしでタスクを実行する能力の評価

しかし、人々が実際にチャットボットやエージェントをどのように使用しているかには着目されていません。これが問題だと考えられています。

実際の使用では、以下のようなシナリオが考えられます。

1. ユーザーがチャットボットを正解に導く
2. 出力の問題点についてフィードバックを与える
3. 出力の一部の変更を要求する

また、エージェントが行動を起こす能力を持っていても、重要な行動には人間の確認が必要な場合もあります。

人間のフィードバックがエージェントの性能を大幅に向上させる可能性があります。例えば、Shiらの研究では、簡単なフィードバックによってGPT-4の性能が0%から86%以上に向上したことが報告されています。

裏を返せば、人間を介在させない評価方法では、エージェントの有用性を過小評価している可能性があります。

一方で、人間介在型の評価には以下のような課題があります。

1. コストがかかる
2. 実装が複雑
3. エージェントの精度が、システムだけでなく人間のスキルレベルにも依存する

何はともあれ、現状は人間介在型の評価は今後の重要な研究方向性とされています。

## 再現性を保証したい

LLMエージェントの評価において、再現性の欠如は大きな問題として浮き彫りになっています。

再現性とは、論文に付随するコードとデータを用いて、報告された結果を再現できることを指します。再現性が保証されないと、そのエージェントが本当に優れたものなのか見かけだおしなのか判別できません。

再現性の欠如は以下のような影響をもたらします。

1. 下流の開発者が実世界のアプリケーションにエージェントを採用する際の判断を誤らせる可能性がある
2. 最先端の結果に基づいて研究を進めようとする研究者に多大な時間的コストを強いる

今回、再現性欠如の根本原因として5つの要因が挙げられています。すべて、LLM評価とエージェント評価の違いに起因します。

**（１）エージェント設計に関する評価スクリプトの前提条件**

多くのエージェントに適用できない前提が置かれています。例えば、評価スクリプトが特定のエージェント設計を想定しており、他のエージェントに適用できない場合があります。

**（２）LLM評価ベンチマークのエージェント評価への転用**

ベンチマークの設計変更が必要となる場合があります。実際にHumanEvalベンチマークでは、一部の問題に例示用テストケースが含まれていないため、エージェント評価に適していません。

**（３）エージェント評価の高コスト**

試行回数が限られてしまうので信頼区間の推定が困難です。例えば、SWE-benchの評価では、1回の評価に8,000ドル以上かかる可能性があり、複数回の実行が困難となります。

**（４）外部要因への依存**

ウェブやコマンドラインなど、動的な環境との相互作用が評価に影響を与えます。WebArenaベンチマークでは、Redditサイトのレート制限が評価結果に影響を与える事例が報告されています。

**（５）標準化された評価の欠如**

エージェントの実装や評価には微妙なバグが混入する可能性があります。LATSやSTePエージェントの評価では、一部のタスクが誤って正解と判定されていた事例が確認されました。

上記の問題は、エージェント評価に関する明確な基準が確立されていないことに起因しています。LLM評価では、HELMやLM Evaluation Harnessなどの標準化されたフレームワークが存在しますが、LLMエージェントの評価には同様のフレームワークが存在しません。

そのためエージェント評価フレームワークの開発が、今後の重要な課題として挙げられます。以下の要素が必要になります。

1. 様々なエージェント設計に対応できる柔軟性
2. エージェント特有の評価要素（環境との相互作用など）の考慮
3. コスト効率の良い評価方法の提案
4. 再現性を確保するための標準化されたプロトコル

## まとめ

本記事では、LLMエージェントのベンチマーキングに関する研究を紹介しました。現在の評価手法の問題点を指摘し、改善策を提案しています。

主な課題として、コスト制御の欠如、評価目的の混同、ベンチマーク設計の不備、人間の関与の無視、再現性の欠如が挙げられました。

課題に対しては、コスト制御された比較、評価目的の明確化、適切なホールドアウトセットの使用、評価の標準化が提案されています。実際に精度とコストの同時最適化アプローチの有効性が実証されました。

企業や組織がLLMエージェントを導入する際のヒントになるかもしれません。

※なお論文の原文ではLLMエージェントではなくAIエージェントと表記されていましたが、内容としては一貫してLLMベースのエージェントシステムを指していたため、本記事ではLLMエージェントと表記し直しています。

- 参照論文URL： [https://arxiv.org/abs/2407.01502](https://arxiv.org/abs/2407.01502)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[LLMの小規模化と高性能化を両立させた『Gemma 2』Google DeepMindが発表](https://ai-data-base.com/archives/71982)

[RAGシステムの最適な構築を探る](https://ai-data-base.com/archives/72121)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)