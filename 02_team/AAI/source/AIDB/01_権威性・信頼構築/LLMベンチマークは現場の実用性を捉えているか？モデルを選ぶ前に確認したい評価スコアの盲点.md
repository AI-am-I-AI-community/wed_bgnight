---
title: "LLMベンチマークは現場の実用性を捉えているか？モデルを選ぶ前に確認したい評価スコアの盲点"
source: "https://ai-data-base.com/archives/89851"
author:
  - "[[AIDB Research]]"
published: 2025-05-22
created: 2025-06-13
description: "本記事では、LLMの実利用とベンチマーク評価の間にあるズレに注目した研究を紹介します。評価指標の多くは技術系タスクを前提に設計されていますが、実際の業務ではもっと多様な使い方がされています。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、LLMの実利用とベンチマーク評価の間にあるズレに注目した研究を紹介します。評価指標の多くは技術系タスクを前提に設計されていますが、実際の業務ではもっと多様な使い方がされています。

調査では、よく使われるタスクの傾向や、既存ベンチマークが対応できていない能力が整理されています。  
LLMを導入・活用する立場から、評価スコアを見る際の観点を少し見直すきっかけになるかもしれません。

![](https://ai-data-base.com/wp-content/uploads/2025/05/AIDB_89851-1024x576.png)

## 背景

生成AIが業務に浸透するにつれ、その性能評価にも実務目線の視点が求められるようになってきました。いま多くの企業が、LLMを単なる技術検証の対象としてではなく、文章作成や情報整理といった日常業務の支援ツールとして活用し始めています。そうした現場の利用実態と、既存のベンチマーク評価のあいだには、見過ごせないギャップが生じています。

現在広く使われている評価の多くは、コード生成や知識の想起などの限定的なタスクに基づいており、実際の職場で期待されている支援とはかけ離れた設計になっています。たとえば、LLMを活用して文書を読みやすく整えたり、要点をまとめたり、引用形式を整えたりといった場面は評価の対象外になっていることが多く、こうしたズレがモデル選定や導入後の期待値に影響を及ぼしている可能性があります。

モデル自体の進化もまた、評価との乖離を広げています。最先端であると大きく打ち出されたモデルも、その主張はあいまいな言い回しや断片的な引用に依存しており、確たる根拠に乏しいことは往々にしてあります。同様に、コーディング能力や言語翻訳など、特定のタスクでのスコアを根拠に性能をアピールしているモデルも多い状況です。

今の評価方法にはいくつかの懸念があります。実務にどれほど関係があるかが曖昧なうえ、統計的な信頼性や敵対的入力への耐性、事実よりも流暢さを優先する傾向、さらには自動評価指標の限界などが指摘されています。非公開のデータや基準に基づく評価も多く、透明性の点でも課題が残ります。

最新のLLMは、人間の指向に沿った出力を目指して調整されており、有用性や真実性、無害性の観点が強く意識されています。ところが、それを測るベンチマークは依然としてMMLUやAIMEといった学術的・抽象的な問題に偏っており、日常的な業務タスクでの有用性を直接示すものではありません。

また、テキスト生成AIは会話形式の応答を基本としています。プロンプトに応じて返す応答の流れは、指示の意図をくみ取り、ユーザーと対話しながら作業を進めるという、実際の利用に即したスタイルです。この点においても、現在の評価指標は十分に対話の文脈ややり取りの柔軟性を反映できているとは言いがたい状況です。

こうした課題を踏まえ、研究者たちは「LLMが実際に何をどのように支援しているか」を捉え直し、人間中心の観点から現実的な利用能力を測る新たな評価枠組みの構築を試みました。その出発点となったのが、「ユーザーが日常業務でどのようにLLMを使っているのか」という問いです。

以下で全貌を詳しく紹介します。

## 調査方法

LLMが実際の業務でどう使われているのかを理解するには、ただ理論を語るだけでは不十分です。今回研究者らは、実際の働く現場の声と、リアルな利用データの両方を使って、LLMがどのような能力を発揮しているかを調べました。

### 業務タスクの整理と分類

まずは、LLMがどのような業務をサポートしているのかを把握するために、18,000人以上のデンマークの労働者を対象にした調査データを活用しました。このデータは、LLMを使うことで特定の業務がどれくらい効率化されるかを測るために使われています。

分析には、OpenAIの”E1（直接的露出）”という指標の改良版を使いました。これは、ChatGPTを使うことで、その業務の完了時間が半分以下になるかどうかを評価するもので、効率化の度合いを可視化できます。

タスクの評価は、LLMによる生成と人間による検証のハイブリッド形式で行われました。米国O\*NETの職務タスクデータベースから、各職種で重要な業務タスクを選び出し、最終的に11の職種から21の代表的なタスクを抽出しました。

これらのタスクをもとに、LLMがどんな認知的なプロセスを担っているかを分析し、最終的に6つの能力に分類しました。分類は、複数の研究者が意見を出し合い、業務の性質や成果物の違いに注目しながらまとめられました。実務に即した、重なりのある柔軟な分類が意識されています。

### 利用ログを使った裏付け

次に、分類した6つの能力が実際の使われ方と一致しているかを確認するために、Claude.aiの利用ログを分析しました。対象となったのは、400万件以上のプロンプトです。

これらのプロンプトは、O\*NETで定義された業務タスクとマッチングされ、どの職種でどんなLLMの使われ方がされているのかが整理されました。結果として、合計35,000件以上のユニークなタスクが抽出されています。

中でも、よく使われている上位100のタスクに注目しました。これらのタスクだけで、全体の利用の半分以上を占めていたためです。

各タスクは、6つの能力のどれに当てはまるかを人手で確認し、複数の能力にまたがるものも丁寧に分類しています。

### 実際のプロンプトをもとにした例の設計

各能力がどのような業務で使われているのかをわかりやすくするために、具体的なプロンプト例も作成しました。たとえば、要約に関する能力であれば、「このレポートを300文字で要点だけまとめて」といった実際にありそうな依頼内容が含まれています。

プロンプト例を作ったのには、次のような目的があります。

- 能力と業務が現実の使われ方に沿っているかを確認する
- 職務タスクとLLM入力の橋渡しをわかりやすくする

この設計によって、抽象的な分類だけではなく、実際にユーザーがどうLLMを使っているのかがよりリアルに伝わります。

### 利用頻度をもとに能力の重要度を算出

各能力がどれだけ使われているかを知るために、上位100タスクの中でそれぞれの能力がどれだけ登場したかを数え上げました。単にタスクの種類ではなく、実際の利用の中での重みを可視化するためです。

棒グラフにまとめることで、どの能力がどれだけ使われているかがひと目でわかるようになっています。

### 現在の評価指標の整理

最後に、既存のLLM評価ベンチマークが、6つの能力に対してどれだけ対応できているかを分析しました。あわせて、どんな観点で評価されているかも整理しています。

評価の軸として採用されたのは以下の5つです。

- 一貫性（自然なやりとりになっているか）
- 正確性（内容が事実に基づいているか）
- 明確性（出力がわかりやすく、構造が整理されているか）
- 関連性（実務でよくあるタスクと重なっているか）
- 効率性（時間や手間をどれだけ省けるか）

こうした軸をもとに、各能力と既存ベンチマークとの整合性を確認しています。

### 評価対象とされた主なモデル

本研究では、能力ごとの評価にあたって以下の主要なLLMが対象とされました。

- GPT-4、GPT-4o、GPT-4.1、GPT-4.5（OpenAI）
- Gemini 2.5（Google DeepMind）
- DeepSeek V3、DeepSeek-R1（DeepSeek-AI）
- Grok 3（xAI）
- Qwen2.5-Max、Qwen 3（Alibaba）
- LLaMA 4（Meta AI）
- Claude 3.5 Sonnet、Claude 3.7 Sonnet（Anthropic）

モデルを横断的に分析することで、LLMの能力と、評価との対応・ギャップをより明確にすることを目指しました。

## 調査結果

LLMが実際にどんな業務でどのように使われているのか、そして今使われている評価指標がそれをどれだけカバーできているのか。ここでは、その実態とギャップを整理していきます。

まず、Claude.aiの利用ログ400万件超を分析したところ、タスクの使われ方には大きな偏りがあることがわかりました。上位100種類のタスクだけで全体の50%以上、上位500まで広げると約80%を占めていました。LLMはさまざまなタスクに応用できる一方、実際にはよく使われる定番の用途に集中しているということです。

![](https://ai-data-base.com/wp-content/uploads/2025/05/AIDB_89851_1.png)

Claude.aiの利用ログを分析した結果。上位100の職業タスクだけで全体のプロンプトの50%以上を占めており、使用が一部のタスクに集中していることが示された

### 業務でよく使われていた6つの能力

この分析では、実際の業務でLLMが頻繁に活用されていた6つの能力が浮かび上がりました。

- 要約
- 技術支援
- 作業レビュー
- データ構造化
- 生成
- 情報検索

それぞれの能力には異なる役割があります。情報検索は事実を探す支援、生成は文章や内容を新たに作る支援。要約やレビューは内容を整理したり、品質をチェックしたりする場面で活躍します。

![](https://ai-data-base.com/wp-content/uploads/2025/05/AIDB_89851_2-1024x617.png)

6つのLLM能力と評価基準との対応を整理し、客観評価と主観評価の両面から現実の業務タスクにおける性能の複雑さを捉える枠組み

とくに特徴的だったのは、こうした能力の多くが1つのタスクに重なって現れている点です。たとえば「ソフトウェアの修正」タスクでは、技術支援と作業レビューの両方の能力が求められていました。

上位100タスクについて、それぞれどの能力に関連していたかを集計したところ、次のような割合になりました。

- 技術支援（65.1%）
- 作業レビュー（58.9%）
- 生成（25.5%）
- 情報検索（16.6%）
- 要約（16.6%）
- データ構造化（4.0%）

この分布から見えてくるのは、LLMが「考えて整理する」「診断して手直しする」といった、思考と判断を伴うタスクに多く使われているという点です。一方、表の整形や定型文のフォーマットといった作業はそこまで目立っていません。

![](https://ai-data-base.com/wp-content/uploads/2025/05/AIDB_89851_3.png)

上位100の職業タスクにおいて各LLM能力がどれだけ関連しているかの割合。実際によく使われている能力の分布

### 評価指標がカバーしていた能力

続いて、現在広く使われているベンチマークが、この6つの能力のうちどこまでを評価できているのかを調べました。

明確にベンチマークが紐づいていたのは次の4つの能力です。

- 情報検索に使われているのはMMLU、AGIEval English、SimpleQA
- 技術支援に使われているのはSWE-bench、HumanEval、WebDev Arena
- 要約に使われているのはMRCR
- 生成に使われているのはChatbot Arena Creative Writing、Writin [gB](https://ai-data-base.com/archives/26343 "勾配ブースティング") ench

逆に、作業レビューやデータ構造化といった業務上重要な能力については、汎用ベンチマークとの対応が見られませんでした。これは評価の範囲そのものに偏りがあることを意味しています。

### 評価できている能力と現実とのズレ

ベンチマークがどれくらい実際の使われ方に合っているのかも検証されています。

#### 技術支援

WebDev Arenaは、実際のWeb開発に近い自然なプロンプトを使い、人間の投票で評価されています。現実の業務に近い文脈で、LLMの役立ち方が評価されています。

#### 情報検索

SimpleQAは、多肢選択ではなく短い質問と回答の形式を採用しており、実際の対話に近いスタイルになっています。事実性の高さと一貫性をバランスよく評価できる指標です。

#### 要約

MRCRは、長文から必要な要素を抜き出して再構成する力に焦点を当てています。ビジネス文書の要約など、実務に即したタスクとの親和性が高いベンチマークです。

#### 生成

Chatbot Arenaでは、人間の好みによる評価を通じて創作の質を測っています。自由度の高い表現を扱える一方で、Writin [gB](https://ai-data-base.com/archives/26343 "勾配ブースティング") enchのような構造化されたベンチマークと組み合わせることで、用途に応じた評価が可能になります。

### 評価されていない能力とその重要性

一方、作業レビューとデータ構造化には、広く使われているベンチマークがありませんでした。

この2つは、実際の利用頻度こそ高くないかもしれませんが、職場での「使いやすさ」「整っている感じ」「手間が減った感覚」などに深く関わってくる能力です。にもかかわらず、現状では定量的に比較する手段が用意されていないのが実情です。

このギャップは、ベンチマークがどこを重視し、どこを見落としているかを浮き彫りにしています。

### モデルごとの能力傾向

モデルごとの評価結果を見ると、能力の得意・不得意にも差が見られました。

- Gemini 2.5は要約、生成、技術支援のいずれでもトップクラスのスコアを記録
- Claude（Anthropic）は要約と技術支援の分野で安定した高評価を獲得

こうした傾向は、単なる総合スコアよりも参考になります。実際の業務で求められる能力と、モデルごとの得意分野が合っているかを見ながら選定することで、導入の納得感も高まります。

### 評価と実利用のギャップ

全体として明らかになったのは、現在の評価指標ではLLMの利用実態を完全にはカバーできていないということです。

- 作業レビューとデータ構造化に対応するベンチマークが存在しない
- 要約と生成も、対応するベンチマークは限られている
- 評価全体が技術寄りで、非エンジニアの使い方が反映されにくい

こうしたズレは、モデル開発側にとっても、ユーザーにとっても、LLMの真価を適切に把握するうえで障害になります。

今後の評価設計では、こうした実利用に寄り添った視点が必要です。

![](https://ai-data-base.com/wp-content/uploads/2025/05/AIDB_89851_4-1024x677.png)

4つのLLM能力（技術支援、情報検索、要約、生成）における各社の代表モデルの評価結果。タスクごとの強みとモデル間の性能差

## 考察

結果とインサイトをまとめると以下のようになります。

### 評価指標と実利用のギャップ

いま使われているLLMの評価方法には、実際の使われ方とのズレが残っています。多くのベンチマークは、コード生成や数式処理、知識の正確な再現といった、比較的かっちりしたタスクに偏っています。しかし、ユーザーがLLMに頼る場面はそれだけではありません。

実際には、文章の下書きづくりや要点の整理、文体の調整、アイデア出しといった、もっと自由度の高い、共同作業に近い使い方が中心になっています。こうした使い方をきちんと評価するには、ベンチマークのほうが変わる必要があります。

### 評価が技術よりに寄っている理由

現状のベンチマークが技術系タスクに寄っているのは、設計の出発点に開発者視点があるためです。Pythonでのコーディングなどが主な評価対象になっていて、医療や教育、ビジネス現場での文章作成や整理のようなタスクは後回しにされがちです。

加えて、評価に使われるプロンプトも、開発者の書くものが多く含まれていて、日常的な対話や複数回にわたるやりとりといった実務の使われ方はあまり反映されていません。

### 人間の視点が抜けたままになっている

多くのベンチマークでは、自動で採点できることが重視されています。これは拡張性の面では便利ですが、人間が気づくような「微妙なズレ」や「文脈による違和感」などが評価から抜け落ちてしまいます。

たとえば、文章のトーンが硬すぎる、表現がまわりくどい、読み手によって意味が変わるといった部分は、人が実際に読まなければ気づけません。そうした要素を拾い上げるには、少人数の評価でもいいので、人間のレビューを取り入れる工夫が必要です。

### 評価から漏れている能力も多い

今回の分析では、LLMの能力として（繰り返しになりますが）次の6つが挙げられました。

- 要約
- 技術支援
- 作業レビュー
- データ構造化
- 生成
- 情報検索

ところが、現在のベンチマークできちんと評価できているのは、要約・技術支援・生成・情報検索の4つだけです。

たとえば、文書の表現や構成を調整する「作業レビュー」は、仕事の中ではかなり頻繁に使われているのに、対応する評価指標がありません。同様に、表や書式を整える「データ構造化」も無視されています。

こうした能力がベンチマークで測れない状態では、ユーザーはモデルを正しく比較できず、ベンダーも強みを正当に示せません。

### 評価軸そのものに偏りがある

既存のベンチマークには、いくつか共通する見落としがあります。

- Pythonなど一部の言語やツールに偏っている
- 作業がどれだけ早く楽になったかを測っていない
- 出力が人にとって理解しやすいかを見ていない

モデルが正しい答えを出すかどうかだけでなく、それが「人にとって役立つかどうか」を見る視点が必要です。

### 能力ごとの評価スイートが必要

こうした問題をふまえて、6つの能力ごとに評価スイートを作ることが提案されています。評価の基準としては、こちらも繰り返しになりますが次の5つが挙げられます。

- 一貫性（実際のやりとりに近いか）
- 正確性（内容の正しさがあるか）
- 明確性（読みやすさや構造のわかりやすさ）
- 関連性（実務でよくあるか）
- 効率性（時間や手間が減るか）

主観的な判断が必要な場面では、人間の評価を取り入れることが前提です。規模は小さくても、質の高い評価軸をつくることのほうが重要です。

### リーダーボードの数字だけでは見えてこない

最新のLLMは、わずかなスコア差を根拠に「最も強い」とされることがあります。しかし、その数字は実際の差を表しているとは限りません。モデルの調整次第で動く部分もあり、評価条件が公開されていないケースもあります。

クラウドソース型の評価（たとえばChatbot Arena）は、こうした問題に対するひとつの解決策ではありますが、それでもプロンプトや評価者の情報が見えないなど、透明性には課題が残っています。

また、実際の業務のような「複数回のやりとり」や「再修正を含むプロセス」は、今の評価ではほとんど無視されています。

今後は、対話の流れや文脈への対応、繰り返しの修正など、より実務に近い形での評価設計が必要になります。

### 今後に向けた展望

ユーザーがLLMに期待しているのは、正解を当てることではなく、仕事をスムーズに進めることです。にもかかわらず、現状のベンチマークはその期待を測れていません。

今回の研究は、実際の使用ログやベンチマークの中身をつきあわせながら、そのギャップを明らかにしました。ただし、プロンプトの分類が正確かどうか、非公開の評価手法が別の基準で運用されていないかなど、今後さらに確認が必要な点もあります。

今後は、各能力に合った評価スイートをつくり、人間による判断も組み込みながら、現場の使われ方に即した、再現性ある基準を整えていくことが求められます。

## まとめ

本記事では、LLMの活用実態と評価ベンチマークの関係を分析した研究を紹介しました。

ユーザーが実際にLLMをどのような業務で使っているかを整理し、それに対する評価の偏りも可視化されています。

現場でよく使われている作業レビューや構造化支援などが評価から漏れている点は、見逃せないポイントです。こうしたギャップは、LLMを選ぶ際の判断基準が、実務とずれている可能性を示唆しています。

自分たちのユースケースに照らして、どの能力を重視すべきかを見直すヒントになるかもしれません。

**参照文献情報**

- タイトル：Evaluating LLM Metrics Through Real-World Capabilities
- URL： [https://doi.org/10.48550/arXiv.2505.08253](https://doi.org/10.48550/arXiv.2505.08253)
- 著者：Justin K Miller, Wenjia Tang
- 所属：University of Sydney

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[自然言語での曖昧なリクエストが「LLMのコード生成性能に与える影響」とLLMが誤解しないよう修正するアプローチ](https://ai-data-base.com/archives/89804)

[いまだ対策が求められる幻覚（ハルシネーション）　プロンプト手法とRAGの組み合わせでLLMの事実性を守る](https://ai-data-base.com/archives/88124)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)