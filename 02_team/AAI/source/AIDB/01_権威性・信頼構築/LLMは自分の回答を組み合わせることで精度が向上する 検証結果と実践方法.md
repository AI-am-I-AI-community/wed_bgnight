---
title: "LLMは自分の回答を組み合わせることで精度が向上する 検証結果と実践方法"
source: "https://ai-data-base.com/archives/86593"
author:
  - "[[AIDB Research]]"
published: 2025-03-11
created: 2025-06-13
description: "本記事では、LLMが自分自身で生成した複数の回答をうまく組み合わせることで、回答の精度が高まるという興味深い研究を紹介します。一般的には一度の質問に一つの回答を生成するといった使い方がされています。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、LLMが自分自身で生成した複数の回答をうまく組み合わせることで、回答の精度が高まるという興味深い研究を紹介します。

一般的には一度の質問に一つの回答を生成するといった使い方がされています。しかしそれでは複雑な問題に対して不十分な場合があります。

そこで今回は、LLMが複数の回答を生成し、それらを活用してより質の高い回答を生み出す方法と、その効果について詳しく紹介していきます。

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_86593-1024x576.png)

参照論文情報は記事の下部に記載されています。

## 背景

LLMが複雑な問題を解く際には、しばしば複数の手順や深い思考が求められます。しかし通常の方法で単純に質問を入力するだけでは、正確な答えにたどり着けない場合も少なくありません。

そのため、モデル自身に回答を評価させる「自己修正」と呼ばれる方法や、「複数の候補から最適なものを選ぶ」方法が提案されてきました。しかし最近の研究では、これらの方法があまり効果的でないことが明らかになってきました。

その原因として、LLMが学習の過程で「自らの回答を正しく評価し比較する能力」、いわゆる「識別的判断力」を十分に身につけていないという根本的な問題があると指摘されています。この判断力を向上させるためには、特別な追加学習が必要と考えられています。

また、既存の手法の中でもう一つ有望視されてきたのが「自己整合性」という手法です。これは、LLMが生成した複数の回答から多数決で最も多い回答を選ぶことで [正解率](https://ai-data-base.com/archives/25930 "正解率") を向上させる方法です。しかし回答が明確に定まらない自由記述型の問題には適用が難しく、汎用性に欠けるという問題（限界）があります。

こうした状況を受けて、今回ジョージア工科大学、マイクロソフト、アマゾン、オールバニー大学からの研究者チームは新しい手法の開発に挑みました。外部からのフィードバックや多数決に頼らずに、LLM自身が生成する多様な回答を活用し、それらを統合することで新たな回答を導き出す手法です。

以下で詳しく紹介します。「なんだか難しいな？」と思われる方にとっても、最後まで読めば納得できる内容になっています。

## 提案手法「Generative Self-Aggregation（GSA）」

通常、言語モデルは質問に対して一度に一つの回答を生成しますが、それでは複雑な問題に対して誤った答えを出すことがあります。そこで今回、「一度に一つ」ではなく、「複数の回答」をモデル自身が生成し、その多様な回答群から新たな回答を導き出すことで、品質の高い回答を得る手法が考案されました。

生成された回答をモデル自身が評価したり選択したりする「識別的な判断」を一切行わず、モデルが本来得意としている「文脈を参照して新しい文章を生成する能力」だけを用いて回答品質を改善しする方法です。言い換えると、モデルが苦手な自己評価を避け、得意な生成能力を最大限に活用しようという工夫です。

以下の二段階に分けて進行します。順に説明します。

### 第1段階：多様な回答の生成

最初のステップでは、モデルが一つの質問に対して複数の異なる回答を生成します。

このとき、単に最も確率の高い単語だけを順次選ぶ方法（Greedy decoding）では、一つの回答しか得られません。そこで、モデルからさまざまな観点や推論経路を引き出すために、あえて確率に基づく「ランダム性」を取り入れた回答生成（ [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") ）を行います。

あえてモデルに多様な回答を生成させることが重要となる理由は、複雑な問題において「正解に至る経路」が一つとは限らないからです。

例えば数学問題なら、ある回答は途中までは正しい推論をしているけれど、最後で計算ミスをしてしまうかもしれません。他の回答は違う計算方法で正しい答えに到達するかもしれません。

知識を問う問題でも、モデルが持つ知識の異なる側面がそれぞれの回答に反映されることで、多面的な理解が促される可能性があります。

この多様性こそが、次の段階で新しい回答を生み出す際の重要な材料となります。

この”「ランダム性」を取り入れた回答生成（ [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") ）”の具体的な方法としては、 **「Temperature Sampling」** や **「Nucleus Sampling（Top-p sampling）」** が挙げられています。

**「Temperature Sampling」** とは、モデルが出力する単語の確率分布に対して、「温度」と呼ばれるパラメータを調整して、生成される回答の多様性を制御する方法です。  
温度（Temperature）が低いと（例えば0.2など）、確率の高い単語を強く優先するため、生成される文章は比較的似通ってしまいます。一方、温度を高く設定（例えば1.0以上）すると、より低い確率の単語も積極的に選ばれるため、多様性のある回答が生成されます。ただし、あまり高すぎると文脈に合わない不自然な回答になる可能性もあります。

**「Nucleus Sampling（Top-p sampling）」** は、単語の確率が累積で一定の閾値（たとえば0.95）を超えるまで、確率が高い単語を順に候補として残し、それらの中からランダムに選択します。これにより、あまりにも確率が低い（非現実的な）単語が選ばれるのを防ぎつつ、多様な単語を候補に残すため、現実的でありながらバリエーションに富んだ回答が生成されやすくなります。

これらのパラメーターは、比較的一般的に制御することができるものです。APIを呼び出すコードを自分で作るにしても、AWSなどのクラウドサービスを使うにしても、制御するメニューが用意されています。

実際の作業手順は次のような流れになると推測されます。

1. モデルに問題（質問または指示）を入力する。
2. モデルが各単語について出力する確率分布を得る。
3. Temperature SamplingやNucleus Samplingなどを使って、確率的に次の単語を選ぶ。
4. 選ばれた単語を元に文脈を更新し、再び次の単語を確率的に選ぶ（繰り返し）。
5. このプロセスを回答文が完結するまで繰り返し、一つの回答を完成させる。
6. 以上のステップを繰り返し、複数回異なる回答を生成する（例えば3〜5回程度）。

こうして得られた複数の回答が、「多様な回答」として第2段階（回答統合フェーズ）に活用されます。

### 第2段階：複数回答を活用した”文脈ベース”の回答統合

次のステップでは、前の段階で得られた複数の回答をそのままモデルへの新しい入力（文脈）として活用し、それを基にさらに良質な回答を生成させます。最初の質問とともに、生成された複数の回答をすべて提示して、再度モデルに回答を求めるという方法が取られます。

ここで重要なのは、モデルに「どの回答が正解であるか判断しなさい」と要求するのではなく、「これらの複数の回答を踏まえて、新たな回答を生成しなさい」と指示することです。こうすることで、モデルは自分の得意とする「文脈から次の単語を予測する能力」を活かし、複数の回答に含まれる良質な要素を自然に抽出し統合します。

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_86593_2.png)

第二段階（複数の回答を統合して新たな回答を生成する段階）において、言語モデルに実際に入力するためのプロンプト（指示文）の例

```js
### 問題文：
{query}

### 参考となる回答例：
{diverse_responses}

### 指示：
1. 上記の解答例をよく確認すること。
2. 問題を解決するPython関数を作成すること。
3. 作成した関数について簡潔な説明を添えること。
```

つまり、回答群の中に含まれるそれぞれの回答の「強み」を組み合わせつつ、「弱み」を避けるような、より洗練された回答を生成できる仕組みになっています。

例えば、プログラミング課題に取り組む際、複数のコード回答がそれぞれ異なるアプローチを示しているとします。それらを統合することで、モデルは各回答の良質な部分を選択的に取り入れ、より効率的で正確なコードを新たに生成します。

同様に、数学的な推論課題においても、モデルは回答の「最終的な答え」だけでなく「答えに至る途中の推論プロセス」も文脈として参照できるため、より堅実な論理展開をするよう促されます。

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_86593_1-1024x535.png)

提案手法（GSA）の概要図。LLMが複数の回答を生成し、それらを統合してより良い回答を生成する流れを、数学の問題を例として視覚的に示している

## 実験方法

研究チームは、本手法GSAをさまざまな種類の問題に適用し、その効果を測定しました。その中には数学的な推論を必要とする問題、幅広い知識を問う問題、そして自由に記述する形式の問題（たとえば会話やプログラミング）などが含まれます。

また、GSAがモデルの規模や構造に関わらず有効かどうかを確認するために、性能が異なる複数のLLMを用いています。

### 実験に使用した言語モデル

実験では、性能や特性が異なる4種類のLLMを使用しています。GSAが特定のモデルだけに有効なのか、あるいはさまざまなタイプのモデルにも通用するのかを確認するためです。以下に使用した各モデルを簡単に説明します。

#### Llama 3（8B）

Llama 3はオープンソースとして公開されているモデルで、約15兆の単語（トークン）を使って事前に学習されています。さまざまな分野のベンチマークテスト（性能評価テスト）で高い性能を示しており、現在広く利用されているモデルの一つです。

#### Gemma 2（9B）

Gemma 2は、サイズが中規模（約90億パラメータ）でありながら、効率的に高性能を実現するために知識蒸留（大きなモデルから知識を引き継ぐ手法）を活用したモデルです。約8兆の単語で学習されており、比較的小規模ながら、性能面で工夫が施されています。

#### Qwen 2.5（14B）

Qwen 2.5は、知識に基づく問題や推論力が求められる問題に対する性能が高いとされています。

#### GPT4o mini

GPT4o miniはGPT-4シリーズの一種で、規模を抑えながら推論速度を速め、コストを下げることを目的としています。性能と速度のバランスをとった実用的なモデルとして、幅広い用途で使われています。

### 評価に用いたタスクとデータセット

本手法がどのような問題に対して効果を発揮するのかを幅広く検証するために、異なる種類のタスクやベンチマーク（評価用データセット）を用いています。それぞれ簡単に説明します。

#### 数学的な推論問題

数学的な推論能力の検証においては、Grade School Math 8K（GSM8K）、Math、SVAMPといったデータセットが使用されました。

GSM8Kは小学校レベルの算数の文章題を集めたもので、複数ステップでの計算を要求します。

Mathは代数や幾何、算術など幅広い数学分野を含みます。

SVAMPはモデルの計算や文章題への応用力をさらに厳密に評価するための問題集です。

#### 知識を問う問題

知識の活用能力の評価には、MMLU（Massive Multitask Language Understanding）というデータセットが用いられました。このデータセットは数学から法律まで、非常に幅広い57の分野から構成されます。

ただし、本研究では計算資源の関係で、その中からランダムに10%を選んで評価を行いました。

また、GPQAという大学院レベルの生物学、物理学、化学の専門家によって作成された難易度の高い問題セットも利用されています。

#### 自由記述形式の問題

自由に回答を記述する能の評価には、MT-benchという対話形式での能力を評価するデータセットや、Alpaca Evalという指示に対する従順性を評価するセットが使われました。

また、プログラミング能力を評価するために、Pythonの基礎的な課題を含むMBPP（Mostly Basic Python Problems）も使いました。

### 評価方法とベースライン（比較対象）

研究者たちは、GSAの性能を客観的に評価するため、既存の代表的な手法と比較を行いました。比較対象として、次のような手法を設定しています。

- 「Greedy」：最も確率が高い言葉を単純に選ぶ標準的な方法
- 「Self-Refine」：モデル自身が生成した回答に対して、自らフィードバックを行い修正を繰り返す方法
- 「Self-Consistency」：複数の回答を生成し、多数決によって最も一般的な回答を選ぶ方法
- 「Choose-from-N」：複数の回答からモデル自身に一つを選択させる方法
- 「Best-of-N（Oracle）」：生成された複数の回答の中に一つでも正解があれば成功と見なす理想的な方法（理論上の性能の上限）

なお公平に評価するため、すべての手法に対して同じ計算資源が割り当てられました。

各方法ともモデルの呼び出し回数を同じ4回に設定。また、問題の種類によって、生成する際のパラメータ（温度と呼ばれる多様性調整の設定）を微調整しながら、標準的な評価手法を用いて検証が進められました。

## 主な実験結果

上述の通り、数学的推論や専門知識を問う問題、さらには自由記述型のタスクなど、さまざまな種類の問題に対して検証されました。

その結果、本手法は従来の標準的手法（Greedy）や自己修正型（Self-Refine）、複数回答からの選択型（Choose-from-N）と比較して、多くのケースにおいて提案手法の精度が上回ることが示されました。

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_86593_3-1024x488.png)

複数の言語モデル（Llama 3, GPT 4o mini）に対し、数学問題（GSM8K, MATH, SVAMP）、知識問題（GPQA, MMLU）、自由記述（MT-bench, Alpaca, MBPP）など各種タスクで、GSAと他手法（Greedy, Self-Refine, Self-Consistency, Choose-from-N, Best-of-N）を比較した精度の数値

中でも、GPT4o miniやLlama 3など代表的な言語モデルを用いた評価では、数学的推論（GSM8K、Math）および専門的な知識問題（GPQA、MMLU）において、本手法が既存手法に比べて高い性能を達成することが明らかとなっています。また、GPT4o miniを使用した自由記述型タスク（対話・コード生成）でも同様に、提案手法の有効性が確認されています。

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_86593_4.png)

提案手法と他手法を、生成する回答数を変えながら数学問題（MATH）で比較したグラフ。

一方、従来のChoose-from-Nや自己修正型手法では、状況によっては最も単純なGreedy手法よりも性能が低下するケースが観察されました。このことから、言語モデルに自らの回答を比較・評価させるタスクは必ずしも得意でなく、むしろ複数の回答を参照しながら新たな回答を生成させる方が、モデル本来の能力に適していると考えられます。

さらに、多数決方式（Self-Consistency）との比較では、本手法が数学的推論や知識問題など、明確な答えが存在するタイプの問題でも同等またはそれ以上の性能を示すことが確認されました。加えて、明確な正解が存在しない自由記述型の問題にも柔軟に対応可能であることが示されました。

この柔軟性は、本手法が回答の「内容」や「推論プロセス」そのものを直接参照して生成を行うという仕組みによると考えられます。

また、すべての候補回答が誤っている場合においても、本手法がそれらの一部に含まれる良質な要素を組み合わせて新たに正しい回答を生成するケースも報告されています。この現象は、回答を単純に選択する方式では起こりえないため、本手法がより幅広い状況に適用可能であることを示唆しています。

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_86593_5.png)

Gemma 2, Qwen2.5の各モデルにおけるGSAの性能比較表。数学（GSM8K）、知識（GPQA）、自由記述（MBPP, MT-bench）における各手法の評価を数値化。

### 条件を変えた評価分析

さまざまな条件を設定した評価実験も実施されました。

- 回答の生成数
- [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") 時の温度設定
- 多様性を高めるための回答生成方法（プロンプトの変更、多言語利用など）

を変化させることで、性能の変動が観察されました。

#### 回答生成数の影響

数学推論タスク（MATH）においては、生成する回答数が性能に及ぼす影響が評価されました。その結果、すべての手法は回答数を増やすことで性能向上が見られました。

しかし提案手法の場合、回答数が一定以上（約5個程度）になると性能向上の効果がやや弱まる傾向が確認されました。これは回答数が多くなりすぎると、モデルが大量の情報を処理しきれなくなり、かえって負担が増えるためと考えられます。

一方、多数決方式（Self-Consistency）は回答数の増加に伴って徐々に改善される傾向を示しましたが、選択方式（Choose-from-N）は回答数が多すぎると性能が低下することが確認されました。

これらの結果により、提案手法が比較的少ない回答数でも高い性能を示す柔軟性を持ち、過度な回答数の増加に依存せずとも十分に機能することが示唆されています。

#### サンプリング時の温度設定の影響

回答生成時の多様性を調整する「温度パラメータ」を変更した際の性能変化も検証されました。

その結果、温度が低い場合（約0.2）には生成される回答が互いに類似し、どの手法でも性能改善は限定的でした。

これに対し、温度を中程度（約1.0）まで引き上げ、多様性を適度に高めると、提案手法の性能が著しく改善されました。この時、提案手法はSelf-ConsistencyやChoose-from-Nと比較しても良好な性能を示しています。

しかし、温度をさらに上げすぎる（約1.5以上）と、回答の質が低下して性能も落ちることが確認されています。この結果から、本手法は中程度の多様性を最も効果的に活用していると解釈できます。

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_86593_6.png)

温度（Temperature）の設定を変化させた場合に各手法の性能がどう変化するかを示したグラフ（課題はGSM8KとGPQA、モデルはLlama 3）。

#### 回答生成方法の多様化の影響

プロンプトの変更や多言語での回答生成といった方法を用いて回答の多様性を高める工夫についても実験が行われました。

その結果、標準的な方法（温度調整）に比べて著しい性能向上は観察されませんでしたが、多言語生成を用いた場合にやや性能が向上することが確認されました。

これは、異なる言語で生成された回答がより多様な視点を提供することで、提案手法がそれらを統合する際の情報が増えたためと推測されます。ただし、多言語を用いる方法にはモデル自体の多言語対応が必要となり、モデルによっては活用が難しいことが指摘されています。

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_86593_7.png)

Gemma 2モデルに対して、 サンプリング 方法（Temperature, Promptの変化, 多言語）の違いが性能に与える影響を示した比較表（課題はGSM8K）。

### さらなる詳細分析

本手法が優れた性能を示した理由を明確にするために、生成された回答の「信頼度」に着目した追加分析が行われました。信頼度は、モデルが各回答を生成するときにどれほど自信を持っているかを示す「負の対数尤度（Negative Log-Likelihood: NLL）」という数値を用いて評価されました。

分析の結果、提案手法によって生成された回答群は、モデルに回答を選択させる手法（Choose-from-N）による回答群と比べて、より低いNLL値（つまり、より高い信頼度）を示しました。これは、言語モデルが既存の回答を比較して評価するタスクよりも、複数の回答を文脈として与えられ、それらを参考に新たな回答を生成するタスクのほうが自然に得意であることを示唆しています。

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_86593_8.png)

提案手法（GSA）とChoose-from-N手法で生成した回答の信頼度（NLL）の分布比較図。GSAがより自信度の高い（NLLが低い）回答を生成する傾向を示す。

さらに性能差を詳しく調べるため、回答候補に正解が含まれる数（3つすべて正解、2つ正解、1つのみ正解、すべて不正解）ごとに、提案手法と従来手法の成功率が分析されました。その結果、複数の候補に正解が多く含まれている場合はどちらの手法も高い成功率を示しましたが、正解が一つしかない場合や、候補がすべて不正解の場合には、提案手法の優位性が顕著となりました。

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_86593_9-1024x342.png)

候補回答群の正解数ごとに、GSAとChoose-from-Nの成功・失敗パターンを詳細に分析した棒グラフ（GPQA、MBPP課題で評価）。

提案手法は複数の誤った回答候補からでも部分的な正解要素を抽出して新たに正解を生み出すことが可能であり、一方で回答を選ぶ方式（Choose-from-N）ではそのような成功は原理的に困難であるためです。

この分析を通して、モデルに求める作業を「回答を選ぶ」から「新たに生成する」に切り替えることが、多くの場合で回答品質の向上につながることが明らかになりました。

### ケーススタディ

提案手法がどのように実際に機能しているかを具体的に理解するため、プログラミングの課題と数学の推論課題の事例分析が行われました。

プログラミング課題の例では、複数の回答候補がそれぞれ異なるアプローチを取っていましたが、いずれも完全ではなく、欠点を抱えていました。この状況で提案手法を適用すると、それぞれの回答が持つ良い要素が選択的に統合され、最終的によりシンプルで、しかも正確なプログラムが生成されることが確認されました。

つまり、異なるアイデアやコードの一部をうまく組み合わせることで、どの候補回答よりも質の高い新しい解答が生まれたのです。

数学的な推論課題においても、類似の現象が観察されました。ある問題に対して複数の候補が示されましたが、いくつかの回答は途中まで正しく進んだものの最終段階で計算ミスを起こしていました。

また別の候補は最終的には正解でしたが、途中の計算プロセスが直感的でなく複雑でした。提案手法はこれらの候補回答を踏まえて、より分かりやすく簡潔な計算プロセスを構築し、最終的に正しい答えを提示することに成功しました。

この二つのケーススタディから、提案手法が単なる回答の選択ではなく、多様な候補からそれぞれの強みを抽出し融合する能力を持ち、結果としてより質の高い回答を作り出すことが具体的に示されました。

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_86593_10.png)

GSAの効果を具体例（プログラミング課題および数学課題）で示した図。複数の候補回答からどのように優れた回答を導いたかを具体例として提示。

## まとめ

本記事では、LLMが自分で生成した複数の回答を統合して、より高品質な回答を生成する新しい手法について紹介しました。

本手法は、モデルに自分の回答を評価させるのではなく、複数の回答を参照させて新しい回答を生成させる点に特徴があります。

実験では、数学問題や専門知識を問う問題、自由記述形式の問題など幅広いタスクにおいて、従来の手法を上回る性能を示しています。また、自己評価や多数決に頼らないため、より広い範囲の問題に適用できる柔軟性を持っていることも示されています。

**参照文献情報**

- タイトル：LLMs Can Generate a Better Answer by Aggregating Their Own Responses
- URL： [https://doi.org/10.48550/arXiv.2503.04104](https://doi.org/10.48550/arXiv.2503.04104)
- 著者：Zichong Li, Xinyu Feng, Yuheng Cai, Zixuan Zhang, Tianyi Liu, Chen Liang, Weizhu Chen, Haoyu Wang, Tuo Zhao
- 所属：Georgia Tech, Microsoft Azure, Amazon, University at Albany

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[スマートフォンアプリにおけるLLM活用の開発実態](https://ai-data-base.com/archives/86504)

[外部LLMを利用するときに機密情報を含む可能性のあるプロンプトからの情報漏洩を防ぐ方法](https://ai-data-base.com/archives/86644)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)