---
title: "「o1-preview」は自己評価メカニズムを持つ 計画立案中に自分の行動をチェックして修正"
source: "https://ai-data-base.com/archives/77179"
author:
  - "[[AIDB Research]]"
published: 2024-10-18
created: 2025-06-13
description: "本記事では、OpenAIの最新モデル「o1」の計画立案能力に関する研究を紹介します。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、OpenAIの最新モデル「o1」の計画立案能力に関する研究を紹介します。

従来の研究が計画立案における「単純な成功率」のみに着目していたのに対し、この研究では「実現可能性」、「最適性」、「汎用性」という3つの観点から詳細な評価を行っています。

さらに、タスクの複雑さによる性能変化も調査しており、o1の実世界での応用可能性を探る上で重要な知見を提供しています。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77179-1024x576.jpg)

**参照論文情報**

- タイトル：On The Planning Abilities of OpenAI’s o1 Models: Feasibility, Optimality, and Generalizability
- 著者：Kevin Wang, Junbo Li, Neel P. Bhatt, Yihan Xi, Qiang Liu, Ufuk Topcu, Zhangyang Wang
- 研究機関：テキサス大学オースティン校

## 背景

LLMは様々な推論タスクで驚くべき結果を示していますが、「計画立案」の分野ではその能力がまだ十分に検証されていません。中でもOpenAIが最近発表した「o1モデル」は、数学や コーディングなどの問題解決において大きな進歩を遂げており、計画立案の分野でも同様の可能性を秘めていると期待されています。

これまでの研究では、LLMを使った計画立案の”成功率”のみに焦点が当てられがちでした。しかし、実際の応用を考えると、単に計画を立てられるかどうかだけでなく、その計画の質や汎用性も重要になってきます。

そこで今回テキサス大学の研究者らは、o1モデルの計画立案能力を、以下の3つの観点から詳しく評価することにしました。

1. 与えられた制約条件を守りながら、目標を達成する計画を立てられるか
2. 無駄な手順を省いた効率的な計画を立てられるか
3. 学習していない新しい状況でも適切な計画を立てられるか

このような観点で分析することで、o1モデルの強みと弱みをより明確にし、今後の計画立案システムの改善につながる知見が得られると考えました。

また、単純なタスクから複雑なタスクまで、様々な難易度の問題を用意することで、モデルの性能がタスクの複雑さによってどのように変化するかも調べられています。LLMを実世界の複雑な計画立案問題に応用する際の課題を把握する上で重要なことです。

以下で詳しく紹介します。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77179_1.png)

GPT-4、o1-mini、o1-previewの主要な計画立案の観点における全体的な比較

## 計画能力の評価における3つの視点

冒頭にも説明した通り、本研究ではo1モデルの計画立案能力が、3つの視点から詳しく評価されました。

### 視点１　実行可能性

実行可能性とは、LLMが目標を達成するための有効な計画を立てられるかどうかを評価します。つまり、計画が現実世界の制約の中で実際に実行できるかを見ます。

実行可能性は、さらに3つの要素に分けられます。

1. 各ステップが問題のルールに従っているか
2. 全体の計画が目標達成に向かっているか
3. 初期状態と目標状態を正しく解釈できているか

### 視点２　最適性

最適性は、計画がいかに効率的に目標を達成するかを評価します。単に実行可能なだけでなく、無駄な行動を避け、リソースを最小限に抑えた最良の計画を立てられるかを見ます。

### 視点３　汎用性

汎用性は、LLMが様々な状況や新しい環境で計画を立てる能力を評価します。特に、抽象的な表現や記号を使った問題でも計画を立てられるかどうかを見ます。

## 計画能力ベンチマークを用いた実験

GPT-4、o1-mini、o1-previewという3つのモデルの計画能力が様々なタスクで評価・比較されました。

### 全体の結果

実験結果の全体は下記の表にまとめされています。各モデルがタスクごとにどのようなエラーを起こしたか、そしてどれくらいの成功率だったかを示しています。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77179_2-1024x226.png)

各ドメインにおける各モデルのエラータイプ（IP、LO、MG、IR）の数と成功率（SR）

エラーの種類は以下の通りです。

- IP：実行可能な計画を生成できない
- LO：最適ではない計画
- MG：目標状態の誤解
- IR：問題のルールに従えない

o1-previewが多くのタスクで最高の成功率を示していることがわかります。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77179_3-1024x573.png)

6つのタスクと3つのモデルにおける実現可能性のエラーと成功率

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77179_4.png)

BlocksworldとGrippersタスクにおける各モデルの成功率と最適性率

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77179_5.png)

GrippersとTyreworldタスクにおける元のドメインとランダム化ドメインでの各モデルの成功率

### バーマン（Barman）タスク

ロボットバーテンダーがドリンクを作るタスクです。ロボットは2つの手を使って、ディスペンサー、ショットグラス、シェーカーを操作します。例えば、容器を掴む、ショットグラスに液体を注ぐ、カクテルをシェイクするなどの行動を行います。

各行動には厳密な条件があります。例えば、

- 容器を掴むには、片方の手が空いている必要がある
- カクテルをシェイクするには、シェーカーに正確に2つの材料が入っている必要がある

などです。

#### 分析結果

o1を含むすべてのモデルがこのタスクで苦戦しました。主な問題は、モデルがタスクの細かいルールを守れないことでした。

例えば、

- 片方の手が空いていないのに容器を掴もうとする
- 空ではないショットグラスに液体を注ごうとする

などの現象が起こりました。

モデルが自然言語の文脈では適切に見える行動を生成できても、現実世界の細かい制約を考慮できていないことを示しています。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77179_6-1024x422.png)

BarmanタスクでのGPT-4とo1-miniの失敗例

### ブロックスワールド（Blocksworld）タスク

テーブル上に配置された複数のブロックを、指定された目標の配置に移動させるタスクです。ロボットアームは一度に1つのブロックしか持てず、ブロックを拾う、置く、積み重ねるなどの行動を行います。

難しいのは、これらの行動を正しい順序で実行し、ブロックの操作に関する制約を守ることです。

#### 分析結果

このタスクでは、モデル間で成功率に大きな差が見られました。

- GPT-4では40%の成功率
- o1-miniでは60%の成功率
- o1-previewでは100%の成功率

o1-previewが全問題を解決できたことは、優れた推論能力を持つことを示しています。

ただし、o1-previewでも最適ではない解答は見られました。例えば、不必要な手順を追加するなど、完全に効率的とは言えない計画を立てることもありました。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77179_7-1024x459.png)

(a) o1-miniのIRエラー例、(b) o1-previewの準最適解（LO）例

### グリッパー（Grippers）タスク

2つのグリッパー（つかむ装置）を持つロボットチームが、部屋の間を移動しながら物体を操作するタスクです。

ロボットができる主な行動は3つあります。

1. 部屋から部屋へ移動する
2. 物体を拾う
3. 物体を置く

ただし、これらの行動には次の制約があります。

- 物体を拾うには、グリッパーが空いている必要がある
- 物体を置くには、その物体を持っている必要がある

効果的な計画を立てるには、これらの制約を守りながら行動を組み合わせる必要があります。

#### 分析結果

このタスクでは、o1-miniとo1-previewがGPT-4よりも明らかに優れた性能を示しました。

- GPT-4では成功率70%、最適率20%
- o1-miniでは成功率80%、最適率80%
- o1-previewでは成功率90%、最適率70%

GPT-4は計画を完成させることはできましたが、多くの場合で無駄な行動を含む非効率的な計画を立てました。

一方、o1-miniは追加の推論を行うことで不要な動きを省き、より効率的な計画を立てることができました。

o1-previewは最も高い成功率を示しましたが、1つの事例で目標状態を誤解するというエラー（MG）を起こしました。この事例では、すでに目標が達成されているにもかかわらず、不要な行動を計画してしまいました。

新しいモデルが計画の成功率と効率性を向上させていることを示していますが、同時に目標状態の正確な理解という点ではまだ改善の余地があることも示唆しています。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77179_8-1024x393.png)

(a) o1-previewのMGエラー例、(b) GPT-4の準最適解とo1-miniの最適解を比較

### フロアタイル（Floortile）タスク

ロボットのチームが床のタイルを黒と白で塗るタスクです。

ロボットができる行動は以下の通りです。

- 4方向（上下左右）に移動する
- スプレーガンの色を切り替える
- 自分の前後のタイルを塗る

ただし、以下のような難しい制約があります。

- まだ塗られていないタイルしか塗れない
- すでに塗られたタイルの上は移動できない

ロボットの動きと塗る行動を慎重に計画する必要があります。そうしないと、ロボットが動けなくなったり、塗れないタイルが残ってしまったりする可能性があります。

#### 分析結果

このタスクでは、どのモデル（GPT-4、o1-mini、o1-preview）も問題を解くことができませんでした。しかし、失敗の理由は各モデルで異なりました。

GPT-4とo1-miniの場合、

- 90%の失敗がルールを守れないこと（IR）が原因だった
- 中でも「ロボットは前後のタイルしか塗れない」というルールを無視して、自分がいるタイルを塗ろうとしてしまった

o1-previewの場合、

- ルールを守れないエラー（IR）は30%に減少した
- o1-previewは自己評価メカニズムを持っているため、ルールをより上手く守ることができた
- 例えば、最初は間違ったタイルを塗ろうとしても、すぐに修正することができた

しかし、o1-previewも完全にタスクを解決することはできませんでした。ルールの解釈を間違えたり、動きの順序について誤った仮定をしたりすることがありました。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77179_9-2.jpg)

o1-miniのIRエラーとo1-previewのIPエラーを示している

### テルメス（Termes）タスク

ロボットを制御して構造物を建設するタスクです。ロボットは水平・垂直に移動でき、同じ高さの隣接位置にブロックを置いたり取り除いたりします。また、デポという場所で新しいブロックを作ったり、不要なブロックを壊したりすることもできます。

目標の構造物を建設するためには、ロボットの動きとブロックの使用を効率的に計画する必要があります。高さや位置に関する制約を守りながら行動を組み立てる必要があるのが、このタスクの難しい点です。

#### 分析結果

すべてのモデル（GPT-4、o1-mini、o1-preview）がこのタスクの解決に失敗しました。主な問題は、詳細な計画を立てる能力の不足でした。

共通して見られた主なエラーは以下の通りです。

- 水平・垂直移動時の高さ制約を無視する （例：隣接する位置の高さが大きく異なる場合でも移動しようとする）
- 現在の位置にブロックを置こうとする （ルールでは隣接位置にしか置けない）

モデルが複雑な空間関係を管理し、タスクの細かいルールを守ることの難しさを示しています。モデルが生成した行動は自然言語の文脈では理にかなっているように見えても、実際のロボット制御に必要な操作の詳細を見落としていることが多いのです。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77179_10-1024x424.png)

GPT-4とo1-miniのTermesタスクでの失敗例

### タイヤワールド（Tyreworld）タスク

車両のハブにあるパンクしたタイヤを、膨らませた完全なタイヤに交換するタスクです。レンチ、ジャッキ、ポンプなどの道具を使用します。

タスクを完了するには、以下のような11の定義された行動を正しい順序で実行する必要があります。

- トランクを開閉する
- 道具を取り出したり収納したりする
- ナットを緩めたり締めたりする
- ハブをジャッキアップしたり下げたりする
- ホイールを取り外したり取り付けたりする
- タイヤに空気を入れる

成功するためには、これらの行動を正しい順序で実行し、特定の前提条件を満たす必要があります。例えば、

- ホイールを外す前にレンチでナットを緩める
- ジャッキを下げた後にのみナットを締める

などです。

#### 分析結果

o1-previewは全てのテスト問題で正しい計画を生成し、GPT-4とo1-miniを大きく上回る性能を示しました。GPT-4とo1-miniは最も単純なケース以外のほとんどで失敗しました。

GPT-4とo1-miniの主な問題点は、

- 必要な行動の順序を守れないことが多かった
- 例：「ジャッキアップした後にナットを緩める」「ジャッキを下げる前にナットを締める」など、タイヤ交換の基本的な手順を間違えていた

などでした。

一方、o1-previewは構造化されたタスクでは優れた性能を示しましたが、行動や道具がランダムな記号に置き換えられた一般化テストでは成功率が100%から20%に低下しました。o1-previewが馴染みのある記号を使った規則ベースの計画立案には長けているものの、より抽象的な問題設定では苦戦することを示しています。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77179_11-1024x420.png)

GPT-4とo1-miniのTyreworldタスクでの失敗例

## 考察

### 実験の限界

この研究で使ったデータセットがやや小さいのが主な限界です。実験結果からo1モデルの計画能力について基本的なことはわかりましたが、もっと広く深く理解するには、より大きくて多様なデータセットでテストする必要があります。

大きなデータセットを使えば、小さな環境では見えにくい弱点がわかるかもしれません。また、o1モデルがさまざまな制約や複雑さにどう対応するかもよくわかるでしょう。

また、もっと現実に近い状況でテストすることが大切です。現実世界の計画問題は予想外の変化が多いからです。

### 問題の複雑さとモデルの性能

分析の結果、問題が複雑になるほどo1モデルの性能が下がる傾向がはっきりしました。各問題を「行動の複雑さ」と「空間の複雑さ」という二つの面から見てみました。

特に注目したいのは、フロアタイルとテルメスのタスクです。これらは空間的に複雑で、沢山のルールがあるため、o1モデルが苦手とする部分がよく見えました。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77179_13.png)

行動の複雑さと空間の複雑さの2次元で各問題を評価し、o1-previewモデルの成功率を色分けして示す図

フロアタイルは平面の世界で、ロボットが厳しい塗り方のルールを守りながら狭い範囲を動き回る必要があります。テルメスはさらに難しく、立体的な世界で高さの制限を守りながらブロックを正確に動かさないといけません。

面白いことに、行動の種類が多いか少ないかは、あまりモデルの性能に影響しませんでした。それよりも、空間的な関係や状況の変化が複雑なほど、モデルは苦戦しました。

つまり、o1モデルは単純な行動だけのタスク（グリッパーなど）は得意ですが、複雑な空間や状況を正確に把握しなければいけないタスクは苦手だということです。

### 制約の遵守と状態管理

この研究で分かった重要なことの一つは、o1モデル（特にo1-preview）がGPT-4よりも上手くルールを守り、状況を管理できるということです。

o1-previewは自分の行動をチェックして直す能力があるので、ブロックスワールドやタイヤワールドのような課題で特に力を発揮しました。例えば、タイヤワールドでレンチやジャッキをいつ使うかといった複雑なルールも、よく守ることができました。

ただし、環境が複雑になるとこの能力も低下します。テルメスのような、正確な空間把握や複数の段階を踏む操作が必要な課題では苦戦しました。ルールを破ったり、目標を勘違いしたりすることが増えたのです。

これはつまり、モデルが複雑な状況を把握する能力にまだ限界があることを示しています。この問題を解決するには、脳の働きを真似た方法と記号を使う方法を組み合わせるなど、新しいアプローチが必要かもしれません。

### 計画の最適性と冗長性

o1モデルにとって、最も効率的な計画を立てることはまだ難しい課題ということが分かりました。これは、ブロックスワールドやフロアタイルなどの課題で明らかになりました。

o1-previewは、実行可能な計画は立てられても、最も効率の良い解決策を見つけられないことが多いのです。例えば、ブロックスワールドでは、正しい最終状態には到達できるものの、余計な手順を含む計画を立ててしまいます。

つまり、モデルがルールは理解して守れるものの、リソースを最小限に抑えたり、行動を最適化したりする判断が苦手だということを示しています。

この最適性の問題は重要です。なぜなら、現実世界では単に目標を達成するだけでなく、効率よく達成することも求められるからです。多くの場面で、手順の数や使用するリソースを最小限に抑える必要があります。

この問題を改善するには、コストを考慮した意思決定の仕組みを取り入れたり、o1の推論の仕方を強化したりする必要があるでしょう。

また、すべてのモデルに共通する問題として、実際には存在しないルールを勝手に想像してしまうことがありました。例えば、o1-previewはグリッパータスクで、隣の部屋にしか移動できないと誤解しました。そのため実行可能な計画は立てられても、最も効率の良い計画を作れなくなってしまいました。

### 汎用性と適応能力

o1-previewは、一貫したルールがある課題（例：グリッパー）では、環境が変わっても学んだ戦略をうまく使えることがわかりました。これは、GPT-4よりも優れた性能です。

o1-previewは、意味のない記号でも自然言語の意味に結びつけようとします。また、自分の行動を評価する能力があるので、ある程度ルールを守ることができます。一方、GPT-4は完全に失敗し、目標さえ理解できないことが多かったです。

しかし、o1-previewにもまだ課題があります。「より変化が多く、複雑で抽象的な問題」に対応する能力はまだ十分ではありません。単純な課題では優れていますが、複雑な環境になると性能が落ちてしまうのです。

例えば、タイヤワールドの課題では、普通の設定では全問正解でしたが、行動や道具の名前をランダムな記号に変えると、 [正解率](https://ai-data-base.com/archives/25930 "正解率") が20%まで下がってしまいました。

これは、o1-previewが学んだことが特定の状況に強く結びついていることを示しています。つまり、慣れた状況では強いけれど、全く新しい状況や抽象的な問題には弱いということです。

## まとめ

本記事では、OpenAIのo1モデルの計画能力を評価した研究を紹介しました。

o1-previewモデルは制約の遵守と状態管理で改善を示し、一部のタスクでGPT-4を上回りましたが、複雑なタスクや抽象的問題では課題が残されています。

また、最適な計画の生成や一般的状況への適応にも改善の余地があります。

このような知見を踏まえ、得意不得意を見極めた上で活用していけるとよいかと考えられます。

- 参照論文URL： [https://www.arxiv.org/abs/2409.19924](https://www.arxiv.org/abs/2409.19924)
- コード： [https://github.com/VITA-Group/o1-planning](https://github.com/VITA-Group/o1-planning)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[ロングコンテキストLLMでも、情報の数は「多ければ多いほど良い」わけではない](https://ai-data-base.com/archives/77127)

[500以上の実世界のマルチモーダルタスクを含む、過去最大規模の評価ベンチマーク『MEGA-BENCH』登場](https://ai-data-base.com/archives/74837)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)