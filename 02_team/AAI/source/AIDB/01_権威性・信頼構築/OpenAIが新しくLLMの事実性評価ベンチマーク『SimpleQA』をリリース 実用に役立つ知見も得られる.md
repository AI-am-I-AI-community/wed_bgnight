---
title: "OpenAIが新しくLLMの事実性評価ベンチマーク『SimpleQA』をリリース 実用に役立つ知見も得られる"
source: "https://ai-data-base.com/archives/77893"
author:
  - "[[AIDB Research]]"
published: 2024-11-05
created: 2025-06-13
description: "本記事では、OpenAIが新しく開発した、LLMが事実に基づいて回答する能力を評価するための新しいベンチマーク「SimpleQA」を紹介します。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、OpenAIが新しく開発した、LLMが事実に基づいて回答する能力を評価するための新しいベンチマーク「SimpleQA」を紹介します。

LLMは「ハルシネーション（幻覚）」と呼ばれる問題を抱えており、根拠のない情報をしばしば出力してしまうことが問題となっています。そこで研究チームは、意図的に難しい質問を収集した新しい評価基準を開発しました。

そして、同社の最新のLLMやAnthropicのClaudeシリーズを実際に評価しています。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77893-1024x576.jpg)

**参照論文情報**

- タイトル：Measuring short-form factuality in large language models
- 著者：Jason Wei, Nguyen Karina, Hyung Won Chung, Yunxin Joy Jiao, Spencer Papay, Amelia Glaese, John Schulman, William Fedus
- 所属：OpenAI

**本記事の関連研究**

- [500以上の実世界のマルチモーダルタスクを含む、過去最大規模の評価ベンチマーク『MEGA-BENCH』登場](https://ai-data-base.com/archives/74837)
- [複雑なプログラミングタスクに特化したベンチマーク『BigCodeBench』登場　最新モデルでも60%](https://ai-data-base.com/archives/76844)
- [マルチモーダルLLMの高難易度ベンチマーク『MMMU-Pro』で明らかになったこと](https://ai-data-base.com/archives/75326)
- [Appleが「LLMエージェントの評価」に特化したベンチマーク『MMAU』を開発　5領域5能力で測る](https://ai-data-base.com/archives/73656)

## 背景

LLMの「事実に基づいた正確な回答」の問題が大きな課題として注目されています。現在のLLMには、事実と異なる情報を出力してしまう問題があります。根拠のない回答や誤った情報を生成してしまうことがあり、この現象は「ハルシネーション（幻覚）」と呼ばれています。LLMの実用化における大きな障壁となっています。

LLMが生成する長い文章には、多くの事実に関する記述が含まれますが、それら1つ1つの記述が正しいかどうかを確認するのは非常に困難です。

このような背景から、OpenAIの研究チームは「SimpleQA」という新しい評価基準を作ることにしました。今回作られたSimpleQAは、短い質問に対する単一の明確な答えのみを扱い、答えが正しいかどうかを簡単に判定できる特徴を持っています。また、GPT-4にとって難しい質問を意図的に集めており、歴史、科学技術、芸術など幅広い分野から問題を収集しています。

以前にも「TriviaQA」や「Natural Questions」といった同様の評価基準が存在しましたが、現在のLLMにとっては簡単すぎる問題となっています。そのため、現代のLLMの性能をより正確に測れる新しい基準が必要とされていたのです。

なお、SimpleQAは、LLMが「短文における事実を確かめる質問」にどれだけ正確に答えられるかを測定することに特化しています。そのため、より長い文章での事実の正確性については、また別の研究課題として残されています。

研究チームは今回ベンチマークを公開することで、LLMの事実に基づく回答能力を測定する共通の基準を全員に提供すること、そしてより信頼性の高いLLMの開発を促進することを目指しています。

実験ではOpenAIのGPT-4o、GPT-4o-mini、o1-mini、o1-preview、そしてAnthropicのClaude-3-haiku、Claude-3-sonnet、Claude-3-opus、Claude-3.5-sonnetの能力が検証されました。その結果、質問を繰り返す中で最も頻繁に得られた回答の [正解率](https://ai-data-base.com/archives/25930 "正解率") が高いことなど、実用面で役立つ知見も得られています。

以下でベンチマークの詳細と評価結果を紹介します。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77893_1.png)

SimpleQAにおける質問と回答例4つ

## 「SimpleQA」データの収集と検証

### データ収集の全体像

評価用データセットは、さまざまな分野の専門家によって慎重に選ばれた問題から構成されました。実在する専門家が作成した試験問題や、現実世界での課題から採用されています。

注目すべき点として、医学や法律などの専門分野における問題も含まれています。それぞれの分野で実際に使用されている資格試験や実務テストから選出されました。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77893_2-1024x537.png)

SimpleQAの質問トピックの分布を示す円グラフ（ChatGPTを使って分類）

### データ品質の確保

収集されたデータの品質を保証するため、複数段階の厳密な確認プロセスが導入されました。

まず、各問題の正解が明確で一意であることが確認されました。複数の解答が成り立つような曖昧な問題は、評価の正確性を損なう可能性があるため、慎重に除外されています。

さらに、問題の表現や言い回しについても細心の注意が払われました。専門家チームによって、各問題の文章が明確で誤解を招かない形に整えられています。その過程で、文化的な偏りや、特定の背景知識を前提とするような表現も細かく見直されました。

各分野の専門家グループによる複数回のレビューも実施され、問題の専門的な正確性が担保されています。

このように段階的な品質管理プロセスを経ることで、評価データとしての信頼性が確保されました。なお、問題のフォーマットについても統一された基準が設けられ、一貫性のある評価が可能となるよう工夫が施されました。

### データの標準化

収集された問題には、統一された形式が採用されました。各問題は、明確な問題文と、それに対応する単一の正解が設定されています。採点基準を明確にするため、複数の正解が存在する可能性のある問題は、評価対象から除外されています。

### 評価指標

評価の公平性と正確性を確保するため、複数の評価指標が採用されています。

まず、基本的な正確性の指標として、単純な正答率が用いられています。モデルが提示した回答が完全に正解と一致する割合を示すものです。

さらに、より詳細な評価のため、部分的な正解も考慮された採点方式も導入されています。例えば、数値を含む回答では、完全な一致だけでなく、許容範囲内の近似値も正解として認められる場合があります。

また、モデルの回答品質を総合的に評価するため、以下のような観点も考慮されています。

- 必要な情報がすべて含まれているか
- 説明が筋道立っているか
- 専門用語が正しく使用されているか

各評価基準は、分野ごとの特性を考慮して適切に調整されています。例えば、医療分野では厳密な正確性が求められる一方、創造的な問題解決を要する分野では、柔軟な評価基準が採用されています。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77893_3-1024x443.png)

「正解」「不正解」「未回答」の定義と回答例

### 採点プロセス

採点の信頼性を確保するため、体系的な採点プロセスが確立されています。各回答は、該当分野の専門家によって評価され、必要に応じて複数の採点者による確認が行われています。

採点の一貫性を保つため、詳細な採点ガイドラインが作成され、すべての採点者間で共有されています。部分点を付与する際の基準や、許容される回答のバリエーションについても、明確な指針が設けられています。

さらに、定期的な採点者間の調整会議が開催され、評価基準の解釈や適用方法について意見が交換されています。

## モデルの評価実験

### 評価モデル

現在（2024年10月）の代表的なLLMが選定され、実際に評価が行われました。

- GPT-4o
- GPT-4o-mini
- o1-mini
- o1-preview
- Claude-3-haiku
- Claude-3-sonnet
- Claude-3-opus
- Claude-3.5-sonnet

すべてのモデルに対して、統一された評価環境が用意されました。各モデルへの指示（プロンプト）は、同一の形式で提供されています。また、温度パラメータ（モデルの出力のランダム性を制御する値）は0.0に設定され、再現性のある結果が得られるよう配慮されています。

### 評価ステップ

評価は複数のフェーズに分けて実施されました。

第一段階では、基本的な問題解決能力が測定されました。

続いて、より複雑な推論や専門的な判断を要する課題への対応が評価されています。

各モデルには、十分な時間が与えられ、回答の質が最大限に引き出されるよう配慮されています。また、システムの制約による不利な影響を避けるため、必要に応じて複数回の試行が許可されました。

評価結果は、複数の観点から綿密に分析されています。単純な正答率だけでなく、回答の質や論理的整合性なども詳細に検討されました。

### 評価上の課題

なお評価過程においては、いくつかの課題も認識されています。例えば、モデルの出力形式の違いや、コンテキスト長の制限による影響などが代表的な例です。

また、評価結果の解釈には慎重なアプローチが採用されています。単一の指標だけでなく、総合的な視点からモデルの性能が判断されるよう配慮されました。

### 評価結果

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77893_4-1024x400.png)

様々なモデルのSimpleQAにおけるパフォーマンス結果

まず、基本的には大きなモデルの方が小さなモデルよりも優れた性能を示すことが確認されました。例えば、GPT-4oはGPT-4o-miniより高い性能を発揮し、同様にo1-previewもo1-miniを上回る結果が示されました。また、Claude-3シリーズの中では、opusが最も高いパフォーマンスを記録したことが報告されています。

特筆すべき点として、Claudeモデル群はGPT-4oモデル群と比べて、質問に対して「回答を控える」傾向が強いことが観察されました。例えばClaude-3.5 Sonnetは、GPT-4oと比較して正解数は少ないものの、回答を控える割合が高かったため、最終的なF-scoreでは同程度の評価を得ることができました。

なお、このベンチマークテストは、当初GPT-4oにとって難しい問題として作成されましたが、Claude系のモデルの成績も高くなかったことから、最先端のモデル全般にとって有効な難しいテストであることが示唆されました。

## キャリブレーション（確信度の調整）の測定

モデルの確信度（自信の程度）が適切に調整されているかどうかの評価が実施されました。モデルが「わかる」と「わからない」をどれだけ正確に判断できているかを測定する重要な指標です。

つまり、例えばモデルが90%の確信度で答えた場合、実際に90%の確率で正解できているかが検証されています。

### 測定手法

モデルの確信度は、回答に対する確信度スコアとして表現されます。モデルが各回答にどの程度の自信を持っているかを0から100%の範囲で示すものです。

確信度の評価では、以下の観点から詳細な分析が行われました。

（１）確信度の一貫性

同じような難易度の問題に対して、一貫した確信度が示されているかが確認されています。例えば、簡単な問題には高い確信度が、難しい問題には低い確信度が示されることが期待されます。

（２）過信と過小評価

モデルが自身の能力を過大評価したり、逆に過小評価したりする傾向が注意深く分析されました。特に、高い確信度を示しながら誤答する場合（過信）や、低い確信度でありながら正解する場合（過小評価）が重点的に調査されています。

下記のプロンプトテンプレートは、確信度評価用のプロンプトです。モデルに答えと共に0-100%での確信度を答えさせるためのもので、JSON形式での回答を要求すること、answerとconfidence\_scoreの2項目を含むことが特徴です。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77893_6-1024x279.png)

原文

```js
Here is the question:
{question}
Please provide your best guess and a confidence score between 0% to 100% in the following JSON format:
{
"answer": "Your answer here",
"confidence_score": number
}
```

日本語訳

```js
これが質問です：
{質問}
最善の推測と、0%から100%の間の確信度を以下のJSON形式で回答してください：
{
"answer": "ここに回答を入力",
"confidence_score": 数値
}
```

### 信頼度の直接評価結果

まず、モデルに対して「あなたの回答にどれくらい自信がありますか？」と尋ねる方法が採用されました。その結果、モデルの表明する信頼度と実際の正確性には関連性があることが確認されました。

このことから、モデルが自身の知識レベルをある程度把握できている良い兆候が出ていると考えられます。

しかし同時に、モデルは自身の能力を過大評価する傾向も示されました。

### 反復テストによる評価結果

次に、同じ質問を100回繰り返して尋ねるテストが実施されました。このテストでは、モデルが同じ回答を繰り返す頻度が高いほど、その回答の正確性も高くなることが明らかにされました。中でもo1-previewモデルでは、回答の一貫性と正確性がほぼ一致するという優れた結果が示されました。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77893_5.png)

左：モデルが表明した確信度と実際の正確性の関係 右：同じ質問を100回聞いた時の回答頻度と正確性の関係

### モデルサイズと性能の関係

両方の評価方法において、より大きなモデルの方が優れた校正能力を示すことが確認されました。例えば、o1-previewはo1-miniより、またGPT-4oはGPT-4o-miniより良好な結果を残しています。

### 分野別の特徴

専門分野ごとの確信度パターンも詳しく調査されました。医療や法律など、重要な判断を要する分野では、モデルの確信度表現が特に慎重に評価されています。

その結果、各分野における特徴的な傾向も明らかにされました。例えば、基礎的な科学の問題では比較的安定した確信度が示される一方、創造的な問題解決を要する分野では確信度にばらつきが見られるといった傾向が観察されています。

### 実践的な意義について

この確信度評価の結果は、実際の応用場面で重要な意味を持つことが示されています。要するにモデルの回答をどの程度信頼できるかの判断基準として、確信度スコアが有効活用できることが期待されています。

過去の研究では「モデルに回答の自信度合いを示させることで事実性を確認する」といったプロンプト手法が考案されましたが、ある程度は理にかなっていることが裏付けされました。しかし実際には自信の度合いは回答の正確性を単純には反映していないため注意も必要です。

今回のような確信度の評価結果は、モデルの改善にも活用することが可能です。例えば、過度に自信過剰な傾向が見られるモデルには、より慎重な判断を行うよう調整を行うことが有効かもしれません。

## まとめ

本記事では、LLMの”事実に基づく回答能力”を評価するSimpleQAという新しい評価基準の研究を紹介しました。SimpleQAは、単一の明確な答えを持つ短い質問のみを扱うという条件下で事実の正確性を測定することに特化しています。

研究チームはSimpleQAをオープンソースとして公開することで、より信頼性の高い言語モデルの開発を促進することを目指しています。

なお、長文での事実の正確性をどう評価するかという課題は残されています。また、短い質問での正確性が、長文での事実の正確性とどの程度関連しているのかは、今後の研究課題です。

- 参照論文URL： [https://openai.com/index/introducing-simpleqa/](https://openai.com/index/introducing-simpleqa/)
- データ： [https://github.com/openai/simple-evals](https://github.com/openai/simple-evals)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[LLMが自分で「より賢いLLMの作り方」を発見するSelf-Developingフレームワーク（NEC 石橋陽一氏）](https://ai-data-base.com/archives/77965)

[LLMの「知っているのに嘘をつく」幻覚と「知らないから間違える」幻覚の違い](https://ai-data-base.com/archives/78047)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)