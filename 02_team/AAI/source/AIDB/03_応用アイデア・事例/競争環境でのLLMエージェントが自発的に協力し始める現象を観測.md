---
title: "競争環境でのLLMエージェントが自発的に協力し始める現象を観測"
source: "https://ai-data-base.com/archives/72854"
author:
  - "[[AIDB Research]]"
published: 2024-07-16
created: 2025-06-13
description: "本記事では、LLMエージェントが競争環境で自発的に協力行動を形る過程を探究した研究を紹介します。3つの実験を通して、LLMの協力における能力が検証されました。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、LLMエージェントが競争環境で自発的に協力行動を形る過程を探究した研究を紹介します。

3つの実験を通して、LLMの協力における能力が検証されました。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_72854-1024x576.jpg)

**参照論文情報**

- タイトル：Shall We Team Up: Exploring Spontaneous Cooperation of Competing LLM Agents
- 著者：Zengqing Wu, Run Peng, Shuyuan Zheng, Qianying Liu, Xu Han, Brian Inhyuk Kwon, Makoto Onizuka, Shaojie Tang, Chuan Xiao
- 所属：Osaka University, Kyoto University, University of Michi [gan](https://ai-data-base.com/archives/26269 "敵対的生成ネットワーク（GAN）"), Ann Arbor, NII, Fordham University, University of California, Los Angeles, University of Texas at Dallas, Nagoya University

## 背景

LLMエージェントを用いたシミュレーションはどれほど現実世界の状況を反映しているか？という疑問があります。

一部の研究では、LLMが基本的な人間の行動や推論能力を模倣できることが示されています。同時に、LLMは特定の偏見を持つ可能性などの問題も指摘されており、高度で複雑なシナリオでは影響がある可能性があります。

そこで研究者らは、前提や仮定に縛られることなく、エージェント同士の相互作用に基づいて実験を行うべきだと考えました。

現実世界を模した状況を適切に検証するため、本研究では競争的な環境において、自然に協力が発生するかどうかを検討しています。

競争的な環境とは何か？例えば、キャンディー市場で優位性を争う2つのスナック会社を考えてみましょう。彼らは顧客を引き付けるために継続的に価格を下げ続けるかもしれません。あるいは、相互に利益をもたらす関係を構築するために、同時に価格を引き上げることを決定するかもしれません。

競争的な条件下では、エージェントが対立相手と協力することは直感的ではありません。しかし、もしかすると協力のメリットを見出すかもしれません。

今回研究者らは、プロンプトを慎重に設計し、指示的な記述（例：「あなたは協力するかもしれません」）などを避けています。バイアスの影響を可能な限り排除し、LLMエージェントが自然発生的に協力を学ぶ様子を観察することが試みられています。

## LLM同士の競争において「協力」は自然に発生するか

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_72854_1.png)

火災時の2つの潜在的シナリオ。左側は人々がパニックになり群衆に押し寄せる様子、右側は冷静に列を作り互いに励まし合う様子

今回の研究では、対立する目的を持つエージェントが、相互作用を通じて協力の利益を認識し、自発的に協調行動を選択できるかを調査しようとしています。つまり明示的な指示なしに協調行動が発生するのかを検証します。

LLMは人間の価値観に沿うよう調整されていますが、事前の調整に基づく協力は自然発生的とは見なされません。そこでプロンプト設計では、エージェントへの明示的な指示や、シミュレーションの性質を示唆するキーワードを避けられました。

また、評価においては、エージェントが自ら協力の利益を認識し、徐々に協調行動を選択していく過程に着目しています。事前知識に基づく協力はこの基準から除外されます。そして、エージェントが相互作用を通じて協力の有益性を認識し、自発的に協調行動を選択するかどうかが注目されています。結果は学習能力や適応能力を反映すると考えられています。

## 実施された3つのケーススタディ

金融、経済学、行動科学における下記3つのシナリオが実験されました。

**（１）ケインズの美人コンテスト  
**複数のプレイヤーが0から100の間で数字を選びます。全プレイヤーの選んだ数字の平均の3分の2に最も近い数字を選んだプレイヤーが勝者となります。  
短期的な単一の意思決定過程における集団内の協力が観察されます。

**（２）ベルトラン競争  
**2つの企業が製品の価格を決定し、利益を最大化しようとする経済モデルです。より長期的な時間軸での協力形成が観察されることになります。エージェントは過去の文脈を利用しながら、相手と効果的にコミュニケーションを取る必要があります。

**（３）緊急避難  
**地震からの避難をシミュレートします。多数のエージェントが適切な出口を選び、到達しようとします。3つのケーススタディの中で最も複雑で、時間的情報と空間的情報の両方が含まれます。エージェントは環境内の観察とコミュニケーションに基づいて継続的に意思決定を行います。

ケインズの美人コンテストでは相手の戦略が不明な中でグループディスカッションが行われます。ベルトラン競争では相手の利益が不明で、1対1の会話が行われます。緊急避難では部分的な観察のみが可能で、近接したエージェント間でのコミュニケーションが行われます。また、ケインズの美人コンテストとベルトラン競争には分析的解が存在しますが、緊急避難には存在しません。  
このように3つの実験ケースはさまざまな面で異なります。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_72854_2-1024x455.jpg)

3つのケーススタディにおけるシミュレーションの流れ。コミュニケーション、計画、行動、更新の各フェースを通じてLLMエージェントがどのように管理されるかを図示

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_72854_3-1024x108.png)

3つの選択されたシナリオの共通点と相違点。情報の可視性、コミュニケーション形態、シミュレーション中の決定回数、分析的解の有無について比較。KBC、BC、EEはそれぞれ

## ケーススタディ１：ケインズの美人コンテスト

24名のLLMプレイヤーによってシミュレートされました。各プレイヤーは0から100までの数字を選択します。全プレイヤーが選んだ数字の平均の3分の2に最も近い数字を選んだプレイヤーが勝者となり、1ドルを獲得します。

シミュレーションの一般性を確保するため、各設定につき15回の実行がGPT-4をバックボーンとして行われました。

### シミュレーション手順

（１）コミュニケーションフェーズ  
数字を選ぶ前に、プレイヤー間でグループディスカッションが行われます。プレイヤーは順番に自分の考えを他のプレイヤーと共有します。全ラウンドの対話履歴が参照可能です。

（２）プランニングフェーズ  
プレイヤーは数字選択の戦略について（個別に）話し合います。

（３）アクションフェーズ  
プレイヤーは選択する数字を提案します。プランニングとアクションフェーズは1回のAPI呼び出しで行われ、プレイヤーは戦略と0から100の間の数字を出力します。

（４）アップデートフェーズ  
全プレイヤーの数字が選択された後、SABMフレームワークによって勝者が決定されます。勝者には競争を促すためのルールに従って報酬が与えられます。

### 評価方法

研究の目的は、LLMが協力する過程を観察することです。プレイヤーはコミュニケーションを通じて戦略を適応させ、利益を最大化するために協力を行うと予想されていました。

協力の発生を追跡するため、量的手法が採用され、プレイヤーが選択した数字の「分散」が分析されました。「分散」とは、データの散らばり具合を示す統計量です。分散が大きいほど、選択された数字が広く散らばっていることを意味し、小さいほど数字が集中していることを示します。

分散が小さいほど、プレイヤーが類似した数字を選んでいることを示し、これは集団的な利益につながる可能性があります。異なるラウンドのコミュニケーションとプランニングを経た後の分散を分析することで、分布の変化が観察されます。

分散が減少傾向を示す場合、プレイヤーが当初はランダムまたは様々な理由で数字を選択していたものの、時間とともに他のプレイヤーと類似した数字を選ぶようになったことを示唆します。この傾向は、徐々に協力が形成されていることを示す指標として解釈されます。

### シミュレーション設計

協力が徐々に形成されるかを調査するため、下記のようにベースラインが設計されました。

エージェントは数字を選択する前に、k回のコミュニケーションラウンド（kは0から3の範囲）を経験します。k=0の場合、エージェントはコミュニケーションなしで直接数字を選択します。k>1の場合、エージェントは現在のラウンドの自分の前までの会話履歴と、すべての過去のラウンドの履歴を閲覧できます。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_72854_4.png)

ケインズの美人コンテストにおけるベースライン設計。エージェントがk回のコミュニケーションを行った後、計画と行動を決定する流れを図示

### 協力の自然発生性の検証

協力が明示的な指示なしに自然に発生することを確認するため、「他のプレイヤーと協力しなければならない」といった特定の指示をプロンプトに組み込む実験も行われました。

反対に、エージェントに非協力的な性格を与え、利己的に行動するよう明示的に指示するシナリオも評価されました。

### 結果概要

下の図は主な結果を示しています。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_72854_5.png)

ケインズの美人コンテストにおける異なる設定での選択の分散。 左(a)は異なる指示、右(b)は異なるモデルでの結果を比較

全体として、LLMプレイヤー間の選択の分散が、コミュニケーションがない状態（k=0）から徐々にコミュニケーションが増える状態（k>0）へと一貫して減少することを示しています。この傾向は、エージェントが積極的に議論し、より良い相互利益のために同じ数字を選ぼうとしていることを示唆し、協力的な行動と解釈されます。

加えて、コミュニケーションログには「より低い数字戦略で進めましょう」や「グループのコンセンサスに同意します」といった協力を示す表現が観察されました。特に後半のラウンド（k=2または3）では、大多数のエージェントにこのような表現が見られ、コミュニケーションを通じて協力が徐々に形成されていることが示唆されました。

### プロンプトへの明示的指示の影響

プロンプトに明示的な指示を追加した場合の行動の違いが調査されました。上記の図aに示されるように、エージェントに明示的に協力するよう指示すると、k=1の時点で分散が大幅に0に近づきます。その後、15回の実行を通じて、すべてのプレイヤーが一貫して同じ選択をしました。

これは、ベースライン（指示なし）で観察された協力が、コミュニケーションによって自発的に動機づけられたものであることを裏付けています。逆に、非協力的な性格を持つエージェントは、すべてのラウンドを通じてはるかに大きな分散を示し、これは協力の定義と一致しています。

したがって、ベースラインは潜在的な指示の影響をほとんど受けておらず、自然発生的な協力現象を成功的にシミュレートしていると結論づけられました。

### モデル間の比較

上記の図bは、異なる高性能モデルにおけるLLMプレイヤーの行動を示しています。Claude 3（claude-3-sonnet-20240229）の曲線はk=0からk=1にかけて大きく低下しており、LLMプレイヤーが情報を共有し、この共有されたコンテキストに基づいて決定を下す能力を反映しています。

しかし、GPT-4とは異なり、Claude 3の分散はk=1からk=3にかけて増加しています。コミュニケーションログの分析によると、Claude 3はGPT-4と比較して、より抽象的な戦略について議論し、具体的な数値の議論が不足していることが明らかになりました。

そのため、LLMプレイヤーは特定の数字に同意することはあっても、具体的な選択がエージェント間で異なる（例：一部が66を選び、他が33を選ぶ）結果となり、複数の勝者が出るものの選択の分散は増加しました。  
分散に基づくと自然発生的協力の定義には合致しませんが、ログからは協力の形跡が観測されました。

### 人間のデータとの比較

最後に、人間データとの比較を行うための実験結果が下の図にまとめられています。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_72854_6.png)

シミュレーションでのプレイヤーの選択とニューヨークタイムズの実験結果の分布を比較

ベースラインのシミュレーション結果が、ニューヨーク・タイムズが実施した大規模な経験的実験（N=61,140）の数値選択分布と概ね一致していることを示しています。LLMプレイヤーとニューヨーク・タイムズ（NYT）プレイヤーの両方が、コミュニケーションなしの設定で主に33を選択しました。

0、22（33の3分の2）、50、66付近の他のサブピークもよく反映されており、GPT-4が多段階の推論を成功裏に行い、人間の行動を忠実に反映していることが示されています。これは先行研究の知見とも一致しています。

**ケーススタディ1（ケインズの美人コンテスト）の結果と結論**

1. コミュニケーションの増加に伴い、プレイヤーの選択の分散が減少
2. 協力を示唆する表現がコミュニケーションログに観察される
3. 明示的な協力指示がある場合、選択の分散が急激に減少
4. 非協力的な性格を持つエージェントは、より大きな分散を示す
5. 異なるLLMモデル間で協力形成のパターンに違いがある
6. シミュレーション結果が実際の人間の行動データと類似

## ケーススタディ２：ベルトラン競争

タスクの説明は前述のとおりですが、今回は同じ限界費用を持つ2つの企業間でシミュレートされ、1200ラウンドに達するか、200ラウンド連続で談合が続くまで継続する設定で実験されました。

談合は、両プレイヤーが近い価格を維持し、その価格がベルトラン均衡価格と談合価格の間で長期間（200ラウンドと定義）維持される場合に識別されます。二つの基準となる価格の説明を下記に示します。

- ベルトラン均衡価格：競争がナッシュ均衡（注：他のプレイヤーの戦略を所与としたとき、自分の戦略を変更しても利得が増加しない状態）に達したときの価格、この場合、談合は観察されない
- 談合価格：両プレイヤーが完全な談合に達したときの価格で、同じ企業を運営しているかのように行動する

上記の2つの価格は、利益を生み出すことができる合理的な価格範囲を示しています。

なお結論の一般性を確保するため、各設定につき5回のシミュレーションが実行されました。結果をまとめた図（後述）には1回の実行結果が示されています。

### シミュレーション手順

各ラウンドのシミュレーションは以下のフェーズを経て進行します。

（１）コミュニケーションフェーズ  
企業は1ラウンドで3回交代で、価格設定に限らず任意のトピックについて議論します。

（２）プランニングフェーズ  
各企業は、両社の過去の価格履歴と自社の製品需要および利益情報に基づいて、戦略を立案または修正します。

（３）アクションフェーズ  
各企業は独立して、同時に製品価格を設定します。

（４）アップデートフェーズ  
両企業が価格を決定した後、シミュレーションシステムは現在の価格設定下での市場需要と各企業の利益を計算します。

### 暗黙の談合と明示的な談合

暗黙の談合とは企業間で価格競争を避け、より高い価格と限定的な生産量を維持するための非公式で暗黙の協調を指します。明示的なコミュニケーションや合意なしに行われます。

一方で明示的な談合は、競合他社間で価格を固定し、その他の反競争的行為に従事する正式な合意を指します。実質的に単一の事業体として行動し、共同利益を最大化します。

### ベルトラン競争における自然発生的協力の定義

まず、2つの企業の価格が互いに非常に近い状態にあることがポイントです。価格は、完全競争状態（ベルトラン均衡価格）よりは高く、完全な談合状態（談合価格）よりは低い水準に設定されます。このような状況では、企業同士が直接的な合意なしに、お互いの存在と影響を暗黙のうちに認識しています。

企業は極端な価格競争を避け、適度に高い価格を維持しようとします。ここで重要なのは、直接的な価格合意が存在しないことです。各企業が独立して似たような行動を取りますが、結果として協調的な状態が生まれます。

上記の状態では、完全な談合ほどではありませんが、ある程度の利益を共有できる状況が目指されます。つまり、企業が明示的に協力を合意したわけではありませんが、結果として協調的な行動を取っている状況を指します。

一方、明示的な談合の場合は異なります。この場合、チャットログなどから直接的な価格合意の証拠が見つかることがあり、それによって協力の存在が判断されます。

### 実験結果

#### コミュニケーションがない場合

コミュニケーションがない状況下でも、下記の図aに示されるように、企業は初期の200ラウンド後に価格戦略の調整が開始されました。価格を引き上げることで利益が増加し、価格競争を避けられることが認識されたためです。400ラウンド頃には、価格は約7の水準で安定しました。この価格はベルトラン均衡価格の6を上回っており、過去の競争行動に基づく相互理解から生じた暗黙の談合を示唆しています。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_72854_7-1024x325.png)

ベルトラン競争における異なるシナリオでの価格競争。 (a)はコミュニケーションなし、(b)はコミュニケーションあり、(c)は400ラウンド後にコミュニケーションを停止した場合の結果

しかし、コミュニケーションがないため、収束した価格は談合価格の8には達していません。

この結果は、 [強化学習](https://ai-data-base.com/archives/26125 "強化学習") を用いた先行研究のシミュレーション結果と一致していますが、LLMエージェントの方が遥かに速く談合を形成しています（LLMエージェントは400ラウンドで、強化学習では2000ラウンドでの形成）。

#### コミュニケーションがある場合

コミュニケーションがある設定では、初期のラウンド（最初の30ラウンド）から明示的な価格合意がコミュニケーションログに観察されました。例えば、20ラウンド目のコミュニケーションフェーズで、企業2は「適度な価格差を維持しながら、異なる価格帯を探ることで、両社とも利益を最大化できる」と提案し、企業1がこれに同意しています。

上記の図bに示されるように、実施前に企業間で価格戦略と協力の可能性について頻繁に議論されており、これが信頼を大幅に高め、価格戦争を開始する可能性を低下させています。価格合意は、シミュレーションの後半のラウンドでより具体的になり（価格帯ではなく特定の価格について）、価格決定のばらつきが減少しました。

結果として、最初の30ラウンド後から価格が徐々に引き上げられ、最終的に談合価格の8近くに収束しました。この価格はコミュニケーションなしの設定よりも高く、エージェント間の協力を反映しています。

#### コミュニケーション中断の影響

図cでは、最初の400ラウンドは図bと同じ対話付きの価格決定記録を用い、その後の200ラウンドはコミュニケーションなしの設定が使用されました。図bでは対話によって合意形成と協力が促進され、価格が8まで引き上げられましたが、図cの後半200ラウンドでは価格が7と8の間に収束しています。これはコミュニケーションなしのシナリオ（図a）に類似しています。

図bとcの比較から、カルテル的談合と価格上昇が実際にエージェント間のコミュニケーションから生じていることが示されています。エージェントにどのトピックについて議論するかを明示的に指示していないため、対話を通じてコンセンサスを形成し、より高い利益のために価格を引き上げる行動は、自然発生的な協力の一形態と見なすことができます。

### 結論

コミュニケーションの有無に関わらず、エージェントは異なる条件下で談合を達成できることが示されました。コミュニケーションを通じて、企業は最大の利益を実現できますが、コミュニケーションがなくても、エージェントは自律的に協力を形成する能力を持っていることが観察されました。

既存の研究によると、談合には多くの場合、利益を増加させるための暗黙の価格合意が含まれることが示されており、LLMエージェントのパフォーマンスはこれらの知見と一致しています。

### 明示的な指示の影響

下の図（の右下）に示されるように、「協力を奨励」設定下のエージェントは、デフォルト設定と比較して、より迅速に協力が形成されただけでなく、ラウンドを通じてより安定した価格（変動が少ない）を維持しました。対話の開始時から明確な協力シグナルが見られ、最終的に談合価格に到達しました。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_72854_8.png)

ベルトラン競争の最初の200ラウンドにおける、デフォルト設定と協力を奨励した設定での価格推移を比較

これは、戦略的な奨励が協力の効率を大幅に向上させる可能性があることを示しています。間接的に、協力を明示的に指示しない設定での協力的行動が、コミュニケーションから生じていることを示唆しています。最初の50ラウンドのコミュニケーションを通じて、エージェント間で合意に達するまでにより多くのラウンドを要しています。

さらに、談合価格に到達するまでに約200ラウンドを要するパターンは、この協力がLLMのバックグラウンド知識やデータ漏洩によるものではないことを示唆しています。そうでなければ、エージェントはシミュレーションの初期ラウンドから最適な談合を追求するはずです。

**ケーススタディ2（ベルトラン競争）の結果と結論**

1. コミュニケーションなしでも暗黙の談合が形成される
2. コミュニケーションがある場合、より高い価格での明示的な談合が観察される
3. コミュニケーションを中断すると、価格が低下する傾向がある
4. 協力を奨励すると、より迅速かつ安定した協力が形成される
5. LLMエージェントは強化学習よりも速く談合を形成する
6. エージェント間のコミュニケーションが価格上昇と談合形成に重要な役割を果たす

## ケーススタディ３：緊急避難

緊急避難タスクは先行研究のようにグリッド環境でシミュレートされました。33×33のセルで構成されており、部屋には3つの非常口（左、右、下）が設置されています。シミュレーションでは、避難者が複数のラウンドにわたって目標とする出口に到達しようと試みます。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_72854_9.jpg)

緊急避難シミュレーションのグリッド環境の概要。(a)は赤いエージェントの視野範囲、(b)は簡略化されたシミュレーションの時間経過

100人のエージェントを用いて緊急避難がシミュレートされ、全エージェントが無事に脱出するか50ラウンドに達した時点でシミュレーションが終了します。エージェントの初期位置を変えて5回のシミュレーションが繰り返されました。

### シミュレーション手順

各ラウンドのシミュレーションは以下のフェーズを経て進行します。

（１）コミュニケーションフェーズ  
避難者は周囲の人々と感情を共有するよう求められます。特定の距離内にいるエージェントのみがメッセージを聞くことができます。

（２）プランニングフェーズ  
3つの出口までの距離とその周辺の混雑状況が提供され、エージェントはこれらの出口に対する感想を述べ、目標とする出口を1つ選択します。チャット履歴も考慮に入れられます。

（４）アクションフェーズ  
目標とする出口が決まると、エージェントはどの方向に進むかを選択します。8方向のいずれかに1セル移動するか、現在のセルにとどまることができます。

（５）アップデートフェーズ  
全エージェントが行動を選択した後、SABMフレームワークによってグリッド環境が更新され、エージェントの新しい位置が反映されます。脱出に成功したエージェントは「脱出済み」とラベル付けされ、シミュレーションから除外されます。

### エージェントの行動設定

各ラウンドで、1人のエージェントが20%の確率でコミュニケーションを行い、計画を調整します（フェーズ1と2）。それ以外の場合は、最新の計画に基づいて直接行動を選択します。この設定によってエージェントが毎ラウンド会話したり、頻繁に計画を変更したりすることが防止され、より現実的なシミュレーションが実現されます。

### 避難における競争と協力

全エージェントができるだけ早く脱出しようとするため、自然に競争が発生し、しばしば混雑につながります。しかし、エージェントが積極的に情報を共有し、雰囲気を落ち着かせ、群衆を誘導できれば、結果的により速く、かつバランスの取れた方法で脱出できる可能性があります。これらの状況は同時に起こりえます。

この実験の目的は、(1)現象を成功裏にシミュレートし、(2)情報共有、励まし、出口誘導といった協力的行動が存在するかを観察することです。

### 協力の定義と評価

避難における協力は、情報共有、他者への励まし、出口の案内などの行動として定義されます。これらの行動が観察されるかどうか、また、それらが避難速度や出口選択のバランスにどのような影響を与えるかが評価されます。

### 比較設定

3つのベースラインが比較されました。コミュニケーションなし、コミュニケーションあり、そしてコミュニケーションありで非協力的な性格を持つエージェントです。

### コミュニケーションが避難速度に与える影響

ラウンドごとの脱出したエージェントの累積数が以下の表に示されています。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_72854_11-1024x113.png)

異なる設定下での、ラウンドごとの脱出したエージェントの累積数（100エージェント中）。一般的に、コミュニケーションを行うエージェントがより早く脱出し、非協力的なエージェントがより遅く脱出することを示す

ほとんどのラウンドで、コミュニケーションを行うエージェントが最も速く脱出しており、5回の実行すべてで50ラウンド以内に全員が脱出に成功したのは、このグループのみでした。要するにコミュニケーションが避難速度に正の影響を与えていることが強く示唆されています。

そしてログを詳しく分析すると、効果的なコミュニケーションの事例が見つかりました。例えば、ある避難者が「下の出口が近くて人も少ないようです。より速い脱出のためにそちらを選びましょう。頑張って、お互いに助け合いましょう！」と共有し、別の避難者がこのメッセージを強調しています。  
このような情報共有と励ましを通じたコミュニケーションは「協力」とみなされ、避難速度の向上に寄与していると考えられています。

### コミュニケーションが出口選択に与える影響

下の図は、異なる出口から脱出した避難者の分布を示しています。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_72854_10.png)

各出口からの累積脱出エージェント数。コミュニケーションあり、なし、非協力的な場合の3つのシナリオを比較

避難者同士がコミュニケーションを取れる場合、出口選択がより均等に分散していることが観察されました。この均衡は、避難者間で自然発生的に情報交換が行われ、出口までの距離と混雑度の両方を考慮して最適な出口を識別できるようになったことに起因すると考えられます。

### 非協力的な性格を持つエージェントの影響

非協力的な性格を持つエージェントは、コミュニケーションを行うにもかかわらず、最も遅い避難速度を示しました。これは、協力的な態度がない場合、単にコミュニケーションの機会があるだけでは効果的な避難につながらないことを示唆しています。

### 協力的行動の具体例

ログ分析から、以下のような協力的な会話が観察されました。

「下の出口が近くて人も少ないようです。そちらを選びましょう。」→情報共有

「頑張って、お互いに助け合いましょう！」→励まし

「左の出口は混んでいます。右か下を試してみてください。」→状況報告

上記はエージェント間で自然に発生した協力行動の一部です。

### 結論

シミュレーションの結果、コミュニケーションを通じた協力が避難プロセスを大幅に改善できることが示されました。具体的には、避難速度の向上と出口選択の均等化が観察されました。これらの結果は、緊急時におけるコミュニケーションと協力の重要性を強調するものです。

また、LLMエージェントが複雑な社会的状況をシミュレートし、人間らしい行動パターンを再現できる可能性が示されました。この研究アプローチは、緊急時の人間行動のより深い理解と、より効果的な避難戦略の開発に貢献する可能性があります。

**ケーススタディ3（緊急避難）の結果と結論**

1. コミュニケーションを行うエージェントがより速く脱出する
2. コミュニケーションにより、出口選択がより均等に分散する
3. 非協力的な性格を持つエージェントは最も遅い避難速度を示す
4. 情報共有、励まし、状況報告などの協力的行動が観察される
5. コミュニケーションを通じた協力が避難プロセスを大幅に改善する
6. LLMエージェントが複雑な社会的状況をシミュレートし、人間らしい行動パターンを再現できる可能性が示される

## 考察

計算社会科学では、コンピューター上のシミュレーションと現実世界の出来事をいかに近づけるかが重要な課題です。今回の研究では、競争的な環境でも自然に協力が生まれる可能性が探索され、その結果、LLMは特別な指示がなくても協力する状態へと徐々に変化できることがわかりました。

また、エージェントへの指示の有無による比較実験では、指示がない場合の方が、より自然な人間の行動に近いことがわかりました。このことから、社会シミュレーションでLLM（例：GPT-4）を使う際は、なるべく指示を減らすことで、より現実に近い結果が得られる可能性があると解釈できます。

3つの事例研究で人間らしい行動のシミュレーションに成功しましたが、LLMが本当に人間のように考えているのか、それとも単純な近道（ショートカット）を使っているのかという疑問は残っています。  
しかしショートカットやバイアスを完全に排除した実験はできません。また今回は良い結果が得られましたが、他の状況では人間の行動を正確に反映しない可能性もあります。

ただし、全てのショートカットをなくす必要はありません。人間も「よく考えてゆっくり判断する」ことと「直感的に素早く判断する」ことの両方ができるからです。LLMでも両方の思考方法を使うことで、より人間らしい行動のシミュレーションができると考えられます。

LLMの内部の仕組みが人間の直感とどれくらい似ているかを調べるのは難しいですが、この研究のようにLLMが直感的な判断を使いにくい状況でどのように学習するかを観察するのは有効な手段になるかもしれません。

## まとめ

本記事では、競争的環境下でのLLMエージェントの自然発生的協力を探究した研究を紹介しました。

3つの異なるシナリオを通して、エージェントが明示的な指示なしに協力行動を発展させる能力が検証されました。結果は実世界のデータとよく一致し、社会シミュレーションにおける事前知識排除の重要性が示されました。

全体を通して得られた重要な結果や結論は以下の通りです。

1. LLMエージェントは競争下で自然発生的な協力を形成できる
2. コミュニケーション増加により協力が強化される
3. 異なる分野のシナリオで一貫して協力行動が観察された
4. エージェントの行動が実際の人間の行動と類似
5. 指示なしの方がより自然な人間行動に近い結果に
6. LLMは長期的・複雑な競争シナリオで効果的に適応
7. 社会シミュレーションでは事前設定の最小化が重要
8. 本アプローチはシミュレーションと現実のギャップを縮小
9. LLMの熟考的推論評価の新手法として有効
10. LLMモデル間で協力形成パターンに違いあり
11. LLMは既存手法より速く協力行動を形成
12. 複雑な社会状況の精密シミュレーションの可能性を示す
- 参照論文URL： [https://arxiv.org/abs/2402.12327](https://arxiv.org/abs/2402.12327)
- コード： [https://github.com/wuzengqing001225/SABM\_ShallWeTeamUp](https://github.com/wuzengqing001225/SABM_ShallWeTeamUp)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[LLMの「頑固な知識」を変えることができるコンテキスト内編集手法（中国科学院大学Baolong Bi氏）](https://ai-data-base.com/archives/72359)

[心の理論をLLMエージェントに実装することの効果](https://ai-data-base.com/archives/72954)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)