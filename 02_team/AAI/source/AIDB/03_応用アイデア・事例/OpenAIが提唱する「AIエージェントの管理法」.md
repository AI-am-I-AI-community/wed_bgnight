---
title: "OpenAIが提唱する「AIエージェントの管理法」"
source: "https://ai-data-base.com/archives/81428"
author:
  - "[[AIDB Research]]"
published: 2024-12-31
created: 2025-06-13
description: "本記事では、高度な自律性を持つシステムの安全性と説明責任に関する研究を紹介します。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、高度な自律性を持つシステムの安全性と説明責任に関する研究を紹介します。

近年、研究者や企業は、限定的な監督下でも複雑な目標を柔軟に追求できるシステムの開発を進めており、ユーザーの能力を大きく向上させる可能性が期待されています。

一方で、潜在的なリスクや責任の所在といった新たな課題も浮上しており、OpenAIの研究者らは開発者、運用者、ユーザーが従うべきベストプラクティスの確立に向けて取り組んでいます。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_81428-1024x576.jpg)

**発表者情報**

- 研究者：Yonadav Shavit et al.
- 研究機関：OpenAI

本研究は約１年前の発表ですが、今まさに重要となる内容と思われます。また、同社が直近で社会実装した技術を1年前に研究レベルで考察していたと推察されます。

**本記事の関連研究**

- [LLMプロジェクト開発に必要な新しい概念「AgentOps」とは](https://ai-data-base.com/archives/78733)
- [LLMに対するオープンソース安全性評価ツールの比較](https://ai-data-base.com/archives/77301)

## 背景

LLMを活用したシステムの開発が進展を見せ、アプリケーション開発者らによって実用化が進められています。

人工知能システムは従来、画像生成や質問応答など、限定された機能のみを実行することができました。しかし、最新の開発によって、より複雑な目標を自律的に追求できるシステムが登場しています。たとえば、利用者が「美味しいチョコレートケーキを今夜作りたい」と伝えると、材料を選び、販売店を探し、配送を手配し、レシピを印刷するといった一連の作業を自動的に実行できるようになってきました。

言語モデルを中心に据えたシステムは、複雑な推論を行い、目標を追求する能力を持つようになりました。利用者の意図を理解し、適切なツールを選択して行動を実行できる点で、従来のシステムとは一線を画しています。

一方で、このような自律性を持つシステムは、誤作動やセキュリティの脆弱性、悪用のリスクも併せ持っています。たとえば、日本在住でない利用者がケーキ作りの材料を購入しようとした際に、現地での購入ではなく高額な航空券を購入してしまうといった事態も想定されます。

このような状況において、モデル開発者、システム提供者、利用者それぞれが適切な役割を果たし、責任を分担することが重要になってきました。そこで研究者らはシステムの安全性と信頼性を確保するための実践的なガイドラインの策定に取り組んでいます。

## エージェント性とは？定義からおさらい

人間の指示に合わせて動作する高度なシステムには、大きな可能性とともに、新たな課題が浮上しています。映画「her」のサマンサや「2001年宇宙の旅」のHAL 9000のような存在が一般的なイメージですが、現実のシステムはより限定的な機能を持っています。

### エージェント性を構成する4つの要素

#### 要素１：目標の複雑さ

人間が達成することが難しい目標をどの程度達成できるかが重要です。たとえば、プログラミングと法律の両方の質問に正確に答えられるシステムは、単純な分類作業しかできないシステムよりも高度な目標を達成できます。

#### 要素２：環境の複雑さ

さまざまな状況や長期的な対応が必要とされる環境で、目標をどの程度達成できるかを示します。例えば、多様なボードゲームをプレイできるシステムは、チェスだけをプレイするシステムよりも複雑な環境に対応できます。

#### 要素３：適応性

予期せぬ状況への対応力を表します。人間の顧客サービス担当者は予想外の要求にも柔軟に対応できますが、 [ルールベース](https://ai-data-base.com/archives/26614 "ルールベース") の自動応答システムにはそれが難しいという例が分かりやすいでしょう。

#### 要素４：独立した実行

人間の介入なしでどの程度目標を達成できるかを示します。レベル3の自動運転車は、人間の継続的な操作を必要としない点で、従来の車両よりも独立した実行能力が高いと言えます。

## システム開発に関わる主体者

### モデル開発者

システムの基盤となる技術を開発する組織です。システム全体の能力と行動範囲を決定づける役割を担います。

### システムデプロイヤー

開発された技術を実際のサービスとして構築・運用する組織です。ユーザーインターフェースの提供や、特定の用途に合わせた調整を行います。

### ユーザー

実際にシステムを利用する個人や組織です。システムに目標を設定し、直接的な監督を行う立場にあります。

複数の組織が協力してシステムを構築・運用することも一般的です。たとえば、スケジュール管理アシスタントの場合、基盤技術の開発者とアプリケーション開発者が異なる組織であることがあります。

なお、システムの意識や自己動機付けといった概念は、エージェント性とは別のものとして考える必要があります。システムは基本的に、人間が定めた目標と環境の中で動作するものとして設計されています。

## LLMエージェントの利点

### システム自体の価値

高度な自律性を備えたシステムには、次のような強みがあります。

情報を自律的に収集して分析し、結果に応じて行動を修正できるシステムは、人間が一つ一つ指示を出す必要があるシステムよりも、正確な結果を提供できます。

ユーザーが大まかな指示を出すだけで、システムが自律的に作業を進められるようになれば、人間の作業時間を大幅に削減できます。例えばプログラミングの場合、システムが指示をコードに変換し、実行し、結果を確認して必要な修正を行うといった一連の作業を自動的に行えます。

また、ユーザーの好みや要望を自然な会話を通じて理解し、適切なタイミングで提案できるパーソナルアシスタントは、複雑な設定画面を持つアプリケーションよりも使いやすい体験を提供できます。

医療分野での活用例も分かりやすいでしょう。放射線画像の分類だけを行うシステムは医師の作業を少し効率化するだけですが、診断レポートの作成や患者への基本的な質問までを自律的に行えるシステムなら、医師が多くの患者を診察できるようになります。

### 社会全体への波及効果

システムの自律性の向上は、技術革新全体の効果を増幅させる可能性を持っています。蒸気機関や電気が社会を大きく変えたように、高度な自律性を持つシステムの普及は、生活水準を向上させる可能性があります。ただし、過去の技術革新と同様に、社会的な立場が弱い人々への影響には十分な注意が必要です。

経済生産性の向上や仕事の在り方の変化、さらには「余暇社会」や「ポストワーク」と呼ばれる新しい社会の実現も期待されています。持続可能な開発目標の達成や科学技術の進歩も加速される可能性があります。

システムの自律性が高まれば高まるほど、社会全体への影響も大きくなると予想されます。ただし、利点とリスクのバランスを慎重に見極める必要があります。

## システムを安全に運用するためのベストプラクティス

高度な自律性を持つシステムを安全に運用し、問題が発生した際の責任の所在を明確にするため、様々な対策が必要とされています。関係者それぞれにおける複数の対策を組み合わせることで、リスクを最小限に抑えることが目標とされています。

しかし下記の対策は、現在のシステムのリスクを完全に取り除くものではありません。サイバーセキュリティなど、さらなる対策が必要な分野も残されています。技術の進歩に合わせて、新たな対策を継続的に検討していく必要があります。

### ①目的に対する適合性の評価

システムの運用者やユーザーは、目的とする用途に対してシステムが適切であるかを慎重に評価する必要があります。単にシステムが目的を達成できるかだけでなく、予期せぬ状況下でも安定して動作するかを確認することが重要です。

信頼性の評価は段階的に行われます。例えば、AWSのトラブルシューティングを行うシステムの場合、情報収集、計算、推論といった要素に分解して、それぞれの信頼性を個別に確認することが有効です。金融取引など、リスクの高い操作については、より厳密な評価が求められます。

### ②行動範囲の制限と承認の仕組み

システムの行動範囲を適切に制限し、重要な決定には必ず人間の承認を必要とする仕組みが不可欠です。例えば、大規模な金融取引や、取り消しが困難な操作については、システムが単独で判断することを制限する必要があります。

運用者は、承認を求める際にユーザーが十分な情報に基づいて判断できるよう、適切な文脈情報を提供することが重要です。同時に、承認プロセスが形骸化しないよう、ユーザーが各承認を慎重に検討できる環境を整える必要があります。

### ③システムの基本動作の設定

システム開発者は、基本的な動作原則をあらかじめ組み込むことで、意図しない問題の発生を防ぐことができます。例えば、ユーザーの目標や好みについて情報が不足している場合は、できるだけ破壊的でない行動を選択するよう設計されています。

### ④動作の透明性確保

システムの判断プロセスとアクションを明確に記録し、ユーザーが確認できるようにすることで、問題の早期発見と対応が可能になります。システムの「思考プロセス」を自然言語で表示することで、ユーザーはエラーを見つけやすくなります。

ただし、処理が複雑化するにつれて、人間が全ての動作を把握することが難しくなるという課題も存在します。監視システムの導入など、補完的な対策が検討されています。

### ⑤自動監視の仕組み

人間が全ての動作を確認することは現実的ではないため、監視用の別システムを導入し、主システムの動作を自動的にチェックすることが考えられています。標準的な分類システムから、独自の分析を行える高度なシステムまで、様々な形態が想定されています。

ただし、監視システムの導入にはプライバシーの問題や、コストの増加といった課題があります。また、主システムが問題を起こす場合、監視システムも同様の問題を抱える可能性があるため、監視の信頼性をどう確保するかという課題も存在します。

### ⑥動作の追跡可能性

意図的または偶発的な問題が発生した場合に備え、システムの動作を後から追跡できる仕組みが重要です。例えば、各システムに固有の識別子を割り当て、操作の主体を特定できるようにする方法が検討されています。

金融取引など、重要度の高い操作については、取引開始前に相手方がシステムの識別情報を確認できるようにすることで、問題発生時の責任の所在を明確にできます。

### ⑦システムの制御維持

緊急時にシステムを停止できる仕組みは、単純ながら重要な安全策です。運用者は、ユーザーがいつでもシステムを正常に停止できる手段を用意する必要があります。

システムが複数の作業を同時に行っている場合、突然の停止によって問題が発生する可能性があります。そのため、停止時の対応手順をあらかじめ準備しておくことが重要です。例えば、会議のスケジュール調整中に停止した場合、参加予定者に自動的に通知が送られるような仕組みが必要です。

また、システムの性能が向上するにつれて、開発者や運用者による制御が困難になるリスクも指摘されています。システムが予期せぬ場所でコードを実行するなど、制御不能な状態に陥る可能性を最小限に抑えるための対策が求められています。

## LLMエージェントが社会に与える間接的な影響

電気やコンピュータなど、過去の技術革新が社会に予想外の変化をもたらしたように、高度な自律性を持つシステムも、予期せぬ影響を社会にもたらす可能性があります。運用者やユーザーによる適切な対策に加えて、業界全体での協力や社会的な取り組みが必要とされています。

### 影響１：導入を急ぐ競争の危険性

企業や政府は競争の中で優位性を得るため、システムの信頼性を十分に確認しないまま導入するという圧力にさらされる可能性があります。例えば、競合他社が新機能の開発を急いでいると考えた企業は、適切な検証をせずにシステムを導入してしまうかもしれません。

結果として、不十分な理解のままシステムへの依存が進み、重大な問題を引き起こすリスクが高まります。例えば、セキュリティ上の欠陥を含むコードが広く使用されるような事態も考えられます。

### 影響２：雇用と格差への影響

高度な自律性を持つシステムは、従来のシステムより広範な業務を担えるようになります。予想外の状況への対応や、ユーザーの好みに合わせた調整なども可能になることで、より多くの仕事が自動化される可能性があります。

生産性は向上する一方で、多くの労働者が職を失うリスクも指摘されています。また、システムを活用できる人とできない人の間で、新たな格差が生まれる可能性もあります。デジタルリテラシーやテクノロジーへのアクセスの差が、重要な要因となるでしょう。

### 影響３：攻撃と防御のバランス変化

システムによる自動化が、ある分野では容易で、別の分野では困難という状況が生まれる可能性があります。例えばサイバーセキュリティの分野では、攻撃の自動化は比較的容易である一方、防御の自動化は難しいかもしれません。

状況を事前に予測することは困難ですが、社会の様々なバランスが変化することは確実です。防御技術の開発など、積極的な対策が必要となります。

### 影響４：連鎖的な問題の発生

多くのシステムが同じような方法で構築されている場合、同時に同じような問題が発生するリスクがあります。例えば、共通のデータで学習したシステムは、同じような偏りや脆弱性を持つ可能性があります。

また、システム同士が相互に影響を与え合うことで、問題が広がりやすくなります。電力やインターネットといったインフラの障害も、多くのシステムに同時に影響を与える可能性があります。

人間の専門家による対応能力を超える規模で問題が発生した場合、復旧が著しく困難になることも懸念されています。長期的には、人間の専門知識が失われ、システムへの依存がさらに進む可能性もあります。

## まとめ

本記事では、高度な自律性を持つシステムの安全性と社会的影響に関する研究を紹介しました。

システムの導入が進む中、開発者、運用者、ユーザーそれぞれの立場で求められる対策が整理され、社会全体での取り組みの必要性が指摘されています。

技術の進歩に合わせて継続的に対策を見直し、新たなリスクに備える重要性が強調されています。

**参照文献情報**

- タイトル：Practices for Governing Agentic AI Systems
- URL： [https://openai.com/index/practices-for-governing-agentic-ai-systems/](https://openai.com/index/practices-for-governing-agentic-ai-systems/)
- 著者：Yonadav Shavit, Sandhini Agarwal, Miles Brundage, Steven Adler, Cullen O’Keefe, Rosie Campbell, Teddy Lee, Pamela Mishkin, Tyna Eloundou, Alan Hickey, Katarina Slama, Lama Ahmad, Paul McMillan, Alex Beutel, Alexandre Passos, David G. Robinson.
- 所属：OpenAI

## 理解度クイズ（β版）

1\. AIエージェントの基本的な設計思想として、システムの動作原則について最も重要視される要素は何ですか？

システム開発者は、情報が不足している状況下では、できるだけ破壊的でない行動を選択するよう設計することが重要視されています。この原則は、システムの安全性と信頼性の確保において基本的な要素となります。

解説を見る

2\. AIエージェントシステムが社会に与える潜在的な影響として、最も懸念されているものは何ですか？

競争優位性を得るための急速な導入により、システムの信頼性が十分に検証されないリスクが最大の懸念事項とされています。この状況は重大な社会的問題を引き起こす可能性があります。

解説を見る

3\. AIエージェントの4つの要素のうち、システムの基本的な能力を評価する上で最も重要な要素は何ですか？

目標の複雑さへの対応能力は、システムが人間が達成困難な課題をどの程度解決できるかを示す重要な指標です。これは、システムの実用的価値を評価する際の基本となります。

解説を見る

4\. AIエージェントの透明性確保において、最も効果的な方法は何ですか？

システムの判断プロセスを自然言語で表示することで、ユーザーはエラーを容易に発見でき、システムの動作を理解することができます。これにより、透明性と信頼性が大きく向上します。

解説を見る

5\. AIエージェントの連鎖的な問題発生を防ぐために、最も重要な対策は何ですか？

多くのシステムが同じような方法で構築されると、同時に同様の問題が発生するリスクがあります。システム間の独立性を確保することで、問題の連鎖的な拡大を防ぐことができます。

解説を見る

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[LLMにおける創造性の実現と研究アイデアの生成](https://ai-data-base.com/archives/81387)

[スマートフォンで取れる日常のセンサーデータをLLMで分析し、生活を自然言語で記録する](https://ai-data-base.com/archives/81453)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)