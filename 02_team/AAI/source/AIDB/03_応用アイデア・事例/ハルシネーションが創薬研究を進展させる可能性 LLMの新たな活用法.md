---
title: "ハルシネーションが創薬研究を進展させる可能性 LLMの新たな活用法"
source: "https://ai-data-base.com/archives/83053"
author:
  - "[[AIDB Research]]"
published: 2025-01-30
created: 2025-06-13
description: "本記事では、LLMにおける「ハルシネーション」が創薬研究においては良い影響を与える可能性を示した研究を紹介します。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、LLMにおける「ハルシネーション」が創薬研究においては良い影響を与える可能性を示した研究を紹介します。

LLMは科学分野での活用が進む一方で、入力に対して事実とは異なる情報を生成してしまう「ハルシネーション」が問題視されてきました。しかし研究チームは、このハルシネーションが創薬に必要な創造性を促進する可能性に着目し、その効果を体系的に検証しています。

なお、LLMのハルシネーションという用語の使用には議論があります。ハルシネーションは人工知能が事実に基づかない情報を生成する現象を指しますが、その呼び方自体に対する見方は分かれています。現在では技術的な文脈で広く使用されており、AIの重要な課題の一つとして認識されています。本記事でもこの用語を引き続き使用します。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_83053-1024x576.png)

**発表者情報**

- 研究者：Shuzhou Yuan et al.
- 研究機関：Dresden University of Technology

論文情報詳細は記事の下部に記載されています。

## 背景

LLMは科学分野における専門的な用途でも、活用され始めています。材料科学、生物学、化学など、多岐にわたる分野で研究ツールとして利用が進められています。

ただ、LLMには「ハルシネーション」と呼ばれる問題が存在します。入力されたソーステキストに関して、もっともらしいものの事実とは異なる情報や、無関係な内容を生成してしまう現象です。この問題はLLMの利用における信頼性や実用性を損なうとして懸念が示されています。

しかし一方で、ハルシネーションが創造性を促進する可能性も指摘されています。

創造性とは、既存の知識を単に取り出すだけでなく、組み合わせたり拡張したりすることで生まれます。実はこのプロセスは、ハルシネーションと類似した性質を持っています。

創造性が重要となる分野の例として、創薬が挙げられます。創薬プロセスでは、膨大な数の潜在的な薬剤を評価し、長期的な実験試験が必要とされ、時間とコストがかかります。これまでにも機械学習を活用して効率化が図られてきましたが、新薬の発見には専門知識と、新しいパターンを見出す創造性の両方が不可欠です。

研究者らは、LLMのハルシネーションが高度な機能や抽象的な性質を持つ分子の発見に貢献する可能性に着目し、創薬におけるハルシネーションの効果を体系的に検証することに取り組みました。

以下で詳しく紹介します。

## 分子の説明文を生成するプロンプトの設計

研究チームは、創薬におけるハルシネーションの効果を検証するため、まず「分子構造をどのように言語化するか」という課題に取り組みました。分子構造を自然言語で記述することができれば、LLMの能力を活用できる可能性が広がります。しかし、その過程でハルシネーションが発生することが予想されます。研究チームは、むしろそのハルシネーションを積極的に活用する方針で実験を設計しました。

### 分子を自然言語で表現する意義

分子を自然言語で表現することは、科学分野において大きな利点をもたらすことが先行研究で示されています。たとえば、化学式だけでなく「この分子は環状構造を持ち…」といった説明文があることで、分子の特徴をより深く理解できます。

### 分子説明文の生成方法

研究チームは、SMILES形式（分子構造を文字列で表現する形式）で書かれた分子を自然言語の説明文に変換する実験を行いました。システムには「創薬の専門家」という役割が与えられ、分子の説明を生成するよう指示されます。

### プロンプトの具体的な構成

プロンプトは以下のような形式で設計されました。

```js
システム：あなたは創薬の専門家です
ユーザー：[SMILES] この分子を自然言語で説明してください
```

### 生成された説明文の評価方法

生成された説明文は、複数のモデルを使って評価されました。 [MolT5](https://arxiv.org/abs/2204.11817) （分子と説明文のペアで学習された専門モデル）の生成した説明文を基準として、事実との一致度が測定されます。

### 評価結果の解釈

測定の結果、ChemLLM以外のほとんどのLLMは、参照用の説明文と比較して10%未満の一致度しか示しませんでした。化学の専門知識で訓練された [ChemLLM](https://arxiv.org/abs/2402.06852) でさえ、約20%の一致度に留まりました。つまり、LLMは分子について説明する際に多くのハルシネーション（事実とは異なる情報）を含んでいることが明らかになりました。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_83053_1.png)

LLMが生成する分子の自然言語記述において、ChemLLMを除くすべてのモデルで 10% 以下のスコアであり、高い幻覚率を持つ。

## 本研究における創薬タスクの定義

研究チームは次のステップとして、その説明文をどのように活用するかという課題に取り組みました。LLMの特性を考慮しつつ、創薬における実用的な評価方法を確立する必要がありました。そこで、分子の持つ特定の性質（例：抗HIV活性など）を予測する分類タスクが設計されました。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_83053_2-1024x468.png)

HIV データセットの分子を例に、評価手法を図示。SMILES 文字列から LLM に自然言語記述を生成させ、その記述をプロンプトに追加し、特定の分子特性を予測する。回答は「Yes」または「No」に制限される。

### タスクの基本設計

創薬に関連する問題は、分類タスクとして定式化されました。たとえば「ある分子がHIVウイルスの複製を阻害する能力を持っているか」といった質問に対して、「はい」か「いいえ」で回答する形式です。

### LLMのための設定調整

実験では、LLMに適した形でタスクを設計する必要がありました。通常の分類問題とは異なり、LLMは次のトークン（単語や文字）を予測する形で回答を生成します。そのため、プロンプトの中で注意深く指示を与える必要があります。

### 回答の制御方法

LLMからの回答は「Yes」または「No」に限定されるよう設計されました。分類問題を単純化することで、回答の評価が容易になり、また結果の信頼性も高まります。LLMは最も確率の高い回答を選択する形で判断を下します。

## 実験設計

上述のタスクを用いて、研究チームは分子の説明文がLLMの判断能力に与える影響を体系的に調査することにしました。以下では、具体的な実験の設計について詳しく見ていきます。

### 基本設定

実験では、プロンプトの基本構造（\[分子構造\]\[説明文\]\[タスク指示\]）は維持したまま、説明文の部分を様々に変更して性能を比較します。

### 比較のためのベースライン設定

実験では2種類のベースラインが設定されました。

SMILESベースライン：説明文を空にして、分子構造のみで判断を行う場合  
MolT5ベースライン：専門モデルが生成した正確な説明文を使用する場合

### LLMによる説明文生成実験

ベースラインに加えて、様々なLLMに説明文を生成させて性能を評価します。実験では2つのパターンが試されました。

- LLMが自身で生成した説明文を使って判断する場合
- 他のLLMが生成した説明文を使って判断する場合

### データセットの選択

[MoleculeNet](https://moleculenet.org/) というベンチマークから5つのデータセットが選ばれました。すべて生体内での分子の振る舞いに関連する分類問題です。

HIVデータセット：分子のHIV複製阻害能力を判定  
BBBPデータセット：分子の血液脳関門透過性を判定  
Clintoxデータセット：臨床試験での毒性による失敗を判定  
SIDERデータセット：医薬品の副作用を判定  
Tox21データセット：12種類の毒性を判定

### データの分割方法

データセットは訓練用と評価用に分割されました。HIVとBBBPでは分子の2次元構造に基づく分割が、他のデータセットではランダムな分割が採用されています。評価用には全体の10%が使用されました。

### 評価指標

性能評価にはROC- [AUC](https://ai-data-base.com/archives/26250 "AUC") スコアが使用されました。予測の正確さを0から1の値で表す指標で、0.5がランダムな予測、1.0が完璧な予測を意味します。

### 実験に使用されたLLM

7種類のLLMが実験に使用されました。

- 一般用途のオープンソースモデル4種（Llama-3-8B, Llama-3.1-8B, Ministral-8B, Falcon3-Mamba-7B）
- 化学に特化したモデル1種（ChemLLM-7B）
- OpenAIのモデル2種（GPT-3.5-turbo, GPT-4o）

オープンソースに関してはパラメータ数7-8B（70億）程度のモデルが選ばれ、公平な比較が可能になるよう配慮されています。

## 主な実験結果

実験の設計に従って一連の検証が実施され、興味深い結果が得られました。以下では、主な実験結果とその分析について詳しく見ていきます。

### 実験における問い

研究チームは2つの重要な問いについて検証を行いました。

1. ハルシネーションを含む説明文は、LLMの性能を向上させるのか
2. どのLLMが生成したハルシネーションが最も効果的なのか

### ハルシネーションの効果検証

実験結果から、Llama-3-8Bを除くすべてのLLMで、ハルシネーションを含む説明文を使用した場合の性能が向上しました。SMILESのみの場合と比較して、予測精度が改善されています。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_83053_3-1024x546.png)

LLMのROC- AUC スコアを比較。GPT-4o による幻覚を含むプロンプトが最も大きな改善をもたらし、Llama-3.1-8B は 18.35% の向上を記録。

### 具体的な性能向上

最も顕著な改善を示したのはLlama-3.1-8Bで、GPT-3.5が生成した説明文を使用した場合、ベースラインと比較して18.35%の性能向上が見られました。また、Falcon3-Mamba-7Bも約10%の性能向上を示しました。

### 最も効果的なハルシネーション生成源

GPT-4oが生成したハルシネーションが、最も一貫した性能向上をもたらしました。平均して4.07%のSMILESベースラインからの向上と、4.54%のMolT5ベースラインからの向上が観察されました。GPT-3.5も同様に良好な結果を示し、平均1.6%から2.08%の性能向上が確認されました。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_83053_4.png)

異なる LLM が生成した幻覚の影響を比較。GPT-4o による幻覚が最も大きな性能向上をもたらし、次いで GPT-3.5 が有効であることが示されている。

### 興味深い発見

化学の専門知識で訓練されたChemLLMでさえ、ハルシネーションを含む説明文から恩恵を受けることが判明しました。専門モデルであっても、一般的なLLMが生成した説明文が予測精度の向上に寄与する可能性が示されました。

以上のように、ハルシネーションを含む説明文は、予想に反して分子の性質予測に有用であることが示されました。正確さを重視した従来の考え方に一石を投じる結果となり、創薬研究におけるLLMの新たな活用可能性が示唆されています。

## 分析

上記の実験結果は興味深い発見をもたらしましたが、より詳細な分析が必要でした。研究チームは特に、モデルサイズ、生成パラメータ、使用言語といった要因に着目して、追加の実証的分析を行いました。

### 分析の観点

主要な実験結果を踏まえ、研究チームは3つの要因について詳細な分析を行いました：モデルサイズ、生成時の温度設定、説明文の言語の違いです。最も良好な結果を示したLlama-3.1-8Bを中心に分析が進められました。

### モデルサイズの影響

Llamaモデルの4つのサイズ（1B、3B、8B、70B）で比較実験が実施されました。結果として、モデルサイズが大きくなるほど、ハルシネーションを含む説明文の効果が高まることが判明しました。ただし、8Bから70Bへの拡大では顕著な改善は見られず、8B程度で効果が頭打ちになる可能性が示唆されています。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_83053_6.png)

モデルサイズの違いが幻覚の影響に与える影響。Llama-3 の異なるサイズのモデルを比較し、サイズが大きいほど幻覚による性能向上が見られるが、8B 以上で効果が頭打ちになる傾向がある。

### 温度パラメータの影響

生成時の温度設定（0.1から0.9まで）を変更して実験が行われました。温度が高いほどより多様な説明文が生成される一方で、事実との一致度は低下する傾向が確認されました。しかし興味深いことに、温度の違いは最終的な性能にはあまり大きな影響を与えませんでした。54.20%から57.10%の範囲に収まっています。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_83053_5.png)

生成温度の違いによる幻覚の影響。温度が高いほど事実整合性スコアが低下し、幻覚が増える傾向があるが、モデルの性能向上には大きな影響を与えない。

### 言語による違い

6つの言語（英語、中国語、ドイツ語、フランス語、日本語、スペイン語）で説明文を生成する実験も行われました。予想外にも、中国語での説明文が最も高い性能（平均ROC- [AUC](https://ai-data-base.com/archives/26250 "AUC") 57.81%）を示しました。事前学習に含まれていない言語であるにもかかわらず、良好な結果が得られた点は注目に値します。

### 言語別の特徴

個々のデータセットでは、最適な言語が異なることも明らかになりました。

- HIVとBBBP：英語が最も効果的
- Clintox：フランス語が最も効果的
- SIDER：ドイツ語が最も効果的
- Tox21：スペイン語が最も効果的

中国語の説明文には、ピンイン（ローマ字表記）と英語での補足説明が多く含まれており、高い性能の要因となった可能性が指摘されています。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_83053_7.png)

異なる言語で生成された幻覚の影響。中国語で生成された幻覚が最も大きな性能向上をもたらし、英語、フランス語がそれに続く。一方で、日本語での生成は最も低い効果を示す。

このように、実験を通じて、ハルシネーションの効果は複数の要因に影響されることが分かりました。モデルサイズは重要な要因である一方、温度設定の影響は限定的でした。また、言語の選択が予想以上に重要な要因であることが明らかになりました。

## ケーススタディ

研究チームはより深い洞察を得るため、具体的な事例の詳細な分析に着手しました。特に、最も顕著な性能向上を示したモデルの組み合わせに焦点を当てて、ケーススタディを実施しました。

### 分析対象の選定

研究チームは、GPT-3.5が生成した説明文と、それを利用したLlama-3.1-8Bの予測を詳しく分析しました。Llama-3.1-8Bは、GPT-3.5の説明文を使用した場合に最も良い性能を示したモデルです。

### サンプル分子の分析

分析対象となった分子（CC1(Br)C(=O)NC(=O)N(C2CC(O)C(CO)O2)C1N=\[N+\]=\[N-\]）について、生成された説明文には明らかなハルシネーションが含まれていました。たとえば、分子構造には水素原子が明示的に含まれていないにもかかわらず、「水素原子で構成されている」という誤った記述が見られました。

### 注目すべき特徴

生成された説明文には2種類の興味深い特徴が観察されました。

1. 明らかな事実誤認（水素原子に関する記述など）
2. 主観的で関連性の薄い情報（「創薬研究への応用可能性がある」など）

### 注意スコアの分析

Llama-3.1-8Bの注意スコア（モデルが文中の各要素にどの程度注目しているか）を分析したところ、停止語を除いて、ハルシネーションを含む部分に高い注目が集まっていることが判明しました。特に分子の構成要素（炭素、水素、酸素など）の説明と、応用可能性に関する記述に高いスコアが付与されていました。

### 性能向上の理由

研究チームは、ハルシネーションによる性能向上の理由について、以下のような解釈を示しています。

”主観的ではあるものの誠実な情報（「創薬研究への応用可能性」など）が含まれることで、モデルの予測に対する確信度が高まり、結果として全体的な性能が向上する可能性がある”。

以上のように、ケーススタディを通じて、ハルシネーションが必ずしも有害ではなく、むしろやはり予測タスクにおいて補助的な役割を果たす可能性が示されました。ただし、どのような種類のハルシネーションが有用なのかについては、さらなる研究が必要とされています。

## まとめ

本記事では、LLMのハルシネーションが創薬研究において有用である可能性を示した研究を紹介しました。

研究チームによる7種類のLLMと5つのデータセットを用いた実験により、ほとんどのLLMでハルシネーションを含む説明文を利用した場合の性能向上が確認されました。

今後はハルシネーションが創造性を促進するメカニズムのさらなる解明が期待され、LLMを活用した医薬品開発の新たな可能性が拓かれるかもしれません。

**参照文献情報**

- タイトル：Hallucinations Can Improve Large Language Models in Drug Discovery
- URL： [https://arxiv.org/abs/2501.13824](https://arxiv.org/abs/2501.13824)
- 著者：Shuzhou Yuan, Michael Färber
- 所属：Dresden University of Technology

## 理解度クイズ（β版）

1\. この研究で、ハルシネーションを含む説明文が創薬研究に与えた主な影響は何ですか？

ほとんどのLLMで、ハルシネーションを含む説明文を使用した場合に予測精度が向上しました。化学の専門知識で訓練されたChemLLMでさえ、一般的なLLMが生成した説明文から恩恵を受けることが判明しました。

解説を見る

2\. 研究チームはLLMの出力する説明文の事実との一致度について、どのような発見をしましたか？

ChemLLM以外のLLMは参照用の説明文と比較して10%未満の一致度しか示しませんでした。化学専門のChemLLMでさえ約20%の一致度に留まりました。

解説を見る

3\. 異なる言語での実験結果について、最も意外な発見は何でしたか？

事前学習に含まれていない言語であるにもかかわらず、中国語での説明文が平均ROC- [AUC](https://ai-data-base.com/archives/26250 "AUC") 57.81%と最も高い性能を示しました。データセットによって最適な言語が異なることも判明しました。

解説を見る

4\. モデルサイズと性能の関係について、研究で明らかになった点は何ですか？

モデルサイズが大きくなるほど性能は向上しましたが、8Bから70Bへの拡大では顕著な改善は見られませんでした。8B程度でハルシネーションの効果が頭打ちになる可能性が示唆されました。

解説を見る

5\. 研究の結果から、創薬研究におけるLLMの活用について導き出された主な示唆は何ですか？

ハルシネーションは従来は問題視されていましたが、創造性を促進する可能性があることが示されました。特に創薬研究において、新しいパターンを見出すための有用なツールとなる可能性が示唆されました。

解説を見る

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[LLMにおける「計画立案能力」を高めるプロンプト手法の新提案](https://ai-data-base.com/archives/82983)

[OpenAI o3-miniの安全機能に関する大規模検証　1万件超のテスト結果](https://ai-data-base.com/archives/83156)　

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)