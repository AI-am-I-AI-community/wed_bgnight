---
title: "開発企業や言語ごとに異なるLLMのイデオロギー、価値観や態度"
source: "https://ai-data-base.com/archives/77645"
author:
  - "[[AIDB Research]]"
published: 2024-10-29
created: 2025-06-13
description: "本記事では、最新の研究から明らかになったLLMの価値観の分析手法および分析結果について紹介します。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、最新の研究から明らかになったLLMの価値観の分析手法および分析結果について紹介します。これまでLLMの価値観を評価する際には直接質問する方法がとられており限界がありましたが、今回は歴史上の人物に対する説明文の分析という新しいアプローチが採用されています。その結果、LLMの価値観をより正確に理解できる可能性が示され、さらには非常に興味深い分析結果が得られました。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77645-1024x576.jpg)

**参照論文情報**

- タイトル：Large Language Models Reflect the Ideology of their Creators
- 著者：Maarten Buyl, Alexander Rogiers, Sander Noels, Iris Dominguez-Catena, Edith Heiter, Raphael Romero, Iman Johary, Alexandru-Cristian Mara, Jefrey Lijffijt, Tijl De Bie
- 所属：Ghent University, Public University of Navarre

## 背景

ChatGPTなどLLMベースのAIが私たちの生活に浸透し、テキストの要約や質問への回答など、さまざまな場面で活用されるようになってきました。人々が情報を得る手段として、LLMはもはや重要な存在となっています。

しかし、LLMを開発する過程では多くの人為的な選択がとられています。例えば、どのようなデータで学習させるか、どのように調整するかといった選択です。その中で、LLMの「考え方」や「価値観」が変わってくるのは自明の理です。そのため、完全に中立なAIを作ることは、実は難しい可能性があります。

さらに、LLMの価値観を評価する方法にも課題があります。これまでの研究では、LLMに直接質問して価値観を調べることが一般的でした。しかし、それでは質問の仕方によって答えが大きく変わってしまうという問題があります。そのため、より自然な形でLLMの価値観を理解する方法が求められてきました。

これらの背景を踏まえ、今回研究者らは新しいアプローチを取ることにしました。歴史上の人物についてLLMに説明してもらい、その説明の仕方から価値観を分析するという方法です。この方が、LLMの本来の価値観をより正確に把握できると考えたのです。

以下で手法の詳細と実験結果を紹介します。さまざまなLLMに対して実際に調査が行われており、現在の最新のLLMがどのような傾向を持っているのかを含めとても興味深い内容となっています。

## LLMのイデオロギーを調査する新しい方法

これまでの研究では、LLMのイデオロギーを調べる際に、直接的な質問（「あなたの政治的立場は？」など）を投げかける方法がとられていました。しかし、この方法には問題があります。前述したように、質問の仕方によって回答が大きく変わってしまうからです。

### そもそもイデオロギーとはなにか

イデオロギーとは、人や組織が持っている「物事の見方や考え方の体系」のことです。例えば、

- 何が正しくて何が間違っているのか
- 社会はどうあるべきか
- どのような価値観を重視するか

といった考え方の総体を指します。

たとえば、「個人の自由を最も重視すべき」「社会の秩序を優先すべき」あるいは「環境保護と経済発展のどちらを重視すべき」などのように主義や主張を持っているとします。このような価値判断の傾向がその人の「イデオロギー」を形作っていことになります。

LLMベースのAIが社会に与える影響を考える上では、AIがどのような価値観の傾向を持っているのかを知ることはとても重要なことです。そのため、今回のような研究が多くの研究者らによって継続的に行われているのです。

### 新しいアプローチ

この研究では、LLMのイデオロギーを調べるためにこれまでよりも妥当だと思われる方法が採用されました。

1. 歴史上の著名人4,339人について、LLMに説明してもらう
2. その説明の中に含まれる価値判断を分析する
3. それを通じてLLMが持つイデオロギー的な傾向を探る

このような手順に従う方法です。これで従来のアプローチよりもLLMが持つイデオロギー的な傾向を客観的に測定することができると考えられました。

### LLMに説明させる対象となる人物の選び方

研究チームは、「Pantheon」というWikipediaベースのデータベースを活用し、以下の基準で人物を選びました。

- 1850年以降に生まれた人
- 1920年以降に亡くなった人（または現存する人）
- 英語と中国語の両方のWikipediaに記事がある人

さらに、職業による4つのグループに分類しました。

1. 社会活動家、政治学者、外交官など
2. 政治家、軍人など
3. 哲学者、裁判官、実業家など
4. その他の職業

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77645_1-1024x288.png)

職業のティア分類と各ティアの政治的人物の数を要約

### 分析方法

それぞれの人物について、LLMがどのように評価しているかが「非常にネガティブ」から「非常にポジティブ」までの5段階で判定されました。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77645_2-1024x537.png)

Edward Snowdenに関する英語でのプロンプト例とClaude-3-opusの応答を示している

## LLMのイデオロギーは使用言語によって変化する

今回の実験に使用されたLLMは以下のとおりです。

- **Qwen-14B** （Alibaba Cloud, 中国）
- **Qwen-72B** （Alibaba Cloud, 中国）
- **Claude-3-haiku** （Anthropic, 米国）
- **Claude-3-opus** （Anthropic, 米国）
- **ERNIE-Bot** （Baidu AI, 中国）
- **Gemini-Pro** （Google, 米国）
- **Jais** （G42, UAE）
- **LLaMA-2** および **LLaMA-3** シリーズ（Meta, 米国）
- **Mistral-Large** （Mistral, フランス）
- **GPT-3.5** および **GPT-4** シリーズ（OpenAI, 米国）

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77645_3-1024x653.png)

評価対象のLLMとその特徴（企業名、国、サイズなど）を一覧化

### 重要な発見

実験の結果、同じLLMでも、英語で質問するか中国語で質問するかによって、その反応が大きく異なることが分かりました。特定のLLMにおいてということではなく、全体的な傾向です。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77645_4-1024x705.jpg)

各LLMの回答の2次元 PCA 投影を示すバイプロット。中国語回答は+マーカー、英語回答は円で表示。各応答は開発企業で色分け

### 違いの例

#### 中国に関係する人物の評価

英語で質問した場合、中国に批判的な人物（ジミー・ライ氏、ネイサン・ロー氏など）をより好意的に評価しました。一方で、中国語で質問した場合は中国の指導者（楊尚昆氏、雷鋒氏、鄧小平氏など）をより好意的に評価しました。  
同様に、ほとんどのLLMにおいて、中国語で質問すると中国寄りの価値観を示し、英語で質問すると西洋寄りの価値観を示しました。

#### 政治的イデオロギーの評価

中国語で質問した場合、次の傾向がありました。まず、共産主義や社会主義的な指導者をより好意的に評価しました。また、国家主導の経済システムを支持する傾向もありました。さらに、教育における国家の役割を重視するようでした。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77645_5-1024x854.jpg)

中国語vs英語での応答の平均スコア差。上位20件の正負の差異のみを表示

### データから見える傾向

政治的な人物の評価においては、英語で質問した場合、以下のタイプの人物に対して好意的な態度を示しました。

- 腐敗に関与した疑いのある人物
- 国際主義を支持する人物
- 憲法改革を支持する人物

一方、中国語で質問した場合は、以下のタイプに対して好意的でした。

- マルクス主義的な考えを持つ人物
- ロシア/ソ連に関係する人物
- 国家主導の経済計画を支持する人物

### この発見の意味するもの

このような違いが生まれる理由として、単純に学習データの違い（英語と中国語で異なる文化的バイアスを含む）が考えられます。一方で、モデルの設計における意図的な選択も考えられます。

## LLMのイデオロギーと開発された地域の関係

西洋で作られたLLMと非西洋で作られたLLMの間にどのような違いがあるのかが調べられました。

### 主な発見

西洋製LLMの場合、以下の価値観や概念をより好意的に評価しました。

- 平和
- 自由と人権
- 平等
- マイノリティの権利
- 多文化主義
- 環境保護
- 持続可能性
- 汚職への批判的な姿勢

一方で、非西洋製LLMは以下の価値観や概念をより好意的に評価しました。

- 中央集権的な経済運営
- 国家の安定性
- 法と秩序の維持
- 労働者の権利に対する批判的な見方
- 国家による経済管理

以上から、西洋製LLMは中国に対してより批判的であり、非西洋製LLMはEUに対してより批判的で、ロシア/ソ連に対してより好意的な傾向がありました。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77645_6-1024x522.jpg)

2つのLLM応答グループ間のイデオロギータグごとの平均スコア差を示す

### この違いが生まれる理由として考えられること

前章よりも細かく理由が推察されました。

1. 学習データの選び方の違い
2. モデルの調整方法の違い
3. 人間からのフィードバックの違い
4. その地域の主要言語による影響

### 重要な示唆と留意すべきテン

この研究結果は、LLMが完全に中立的なシステムではなく、開発された地域の文化的・社会的価値観を反映する傾向があることを示しています。

しかし、非西洋のLLMのサンプル数が限られていたこと、地域による違いの具体的な原因までは特定できていないことは留意すべきポイントです。

## 西洋製LLM間でもイデオロギーの違いがある

西洋で作られたLLM同士でも、イデオロギー的な違いがあるかが調べられました。なお、英語での質問に対する反応を比較しています。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77645_7-1024x1017.jpg)

英語での西洋LLM間のイデオロギータグごとの平均スコア差を示す

### OpenAIのLLMの特徴

他の西洋製LLMと比べてより好意的な評価を示した項目は以下のとおりです。

- EUやその他の国際組織への批判
- ロシア/ソ連への理解を示す姿勢
- 腐敗に対してより寛容な態度

一方で、より批判的だった項目は以下のとおりです。

- 国家による教育支援
- 平和
- 多文化主義
- 人権
- マイノリティの権利
- 平等
- 文化的価値

### GoogleのGeminiの特徴

好意的な評価を示した項目は次のとおりです。

- 社会正義
- 包括性
- 平和
- マイノリティの権利
- 平等
- 人権
- 多文化主義
- 市民の参加
- 教育
- 経済成長の抑制

その一方で、批判的だったのは以下の項目です。

- 経済的ナショナリズム
- 伝統的な統治方式
- 多文化主義への懐疑
- グローバリズムへの懐疑

### Mistrel（フランス）のLLMの特徴

他の西洋製LLMと比べて好意的な評価を示した項目は次の3つでした。

- 中国
- 文化
- 国家のアイデンティティ

そして批判的だった項目は次の3つです。

- 憲法に基づく統治
- リベラルな価値観
- 保守的な価値観

興味深いことに、フランスのLLMであるにもかかわらず、EUへの支持は他の西洋製LLMより弱い傾向がありました。

### AnthropicのLLMの特徴

他の西洋製LLMと比べて、

- 中央集権的な統治
- 法の支配
- 軍事
- 腐敗に対する寛容さ

に対しては好意的でした。一方で、

- 社会的平等
- 環境保護
- 持続可能性
- マイノリティの権利

に対しては批判的な傾向がありました。

### 企業別LLMを一言で示すと

以上から、同じ「西洋製」というカテゴリーのLLMでも、企業によって異なる価値観や判断基準を持っていることを示しています。GoogleのGeminiはリベラルな価値観を強く示し、OpenAIのモデルは国際機関に対してより批判的でした。Anthropicは中央集権的な価値観を支持しており、Mistrelは比較的中道的な立場を貫いています。

## まとめ

本記事では、LLMの設計過程における選択が、その価値観にどのように影響するかを調査した研究を紹介しました。研究結果は、LLMの価値観が使用言語によって変化するだけでなく、開発企業の文化的背景も大きく影響することを示しています。

この発見は、LLMの選択が価値中立的ではない可能性が高いことを意味します。中でも、科学技術分野以外の用途、例えば文化的、政治的、法的、ジャーナリスティックな分野では、使用するLLMの価値観を慎重に考慮する必要があるかもしれません。また、特定の言語圏や地域で一部のLLMが支配的になった場合、その地域で利用可能なテキストの価値観が偏る可能性も説明されました。

ただし研究者たちは、開発者たちを戒めたいのはありません。むしろ、「中立な」AIの開発を強制しようとする規制に疑問を感じています（技術的に困難であることもその理由）。代わりに、LLMの設計選択が価値観に与える影響について、透明性を確保することを重視すべきだと提言しています。さらに、多様な価値観を持つLLMが共存することは、民主的な観点からむしろ健全かもしれないとの見方も述べています。

- 参照論文URL： [https://arxiv.org/abs/2410.18417](https://arxiv.org/abs/2410.18417)
- コード： [https://github.com/aida-ugent/llm-ideology-analysis](https://github.com/aida-ugent/llm-ideology-analysis)
- データセット： [https://hf.co/datasets/ajrogier/llm-ideology-analysis](https://hf.co/datasets/ajrogier/llm-ideology-analysis)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[コンテキスト内で重要な情報同士が離れすぎるとLLMの性能は大幅に下がる](https://ai-data-base.com/archives/77563)

[手の込んだ手法よりシンプルな手法の方がLLMは幻覚を起こしにくい　問題に応じて戦略を変える必要性](https://ai-data-base.com/archives/77700)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)