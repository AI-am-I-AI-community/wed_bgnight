---
title: "LLMにおける通説への提言"
source: "https://ai-data-base.com/archives/71978"
author:
  - "[[AIDB Research]]"
published: 2024-07-01
created: 2025-06-13
description: "今回研究者たちは、LLMに関する”一般的な主張”を批判的に検討してまとめています。LLMの定義、特性、影響力について分析を行い、多くの主張がもしかすると十分な根拠を欠いている可能性があることを指摘しています。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

今回研究者たちは、LLMに関する”一般的な主張”を批判的に検討してまとめています。LLMの定義、特性、影響力について分析を行い、多くの主張がもしかすると十分な根拠を欠いている可能性があることを指摘しています。

ICML2024で採択された論文です。

![](https://ai-data-base.com/wp-content/uploads/2024/06/AIDB_71942-1024x576.jpg)

**参照論文情報**

- タイトル：Position: Key Claims in LLM Research Have a Long Tail of Footnotes
- 著者：Anna Rogers, Alexandra Sasha Luccioni
- 所属：IT University of Copenhagen, Hugging Face

**本記事の関連研究** ：

- [大規模言語モデル（LLM）のこれまでとこれから①　-代表的なモデル編-](https://ai-data-base.com/archives/64232)
- [『プロンプトレポート』OpenAIなどが作成した調査報告書　〜その1　重要な用語と各種プロンプト手法〜](https://ai-data-base.com/archives/70953)
- [LLMなどの生成AIの背後にある思考プロセスは人間とは全く異なるかもしれないことを示す仮説『生成AIのパラドックス』](https://ai-data-base.com/archives/58414)

## 背景

LLMに関する議論の多くは、明確な定義や十分な根拠のない主張に基づいて行われていることが懸念されています。

例えば、そもそもLLMの定義自体が曖昧であると考えられています。LLMという用語は広く使用されていますが、その正確な意味については共通理解が得られていない状況です。

また、LLMの機能や特性に関する一般的な主張の多くが、十分な検証なしに繰り返し述べられていることも問題視されています。例えば、LLMの堅牢性や最先端の性能、スケーリングの重要性などについての主張が、必ずしも厳密な証拠に基づいていない可能性があるといいます。

このような状況は、LLMに関する誤った認識を広めたり、研究の方向性を偏らせたりする危険性があります。特に、商業的な利益のために形成されたイメージが無批判に受け入れられることで、一般の人々や研究者自身が誤解を招く可能性が懸念されています。

今回、LLMに関する主要な用語や主張について、より正確で厳密な定義や検証の必要性が主張されています。そしてLLMの定義を提案し、LLMの機能に関する5つの一般的な主張を批判的に検討することが試みられています。

以下で詳しく紹介します。

## LLMとは何か

LLMという用語は広く使用されていますが、その正確な定義は少し曖昧なところがあります。従来の言語モデルの定義とは異なる文脈で（LLMという用語が）用いられることが多く、理解にずれが生じています。

### 定義を提案

今回著者らは、LLMを定義するための3つの基準を提案しています。

1. テキストのモデル化と生成を行う  
	LLMは入力コンテキストに基づいてテキストを生成できる必要があります。ここでいうテキストは、文字、ピクセル、音声など様々な形態を含みます。
2. 大規模な事前学習がされている  
	LLMは大規模なデータセットで事前学習される必要があります。著者らは英語 [コーパス](https://ai-data-base.com/archives/26324 "コーパス") の場合、10億トークン以上を「大規模」の目安として提案しています。
3. [転移学習](https://ai-data-base.com/archives/26578 "転移学習") への活用ができる  
	LLMは他のタスクに転用できる情報を含んでいる必要があります。現在は主にファインチューニングやプロンプティングが用いられていますが、他の手法も含まれます。

上記の定義に基づくと、BERTやGPTシリーズのモデル、十分に大きな [コーパス](https://ai-data-base.com/archives/26324 "コーパス") から学習されたn-gramモデルなどがLLMに該当します。一方、word2vecのような単語レベルの表現は、単体ではLLMとは見なされません。

### マルチモーダルモデルの扱い

上記の定義では、GPT-4のようなマルチモーダルモデルも、テキスト出力が可能であればLLMに含まれます。ただし、テキスト以外のデータの扱いについては、さらなる検討が必要とされています。

### 他の関連用語との比較

「基盤モデル」や「フロンティアモデル」といった関連する用語との違いとして、LLMはより具体的で、言語データのモデリングに特化した用語として位置づけられています。

著者らは、今回の定義も完全ではないとしています。その上で、LLMに関する議論をより明確にするための出発点としてほしいと考えています。

## 5つの通説を検証する

以下では、LLMに関する5つの一般的な主張の妥当性が検証されています。各主張は、完全に誤りというわけではありませんが、多くの注意点が指摘されています。

### （１）LLMは堅牢なのか？

LLMは従来のAIより柔軟に対応できると言われています。大量のデータで学習しているので、新しい状況にも対応できるだろうという考えに基づいています。しかし、実際にはどうでしょうか？以下の２つのケースに分けて考える必要があります。

1. 学習したデータに近い状況での使用
2. 全く新しい状況での使用

LLMは学習データに近い状況ではうまく動きます。しかし、それだけでは本当の意味で堅牢とは言えません。

実際には、学習データとは違う場面に遭遇することが多いです。例えば、テキスト分類の場合、新しい話題が次々と登場しますし、言葉の使い方も日々変化します。こういった新しい状況でのLLMの性能は、まだはっきりしていません。

LLMが思わぬ失敗をすると、深刻な問題につながることがあります。例えば、機械翻訳の間違いで難民申請が却下されたケースもあります。

外せない観点として「近道（ショートカット）学習」という問題があります。データの中の偶然の関連性を学習してしまうことです。最新のLLMでもこの問題は解決していません。

また、プロンプト（LLMへの指示）をほんの少し変えただけで、出力が大きく変わってしまう「プロンプト感度」という問題も見つかっています。これも、LLMの堅牢さに疑問を投げかけるものですね。

このように、LLMの堅牢さについては、まだ多くの課題が残っています。今後の研究に期待される部分です。

### （２）自然言語処理でベストなツールなのか？

LLMは言語処理タスクで最高の性能を示すとよく言われていますが、注意が必要です。まず、LLMの評価方法には2種類あります。

1. Few-shot学習：新しいタスクにそのまま使う
2. 微調整：新しいタスクのために少し学習を追加する

最近のLLM研究では、主にFew-shot学習で評価されています。そのため、Few-shot学習が最高性能だと思われがちです。

しかし、実際はそうとは限りません。他の方法の方が良いこともあります。また、特殊な分野や複雑なタスクでは、Few-shot学習のLLMが不利になることもあります。

ただし、LLMと他の方法を比べるのは、モデルの構造や学習データの違いが大きく影響するため難しいです。

また、LLMの評価結果には注意が必要です。テストデータが学習データに含まれていた可能性（データ汚染あるいはリークと言う）があるからです。

要するに、LLMが最高というのは、特にFew-shot学習の場合、必ずしも正しくないかもしれません。評価方法、タスクの種類、データ汚染の問題など、様々な要因を考える必要があります。LLMの本当の性能を知るには多角的な評価が必要です。

### （３）LLMの性能向上は単にスケーリングの結果なのか？

LLMの成功において、スケーリングが中心的な役割を果たしているという主張がよく見られます。この考えは、モデルサイズ、データサイズ、計算量を増やすことで性能が向上するという「スケーリング則」に基づいています。

確かに、LLMのサイズは年々増大しており、より大きなモデルがより良い性能を示す傾向が観察されています。例えば、2018年のBERT-baseは3億4000万パラメータでしたが、2022年のPaLMは5400億パラメータに達しています。

ただし多くの場合、モデルサイズの増加と同時に訓練データも拡大されているため、性能向上の要因を特定するのが難しくなっています。

少なくとも単純にモデルサイズを大きくすれば良いわけではありません。単に訓練データの量を増やすだけでなく、その質も重要な要素です。より質の高い、多様なデータを用いることで、モデルにより多くの知識が供給されます。つまり、性能向上は純粋な計算量の増加ではなく、より豊富な知識の獲得によるものかもしれません。

LLMの性能は、利用可能なデータに依存します。チェスや囲碁などのゲームと異なり、LLMは人間が作成したデータに依存しているため、単純に計算量を増やすだけでは限界があります。

そのため、最近のLLM開発では、訓練データの品質向上に多くの労力が費やされています。例えば、PaLM 2の報告書では、英語ベンチマークでの高い性能が高品質なデータに起因すると明記されています。

加えて近年、スケーリング仮説に対する懐疑的な見方も増えています。例えば、一部のタスクでは、モデルサイズを大きくしても性能が向上しないことが示されています。

LLaMaシリーズのような、比較的小規模でありながら高性能なオープンアクセスモデルの成功も、単純なスケーリングだけが重要ではないことを示唆しています。

また知識蒸留（大きなモデルの知識を小さなモデルに転移する技術）や疎性（モデルの一部のみを使用する技術）の成功は、モデルサイズ以外の要因も重要であることを示しています。

要するにスケーリングはLLMの性能向上に寄与していますが、それだけでは十分ではありません。データの質、モデル [アーキテクチャ](https://ai-data-base.com/archives/26562 "アーキテクチャ") 、学習手法など、他の要因も同様に重要です。また、実用面ではモデルサイズの増大が障害となる可能性もあるため、バランスの取れたアプローチが求められています。

### （４）LLMは汎用技術と呼べるのか？

LLMが汎用技術であるという主張が、メディアや一部の研究者によってなされています。

汎用技術とは、経済学者や歴史学者によって用いられる用語で、時代を画する広範囲に影響を与える技術を指します。ただし何が汎用技術に該当するかの判断は難しいとされています。

経済学者のLipseyとCarlawによって提案された汎用技術の4つの基準は以下のとおりです。

1. 単一の認識可能な汎用技術であること
2. 経済全体で広く使用されること
3. 多様な用途があること
4. 多くの波及効果を生み出すこと

上記の基準に基づいて、歴史的には車輪や印刷機、電気などの24の技術が汎用技術と見なされています。

現時点で、LLMをこれらの基準に照らし合わせると、汎用技術としての地位を主張するのは時期尚早だと指摘されています。その理由は以下のとおりです。

1. LLMは単一の技術ではなく、多様な技術の集合体です。
2. 現在、LLMは経済全体で広く使用されているとは言えません。
3. LLMの使用は特定の産業や組織に限られています。
4. LLMは大量の [GPU](https://ai-data-base.com/archives/26570 "GPU") や特殊な労働力に依存しており、広範な経済活動での利用は制限されています。

特に2と3に関連する事実としてLLMは学習データに近い状況で最も効果を発揮するため、多様な経済セクター、特に小規模なコミュニティや言語での有用性には疑問が呈されています。

LLMの潜在的な波及効果については、まだ評価するのが早すぎるとされています。ChatGPTは急速に普及しましたが、それは技術的な革新というよりも既存のモデルに簡単なユーザーインターフェースが追加されたことによるものだと指摘されています。

今は、LLMが何に使えるのか、どのような条件下で使用できるのかを明確にすることに焦点を当てるべきだと考えられます。LLMの潜在的な影響力はもちろん認められていますが、現時点では汎用技術としての地位を確立するには至っていないと結論づけられています。継続的に評価が進められていきます。

### （５）LLMに本当に「創発的特性」はあるのか？

LLMが「創発的特性」を示すという主張がしばしば議論されています。「創発的特性」という用語は、LLM研究において少なくとも4つの異なる意味で使用されていることに注意が要ります。

1. モデルが明示的に訓練されていない能力を示す場合
2. モデルが事前学習データから学習した能力を示す場合
3. 小規模モデルには存在せず、大規模モデルにのみ存在する特性
4. モデルのサイズを大きくすると急激に現れる予測不可能な特性

上記の定義には、実はそれぞれ問題点が存在します。例えば、2つ目の定義は単に「学習された特性」を指しているに過ぎません。3つ目の定義は、小規模モデルでも同様の能力が実現可能な場合に問題が生じます。4つ目の定義については、性能の急激な向上が評価指標の選択によるものである可能性が示唆されています。

現在のところ、創発的特性の存在を証明することは非常に困難であると考えられます。モデルの出力が訓練データに存在しない情報に基づいているということを示すのは、現状では不可能に近いとされています。

（ChatGPTのような商用モデルの場合、訓練データが公開されていないため、創発的特性の存在を検証することはさらに困難です）

新しく作成されたベンチマークでさえ、訓練データとの類似性を完全に排除することは難しいとされています。LLMの訓練データは膨大であり、公開されていない情報も含まれている可能性があるためです。

おそらく、データから学習されていない創発的特性の存在を示す証拠は現時点では存在しません。むしろ、LLMの高い性能は訓練データに強く依存していることを示す証拠が多く存在しています。

科学哲学における創発の概念（例：竜巻が砂やゴミから構成されているが、その特性は構成要素とは異なるという考え）と照らし合わせても、LLMの「創発的特性」は特別なものではない可能性があります。多くのディープラーニングモデルが同様の特性を持っていることも考慮に入れたいところです。

LLMの能力をより正確に理解するためには、訓練データとモデルの出力との関係をより詳細に分析する必要があると結論づけられます。

## 機械学習に与える影響

LLMの成功は、機械学習分野に良い影響を与えています。お金が集まり、実際の場面で使われるようになり、注目も集めています。でも、心配な点もいくつか出てきました。

**研究の偏り**

LLMが注目されすぎて、他の研究方法がおろそかになっています。新しい発見を見逃すかもしれません。

**研究の格差**

LLMの研究にはお金がかかります。例えば、GPT-4の開発には1億ドル以上かかったそうです。大学院生や小さな研究室では、最新のLLM研究に参加するのが難しくなっています。

**企業の影響力増大**

学会で企業からの参加が増えています。 [自然言語処理](https://ai-data-base.com/archives/26319 "自然言語処理（NLP）") の分野では180%も増えました。研究テーマの選び方にも企業の考えが影響しています。

**研究の再現性問題**

LLMの研究結果を他の人が同じように試すのが難しくなっています。中でもインターネット経由でしか使えないモデルは、時間とともに変わってしまうかもしれません。

**理論軽視の傾向**

LLMの能力が強調されすぎて、言語や社会、人の考え方についての基礎理論が軽く見られがちです。科学としても、技術としても問題があります。

**社会への影響**

LLMが十分に確認されないまま使われると、特定の人々や言語を話す人々に不利益をもたらすかもしれません。

まとめると、研究の多様性を保ち、誰もが参加でき、結果を確認でき、基礎理論も大切にしながら、LLMの良いところを活かすバランスが大切だと考えられています。また、LLMを社会で使う時は、その影響をよく考え、公平で安全に使えるよう努力することが欠かせません。次のセクションでは、今後の指針に関する提案を詳細にまとめます。

## 今後の方向性

LLM研究における課題を踏まえ、今後の方向性が提案されています。

### （１）研究アプローチの多様性維持

LLM研究に偏重することなく、多様なアプローチや課題に取り組むことの重要性が強調されています。学会では、「ニッチ」な研究提案に対しても公平な審査が行われるよう努力する必要があります。言語学や認知科学などの他分野との重要な接点を見逃すリスクを軽減したいところです。

### （２）用語の明確な定義

「大規模言語モデル」や「創発的特性」などの曖昧な用語について、研究論文では明確な定義を提示することが推奨されます。例えば、「視覚と言語の [Transformer](https://ai-data-base.com/archives/26535 "Transformer") モデル」や「2000億パラメータの [Transformer](https://ai-data-base.com/archives/26535 "Transformer") ベースの自己回帰言語モデル」など、詳しくて的確な言い方がいいかもしれません。

### （３）非公開モデルのベースラインとしての使用回避

GPT-4のような非公開モデルをベースラインや研究対象として使用するのは問題があります。ベンチマークデータの汚染の可能性や再現性の低などがあるためです。代わりに、FLAN-T5やBLOOM、LLaMaなどのオープンソースまたはオープンアクセスモデルの使用が推奨されます

### （４）LLMの機能に関する厳密な研究

LLMの機能に関する多くの知識ギャップを埋めるため、より厳密な研究が必要とされています。例えば、特定のタスクでLLMが最高性能を示す要因や、LLMの脆弱性の種類とその緩和方法などが研究課題として挙げられます。

### （５）評価手法の改善

LLMをもっと適切に評価するには、様々な角度から見る必要があります。また、他の研究者も同じ結果が得られるようにすることが大切です。さらに、評価の基準そのものが本当に正しいのか、もう一度考え直す必要があります。

理想的な評価方法は、LLMの特定の能力、例えば文法理解や文脈把握などを個別に見ていくことです。そして、LLMがどこまで正しく動き、どこから間違え始めるのかをじっくりと調べます。同時に、LLMの弱点も積極的に見つけ出すようにします。

こういった総合的なアプローチで、LLMの能力をより正確に把握したいですね。

### （６）訓練データと出力の関連性分析

LLMが出す答えと、学習に使ったデータとの関係をもっとよく調べる新しい方法が必要です。例えば、LLMがデータをどのように記憶し、活用しているかを詳しく研究します。また、LLMが学習に使ったデータを簡単に探せるようなツールを開発することも有効でしょう。

このような理解が進めば、LLMの性能向上や適切な使用方法の発見にもつながると考えられます。

## まとめ

本記事では、LLMに関する一般的な主張を批判的に検討した研究を紹介しました。研究者たちは、LLMの定義や特性に関する主張の多くが十分な根拠を欠いていることを主張しています。

彼らは、用語の明確化、実験手法の改善、評価方法の見直しなどを提言しています。

ヒートアップした市況に影響された研究環境を見直すことで、長期的には産業にも良い影響があるかもしれませんね。

- 参照論文URL： [https://arxiv.org/abs/2308.07120](https://arxiv.org/abs/2308.07120)
- ICML2024での論文ページ： [https://openreview.net/forum?id=M2cwkGleRL](https://openreview.net/forum?id=M2cwkGleRL)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[LLMはRAGコンテキストと事前知識のどちらに依存する？](https://ai-data-base.com/archives/71857)

[LLMの小規模化と高性能化を両立させた『Gemma 2』Google DeepMindが発表](https://ai-data-base.com/archives/71982)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)