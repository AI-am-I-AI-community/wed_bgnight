---
title: "LLMでWikipediaのような文書を作成する方法「STORM」スタンフォード大学研究者ら開発"
source: "https://ai-data-base.com/archives/68269"
author:
  - "[[AIDB Research]]"
published: 2024-04-26
created: 2025-06-13
description: "スタンフォード大学の研究グループが提案した「STORM」と呼ばれるプロンプトフレームワークを紹介します。LLMを活用し、特定のトピックに関する情報を自動で収集・整理し、Wikipedia風の記事を生成することを目指す手法です。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

スタンフォード大学の研究グループが提案した「STORM」と呼ばれるプロンプトフレームワークを紹介します。LLMを活用し、特定のトピックに関する情報を自動で収集・整理し、Wikipedia風の記事を生成することを目指す手法です。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68269-1024x576.jpg)

**参照論文情報**

- タイトル：Assisting in Writing Wikipedia-like Articles From Scratch with Large Language Models
- 著者：Yijia Shao, Yucheng Jiang, Theodore A. Kanell, Peter Xu, Omar Khattab, Monica S. Lam
- 所属：Stanford University

**本記事の関連研究** ：

- [LLMにおける、長いコンテキストから欲しい情報を見つけ出す「needle-in-a-haystack（干し草の中の針）」テスト結果とプロンプト例](https://ai-data-base.com/archives/68016)
- [プロンプトに例を多く載せるほど、どんなタスクでも性能が上がるのか？DeepMindによる『Many-shot Learning』の実験結果](https://ai-data-base.com/archives/67883)
- [LLMが思考のネットワークを構築し、人間の推論プロセスを模倣する『THOUGHTSCULPT』プロンプティング](https://ai-data-base.com/archives/67755)
- [GPT-4やGeminiなどさまざまなLLMで、プロンプトの入力が長くなるにつれて推論性能に顕著な低下が見られる](https://ai-data-base.com/archives/64873)

## 背景

Wikipediaは協働編集によって作成される最大級のオンライン百科事典として知られています。知識の民主化に大きく貢献するプラットフォームである一方で、大規模なナレッジベースを手作業で構築・維持することは容易ではありません。

そこで今回、研究者らはウィキペディアの記事を自動生成するシステムに着手しています。

Wikipediaのような記事の自動生成にはいくつか課題があります。

1. 通常、記事生成に必要な情報源はあらかじめ用意されていることが前提とされている。
2. 一部のセクションや段落のみを生成する研究は多いが、記事全体の生成はあまり探求されていない。
3. 生成された記事の構成が整っていなかったり、情報が断片的だったりするなど、品質面に不安がある。

研究者らは、上記の課題を解決するための手法として、RAGの枠組みを拡張し、Wikipedia自動生成に特化したフレームワーク「STORM」を考案しました。

RAGとは、言語モデルに外部の知識源から関連情報を取得させ、その情報を利用して文章を生成させる手法です。

考案されたSTORMには以下の特徴があります。

1. トピックに関連する幅広い情報を収集する
2. 記事の適切なアウトラインを生成する
3. セクションごとに本文を詳細に書く

以下では研究全体について詳しく説明します。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68269_1.png)

Wikipediaのような記事をゼロから書くことを探求し、記事を作成する前にプレライティングステージが必要であることを示した図

## 評価用のデータセット

まず研究者らは、手法の性能を評価するために、FreshWikiというデータセットを作成しました。最近編集された高品質なWikipedia記事を収集したものです。

データセット作成の基準は以下の通りでした。

1. 言語モデルの学習に使用されたデータに含まれていない、最新の記事を収集する。
2. Wikipediaの品質評価基準に基づき、一定以上の品質を満たす記事のみを収集する。

研究者らは2022年2月から2023年9月までの期間に編集された記事の中から、編集回数が多く、品質が高い記事を選定しました。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68269_2.png)

既存研究におけるWikipedia記事生成のセットアップを比較した表。段落生成には記事のアウトラインは不要。

FreshWikiは、言語モデルの学習データに含まれていない記事を対象とした評価を可能とし、システムの汎化性能を測ることがポイントです。

## STORMフレームワーク

今回考案されたSTORMを一言で言うと、与えられたトピックに関するWikipedia風の記事を自動生成するためのフレームワークです。以下の3つのステップからなります。

1. 多様な観点からの質問生成
2. 対話形式での情報収集
3. アウトラインの作成

研究者らは、これらのステップを組み合わせることで、高品質な記事を生成することを目指しました。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68269_3-1024x429.png)

プレライティングステージ（要するに下書きを作るプロセス）を自動化するSTORMの概要図

STORMは、実際には一連のプロンプトを巧みに組み合わせる手法です。下記に示すステップの説明に基づいて、プロンプトによるモデルの実行を繰り返すことで実行します。

### ステップ1：多様な観点からの質問生成

まず、与えられたトピックに関連する様々な観点を発見し、それぞれの観点から質問を生成します。以下のように行われます。

1. 与えられたトピックに関連する他のWikipedia記事を収集する。
2. 収集した記事の構成を分析し、トピックを多角的に捉える観点を発見する。
3. 発見した観点に基づき、トピックに関する質問を生成する。

例えば、「2022年冬季オリンピックの開会式」というトピックが与えられた場合、「イベント企画者の観点」や「参加国の観点」など、様々な観点を発見します。  
そして、それぞれの観点から「開会式の予算はいくらか？」「参加国の入場順はどのように決められるか？」などの質問を生成します。

### ステップ2：対話形式での情報収集

次に、生成した質問に対する答えを、信頼できるオンラインソースから収集します。なお、対話形式で行われます。

1. 生成した質問を、トピックに関する専門家モジュールに投げかける。
2. 専門家モジュールは、信頼できるオンラインソースを検索し、質問に対する答えを収集する。
3. 収集した情報をもとに、さらなる質問を生成し、対話を継続する。

なおここでの専門家モジュールは、人間ではなく、言語モデルや検索機能を指しています。

### ステップ3：アウトラインの作成

そして収集した情報をもとに、記事のアウトラインを作成します。以下のように行われます。

1. 与えられたトピックに関する言語モデルの知識をもとに、初期のアウトラインを生成する。
2. 収集した情報を用いて、初期アウトラインを洗練し、より詳細で体系的なアウトラインを作成する。

作成したアウトラインと収集した情報をもとに、Wikipedia風の記事を生成します。記事は、アウトラインに沿って、セクションごとに生成されます。

生成された各セクションには、収集した情報から関連する文献が引用されます。

最後に、生成されたセクションを統合し、記事全体の整合性を確保します。また、記事の冒頭には、全体の要約を付け加えます。

以上が、STORMの一連の処理の流れです。多様な観点からの情報収集と、体系的なアウトラインの作成が主なポイントです。

## 評価実験

研究者らは、STORMの性能を評価するために、一連の実験を行いました。FreshWikiデータセットから選ばれた100のトピックを用いて、STORMと3つの手法の性能が比較されました。

比較手法は以下の3つです。

1. Direct Gen（要するに直接生成する手法）：言語モデルに直接トピックを与え、アウトラインと記事を生成する
2. RAG：トピックに関連する情報を検索し、検索結果と共にトピックを言語モデルに与えて、アウトラインと記事を生成する
3. Outline-driven RAG (oRAG)：RAGと同様にアウトラインを生成し、さらにアウトラインの各セクションに関連する情報を検索して記事を生成する手法。

これらの手法は、情報収集とアウトライン作成の方法が異なります。STORMの優位性を確かめるために用意されました。

### 評価指標

実験では、以下の評価指標が用いられました。

**アウトラインの評価指標**

- 見出しのソフトリコール

生成されたアウトラインの見出しと、人手で作成された記事の見出しの一致度を評価する

- 見出しのエンティティリコール

生成されたアウトラインの見出しに含まれる固有表現が、人手で作成された記事の見出しにどの程度含まれているかを評価する

**記事の評価指標**

- ROUGEスコア

生成された記事と、人手で作成された記事の類似度を評価する。

- エンティティリコール

生成された記事に含まれる固有表現が、人手で作成された記事にどの程度含まれているかを評価する。

- 記事の品質評価

生成された記事を、興味深さ、一貫性、関連性、網羅性、検証可能性の5つの観点から評価する。

### 実験方法

今回研究者らは、STORMをゼロショットプロンプティングを用いて実装しました。事前学習済みの言語モデルを利用して、柔軟に情報収集とアウトライン作成を行う実験です

なおRAG部分（情報収集フェーズ）においては、 [You.com](https://about.you.com/hc/features-and-services/what-apis-does-you-com-offer/) の検索APIが用いられました。

## 実験の結果

研究者らは、実験結果を詳細に分析し、STORMの性能とその要因について考察を行いました。

### アウトラインの品質評価

アウトラインの評価では、比較手法よりも優れた性能を示しました。見出しのソフトリコールと見出しのエンティティリコールの両方で、最も高いスコアを達成しています。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68269_5.png)

研究者らは、この結果について以下のように分析しています。

言語モデルは、そのパラメータに蓄積された知識により、トピックに関する高レベルな情報を生成することができます。その上でSTORMフレームワークを用いると、さらに多様な観点からの質問生成と対話形式での情報収集により、トピックに関するより詳細で具体的な情報を収集することができます。

一方で、比較手法の中では、RAGがアウトラインの生成に苦戦する傾向が見られました。関連情報を検索した結果を直接言語モデルに与えると、情報が整理されておらず、アウトラインの生成が困難になるためだと研究者らは分析しています。

### 記事の品質評価

記事の評価においても、比較手法を上回る性能を示しました。ROUGEスコアとエンティティリコールの両方で、最も高いスコアを達成しました。また、記事の品質評価では、興味深さ、関連性、網羅性の観点で比較手法よりも高い評価を得ました。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68269_4-1024x229.png)

研究者らは、この結果についても、STORMの多角的な情報収集とアウトラインの作成が寄与していると分析しています。多様な観点から収集した情報を体系的に整理し、適切なアウトラインを作成することで、読み手にとって興味深く、トピックに関連する情報が網羅的に含まれるようになるとしています。

また、oRAGがRAGよりも優れた性能を示したことから、アウトラインを用いて記事を生成することの重要性が示唆されました。

### アブレーション実験

※アブレーション実験とは、細かな点を検証するための追加実験。

研究者らは、STORMにおける各要素の重要性を評価するために、以下の2つの条件で評価しました。

1. STORM w/o Perspective：質問生成の際に、観点情報を用いない条件。
2. STORM w/o Conversation：対話形式での情報収集を行わず、質問を一度に生成する条件。

実験の結果、いずれの条件でもSTORMの性能が低下することが確認されました。特に、STORM w/o Conversationの性能低下が顕著であり、対話形式での情報収集の重要性が示唆されました。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68269_6_2.png)

対話形式での情報収集により、モデルはトピックに関する理解を深め、より的確な質問を生成することができるだと分析されています。また、対話を通じて収集した情報は、アウトラインの作成にも役立つと推察されています。

また、観点情報を用いない場合でもSTORMは一定の性能を維持したことについても考察しました。  
言語モデルのパラメータに蓄積された知識が、ある程度の情報収集を可能にしているのだと予想されます。しかし、観点情報を用いることでより適切なアウトラインと記事を生成することが可能であるのは変わりません。

## 熟練したウィキペディア編集者による評価

研究者らは、本手法の性能をより詳細に評価するために、熟練したウィキペディア編集者10名に協力を依頼し、人手による評価を行いました。

FreshWikiデータセットから無作為に選ばれた20のトピックに対して、STORMとoRAGによって生成された記事のペアが用いられました。

なおoRAGとSTORMの違いは次のとおりです。  
oRAGは単純な検索に頼るのに対し、STORMは多様な観点からの質問生成と対話形式での情報収集を行います。また、oRAGは検索結果のみをもとにアウトラインを生成するのに対し、STORMは収集した情報と言語モデルの内在知識を組み合わせてアウトラインを生成します。さらに、oRAGは各セクションごとに情報を再検索するのに対し、STORMは収集した情報を統合的に活用して記事を生成します。

### 評価基準

以下の5つの観点から記事が評価されました。

1. 興味深さ：記事がどの程度読者を引きつけるか。
2. 一貫性：記事の構成が論理的で一貫しているか。
3. 関連性：記事がトピックに関連し、焦点が合っているか。
4. 網羅性：記事がトピックを深く掘り下げ、十分にカバーしているか。
5. 検証可能性：記事の内容が信頼できる情報源で裏付けられているか。

各観点は、1から7までの尺度で評価されました。また、編集者は記事のペアを比較し、より好ましい記事を選択しました。

### 評価結果

STORMによる記事はoRAGによる記事よりも高い評価を得ました。指標の中でも一貫性、関連性、網羅性において優れていると評価されました。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68269_7.png)

STORMの記事は、oRAGの記事と比較して、より広範で深い内容を含んでいると評価されました。編集者からは、「STORMの記事は、ウィキペディアの記事よりも多くの背景情報を提供している」、「AIの記事は、ウィキペディアの記事と比較して、より深い内容を含んでいる」といったコメントが寄せられました。

また、ペアワイズ比較においても、STORMの記事がoRAGの記事よりも好ましいと判断されるケースが多く見られました。

### 生成記事の課題

一方で、編集者からは、「生成された記事にはまだ改善の余地がある」との指摘もありました。具体的には記事の中立性と検証可能性に関する課題が指摘されました。

フィードバックを分析した結果、以下のような課題が明らかになっています。

1. インターネット上の情報源には偏りがあり、それが生成された記事に反映される傾向がある。
2. 言語モデルが、関連性の低い情報同士を不適切に関連付けてしまう場合がある。

事実レベルでの検証を超えた、高度な情報の取捨選択と統合が必要であることを示唆しています。

### 有用性

編集者は、STORMが執筆の”準備段階”で有用であると評価しました。情報収集とアウトラインの作成において、作業を支援する可能性が高いと考えられています。

なお、STORMは新しいトピックに関する記事の編集にも役立つと評価されました。一方で、Wikipediaコミュニティ全体に対するSTORMの有用性については、意見が分かれる結果となりました。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_68269_8.png)

STORMの有用性に関する調査結果（n = 10）

## まとめ

本記事では、LLMを用いてWikipediaのような記事を自動生成するSTORMという手法の研究を紹介しました。

与えられたトピックに関する情報を自ら収集し、それらを体系的に整理して、読みやすい文章で記事を生成するフレームワークです。

自動評価と熟練したウィキペディア編集者による人手評価の両面から、STORMの有効性が示されました。執筆の準備段階、情報収集とアウトラインの作成において有用であることが示唆されています。新しいトピックに関する記事の編集にも役立つと期待されています。

今後、STORMのような技術が発展することで、知識が公平に行き渡るスピードや品質が向上すると期待されています。

（編集部注：ただし、生成コンテンツが十分に検証されないまま公開されることに対する弊害も議論されています。本手法における「検証可能性」の評価指標がさらに改善されることは重要と考えられます。）

参照論文URL： [https://arxiv.org/abs/2402.14207](https://arxiv.org/abs/2402.14207)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[小さなRetrieverとLLMの組み合わせによる実用的なワークフロー生成システム　またはRAGで幻覚を減らす手法](https://ai-data-base.com/archives/68219)

[マルチモーダルLLMにおける欠点と原因を明らかにする調査研究の結果](https://ai-data-base.com/archives/68367)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)