---
title: "高解像度な深度マップを高速生成するモデル『Depth Pro』Appleが公開"
source: "https://ai-data-base.com/archives/76790"
author:
  - "[[AIDB Research]]"
published: 2024-10-09
created: 2025-06-13
description: "本記事では、1枚の画像から高精度な奥行き情報を高速で推定するモデル「Depth Pro」を紹介します。これまでの手法では難しかった、カメラの内部パラメータなしでの正確な奥行き推定や、髪の毛や毛皮などの細かい構造の捕捉が可能になりました。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、1枚の画像から高精度な奥行き情報を高速で推定するモデル「Depth Pro」を紹介します。これまでの手法では難しかった、カメラの内部パラメータなしでの正確な奥行き推定や、髪の毛や毛皮などの細かい構造の捕捉が可能になりました。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_76790_top2-1024x576.jpg)

**参照論文情報**

- タイトル：Depth Pro: Sharp Monocular Metric Depth in Less Than a Second
- 著者：Aleksei Bochkovskii, Amaël Delaunoy, Hugo Germain, Marcel Santos, Yichao Zhou, Stephan R. Richter, Vladlen Koltun
- 研究機関：Apple

**本記事の関連研究**

- [画像と「動画」の中にあるものを認識する『SAM 2（Segment Anything 2）』をMetaが開発](https://ai-data-base.com/archives/73710)
- [マルチモーダルLLMでゼロショット画像分類の精度を向上させる手法　Googleが考案](https://ai-data-base.com/archives/70709)
- [GPT-4Vで画像分析する際、画像に「ドットマトリックス」を重ねるだけで認識精度が大きく向上](https://ai-data-base.com/archives/65652)
- [画像分析機能を持つオープンソースLLM『LLaVA-1.5』登場。手持ちの画像を分析可能。GPT-4Vとの違い](https://ai-data-base.com/archives/56440)

## 背景

1枚の画像から奥行き情報を推定する技術（深度推定）が発展しています。深度推定は、画像編集や画像生成などへのさまざまな応用可能性を秘めています。

これまでの研究では、次のような課題がありました。

1. 予測された奥行き情報の精度が十分ではなかった
2. カメラの内部パラメータ（焦点距離など）が必要で、一般的な画像には適用できなかった
3. 物体の輪郭がぼやけてしまい、細かい構造を正確に捉えられなかった
4. 処理に時間がかかり、リアルタイムでの使用が難しかった

そこで例えば、多様なデータセットを使った学習や、新しいネットワーク構造が試されてきました。しかし、依然として難しい状況でした。中でもカメラの内部パラメータなしで正確な奥行きを推定することや、髪の毛や毛皮などの細かい構造を正確に捉えることが困難でした。

そんな中、今回Appleの研究者らはこれらの課題を一度に解決するモデル『Depth Pro』を開発しました。

以下で紹介します。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_76790_1-1.jpg)

Depth Proの性能を示す一例。AM-2kとDIS-5kデータセットの画像に対する、Marigold、Depth Anything v2、Metric3D v2の深度推定結果との比較

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_76790_2-1024x410.png)

Depth Proが他の手法より高い精度（縦軸）と短い実行時間（横軸）を達成していることを示す図

## Depth Proモデルの仕組み

### ネットワーク構造

Depth Proは、画像を細かく分析して深度を推定する新しい方法を使っています。この方法の特徴を以下に説明します。

#### 特徴１：パッチエンコーダとイメージエンコーダ

まず、画像を小さな部分（パッチ）に分けて処理します。これを「パッチエンコーダ」と呼びます。このエンコーダは、画像の大きさが変わっても同じように働くように設計されています。

同時に、「イメージエンコーダ」という別のモデルが画像全体を見て、全体的な情報を提供します。これは常に384×384ピクセルの大きさで動作します。

#### 特徴２：固定解像度での処理

次に、このシステム全体が1536×1536ピクセルの固定サイズで動作します。こうすることで画像の広い範囲を一度に見ることができ、処理時間も安定します。他の方法と比べて、より速く正確な結果が得られます。

#### 特徴３：ViTエンコーダの利点

また、最新の画像認識技術であるViT（Vision [Transformer](https://ai-data-base.com/archives/26535 "Transformer") ）をバックボーンのベースモデルとして使用します。新しい技術が開発されたときには簡単に更新できます。

#### 特徴４：処理の流れ

1. まず画像を1536×1536ピクセルに縮小する
2. それを384×384ピクセルの小さな部分に分ける
3. これらの部分をそれぞれ分析する
4. その結果を組み合わせて最終的な深度マップを作る

上記の方法によって、画像全体を一度に高解像度で処理するよりも、計算量を抑えることができます。結果として高精度な処理が小さな計算資源でも実現しています。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_76790_3-1024x391.jpg)

Depth Proのネットワーク アーキテクチャ の概要図。入力画像の処理から深度マップの生成までのプロセスを示している。

### 訓練方法と評価方法

#### ①訓練目標

深度推定の基本的な目標は、カメラからの距離を正確に予測することです。この時、カメラに近い物体をより重視するため、距離の逆数を使います。すると近くの物体の細かい変化をよりよく捉えることができます。

モデルの性能を評価する際は、予測値と実際の値の差の平均を計算します。これを [平均絶対誤差](https://ai-data-base.com/archives/26526 "平均絶対誤差（MAE）") と呼びます。ただし、実際の写真を使う場合、測定誤差などの問題があるため、最も大きな誤差（上位20%）は無視します。

また、写真の撮り方によって物体の見え方が変わることを考慮し、そういった違いに影響されない方法で学習を行います。

さらに、物体の輪郭や形状をより正確に捉えるため、深度の変化の仕方（傾きや曲がり具合）も学習の対象に含めます。

#### ②訓練カリキュラム

以下の2段階に分けて訓練が行われています。

第1段階

まず、様々な種類の写真を使って基本的な深度の捉え方を学びます。実際の写真とコンピュータで作られた写真（合成画像）の両方を使います。合成画像では、深度の変化の仕方も学習の対象にしますが、写真の撮り方の違いに影響されないよう工夫しています。

第2段階

次に、合成画像だけを使って学習します。合成画像は正確な深度情報を持っているため、より細かい部分まで学習できます。なお、物体の輪郭をはっきりさせることに重点を置きます。

#### ③境界の正確さの評価指標

これまでの深度マップの評価方法では、物体の輪郭がどれだけはっきりしているかを正確に判断することが難しいという問題がありました。そこで今回、新しい評価方法が提案されています。

まず深度の違いを利用して物体の輪郭を見つけます。隣り合うピクセルの深さを比較することで、物体の境目を特定し、予測した境目と実際の境目がどの程度一致しているかを調べます。さらに、既存の画像データを活用することで、複雑な実際の写真でも評価が可能になりました。例えば、物体の切り抜き画像などを使って物体の輪郭を定義することができます。

今回の新しい評価方法を使用すると、画像の大きさに関係なく評価でき、人が手作業で輪郭を描く必要がなく、そして髪の毛や動物の毛といった細かい部分まで評価できます。

### 焦点距離の推定はどうやるのか

カメラの焦点距離は、撮影された画像の見え方に大きな影響を与えます。Depth Proシステムには、画像から自動的に焦点距離を推定する機能が追加されています。これは、画像のEXIFデータ（カメラの設定情報）が不正確だったり、欠けていたりする場合にとても役立ちます。

この機能は、深度推定を行うメインのネットワークに小さな追加のネットワークを接続することで実現しています。

実際には、深度推定ネットワークから得られた特徴と、別の画像処理モデル（ViT）から得られた特徴を組み合わせて、画像の水平方向の視野角を予測します。

訓練の際は、この焦点距離推定部分を深度推定部分とは別々に学習させます。この訓練方法にはいくつかメリットがあり、まず、深度推定と焦点距離推定の学習バランスを取る必要がなくなります。また、焦点距離の学習に使うデータセットを、深度推定に使うものとは別に選ぶことができます。例えば、特定の環境で撮影された単一カメラのデータセットは除外し、代わりに焦点距度の情報がある大規模な画像データセットを使うことができます。

以上がDepth Proモデルの仕組み面の説明でした。

## 実験

Depth Proシステムの性能を評価するために行われた様々な実験について説明します。

まず、この研究の課題の一つは、他の研究チームとの公平な比較が難しいことでした。その理由は、各チームが独自のデータセットの組み合わせを使って学習を行っていることにあります。中には非公開のデータセットや、使用に制限のあるデータセットを使用しているチームもあります。また、ラベル付けされていないデータや、巨大な事前学習モデルを使用しているチームもあります。

このような状況では、全く同じデータセットを使って比較することは不可能です。そのため、この研究では各チームが独自に学習させた完成したモデル同士が比較されることになりました。比較の際は、どのチームも学習に使っていない新しいデータセットを使用しました。これを「ゼロショット」評価と呼びます。

実験では、

- 深度推定の精度
- 物体の輪郭の正確さ
- 処理速度

などで比較されました。また、焦点距離の推定精度についても評価を行いました。

まずゼロショットでの深度推定の精度について、様々な種類の画像データセットで試されました。例えば、室内の風景や屋外の風景、人工的に作られた画像などです。  
結果として、Depth Proは多くのデータセットで最高、もしくは非常に高い精度を示しました。特に、異なる環境や状況でも安定して高い性能を発揮したことが注目されます。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_76790_4-1024x256.png)

各手法のゼロショット境界精度（ F1スコア とリコール）を複数のデータセットで比較した表

次に物体の輪郭の正確さ（深度マップの中で物体の境界がどれだけはっきりと表現されているか）について。この評価には、新しく開発された指標が使用されました。結果は驚くべきものでした。Depth Proは、髪の毛や動物の毛皮のような細かい部分でも、はっきりとした輪郭を描き出すことができました。これは、画像から3D情報を再現する際に非常に重要な能力です。他のどのモデルよりも正確に物体の輪郭を捉えることができました。

さらに処理速度についても、高い精度と詳細さを保ちながら、驚くべき速さで深度マップを生成することができました。2.25メガピクセルの深度マップを0.3秒で生成でき、他の高精度なモデルと比べて数十倍から数百倍も速いという結果です。

さらに、焦点距離の推定についても他のモデルを大きく上回る精度を示しました。様々な種類のカメラで撮影された画像に対して、高い正確性を維持できたのです。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_76790_5-1024x505.jpg)

Depth Proと他の手法の焦点距離推定精度（δ25%とδ50%）を複数のデータセットで比較した表

なお、Depth Proと他の代表的なモデル（Marigold、Depth Anything v2、Metric3D v2）の深度マップを使って、新しい視点から見た画像を生成しました。その結果、Depth Proが最も鮮明で正確な新規視点画像を生成しました。物体の輪郭がはっきりしており、細かい部分まで正確に再現されています。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_76790_7-911x1024.jpg)

Depth Pro、Marigold、Depth Anything v2、Metric3D v2の深度マップを使用した新規視点合成の結果比較

Depth Proは深度推定の精度向上だけでなく、3D画像処理や拡張現実などの分野でも活用できるかもしれません。

## まとめ

本記事では、高解像度の奥行き推定を高速に行う「Depth Pro」の研究を紹介しました。「Depth Pro」は、カメラの内部パラメータなしで正確な奥行き情報を推定し、物体の輪郭を鮮明に捉えることができます。

なお研究者らは、Depth Proにも限界があることを明記しています。例えば、半透明な表面や体積散乱が存在する場合、単一のピクセルの深度を定義することが難しく、曖昧になる可能性があります。

今後の研究では、これらの課題に取り組むとともに、さらなる精度向上や応用範囲の拡大が期待されます。

- 参照論文URL： [https://arxiv.org/abs/2410.02073](https://arxiv.org/abs/2410.02073)
- コードとモデルの重み： [https://github.com/apple/ml-depth-pro](https://github.com/apple/ml-depth-pro)

参考（公式による開発ではない）↓

- Web UI for Depth-Pro： [https://github.com/spacewalk01/depth-pro-webui](https://github.com/spacewalk01/depth-pro-webui)
- Hugging Face： [https://huggingface.co/spaces/akhaliq/depth-pro](https://huggingface.co/spaces/akhaliq/depth-pro)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[ハーバード大学とGoogleの研究者ら、LLMチャットボットを総合的に評価するデータセットの作り方を報告（作成されたデータセットも公開）](https://ai-data-base.com/archives/76713)

[複雑なプログラミングタスクに特化したベンチマーク『BigCodeBench』登場　最新モデルでも60%](https://ai-data-base.com/archives/76844)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)