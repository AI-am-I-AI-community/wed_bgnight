---
title: "LLMエージェント間で観察された人間のような「意見の二極化」"
source: "https://ai-data-base.com/archives/82487"
author:
  - "[[AIDB Research]]"
published: 2025-01-23
created: 2025-06-13
description: "この記事では、LLMを使ったエージェント同士のやり取りが引き起こす「意見が偏る現象」についての最新の研究を紹介します。LLMは自然な会話や複雑な意思決定ができるようになりつつあります。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

この記事では、LLMを使ったエージェント同士のやり取りが引き起こす「意見が偏る現象」についての最新の研究を紹介します。

LLMは自然な会話や複雑な意思決定ができるようになりつつあります。しかし同時に、人間が書いたかのように見える内容を作り出せるため、その影響が懸念されています。

研究チームは、LLMを活用したエージェント同士のネットワークをシミュレーションすることで、意見がどのように形成されるのか、そしてそれが社会にどんな影響を与えるのかを明らかにしようとしています。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82487-1024x576.jpg)

**発表者情報**

- 研究者：Jinghua Piao et al.
- 研究機関：清華大学, アムステルダム大学, シカゴ大学, サンタフェ研究所

論文情報詳細は記事の下部に記載されています。

## 背景

LLMの進化によって、自然な会話や思考、意思決定が可能な新しい時代が訪れています。LLMは、人間のように他者と関係を築いたり、コミュニケーションを取ったり、政治的な意見を持つことさえできるようになっています。

しかし、社会ではさまざまな懸念が広がっています。LLMが作り出す内容には、有害な影響や偏り、事実と異なる情報が含まれる可能性が指摘されています。また、時として望ましくない振る舞い（たとえば、他人をだます行動、迎合的な態度、不必要な不信感など）が見られる場合もあります。

特に深刻な問題として、LLMが非常に説得力のある内容を作成できる点への懸念があります。文章は人間が書いたものと区別がつかないほど精巧で、世論に影響を与えたり、社会の分裂を深めたりする可能性があります。

2016年の米国大統領選挙では、自動化されたボットが選挙結果に影響を与えたのではないかという疑いがありました。LLMはボットとは違い、高度な会話能力を持ち、さらに相互作用を通じて進化し、独自のソーシャルネットワークや集団としての意見を形成する可能性があります。その影響は予測が難しく、制御するのも容易ではありません。

こうした課題を背景に、研究者たちはLLMを使ったエージェント同士のネットワークをシミュレーションし、意見がどのように形成されるのか、その仕組みを解明しようとしています。

## 実験設計

研究チームは1000体のLLMエージェントからなるネットワークシステムを構築しました。

各エージェントには、

「自己表現」「コミュニケーション」「意見の更新」

という3つの基本的な機能が実装されています。  
ただしエージェントには「個性」と呼べる特徴（例えば、背景や特定の行動傾向、記憶、具体的な思考）は事前には設定されていませんでした。

また、議論のテーマとして、

- 党派的立場
- 銃規制
- 人工妊娠中絶の是非

が選ばれました。

### エージェントの行動サイクル

エージェントは自分の意見とその理由を表明し、他のエージェントとコミュニケーションを取り、受け取ったメッセージを基に意見を更新します。

意見は「左寄り」から「右寄り」までの5段階で表現されます。

重要なのは、エージェントの行動にはあらかじめ規則が設定されておらず、LLMの判断で自律的に行動する点です。

### 初期設定の工夫

実験の開始時点では、エージェントの意見が「ガウス分布」（データが中央付近に集まり、左右対称に広がる形の分布）に近い形で分布するように設定されました。

エージェント同士の社会的なつながりは、「Watts–Strogatzモデル」と呼ばれる小世界ネットワークの手法を使って初期化されています。このモデルは、現実世界の社会構造に近い特徴を持つネットワークを再現するために用いられます。たとえば、少数の遠く離れた人ともつながりを持ちながら、近しい人同士は密接につながるという特性があります。

また、極端な意見の衝突を避けるため、実験は意見の二極化が進んでいない状態からスタートしています。

## 実験結果と観察された現象

10回程度の相互作用を経て、当初ガウス分布だった意見分布が大きく変化しました。中立的な意見（全体の40%）を持つエージェントの割合が減少し、左右の立場に分かれていく様子が観察されました。中立的な立場を維持することの難しさが示唆されています。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82487_1-edited.jpg)

LLMエージェントのネットワークシステムにおける政治的分極化の概要。 (a) 自己表現・コミュニケーション・意見更新の3段階で構成されるエージェントの基本機能 (b) 党派性、銃規制、中絶に関する意見の時間的変化 (c) 初期状態と最終状態における意見分布 (d) 左派・中立・右派の最終的な割合

### 左寄りの偏り

実験結果では左寄りの意見を持つエージェントが多くなる傾向が見られました。

研究チームは、使用したモデル（GPT-3.5）が本来持つ特性が影響している可能性を指摘しています。一方で、右寄りの意見を持つエージェントも一定数存在し、人間社会で見られるような二極化の構造が自然に形成されています。

※ChatGLM、Llama-3など他のLLMでも同様の実験が行われ、結果の再現性が確認されています。

### 自己一貫性の問題

実験過程で、エージェントが表明する意見と理由付けに矛盾が生じる現象も観察されました。たとえば、中立的な立場を表明しているエージェントが、特定の政治的立場を強く支持するような理由を挙げるなど、一貫性を欠く振る舞いが見られました。また、他のエージェントとの対話を通じて意見を更新した際、その更新された意見が受け取ったメッセージの内容と整合しない場合もありました。特に右寄りの意見を持つエージェントで、このような矛盾が頻繁に発生していました。

研究チームは、この「自己一貫性の問題」を解決するため、社会学の「自己調整・自己規制」の理論を応用しました。エージェントに「自己チェック」の機能を追加し、自分が生成したメッセージや意見が現在の立場や状況と矛盾していないかを確認する仕組みを導入したのです。矛盾が見つかった場合には、エージェントがメッセージや意見を再生成し、整合性を保つように促されます。このような自己規制の仕組みを通じて、エージェントの振る舞いをより一貫性のあるものに改善しました。

## 自己規制機能を持つLLMエージェントの意見形成

前節で観察された意見の二極化現象について、より詳しい分析が行われました。左寄りの意見が優勢になる傾向が見られたことから、研究チームはLLMエージェントの意見形成メカニズムを詳細に調査しています。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82487_2-edited.png)

自己規制機能を持つLLMエージェントから生まれる人間的な分極化。 (a) ペアワイズ実験による自己矛盾性の評価方法 (b) ペアワイズ実験における意見遷移の確率 (c) 政治的課題における自己規制戦略の効果 (d) 自己規制機能を持つエージェントの意見ダイナミクス

### ペアワイズ実験による分析

実験の第一段階として、同じ意見を持つ2体のエージェント間での1対1のやり取りが分析されました。

ネットワークの影響を排除し、純粋な意見形成プロセスを観察するためです。結果として、右寄りの意見を持つエージェントは時として左寄りの意見に転向する一方、左寄りのエージェントは意見を変更しにくい傾向が確認されました。

### 改善された結果

上述した自己規制機能（エージェントが自分の意見や発言内容が矛盾していないかを自己チェックし、必要に応じて修正する仕組み）の導入により、矛盾した行動が9.4%から52.2%減少しました。さらに、左右の意見バランスも実際の社会により近い形に改善されました。重要なのは、意見の二極化自体は依然として発生している点です。二極化はLLMの偏りによるものではなく、社会的相互作用の自然な帰結である可能性が示唆されています。

実験を通じて、LLMエージェントは基本的な社会的能力だけを与えられた状態でも、人間社会に似た政治的二極化を自然に生み出すことが明らかになりました。

## 意見の二極化を引き起こすメカニズムの解明

自己規制機能を持つLLMエージェントのネットワークで観察された意見の二極化について、研究チームはそのメカニズムの詳細な分析を行いました。分析は「ネットワークレベル」と「個人レベル」の2つの視点から進められています。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82487_3-edited.png)

LLMエージェント間の人間的な分極化を生み出すメカニズム。 (a) 同質的な意見を持つ者同士の交流の増加 (b) エージェントの社会ネットワークの進化 (c) エコーチェンバー効果の影響 (d) バックファイア効果の影響 (e-g) 選択的接触、確証バイアス、エリート発信の個人レベルのメカニズムの効果

### ネットワークレベルで見られた現象

時間の経過とともに、同じ意見を持つエージェント同士の交流が156.8%から382.7%増加しました。最終的には、システム内の交流の48.5%から88.3%が同じような意見を持つエージェント間で行われるようになりました。鳥が同じ種類の鳥と群れを作るように、似た意見を持つ者同士が集まる傾向が自然に現れたのです。

また、同質的な意見を持つ者同士の交流は、さらなる意見の二極化を促進することが確認されました。たとえば、過激な意見を持つエージェントとの交流は、そのエージェントの意見をより極端な方向へ押し進める効果がありました。人間社会でも見られる「エコーチェンバー効果」と同様の現象です。

しかし異なる意見を持つエージェントとの接触は、必ずしも意見の緩和につながりませんでした。むしろ、対立する意見との接触が二極化を促進するケースも観察されています。人間社会における「バックファイア効果」（反論を受けることで逆に信念が強化される現象）に似た振る舞いです。

### 個人レベルで見られた現象

エージェントは自然と同じような意見を持つ相手との交流を選ぶ傾向を示しました。実験では、この傾向を持つエージェントの割合を増やすと、システム全体の二極化がより強まることが確認されました。

また、エージェントは自分の既存の意見に合う情報を受け入れやすい傾向も示しました。確証バイアスを持つエージェントの割合を増やすと、やはりシステム全体の二極化が強まる結果となっています。確証バイアスとは、人が自分の既存の信念や意見を支持する情報を優先的に受け入れ、それに反する情報を無視したり軽視したりする心理的傾向を指します。簡単に言えば、「自分が信じたいことを信じやすくなる」というバイアスです。

さらに、ネットワーク内で影響力の強いエージェントの意見が、システム全体の二極化に大きな影響を与えることも明らかになりました。中立的な意見を持つ影響力者がいる場合、システム全体の二極化が28.2%減少するという興味深い結果も得られています。

研究チームの分析により、LLMエージェントの意見形成メカニズムが人間社会のそれと驚くほど似ていることが明らかになりました。ネットワークの自己組織化から個人の認知バイアスまで、多くの共通点が観察されています。

## 二極化を緩和するための介入戦略

前節で明らかになった二極化のメカニズムをもとに、研究チームは二極化を緩和するための具体的な方策を検討しました。LLMエージェントと人間社会の類似性を踏まえ、5つの異なる介入戦略が提案され、検証されています。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82487_4-1024x855.png)

分極化を減少させるための介入戦略。 (a) 元のシステム (b) ランダムな交流の効果 (c) 穏健な対立意見との接触の効果 (d-f) 選択的接触の抑制、確証バイアスの軽減、中立的な影響力者導入の効果と、それぞれの同質的交流への影響

### ネットワークレベルでの介入戦略

エージェント同士のつながりをランダムに設定し、同質的な意見を持つ者同士の集まりを防ぐ試みが行われました。既存の人間関係を無視して新しい出会いを強制的に作り出すような状況を模しています。

また、極端な対立意見ではなく、穏健な対立意見を持つエージェントとの交流が促進されました。エコーチェンバー効果やバックファイア効果を抑制することを意図した戦略です。

### 個人レベルでの介入戦略

エージェントが多様な意見を持つ相手と交流するよう促す設定が導入されました。同じような意見の人とばかり交流する傾向を意図的に抑制する試みです。

さらに、エージェントが異なる意見にもオープンな姿勢を持つよう設定が変更されました。自分の意見と異なる情報も積極的に受け入れる傾向を強化しています。

なお、影響力の強いエージェントに中立的な意見を持たせ、非個人化された中立的なメッセージを発信させる試みも行われました。

### 介入効果の検証結果

二極化が進んだ状態（実験開始から35ラウンド後）のシステムに対して、各戦略の効果が検証されました。結果として、確証バイアスの軽減と中立的な影響力者の導入が最も効果的で、それぞれ11.8%と8.8%の二極化減少が観察されました。

一方で、ネットワーク構造を直接変更する戦略（ランダムな交流の促進など）の効果は限定的でした。既に安定した社会関係が形成された後では、新しい出会いを強制的に作り出すよりも、個人の認知や態度に働きかける方が効果的だという示唆が得られています。

研究チームは、実験結果が人間社会における二極化対策にも示唆を与える可能性を指摘しています。ただし、実際の社会への応用にはさらなる検証が必要とされています。

## 研究の意義

この研究では、二極化を緩和するための介入実験を行い、その中で人間社会とLLMエージェント社会に多くの類似点があることが改めて確認されました。研究チームは、この結果が持つ意義と将来的な応用について以下のように述べています。

### 計算社会科学への貢献

従来のエージェントベースモデルでは、特定のルールや仕組みを追加する必要がありました。しかし、この研究で用いたLLMエージェントは、特別な設定なしに自然なやり取りを通じて複雑な社会の動きを再現できることが明らかになりました。例えば、意見の二極化という現象を再現することで、現実の社会現象をよりリアルにモデル化できる可能性が示されています。

現実の社会実験を大規模に行う場合、コストや運営の複雑さ、さらに倫理的な制約が大きな課題となります。この点で、LLMエージェントのネットワークを活用すれば、実験の設計を事前に検証したり、実現が難しい戦略をあらかじめ除外したりするためのシミュレーションが可能になります。この方法により、社会科学の研究を効率的に進められる可能性が広がっています。

### 社会的影響に関する懸念

LLMは人間と見分けがつかないだけでなく、より説得力のある発言を行う可能性があります。オンラインの社会ネットワークにLLMが参加した場合、人間の社会関係や政治的説得、意見形成にどのような影響を与えるのか、慎重な検討が必要とされています。

従来のボットと異なり、LLMエージェントは相互作用を通じて進化し、独自の集合的意見やソーシャルネットワークを形成する可能性があります。人間のソーシャルネットワークにLLMが大規模に導入された場合の影響は、現時点では予測や制御が困難だと指摘されています。

そのため、LLMエージェントがオンライン空間や現実社会に与える潜在的な影響を十分に理解し、望ましくない結果を防ぐための規制やガイドラインの策定が急務となっています。

### 今後の研究課題

今回の研究では、LLMエージェントのみが存在する環境に限定して検証を行いました。しかし、次のステップとして、人間とLLMエージェントが混在する環境での実験が必要です。LLMが人間の行動や社会にどのような影響を与えるのかを、より詳しく評価すべきであるためです。

また、LLMエージェントがオンラインで活動する際の「社会的な安全性」について、さらなる研究が求められています。具体的には、意見の二極化や情報操作といったリスクを最小限に抑えつつ、LLMの持つ可能性を最大限に活用する方法を見つけることが、今後の重要な課題です。

## まとめ

本記事ではLLMのエージェントが示す政治的意見の二極化に関する研究を紹介しました。

研究チームが構築したネットワークシステムでは、LLMエージェントが人間に似た社会的メカニズムを通じて意見を形成し、二極化していく様子が観察されました。

実験結果は、LLMを用いたシミュレーションが社会科学研究の新しい手法として活用できる可能性を示す一方で、LLMの社会実装に際して慎重な検討が必要であることも示唆しています。

**参照文献情報**

- タイトル：Emergence of human-like polarization among large language model agents
- URL： [https://arxiv.org/abs/2501.05171](https://arxiv.org/abs/2501.05171)
- 著者：Jinghua Piao, Zhihong Lu, Chen Gao, Fengli Xu, Fernando P. Santos, Yong Li, James Evans
- 所属：Tsinghua University, University of Amsterdam, University of Chicago, Santa Fe Institute

## 理解度クイズ（β版）

1\. LLMエージェントのネットワーク実験で、初期設定の意見分布はどのように設定されましたか？

実験開始時、エージェントの意見はガウス分布に近い形で分布するよう設定された。これは極端な状況を避け、自然な意見形成プロセスを観察するための工夫だった。

解説を見る

2\. 研究で観察された「バックファイア効果」とは何を指しますか？

バックファイア効果は、異なる意見との接触が逆に信念を強化させる現象を指す。人間社会でも観察される現象がLLMエージェント間でも確認された。

解説を見る

3\. 実験において最も効果的だった二極化緩和策は何でしたか？

確証バイアスの軽減と中立的な影響力者の導入が最も効果的で、それぞれ11.8%と8.8%の二極化減少が観察された。他の戦略と比較して最も顕著な効果を示した。

解説を見る

4\. 研究チームが指摘したLLMエージェントの特徴的な性質は何ですか？

LLMエージェントは基本的な社会的能力だけを与えられた状態でも、人間社会に似た政治的二極化を自然に生み出すことが示された。追加のルールや機構がなくても複雑な社会現象を再現できる点が特徴的。

解説を見る

5\. 同質的な意見を持つエージェント同士の交流は、最終的にシステム内の交流全体の何割程度を占めるようになりましたか？

時間経過とともに、システム内の交流の48.5%から88.3%が同じような意見を持つエージェント間で行われるようになった。これは人間社会でも見られる「同類交友」現象と類似している。

解説を見る

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[企業環境での自動バグ修復に向けたGoogleの取り組み](https://ai-data-base.com/archives/82409)

[マルチエージェントによる自動カウンセリングシステム](https://ai-data-base.com/archives/82682)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)