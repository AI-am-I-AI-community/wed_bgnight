---
title: "LLMに専門的なドメイン知識を学ばせるのに有効な「読解タスクテキストに変換する」テクニック"
source: "https://ai-data-base.com/archives/73575"
author:
  - "[[AIDB Research]]"
published: 2024-07-31
created: 2025-06-13
description: "本記事では、LLMをドメインに適応させるためのアプローチを紹介します。生コーパスを「読解タスク」に応じた内容のテキストに変換してLLMの学習に利用する手法です。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、LLMをドメインに適応させるためのアプローチを紹介します。生 [コーパス](https://ai-data-base.com/archives/26324 "コーパス") を「読解タスク」に応じた内容のテキストに変換してLLMの学習に利用する手法です。

生物医学、金融、法律の3分野で検証が行われ、一般的なタスクでの性能も評価されました。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_73575-1024x576.jpg)

**参照論文情報**

- タイトル：Adapting Large Language Models to Domains via Reading Comprehension
- 著者：Daixuan Cheng, Shaohan Huang, Furu Wei
- 所属：Microsoft Research, Beijing Institute for General Artificial Intelligence (BIGAI)
- その他の情報：ICL [R2](https://ai-data-base.com/archives/26434 "決定決定係数（R2）") 024に採択

## 背景

LLMを実用するにあたっては、専門的な分野に対する知識を持つように調整することが必要だと考えられています。

これまで、専門分野向けLLMを開発するアプローチとしては、主に3つの方法が採用されてきました。  
1つ目は、専門分野のデータと一般的なデータを組み合わせてゼロからモデルを学習させる方法です。この方法はシンプルですがコストが高くなってしまいます。  
2つ目は、教師あり学習データセットを用いてファインチューニングする方法です。コスト効率が良いものの、タスクに特化しすぎてしまい、汎用的な専門知識の獲得が難しいという問題があります。  
3つ目は、一般的なLLMに専門知識を含む情報を与えてプロンプティングする方法ですが、これはLLM自体を改善するというよりは、LLMの応用方法の一つと考えられています。

そこで本研究では、人間の学習プロセスにヒントを得た新しいアプローチが考案されました。「読解問題に取り組んだあとに練習問題を解く」と質問応答能力が向上しているという考え方です。

この着想から、生 [コーパス](https://ai-data-base.com/archives/26324 "コーパス") を読解問題に変換する手法が提案され、成果が出ました。

なお生 [コーパス](https://ai-data-base.com/archives/26324 "コーパス") とは、自然言語での実例を集めた大規模なテキストデータ集合を指します。人為的に作成されたものではなく、実際の文書、記事、会話などから収集された「生の」テキストデータです。本研究では、各ドメイン（生物医学、金融、法律）に関連する大量のテキストデータが生 [コーパス](https://ai-data-base.com/archives/26324 "コーパス") として使用されています。

以下で提案手法と実験結果を詳しく紹介します。

なお下の図は生物医学、金融、法律の3つのドメインにおける特定タスクの性能を比較したものです。一般LLM、DAPT（生 [コーパス](https://ai-data-base.com/archives/26324 "コーパス") で学習したモデル）、AdaptLLM（今回提案された手法）の結果を示しています。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_73575_1-1024x605.png)

## ドメイン適応事前学習の効果

本研究ではまずはじめに、ドメイン適応事前学習の効果を検証する予備調査が実施されました。

ドメイン適応事前学習とは、既存の言語モデルを特定の分野（ドメイン）に適応させるための手法です。一般的な知識を持つ言語モデルを、特定分野のデータを用いて追加学習させることで、そのドメインに特化した知識や言語使用を獲得させる過程を指します。

今回は一般的なLLaMAモデルを生物医学、金融、法律の各分野の生 [コーパス](https://ai-data-base.com/archives/26324 "コーパス") で継続学習させ、その効果がプロンプティング、ファインチューニング、知識プロービングの3つの方法で評価されました。

プロンプティング評価は、モデルに普通に質問をして答えを見る方法です。例えば、「この薬の副作用は？」と聞いて、答えが正しいかを確認します。日常会話のようにモデルが答えられるかをチェックするものです。

またファインチューニング評価は、モデルに特定のタスクを教えてから、そのタスクをどれだけ上手くできるかを見る方法です。例えば、病気の診断をする練習をさせてから、実際に診断ができるかテストします。

そして知識プロービング評価は、モデルが特定の事実を知っているかを直接確認する方法です。「人間の心臓は何室ある？」のような質問をして、正しく答えられるかを見ます。モデルが覚えている具体的な知識を確認するテストのようなものです。

予備調査の結果、以下の重要な知見が得られました。

1. ファインチューニング評価では、ドメイン適応事前学習を経たモデルが全ての分野で一般モデルを上回りました。
2. しかし、プロンプティング評価では、ほとんどの分野で性能低下が観察されました。
3. 知識プロービングテストでは、ドメイン知識の獲得が確認されました。

結果をまとめると、ドメイン適応事前学習はドメイン知識を強化する一方で、プロンプティング能力（質問や指示に対して適切に応答する能力）を低下させる可能性が示唆されました。この課題を解決することが、今回新しいアプローチを開発する動機となりました。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_73575_3-1024x177.png)

一般モデルとドメイン適応事前学習（DAPT）を行ったモデルのドメイン特化タスクにおけるプロンプティング、ファインチューニング、知識プロービングの性能比較

なお、以下では生 [コーパス](https://ai-data-base.com/archives/26324 "コーパス") で学習（適応事前学習）したモデルをDAPTとして表記します。

## 読解を通じたLLMの適応

今回考案されたのは、ドメイン特化型の生 [コーパス](https://ai-data-base.com/archives/26324 "コーパス") を直接用いるのではなく、「読解テキスト」に変換する手法です。

### 「読解テキスト」の構造

読解テキストは以下の2つのフェーズで構成されます。

1. **「読む」フェーズ  
	**生テキストを読み込む段階
2. **「理解する」フェーズ  
	**テキストの内容に関連するタスクを解く段階

タスクは質問応答形式で設計されます。なお先述したように、この考え方は人間の学習プロセスにヒントを得ています。読んだ後に練習問題を解くことで、獲得した知識に基づく質問応答能力が向上するという考えです。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_73575_2-1024x553.png)

読解テキストの簡略化された例。生のテキストに続いて、そのテキストから構築された一連のタスクが示されている

### 読解テキストの作成方法

読解テキストの作成は、生 [コーパス](https://ai-data-base.com/archives/26324 "コーパス") をタスクに変換する手法が活用されました。

タスクは以下の6種類です。

1. **要約  
	**テキストの主要な内容を簡潔にまとめるタスク
2. **単語からテキスト生成  
	**特定の単語を含む文章を生成するタスク
3. **自然言語推論  
	**2つの文の関係性を判断するタスク
4. **常識推論  
	**物理的または科学的な推論を行うタスク
5. **パラフレーズ検出  
	**2つの文が意味的に等価かどうかを判断するタスク
6. **テキスト補完  
	**与えられたテキストの続きを生成するタスク

タスクは、入力と出力のテンプレートを用いて記述されます。なお、各テンプレートは複数の言い換えバリエーションが用意されました。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_73575_4-1024x789.png)

入出力テンプレートの概要。各タスクタイプに対するパターンとテンプレートが示されている

```js
要約タスク
「要約するとどうなりますか？ {タイトル}」
「{文1}は {文2}について言っています」

単語からテキスト生成タスク
「これら{ドメイン}のキーワード[{単語1}, {単語2}, {単語3}]について文を生成してください： {文}」
「{単語}をどのように定義しますか？ {文}」

自然言語推論
「"{文1}"は"{文2}"を含意していますか？ {はい/たぶん/いいえ}」

常識推論
「{文1}の{結果/原因}は何ですか？ {文2}」

段落検出
「"{文1}"を{支持/反論}する文を作成してください。 {文2}」

テキスト補完
「この記事をどのように完成させますか？ {エンディング}」
```

下の表は、テンプレートにバリエーションを持たせるためのものです。モデルがより自然な言語使用を学習できるように、さまざまな言い回しが用意されました。 [過学習](https://ai-data-base.com/archives/26427 "過学習") の防止も目的となります。日本語においても同様のプロセスを行うことが推奨されます。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_73575_5-1024x611.png)

各タスクで使用される動詞句のリスト

### 一般的な指示文の追加

読解テキストに加えて、一般的な指示文も学習データに組み込まれました。より幅広い入出力パターンへの対応を可能とするためです。既存の指示文データセット（LIMA、WizardLM、Orcaなど）が活用されました。

## 実験

### ドメイン適応事前学習

生物医学分野では、The PileデータセットのPubMed Abstracts、法律分野ではThe PileデータセットのFreeLaw Opinionsが使用されました。金融分野については、FinGPTコードベースを用いて7,000以上の株式に関する2022年5月から2023年5月までの金融ニュースが収集されました。

一般的な指示文は、LIMA、WizardLM、Orcaから取得されました。各ドメインで、読解テキストと一般的な指示文の最適な混合比率が探索され、生物医学と法律では1:1、金融では1:2の比率が採用されました。

基本モデルとしてLLaMA-7Bが使用され、各ドメインで継続学習が行われました。

### 読解テキストの作成

以下の流れで、元の専門的な文章から、LLMが学習しやすい形式の教材を作り出しました。

1. **特定のパターンを使って、元の文章から役立つ情報を見つけ出す  
	**例えば、定義や因果関係などの情報を探す
2. **同じ種類の情報ばかりにならないように、各文章から取り出す情報の量を制限する  
	**各カテゴリーから最大2つまでの例を選ぶ
3. **見つけた情報を使って、様々な形の質問や課題を作る  
	**例えば、同じ内容でも質問の仕方を変えたり、逆の質問を作ったりする
4. **質問や課題を元の文章とつなげて、新しい「読解テキスト」を作る  
	**質問や課題の間には空白行（\\n\\n）を入れて、読みやすくする
5. **平均して、1つの元の文章から約2つの質問や課題（入出力例）が作られる**

### ドメイン特化タスクの評価

各ドメインで以下のタスクが評価されました。

生物医学

1. PubMedQA: 医学文献に基づく質問応答
2. ChemProt: 化学物質と蛋白質の相互作用の分類
3. MQP: 医療質問のペアが類似しているかの判断
4. RCT: 医学論文の文の役割分類（背景、方法、結果など）
5. USMLE: 米国医師国家試験の問題解答

金融

1. ConvFinQA: 金融に関する対話形式の質問応答
2. FPB: 金融文書の [感情分析](https://ai-data-base.com/archives/26497 "感情分析")
3. FiQA SA: 金融テキストの [感情分析](https://ai-data-base.com/archives/26497 "感情分析")
4. Headline: ニュース見出しの株価への影響予測
5. NER: 金融文書中の固有表現（企業名など）の認識

法律

1. SCOTUS: 米国最高裁判決の争点分類
2. CaseHOLD: 法律文書の穴埋め問題
3. UNFAIR-ToS: サービス利用規約の不公平条項の検出

### 評価方法

プロンプティング評価では、各タスクに複数のプロンプトテンプレートが用意され、データ例ごとにランダムに1つが選択されました。テンプレートによる結果のばらつきをなくすためです。

タスクは2種類の質問タイプに分類されました。

1. 多肢選択問題：各選択肢のトークンごとの尤度を比較して予測を行う
2. テキスト補完問題：貪欲探索を用いて自由形式の回答を生成する

なお、金融分野のプロンプト設定はBloombergGPTに準じています。

生物医学分野の一部の分類タスク（MQP、RCT、ChemProt）は、モデルにとって難易度が高いため、少数ショットプロンプティングが採用され、各クラスのデモンストレーション数が同じになるよう調整されました。

## 主な実験結果

提案手法（AdaptLLM）の性能が、従来の手法と比較されました。さらに、各ドメインで公開されている他のモデルとの比較も行われました。

### 一般モデルとの比較

前述した3つのドメイン（生物医学、金融、法律）における様々なタスクにおいて、生 [コーパス](https://ai-data-base.com/archives/26324 "コーパス") の学習では、プロンプティング性能が低下する傾向が見られました。一方、AdaptLLMではこの問題が克服され、一般的な言語モデルを上回る性能が達成されました。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_73575_6-1024x888.png)

一般モデル、DAPT、AdaptLLM、および各ドメインの既存モデルのドメイン特化タスクにおけるプロンプティング評価の結果比較

### 各ドメインでの比較結果

（１）生物医学分野

MedAlpaca（LLaMAを医療質問応答指示でファインチューニングしたモデル）との比較が行われました。MedAlpacaは一部のドメイン特化タスクでLLaMAを上回りましたが、その優位性は一貫していませんでした。MedAlpacaは指示が十分なドメイン知識を付与できていないか、特定のドメインに特化した指示が様々な入出力シナリオに対応できていない可能性が示唆されています。

（２）金融分野

BloombergGPT（金融と一般的な [コーパス](https://ai-data-base.com/archives/26324 "コーパス") を混合してゼロから学習したモデル）との比較が行われました。LLaMA-7BはBloombergGPT-50Bより低いスコアでしたが、AdaptLLM-7Bは同等の性能を達成しました。

（３）法律分野

LexGPT（GPT-Jに法律分野の生 [コーパス](https://ai-data-base.com/archives/26324 "コーパス") を用いてドメイン適応事前学習を行ったモデル）との比較が行われました。LexGPTはGPT-Jと比較してプロンプティング結果が悪化しており、生 [コーパス](https://ai-data-base.com/archives/26324 "コーパス") での継続学習がプロンプティング性能を低下させるという傾向そのものです。一方、AdaptLLMではプロンプティング結果が改善され、提案手法の有効性が示されました。

### 考察

実験結果から、AdaptLLMの特徴が以下のように整理されます。

1. 効果的にドメイン知識が獲得される
2. 従来見られたプロンプティング能力の低下が克服されている
3. ゼロから学習を行うモデルと比較して、より少ないパラメータ数で同等の性能を達成している
4. 特定のドメインや指示に過度に特化せず、様々なタスクに対応できる能力が維持されている
5. 生物医学、金融、法律という異なるドメインで一貫した性能向上が見られ、手法の汎用性が示されている

## 訓練データに関する分析

異なる訓練データとその組み合わせによる影響が詳細に分析されました。

### 分析対象のデータ種類

1. **生テキスト  
	**従来のドメイン適応事前学習で使用される生の [コーパス](https://ai-data-base.com/archives/26324 "コーパス")
2. **読解テキスト  
	**生 [コーパス](https://ai-data-base.com/archives/26324 "コーパス") を変換して作成された読解タスク付きのテキスト
3. **一般指示文  
	**汎用的なタスクに関する指示文
4. **読解テキスト + 一般指示文  
	**上記2と3の組み合わせ

### 結果の概要

まず、生のテキストだけを使うよりも、質問や課題を含む「読解テキスト」を使って学習させた方が、LLMの応答能力が全ての分野で向上しました。様々な形の質問に答える練習をすることで、LLMがより柔軟に対応できるようになったことを示しています。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_73575_7-1024x169.png)

異なる訓練データ（生テキスト、読解テキスト、一般指示文、およびそれらの組み合わせ）を使用した場合のプロンプティング評価スコアの比較

さらに、この「読解テキスト」に一般的な指示文を加えて学習させると、LLMの性能がさらに良くなりました。多様な質問のパターンに触れることで、LLMがより幅広い状況に対応できるようになったためだと考えられます。

最後に、一般的な指示文だけで学習するよりも、専門分野の「読解テキスト」を含めて学習した方が、その分野の特殊な課題でより良い結果を出しました。「読解テキスト」を通じて、LLMが各分野の専門的な知識をうまく身につけられたことを示しています。

つまり、本手法は、LLMが専門知識を学びながら同時に様々な質問に柔軟に答える能力も向上させる効果的な学習方法だということがわかりました。

### 読解タスクタイプの分析

各読解タスクタイプ（要約、単語からテキスト生成、自然言語推論など）の効果も個別に分析されました。その結果、「単語からテキスト生成」と「自然言語推論」のタスクが、ドメイン特化タスクにおいて特に高い効果を示すことが明らかになりました。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_73575_8-1024x478.png)

メイン特化タスクのファインチューニング評価と一般タスクのプロンプティング評価の結果比較。一般LLM、生テキスト、読解テキストで学習したモデルの性能を示している

### 考察

以上から、LLMの学習方法について興味深い洞察が得られました。

まず、生のテキストを質問や課題を含む「読解テキスト」に変換することで、LLMは専門知識を学びながらも、様々な質問に答える能力を維持できることがわかりました。専門性と柔軟性を同時に高める効果的な方法だと言えます。

次に、一般的な指示文を加えることの重要性も明らかになりました。LLMは特定の分野の知識を深めつつ、幅広い状況に対応する能力も向上させることができます。つまり、専門性と汎用性のバランスを取るのに役立つのです。

また、全ての学習タスクが同じように効果があるわけではないことも分かりました。単語から文章を作り出すタスクや、文章の論理関係を理解するタスクが、LLMの能力向上に大きく貢献していることから明らかです。

まとめると、高性能な専門LLMを開発するには、専門知識の獲得と幅広い質問に答える能力のバランスが重要だということが示されています。

## ドメイン知識とプロンプティング能力の分析

提案された「読解テキストを用いた学習手法」が、ドメイン知識の獲得とプロンプティング能力の向上にどのように寄与しているかが詳細に分析されました。プロンプティング能力とは繰り返しになりますが、適切な応答能力です。

### ドメイン知識の評価

以下の評価結果が得られました。

1. **ファインチューニング評価  
	**読解テキストで学習したモデルは、全てのドメインにおいてドメイン特化タスクの性能が一貫して向上しました。なお、生テキストで学習したモデルよりも高い性能を示した点は注目に値します。多様な読解タスクが「マルチタスク指示チューニング」の効果をもたらし、単一タスクのファインチューニングにも好影響を与えたと考えられます。
2. **知識プロービング評価  
	**生物医学と法律の分野で実施された知識プロービングテストでも、読解テキストで学習したモデルの性能向上が確認されました。

まとめると、読解テキストを通じて効果的にドメイン知識が獲得されていることが実証されました。

### プロンプティング能力の評価

プロンプティング能力の向上を検証するため、一般的なLLMベンチマークタスク（下記）を用いたゼロショットプロンプティング評価が実施されました。

1. **各読解タスクタイプに対応する一般タスク  
	**FLANのタスククラスタリング設定に従い、各読解タスクタイプに対して少なくとも3つの一般タスクが評価されました。
2. **一般的な読解理解と閉じた本の質問応答タスク  
	**文脈ありとなしの両方の場合で質問に答える能力が評価されました。

結果として、読解テキストで学習したモデルは、全てのタスクタイプで一貫してプロンプティング性能が向上しました。一般的な指示文を含めずにドメイン特化読解テキストのみで学習したモデルが、ほとんどのタスクタイプで一般的な言語モデルを上回ったのです。

### 結果の考察

結果から、以下のように考察が可能です。

まず、「読解テキスト」を使った学習方法により、LLMが専門知識を身につけながら、同時に様々な質問に柔軟に答える能力も向上させられることがわかりました。専門性と応用力を同時に伸ばせるという意味です。

さらに興味深いのは、特定の分野に特化した学習をしたにもかかわらず、一般的な課題でも性能が向上したことです。本手法が専門性と汎用性のバランスを上手く取れていることを示しています。

加えて、この方法が効率的であることも示されました。短時間で専門知識と質問応答能力の両方を向上させられるのは大きなメリットです。

## まとめ

本記事では、LLMをドメインに適応させる新しい手法の研究を紹介しました。

生 [コーパス](https://ai-data-base.com/archives/26324 "コーパス") を読解テキストに変換して学習に利用する本手法は、ドメイン知識の獲得とプロンプティング能力の向上を同時に実現するものとして結論づけられています。生物医学、金融、法律の分野で一貫した性能向上が確認され、一般的なタスクでも改善が見られました。

- 参照論文URL： [https://arxiv.org/abs/2309.09530](https://arxiv.org/abs/2309.09530)
- モデル： [https://huggingface.co/AdaptLLM](https://huggingface.co/AdaptLLM)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[LLMでASDを含む人間同士のコミュニケーションを支援するアプリケーション開発事例](https://ai-data-base.com/archives/73534)

[Appleが「LLMエージェントの評価」に特化したベンチマーク『MMAU』を開発　5領域5能力で測る](https://ai-data-base.com/archives/73656)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)