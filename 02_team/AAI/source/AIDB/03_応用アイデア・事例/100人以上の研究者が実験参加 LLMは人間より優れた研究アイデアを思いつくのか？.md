---
title: "100人以上の研究者が実験参加 LLMは人間より優れた研究アイデアを思いつくのか？"
source: "https://ai-data-base.com/archives/75562"
author:
  - "[[AIDB Research]]"
published: 2024-09-12
created: 2025-06-13
description: "この記事では、LLMと人間の専門家による研究アイデア作りの能力を比べた大規模な研究を紹介します。研究の目的は、科学研究の自動化を進めるための知見を集めることでした。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

この記事では、LLMと人間の専門家による研究アイデア作りの能力を比べた大規模な研究を紹介します。研究の目的は、科学研究の自動化を進めるための知見を集めることでした。

実験には100人以上の [自然言語処理](https://ai-data-base.com/archives/26319 "自然言語処理（NLP）") （ [NLP](https://ai-data-base.com/archives/26319 "自然言語処理（NLP）") ）の研究者が参加し、LLMと人間が考えたアイデアが比較されました。そして「新しさ」や「実現できるかどうか」など5つの基準で評価が行われました。

その結果は非常に興味深いものでした。

なお、LLMで研究アイデアを生成する際にはRAGも含めたエージェントの仕組みが設計されました。その設計内容も有益な知見となる可能性があります。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75562-1024x576.jpg)

**参照論文情報**

- タイトル：Can LLMs Generate Novel Research Ideas? A Large-Scale Human Study with 100+ [NLP](https://ai-data-base.com/archives/26319 "自然言語処理（NLP）") Researchers
- 著者：Chenglei Si, Diyi Yang, Tatsunori Hashimoto
- 所属：Stanford University

## 背景

LLMが急速に進歩し、科学的な発見を早める可能性が高まっています。研究のアイデアを自動的に考えるエージェントも作られつつあります。しかし、これまでは、LLMが”専門家並み”の新しいアイデアを思いつけるかはわかっていませんでした。

そこで今回研究者らは、研究のアイデア作りを”評価する方法”そのものを作りました。そして、LLMのアイデア作りエージェントを設計し、専門家の [自然言語処理](https://ai-data-base.com/archives/26319 "自然言語処理（NLP）") （ [NLP](https://ai-data-base.com/archives/26319 "自然言語処理（NLP）") ）研究者と直接比べました。このようなプロジェクトは初の試みです。

実験には100人以上の [NLP](https://ai-data-base.com/archives/26319 "自然言語処理（NLP）") 研究者が参加し、一方のグループには新しいアイデアを書いてもらい、LLMと人間のアイデアを（どちらが作ったかは伏せて）もう一方のグループに評価してもらいました。

なお、LLMエージェントの基本的な性能も詳しく調べた結果、まだ解決していない問題も見つかりました。

以下に研究の問題設定とLLMエージェント設計、そして実験結果を詳しく紹介します。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75562_1-1024x326.png)

79人の専門家研究者による3つの条件（人間のアイデア、AIのアイデア、AI+人間の再ランク付けしたアイデア）の49個のアイデアに対するブラインドレビューの概要

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75562_2-1024x284.png)

3つの実験条件における全てのレビュー指標の比較

## 問題設定

この研究のメインテーマは、人間とLLMが考えた研究アイデアを比べることでした。しかし研究アイデアを考えて評価する方法には、まだ決まりがありません。そこで、まず実験の重要事項を決めることから始められました。

そして研究のアイデアを評価するには、次の3つが必要だと考えられました。

1. 指示に従って考えられたアイデア
2. そのアイデアを説明する文章
3. 専門家によるその文章の評価

### アイデア生成の範囲と指示

研究のアイデアにはさまざまな種類があります。簡単な工夫から、大きな研究計画まであります。実験では、アイデアが現実的で面白いこと、そして多くの人が参加できることのバランスを考える必要があります。

今回の研究では、”プロンプティングを使った [NLP](https://ai-data-base.com/archives/26319 "自然言語処理（NLP）") の研究”を対象にしました。最近人気のある分野で、適度なバランスが取れていることが多く、また限られたマシンパワーでも実行できます。

さらに、アイデアを考える過程での偏りを避けるため、7つの研究トピック（下の表を参照）を用意し、人間とLLMの両方に同じ指示を与えました。人間の参加者には好きなトピックを選んでもらい、それに合わせてLLMのアイデアも作りました。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75562_7.png)

アイデアトピックの分布

### アイデアの文章化

アイデアは文章にして伝える必要があります。この過程でも何らかの偏りが生じる可能性があります。そこで、助成金申請のガイドラインを参考に、アイデア提案の形式を決めました。タイトル、問題文、動機、方法、実験計画、例、代替案などを含むテンプレートを作りました。

さらに、文章のスタイルによる影響を減らすため、LLMを使ってすべてのアイデアを同じスタイルに変換しました。これで、評価の際に専門家が人間とLLMのアイデアを区別できなくなりました。

### レビューと評価

研究アイデアの評価は主観的になりがちです。そこで、評価基準は明確に定義され、できるだけ標準化されました。AIの学会のレビュー方法を参考に、新しさ、面白さ、実現可能性、期待される効果の4つの指標が設定されました。そして各指標について1〜10点で評価し、理由も書いてもらいました。

そのようにして、以下3種類のアイデアが比べられました。

1. 人間のアイデア（専門家が書いたもの）
2. LLMのアイデア（LLMが生成したもの）
3. LLMが生成したアイデアから人間が選んだもの

## アイデア生成エージェント

人間の専門家と比べるため、シンプルかつ効果的なLLMアイデア生成エージェントが作られました。エージェントそのものを新しくするのではなく、LLMが今どれくらいアイデアを生み出せるかを理解することを目指して作られました。「論文を探す」「アイデアを作る部分」「アイデアの順位をつける」といった3つの機能があります。それぞれについて詳しく説明します。

なお、実験で使用されたバックボーンLLMはclaude-3-5-sonnet-20240620です。

### RAGで論文検索

アイデアを考え出す基礎として、エージェントは与えられた研究トピックに関係する論文を探す必要があります。そこでRAGが使用されました。

研究トピックが与えられると、LLMはSemantic Scholar APIを使って論文を探すよう指示が与えられます。エージェントの中心となるモデルはclaude-3-5-sonnet-20240620ですが、他のLLMでも使えるはずです。

今回は、最大120の論文が見つかるまで検索を続けるよう設定されました。その後、LLMを使って全ての論文に点数をつけ、順位をつけ直します。点数は以下の3つの基準に基づきます。

（１）トピックに直接関係しているか  
（２）実験を含む実証的な論文か  
（３）面白くて、新しいプロジェクトのヒントになるか

### アイデア生成

アイデアを生み出す上で大切なのは、できるだけたくさんの候補を作ることです。たくさんの候補の中から、後で良いものを見つけ出せるようにします。

そこで今回、各研究トピックについて4000個のアイデアの種を作るようLLMに指示が与えられました。アイデアを作る時には、お手本となる例と探した論文を参考にします。また、以前に作ったアイデアのタイトルも示して、同じものを繰り返さないよう指示します。

たくさんのアイデアの中から似たものを取り除くため、全てのアイデアを数値化して比較します。似ているアイデアを取り除いた後、約5%のアイデアが残ります。

### アイデアのランキング

次に、エージェントは残ったアイデア全てに順位をつけ、その中から最も良いものを見つけます。その際、公開されているレビューデータを参考にします。

公開されているレビューデータとは今回の場合、1200のICLR 2024の投稿とそのレビュースコアなどです。そしてLLMにアイデアの良し悪しを判断させる方法を探り、「2つのアイデアを比べてどちらが良いかを判断させる」アプローチが最も効果的だと分かりました。

なお、全てのアイデアに信頼できる点数をつけるために、”スイスシステムトーナメント”という方法が使われました。似た点数のアイデア同士を比べて良いと判断されたアイデアに点を与える作業を繰り返して、各アイデアの合計点を出す方法です。

ただしLLMによるランク付けがまだ完璧ではないため、人間が手動でアイデアの順位をつけ直す条件も設けました。そして、LLMと人間の専門家では、アイデアの順位付けに違いがあることがわかりました。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75562_3.png)

LLMランカーによってランク付けされたICLR投稿のトップ10とボトム10の平均レビュースコアを、異なるラウンド数での比較

## 専門家によるアイデア作成とレビュー

### 専門家の募集

アイデアを作ったりレビューしたりする専門家は、以下の方法で募集されました。

1. Open [NLP](https://ai-data-base.com/archives/26319 "自然言語処理（NLP）") のSlackチャンネル（71の機関から1426人の [NLP](https://ai-data-base.com/archives/26319 "自然言語処理（NLP）") 研究者が参加）
2. Twitter (X)
3. さまざまな [NLP](https://ai-data-base.com/archives/26319 "自然言語処理（NLP）") グループのSlackチャンネル
4. NAACL 2024会議の公式チャットアプリ

また、会議やイベントでも直接募集されました。

アメリカの参加者は、Google Scholarのプロフィールを基に選ばれました。主要なAI会議で少なくとも1本の論文を発表していることが条件でした。

最終的に、49名がアイデアを作り、79名がアイデアをレビューしました。アイデアを作った人には300ドル、レビューした人には1レビューあたり25ドルの報酬が支払われたとのことです。

参加者は高いレベルの資格を持ち、さまざまな背景を持っています。アイデアを作った49名は26の異なる機関から集まり、主に博士課程の学生でした。レビューした79名は32の機関から集まり、主に博士課程の学生とポスドクでした。

参加者の多くは、多くの論文を書いており、引用も多く受けています。また、レビューした人の大多数が、以前に主要なAI会議や学術誌のレビューをした経験があります。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75562_4.png)

アイデア執筆参加者とアイデアレビュー参加者の研究プロフィール指標

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75562_5-1024x212.png)

アイデア執筆参加者とアイデアレビュー参加者の研究プロフィール指標

### アイデア作成

アイデアを作った人は、選んだトピックにやや詳しく、タスクをやや難しいと感じていました。平均5.5時間かけてアイデアを考え、902語の長さの提案を書きました。要するに参加者はこの作業にかなり力を入れてくれました。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75562_6.png)

各条件の49個のアイデアの統計

### アイデアのレビュー

レビューする人には、好きなトピックと希望するレビュー数を選んでもらいました。その後、選んだトピックの中でランダムにアイデアを割り当てました。全てのアイデアは名前を隠し、各レビュアーが少なくとも1つの人間のアイデアと1つのAIのアイデアをレビューするようにしました。

レビューした人は、トピックにやや詳しく、レビューにもやや自信があると答えました。平均32分かけて1つのレビューを書き、約232語の長さでした（ICLRというAI会議のレビューと同じくらいの長さです）。

また、298のレビューのうち80件が、アイデアが新しくない理由を説明するために、既存の論文へのリンクを提供していました。よく調べ、よく考えたこと（レビューの質が高いこと）を示しています。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75562_8.png)

レビュー割り当ての統計

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75562_9.png)

収集したレビューの統計と、ICLR 2024のレビューとの比較

## 主な結果

実験で得られた3つの統計結果から、AIのアイデアは人間のアイデアよりも新規性スコアが高く、他のすべての指標では同等であることが示されました。

### 統計1

まず、各レビューが独立したデータポイントとして扱われ、同じ条件からのすべてのレビューが集約されました。人間のアイデアがベースライン条件として扱われ、AIアイデアとAIアイデア+人間再ランクがボンフェローニ補正を用いた両側Welchのt検定で比較されました。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75562_10-1024x682.png)

各レビューを独立したデータポイントとして扱った場合の、全条件におけるスコア AIのアイデアが人間のアイデアよりも新規性と興奮度において有意に優れていることが示されている

新規性スコアにおいて、AIアイデア（μ = 5.64±σ = 1.76）とAIアイデア+人間再ランク（μ = 5.81±σ = 1.66）の両方が、人間のアイデア（μ = 4.84±σ = 1.79）よりも有意に優れていることが示されました（p < 0.01）。

つまり、両方のAIアイデア条件も興奮度スコア（どれくらいワクワクするものか）において人間のアイデアよりも有意に優れており、AIアイデア+人間再ランク条件は全体的なスコアでも人間のアイデアよりも有意に優れていることが示されました。

### 統計2

次に、各アイデアのスコアが平均され、各アイデアが1つのデータポイントとして扱われました。すべての条件のサンプルサイズはN=49、つまりアイデアの数となりました。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75562_11-1024x681.png)

各アイデアのスコアを平均し、各アイデアを1つのデータポイントとして扱った場合の、全条件におけるスコア AIのアイデアが新規性において人間のアイデアよりも有意に優れていることが確認されている

結果として、AIアイデア（μ = 5.62±σ = 1.39）とAIアイデア+人間再ランク（μ = 5.78±σ = 1.07）の両方が、人間のアイデア（μ = 4.86±σ = 1.26）よりも新規性スコアが高いという有意な結果（p < 0.05）が依然として見られました。

### 統計3

最後に、各レビュアが1つのデータポイントとして扱われ、各条件に対する平均スコアが計算されました。異なる条件間の差のみが分析され、一標本t検定が行われました。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75562_12-1024x631.png)

各レビュアーを1つのデータポイントとして扱い、AIのアイデアと人間のアイデアの間のスコア差の平均 新規性と興奮度において、AIのアイデアが有意に高いスコアを得ていることが示されている

結果として、AIアイデアとAIアイデア+人間再ランクの両条件で、AIアイデアが人間のアイデアよりも新規性が高いと評価されるという有意な結果（p < 0.05）が見られました。

## 人間アイデアの分析

追加で、人間のアイデアの質、レビュアーの好み、およびレビュアーの合意の程度に焦点が当てられて分析が行われました。

### 人間の専門家は最良のアイデアを提供していない可能性がある

研究後のアンケートが実施され、アイデア作成参加者がどのようにアイデアを思いついたかが調査されました。49人の参加者のうち、37人がその場でアイデアを思いつき、残りの12人は研究前からアイデアを持っていたことが分かりました。

さらに、参加者は提出したアイデアが過去のアイデアの上位43%程度であると回答しました。

ということは、収集されたアイデアが実験に参加した専門家研究者の中位レベルのアイデアである可能性が高いことを示唆しています。

### レビュアーは新規性と興奮度により注目する傾向がある

レビュープロセスにおける異なる指標間のダイナミクスを理解するために、レビュアーがアイデアを評価する際に特定の側面に注目しているかどうかが探られました。

全体的なスコアは主に新規性スコア（r = 0.725）と興奮度スコア（r = 0.854）と相関しており、実現可能性スコアとはほとんど相関がないこと（r < 0.1）が分かりました。

この分析はレビュアーがアイデアをレビューする際に、新規性と興奮度の側面により注意を払っている可能性があることを示唆しています。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75562_13.png)

異なる評価指標間の 相関係数 を示す 全体的なスコアが新規性と興奮度と強い相関を持つ

### アイデアのレビューは本質的に主観的である

レビューが本質的に主観的であり、また実行された論文ではなく「アイデアに基づいてレビューする」ことはさらに主観的である可能性があることもわかりました。

このことはレビュアー間の一致度を使用して調査されました。各論文のレビュアーがランダムに半分に分けられ、一方の半分を使用してすべてのアイデアの上位25%と下位25%がランク付けされ、次に保留されたレビュアのセットとの一致度が測定されました。レビューフォームで各指標の詳細な説明が提供されたにもかかわらず、レビュア間の一致度は比較的低い（56.1%）ことが示されました。

比較のベースラインとして、NeurIPS 2021のレビュア一貫性実験では66.0%の精度が、ICLR 2024の言語モデル関連提出物では71.9%の精度が見出されました。

レビュアー一致度はランダム（50%）よりは高いものの、一般的に会議のレビューよりも低くなっています。

おそらく実際の実験結果を見ずにアイデアを評価する際の主観性がより高いためだと考えられます。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75562_15.png)

人間のレビュアー間の一致度と、人間とAIの間の一致度を比較 この研究でのレビュアー間の一致度が、他の学会のレビュープロセスよりも低いことが示されている

## LLMの限界

今回研究者らは、LLMを用いたアイデア生成システムの限界も考察しました。以下の2つが主な観点でした。

1. 人間よりも多くのアイデアを生成する能力
2. 大量のアイデアから最良のものを抽出する能力

### LLMはアイデア生成において多様性に欠ける

各トピックについて4000個のアイデアが生成されましたが、非重複の固有アイデアは200個しかないことが分かりました。新しいアイデアを生成し続けても、最終的には重複したアイデアが増えるだけで、新しいアイデアの割合が減少していくことが示されました。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75562_14-1024x357.png)

AIが生成したアイデアの重複を測定し、生成されたアイデアの総数に対する非重複アイデアの割合（左）と累積非重複アイデア数（右）の推移

### LLMはアイデアを信頼性高く評価できない

LLMをアイデアの評価者として使用することも試みられましたが、信頼性の高い評価ができないことが示されました。

LLM評価者は以下の3つが比較されました。

1. 直接スコアを求めるプロンプト
2. ペアワイズランカー
3. “AI Scientist”レビュアエージェント

（※”AI Scientist”レビュアエージェントとは、SakanaAIの研究に基づくエージェントだと考えられます。参考： [Sakana AIが科学研究自動化フレームワーク『The AI Scientist』開発](https://ai-data-base.com/archives/74257) ）

すべてのLLM評価者が、専門家レビュアーのスコアよりも低い一致度を示しました。最良のLLM評価者でさえ、人間のレビュアー間の一致度を下回る結果となりました。

さらに、もしLLM評価者が一貫性を示したとしても、それが見せかけの相関関係に依存している可能性が指摘されています。

この結果は、「複雑で主観的なタスクにおいてLLMを評価者として使用することには、慎重になる必要がある」ことを示唆しています。

## 定性的分析とアイデア例

最後に人間とAIが生成したアイデアの定性的分析（上述までの結果は定量的分析）が行われ、ランダムに抽出した4つのペアがケーススタディとして利用されました。

### 自由記述レビューの分析

Claude-3.5を使用してレビューから主要なポイントが抽出され、クラスター化されました。その結果、AIのアイデアの新規性が高く評価されていることが分かりました。

また、AIのアイデアによくある失敗モードも判明しました。

- 実装の詳細が曖昧
- データセットの誤用
- ベースラインの欠落または不適切
- 非現実的な仮定
- リソースの要求が高すぎる
- 動機付けが不十分
- 既存のベストプラクティスに十分従っていない

比較して、人間のアイデアの特徴は以下のとおりです。

1. 既存の研究や実践的考慮事項により根ざしているが、革新性が低い可能性がある
2. 分野の一般的な問題やデータセットにより焦点を当てる傾向がある
3. 新規性や興奮度よりも実現可能性と有効性を優先することがある

（編集部注：3つ目の項目は興味深いですね。（人間の）研究当事者は実現可能性に重きを置く一方で、（人間の）レビュアーは新規性や興奮度に注目しているというギャップが発見されたということです）

### ランダムにサンプリングされた人間とAIのアイデアとレビュー

4つのアイデアのペア（AIと人間のアイデア）がランダムに [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") され、それぞれのタイトル、トピック、平均スコアが提示されました。

| ペア | タイトル（日本語訳） | トピック | 平均全体スコア | 生成者 |
| --- | --- | --- | --- | --- |
| 1 | Modular Calibration for Long-form Answers（長文回答のためのモジュラーキャリブレーション） | 不確実性 | 5.5 | 人間 |
| 1 | Semantic Resonance Uncertainty Quantification（意味的共鳴不確実性定量化） | 不確実性 | 6.0 | AI |
| 2 | Translation with LLMs through Prompting with Long-Form Context（長文コンテキストによるプロンプティングを通じたLLMでの翻訳） | 多言語 | 4.0 | 人間 |
| 2 | Linguistic Pivot Constellation（言語的ピボット星座） | 多言語 | 6.7 | AI |
| 3 | LLM Directed Retrieval Querying for Improving Factuality（事実性向上のためのLLM指向検索クエリ） | 事実性 | 4.7 | 人間 |
| 3 | Semantic Divergence Minimization（意味的乖離最小化） | 事実性 | 3.3 | AI |
| 4 | Autoprompting: Generate Diverse Few-shot Examples for Any Application（オートプロンプティング：あらゆるアプリケーションのための多様なフューショット例の生成） | コーディング | 5.0 | 人間 |
| 4 | Temporal Dependency Unfolding（時間的依存性の展開） | コーディング | 6.7 | AI |

この比較を見ると、LLM（AI）のアイデアは全体的に人間のアイデアよりも新規性が高いと評価される傾向があります。

しかし、LLMのアイデアには実装の詳細が曖昧である、非現実的な仮定をしている、リソース要求が高すぎるなどの問題点も指摘されています。

以上の定性的分析をまとめると、AIのアイデアは新規性が高く評価される傾向がある一方で、実装の詳細や現実的な考慮事項に課題があることが示されました。人間のアイデアは既存の研究に基づいており実現可能性が高い傾向がありますが、革新性に欠ける可能性があることが指摘されました。

## まとめ

本記事では、LLMと人間の専門家による研究アイデア生成能力を比較した研究を紹介しました。100人以上の [NLP](https://ai-data-base.com/archives/26319 "自然言語処理（NLP）") 研究者による評価の結果、AIのアイデアが新規性で人間を上回りましたが、実現可能性ではやや劣りました。

研究チームは、アイデア評価の主観性などの課題を認識しつつ、今後の展開を計画しています。LLMによる研究アイデア生成は科学的発見を加速させる可能性がある一方、アイデアの多様性低下など、慎重に検討すべき課題も残されています。

- 参照論文URL： [https://arxiv.org/abs/2409.04109](https://arxiv.org/abs/2409.04109)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[LLMの推論能力を戦略的に向上させる新しいプロンプト手法『SCoT』](https://ai-data-base.com/archives/75505)

[Self-Reflection（自己反省）がLLMのパフォーマンスに与える影響を網羅的に調査](https://ai-data-base.com/archives/75649)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)