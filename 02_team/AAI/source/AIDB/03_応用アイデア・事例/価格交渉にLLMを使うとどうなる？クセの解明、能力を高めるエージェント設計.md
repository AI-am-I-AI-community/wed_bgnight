---
title: "価格交渉にLLMを使うとどうなる？クセの解明、能力を高めるエージェント設計"
source: "https://ai-data-base.com/archives/90638"
author:
  - "[[AIDB Research]]"
published: 2025-06-09
created: 2025-06-13
description: "本記事では、LLMを価格交渉に使ったときにどんなふるまいを見せるのか、そしてそれをどう改善していけるのかを紹介します。営業支援やチャットボットなどの実務に役立てるには、人間とのやりとりに近づける工夫が欠かせません。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、LLMを価格交渉に使ったときにどんなふるまいを見せるのか、そしてそれをどう改善していけるのかを紹介します。

営業支援やチャットボットなどの実務に役立てるには、人間とのやりとりに近づける工夫が欠かせません。そこで、モデルごとの傾向や交渉のクセ、その違いをどう捉えるかも重要な視点です。

AIと人間の自然な駆け引きを目指すうえで、実務にも応用しやすいヒントになるかもしれません。

![](https://ai-data-base.com/wp-content/uploads/2025/06/AIDB_90638-1024x576.png)

**本記事の関連研究**

- [人間を討論で言い負かすディベート上手なLLMの実装方法](https://ai-data-base.com/archives/74886)

## 背景

価格交渉や条件の交渉のような場面においても、AIをうまく活用できるとしたらどうでしょうか。たとえば、営業やカスタマーサポートの現場で、交渉を支援するAIを活用できれば、現場担当者の負担を減らせるかもしれません。  
あるいは、少し先の未来、チャットボットがユーザーと価格や条件を調整していくことも考えられます。

要するに、LLMを「交渉能力のあるもの」として採用できるかどうかが興味深いポイントです。複数ターンにわたるやりとりの中で駆け引きを行い、戦略的な判断を下せる能力が問われます。

しかし、実際のところ今の段階では2つの大きな壁があると言われています。

まずは、そもそもLLMのそうした能力を評価する上で、リアルな交渉の複雑さをきちんと再現して評価することは難しいこと。  
これまでにもLLMの交渉能力を調べる実験は行われてきましたが、よく使われてきたデータセットは、単一商品の単純な価格交渉に限られ、現実によくある条件（たとえば「分割払いの交渉」や「売り手が独占状態にあるケース」、「評判の悪い売り手との交渉」）は未着手の状況です。

もうひとつは、”交渉相手の動きを見ながら戦略を組み直していく”ような推論をLLMから如何に引き出すかという課題です。現在のLLMは、相手の意図や背景を読み取る力が（他の洗練されている能力と比べると）比較的弱く、たとえば「欲しい商品を確実に手に入れたい」といった人間の気持ちをうまく汲み取れないといった場面も多くあります。

本記事で紹介するのは、上記の課題を踏まえ、現実の市場環境に近い形でLLMの交渉力を引き出すための仕組みです。重要なのは、ただ利益を追うのではなく、「どれだけ希望に沿った交渉結果を得られたか」という観点にあります。

現実のビジネスでLLMを交渉に活かしたいと考える方にとって、今回の話は、AIを交渉に使用するにあたって「どうすれば自然な交渉に近づけるか」「それでもなおまだ難しい点は何か」を考えるヒントになる可能性があります。

## これまでの進歩の整理

LLMに交渉を任せるという発想のもと、過去にはどんな取り組みがあったのかをあらためて振り返っておきます。

### 交渉タスクに関するこれまでの動き

交渉は、単なる会話ではありません。相手の反応を見ながら、妥協したり駆け引きしたりしつつ、自分の希望も通していく必要があります。

このテーマが取り組まれ始めたころ、人間同士がやりとりする交渉データをそのまま学習に使うシンプルな交渉実験が行われました。

その後、「どういう戦略をとるか」と「どう文章にするか」を別々に考える設計が試されるようになり、少しずつ複雑さが増していきました。

また、LLMが自分で自分の出力を評価して、その結果を次の出力に反映するような手法も登場しています。

とはいえ、これまでの研究で扱われてきた交渉は、どれもやや単純な構造にとどまっています。

### 「納得感のある交渉」とは何か

重要な視点は、モデルが出す交渉の結果が、人間にとってどれだけ「納得できるもの」になっているかという点です。たとえば「安く買えたかどうか」だけを指標にしてしまうと、希望の品が手に入らなかったとしても、数字の上では成功と見なされてしまいます。これでは実際のユーザー体験とはズレが生じます。

こうした問題意識のもと、最近は「人間の好みに整合するような報酬設計」をめざす動きが出てきました。人間が「こちらのほうが良い」と感じる選択をもとに、モデルを誘導するような仕組みも試され、利益だけでなく満足度や信頼感といった観点を取り込もうとする試みが進んでいます。

とはいえ、こうした工夫は主に [強化学習](https://ai-data-base.com/archives/26125 "強化学習") の分野で行われており、実装のハードルは高いと言わざるを得ません。

そこで今回研究者たちは新しい工夫を考えました。「この交渉、良かった」と感じられるやりとりを、LLMに教える入口として、まずは評価の軸そのものを見直そうとする試みが行われました。

## LLMの交渉能力を現実的に測定するために

研究者らは、LLMの交渉力を幅広く見直すために実践的内容のベンチマークを構築しました。

作成されたベンチマーク「BARGAINARENA」は、6種類の市場状況を通して、さまざまな交渉パターンを再現する構成になっています。6種類の市場それぞれ、現実に起こりうる取引の特徴や制約を反映しています。

![](https://ai-data-base.com/wp-content/uploads/2025/06/AIDB_90638_2-1024x308.png)

想定されている6つの市場状況

- 最も基本的な交渉の場面として位置づけられており、特別な条件は付加されていない「バニラ市場」
- 売り手や買い手が誤った情報を交渉に持ち込む可能性があり、情報の正確さを見極める必要がある「欺瞞的な市場」
- 売り手が1者しかおらず、買い手にとって選択肢がない状態が想定されている「独占市場」
- 一括での支払いが難しい場合に、支払い方法そのものが交渉対象となる「分割払いが可能な市場」
- 過去のトラブルなどによって売り手にマイナスの印象がついており、それが買い手の態度や価格交渉に影響を与える「評判の悪い市場」
- 希望の商品をそのまま選ぶか、制約に応じて代替品を選ぶかという判断が求められる「複数商品がある市場」。この要素は他の市場タイプに重ねて導入されることもあり、その場合はアスタリスクで区別される

なお、交渉が自然に発生することを前提として、「売り手の初回提示価格」は「買い手の支払い可能な上限」を必ず上回るように設定されています。もし買い手が即座に受け入れられる価格が提示されてしまうと、そもそも交渉が始まらなくなってしまうためです。

### LLMによる交渉の流れ

ベンチマーク上での交渉は、2体のLLMエージェントによって行われ、それぞれの発話は3つの要素に分けて記録されます。

発話をつくる3つの要素

- 相手には共有されない内部の推論を示す部分であり、エージェントの意図や前提の確認が行われる「思考」
- 相手エージェントに向けて発せられる言葉として記録される「発話」
- 発話の中で実際に交渉を進める決定（価格の提示など）にあたる部分だけを抜き出して示す「行動」

### 評価指標としての「支払い意思額」

交渉で使われる金額の指標については、「予算」という表現ではなく「支払い意思額」という言葉が使用されます。

この言い回しが使われる理由は、「単なる金銭的な制約ではなく”この条件であれば払ってもよい”と買い手が感じる心理的な上限」を示すためです。経済学的にも、人間の意思決定の傾向をより適切に捉える考え方とされています。

## 人間の感覚に近づけた評価指標の作成

次に問うべきは、「良い交渉とは何か」です。単に安く買えたかどうかでは測れない、もっと人間にとって自然な評価基準を探っていく必要があります。どんなにリアルな交渉環境を用意しても、それを評価する物差しが不適切なら、意味のある分析にはつながりません。

これまでの交渉研究では、「いくら得をしたか」「どれだけ安く買えたか」といった金額ベースの評価が使われてきました。  
けれども、たとえば希望していた高級カメラではなく、価格が安い代替品を買ったケースを考えてみましょう。金額だけを見れば成功ですが、買い手が満足していないなら、それは本当に良い交渉とは言えないはずです。

こうした違和感に対応するため、研究者らは「人間の感覚に近い」新しい評価軸を導入することにしました。

経済学で使われる効用（満足度）や交渉理論の考え方を取り入れて、交渉の出来栄えを多角的に評価するというコンセプトです。

考え方としては、以下の3つの観点から交渉結果を見ていきます。

- 支払い意思額に対して、どれだけ得をしたかを見る「消費者余剰」
- 売り手の最初の提示額から、どれだけ価格を引き下げられたかを見る「交渉力」
- 最終的に手に入れた商品が、どれだけ自分の欲しかったものに近いかを見る「取得率」

### それぞれの観点で見てみると

消費者余剰は、支払い意思額と実際の支払額の差を、売り手のコストをふまえてどれだけ効率よく得ができたかという観点で見ます。0〜1の数値で表され、1に近いほど良い交渉結果とされます。

交渉力は、売り手の出した最初の価格から、最終的な価格までをどれだけ動かせたかを見ます。コストに対して大幅に引き下げられていれば、高い交渉力を持ったと見なされます。

取得率は、最終的に入手した商品が当初望んでいたものとどれくらい近いかを評価します。言い換えれば、好みの順位に合った買い物ができたかを測るものです。この評価にはテキスト埋め込みを使った類似度計算が使われています。

### 実際に人間の判断と合っているか？

こうした考え方のもと生まれた指標はHAMBAと名付けられました。

HAMBAの評価が本当に人間の感覚に近いのかを確かめるために、クラウドワーカーに評価を依頼する実験も行われました。その結果、HAMBAのスコアは、これまで使われていた利益ベースのスコアよりも人間の評価とよく一致していることが確認されました（HAMBAの [AUC](https://ai-data-base.com/archives/26250 "AUC") は0.80、従来指標は0.68）。

![](https://ai-data-base.com/wp-content/uploads/2025/06/AIDB_90638_4.png)

要するに今回開発されたHAMBAスコアは一言でいうと、交渉の結果がどれだけ人間の満足感に近いかを測る指標です。

## LLMが見せた交渉のクセと傾向

新たに構築された交渉ベンチマークと、人間の感覚に近づけた評価軸を使って、実際にいまのLLMを交渉役として動かす実験が行われました。

![](https://ai-data-base.com/wp-content/uploads/2025/06/AIDB_90638_1-1024x224.png)

既存のベンチマークおよび評価指標と、本研究で新たに開発されたベンチマークおよび評価指標の比較

ここまでのセクションはやや理論的で耐えて読んでいただきましたが、実験結果は非常に面白い内容になっています。

交渉という行為に対して、モデルがどう反応し、どう駆け引きを進めようとするのか。そのふるまいには、意外な「クセ」や「落とし穴」が含まれていました。

### アンカリングと先手の強さはLLMにも共通して存在した

まず確認されたのは、人間でもよく知られている「アンカリング効果」（最初に提示された価格が、その後の判断を大きく左右するという認知バイアス）が、LLMにも影響を与えるという点です。

たとえば、あるカメラを550ドルで売り出す場合と、520ドルで売り出す場合とで交渉を開始すると、最終価格は前者のほうが高くなる傾向がありました。また、買い手が先に価格を提示したときには、逆に価格が低く抑えられる傾向もありました。つまり、交渉の「起点」をどちらが握るかで、結果が変わるということです。

![](https://ai-data-base.com/wp-content/uploads/2025/06/AIDB_90638_5-1024x262.png)

### モデルサイズと交渉能力の関係

モデルの大きさはそのまま交渉のうまさにつながるか？そう単純でもないようです。Geminiシリーズの中では、モデルが大きくなるにつれてある程度性能も上がっていましたが、モデルを横断して全体的に見ると一貫した相関は確認されませんでした。

![](https://ai-data-base.com/wp-content/uploads/2025/06/AIDB_90638_3-1024x261.png)

このことから、交渉の成否は単なる「頭の良さ」やモデルサイズだけでなく、別の要因、たとえば、性格的なふるまいや表現スタイルの違いなどが影響している可能性も考えられます。

### 同じモデル同士は話が通じやすい？

もうひとつ興味深い現象として、同じモデル系列のエージェント同士のほうが、交渉がうまくいく傾向がありました。

たとえばgpt-4oは、GPT系列の相手との交渉において、異なる系列との交渉よりも高い合意率を示すことが多く、Geminiシリーズでもその傾向は明確でした。

![](https://ai-data-base.com/wp-content/uploads/2025/06/AIDB_90638_6-1024x181.png)

とても興味深い結果と言えます。

シリーズ内で言語スタイルや反応のパターンが似ているため、相互理解が進みやすいのだろうかと考察されています。

こうした傾向は、マルチエージェント環境における相性問題とも関係している可能性があります。つまり、LLM同士がどれだけうまく協調できるかを考える上で重要な視点になります。

### 市場構造がもたらす影響

今回新たに作成されたベンチマークのように、複数の市場タイプを設けると、それぞれの市場条件によってモデルのふるまいが大きく変わることが分かりました。

欺瞞的な市場（売り手や買い手が誤った情報を交渉に持ち込む可能性があり、情報の正確さを見極める必要がある状況）では、買い手があえて誤情報を使うケースが想定されます。この設定では、モデルのHAMBAスコア（交渉の結果がどれだけ人間の満足感に近いか）や合意率がともに上昇する傾向が見られました。とくにGeminiシリーズは、スコアと合意率の両立が可能で、比較的強い交渉力を発揮していました。

一方、売り手が独占的な状況になると、交渉は難しくなります。合意率もスコアも下がりやすく、買い手にとって厳しい展開となりました。

分割払いが可能な市場では、合意率は上がったものの、買い手の得られるスコアは下がる場面もありました。柔軟な支払い条件が交渉を成立させやすくする一方で、価格的には不利な取引になりやすいというトレードオフがあったようです。

なお、評判が悪い売り手との交渉では、合意率そのものが下がる傾向が見られました。特に選択肢が少ない状況では、買い手が妥協せざるを得ない構図が浮かび上がります。

### 人間のルールとは違う戦術も

LLMは交渉で好成績を残すこともありますが、そのふるまいは人間が常識的に考える交渉術とはやや異なる場面も見受けられました。

とくに小さめのモデルでは、人間相手であれば「それは通用しないだろう」と思われるような手法を使って、相手から値引きを引き出す場面がありました。分かりやすく言うと、「勝つ」ことに最適化しすぎてしまい、相手との関係性や感情的な納得を無視したふるまいになることがあるのです。

このような観察結果は、LLMが人間と自然に交渉するにはまだ課題が残っていることを示していると言えます。AIエージェントを社会に実装していく際の現実的な壁として認識しておく必要があります。

## 相手を意識した交渉力の強化

上述の通り、いまのLLMは人間との交渉で優れた成果を出す一方で、「人間らしさ」に欠ける場面も多く見られます。たとえば相手の気持ちや立場を推し量ることなく、自分本位に進めてしまうふるまいが目立ちました。

このズレを埋め交渉力を底上げする手法が考案されました。

![](https://ai-data-base.com/wp-content/uploads/2025/06/AIDB_90638_7-1024x317.png)

モデルサイズが大きいほど効果も高まる傾向がある手法とのことです。以下で具体的に紹介します。

### 相手の視点に立つ交渉を促す

人間との交渉で違和感が生じやすい原因のひとつは、LLMが相手の事情を十分に想像せず、自分の都合だけで進めてしまう点にあります。価格を引き下げることだけを目的に、相手のコスト構造や意図を無視した提案をしてしまうと、交渉はうまくいきません。

このようなズレを避けるには、推論のなかで「相手がどう考えているか」を織り込んでいくことが重要です。相手の立場を推測し、その仮説を少しずつ更新しながら、自分の次のアクションを調整していきます。

### 数値によるフィードバックを活用する

具体的な方法論としては、交渉中の思考や提案を、単なる出力として終わらせるのではなく、その内容を人間の評価軸に照らして数値的にフィードバックします。

たとえば、HAMBAスコア（交渉結果の人間整合性を測る指標）を用いて、どの案がより良い交渉とみなされるかを数値化します。

こうしたスコアを、そのままLLMへの追加情報として再利用することで、より望ましい出力に近づけます。生成された出力に対して定量的な評価を与え、それを次の出力に生かすという流れを繰り返すことで、表面的な駆け引きから一歩踏み込んだ推論が促されます。

### 良い交渉を導くステップの設計

手順としては、次の4ステップを組み込むことで、相手を意識した交渉の精度を高めます。

1. まず、交渉に入る前に、自分の考えや仮説を言語化しておきます。なぜその価格を提示するのか、相手はどう考えていそうかを文字として明示します。
2. 次に、その考え方がどれだけ良かったかを評価します。たとえばHAMBAスコアを活用し、人間にとって納得感のある交渉だったかを数値で把握します。
3. 続いて、そのスコアを踏まえて次の交渉に生かします。評価結果をプロンプトの材料として組み込み、次の出力に反映させます。
4. この一連の流れを何度も繰り返しながら、推論と交渉戦略を調整していきます。改善を重ねることで、自然で説得力のある交渉が可能になります。

こうした方法を使うと、従来の単純な戦略と比べて、人間の評価とよりよく一致する出力が得られやすくなるとのことです。さらに、対話のターン数も適度に保たれ、極端に短い妥協や、逆に長すぎる交渉の失敗といった偏りも減らせるそうです。

![](https://ai-data-base.com/wp-content/uploads/2025/06/AIDB_90638_9.png)

従来手法と本手法のパフォーマンス比較表

![](https://ai-data-base.com/wp-content/uploads/2025/06/AIDB_90638_11.png)

従来手法と本手法のパフォーマンス比較グラフ

## まとめ

本記事では、LLMに価格交渉をさせた際のふるまいと、その評価・改善の方法を探る研究を紹介しました。交渉や説得が求められるAIの活用場面で、手法や考え方の応用を検討する手がかりになりそうです。

まず、現実の市場に近い条件での交渉環境、人間の満足度に基づいた新たな評価指標について取り上げました。

実験からは、LLMの癖や限界、交渉における相性やふるまいの違いが明らかになりました。

また、相手を意識した推論と評価ループの活用が、人間らしい交渉の鍵となることも示唆されました。

**参照文献情報**

- タイトル：LLM Agents for Bargaining with Utility-based Feedback
- URL： [https://doi.org/10.48550/arXiv.2505.22998](https://doi.org/10.48550/arXiv.2505.22998)
- 著者：Jihwan Oh, Murad Aghazada, Se-Young Yun, Taehyeon Kim
- 所属：KAIST AI, LG AI Research

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[AIは物語をどう読む？命の選択にどう迷う？　ほか、AI科学ニュースまとめ](https://ai-data-base.com/archives/90757)

[個人の深い価値観にもとづく「その人らしい答え」をAIで再現する手法](https://ai-data-base.com/archives/90734)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)