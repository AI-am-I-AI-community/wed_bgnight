---
title: "LLMから「LLMエージェント」へ ソフトウェアエンジニアリングにおける今後の展開"
source: "https://ai-data-base.com/archives/74375"
author:
  - "[[AIDB Research]]"
published: 2024-08-16
created: 2025-06-13
description: "本記事では、ソフトウェアエンジニアリングにおけるLLMおよびLLMエージェントの影響に関する調査を紹介します。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、ソフトウェアエンジニアリングにおけるLLMおよびLLMエージェントの影響に関する調査を紹介します。

研究者らはソフトウェア工学の主要6分野における117の論文を分析し、LLMとLLMエージェントの応用、性能、ベンチマーク、評価指標を比較しています。その結果、LLMエージェントの優れた点と課題の両方が浮き彫りになりました。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74375-1024x576.jpg)

**参照論文情報**

- タイトル：From LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future
- 著者：Haolin Jin, Linghan Huang, Haipeng Cai, Jun Yan, Bo Li, Huaming Chen
- 所属：The University of Sydney, Washington State University, University of Wollongong, University of Chicago

## 背景

LLMは、コード生成やバグ検出などのタスクで素晴らしい性能を見せており、ソフトウェア開発者の生産性向上に役立っています。しかし、LLMにはいくつかの課題もあります。例えば、コンテキスト長に制限があったり、幻覚（ハルシネーション）が問題となっています。また、外部ツールを利用する能力も限定されています。

そこで、LLMをベースとしたエージェントシステム、つまりLLMエージェントの研究が進められています。LLMエージェントは、LLMの強みを活かしつつ、外部ツールやリソースと組み合わせることで、より複雑なタスクの実行を可能にします。例えば、GitHub Copilotもその一つです。GitHub CopilotはOpenAIのCodexをバックボーンとしており、リアルタイムのコード提案や補完を行うエージェントです。

LLMエージェントは、単なるLLMとは異なり、カスタマイズされたプロンプトを使用して情報を収集したり、自律的に思考し決定を下す能力を持つものとして開発されています。

なお、身体を持ったLLMエージェントの開発も進んでおり、現実世界であればロボット、仮想世界であればバーチャルな体を操作します。例えばMinecraftを上手にプレイするVOYAGERというLLMエージェントが話題になったことがあります。

そして現在、LLMエージェントの「ソフトウェアエンジニアリング」における活用に関心が集まっています。そこで今回研究者らは、要件定義、コード生成、ソフトウェア設計、テスト生成、メンテナンスなどに焦点を当て、LLMとLLMエージェントの応用を比較分析しています。

LLMとLLMエージェントの明確な区別を行っての調査は初めての試みとのことです。そのため、まずはLLMとLLMエージェントの定義の違いから整理されました。

なお、下の図は2020年から2024年におけるLLMとLLMエージェントに関する論文数の推移です。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74375_1-1024x661.jpg)

また下の図は論文の分布を示しています。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74375_2-1024x678.jpg)

## LLMとLLMエージェントの違い

LLMは、大量のテキストデータから学習し、テキスト生成や理解を行う高度な言語モデルです。与えられた入力に対して単一の応答を生成することが主な機能です。例えば、質問に答えたり、コードを生成したりすることができます、しかし能力の範囲は学習データと入力プロンプトによって限られます。

一方、LLMエージェントは、LLMをコアシステムとしながら、より複雑な機能を持つシステムとして設計されます。LLMエージェントの特徴をまとめると以下の通りです。

1. 単なる応答生成だけでなく、状況に応じた判断や選択を行う
2. 必要に応じて、外部のAPIやツールを呼び出してタスクを行う
3. 複数のステップにわたる対話を通じて、問題解決や情報収集を行う
4. フィードバックや経験から学習し、パフォーマンスを向上させる
5. 複数のエージェントが協力して、より複雑なタスクを遂行する

ソフトウェア開発においては、LLMは単にコードを生成するだけですが、LLMエージェントは要件分析から設計、実装、テストまでの一連のプロセスを自律的に管理することが求められます。つまりLLMエージェントは、より人間に近い形で問題解決や意思決定を行うことが期待されています。

ただし、LLMエージェントの開発には、まだ多くの課題が残されています。例えば、意思決定の透明性を確保することや、エージェント間の効果的な協力を行う方法論の確立が待たれています。

以上がLLMとLLMエージェントの違いを定義から確認したものです。  
次に、ソフトウェアエンジニアリングの各プロセスにおけるLLMとLLMエージェントの役割の違いを見ていきます。

## 要件定義（およびドキュメンテーション）

要件定義とドキュメンテーションは、ソフトウェアの目的と機能を明確化し文書化するプロセスです。

### ①LLMの活用

要件工学においてLLMに期待される活用方法を研究事例別で見ていきます。

**（１）要件の分類と抽出  
**BERTモデルを活用して要件の分類精度が向上した事例があります。PROMISEデータセットにおいて96.13%の [F1スコア](https://ai-data-base.com/archives/26112 "F1スコア（F値）") が達成されました。

**（２）要件の生成と記述  
**ChatGPTを用いた要件生成の事例では、特に専門知識を持つユーザーがより効果的に活用できることが示されました。

**（３）ソフトウェア要求仕様書（SRS）の生成  
**GPT-4やCodeLlama-34bを用いたSRS生成を行なった研究では、人間が作成したSRSに匹敵する品質が達成されました。

**（４）曖昧性の検出  
**自然言語要件文書における曖昧性を検出するためのフレームワークが開発された事例では、BERTとK-means クラスタリングを組み合わせて、同じ用語が異なる文脈で使用される場合を特定することが可能と示されました。

### ②LLMエージェントの活用

要件工学においてLLMエージェントの研究はまだ初期段階ですが、いくつか興味深い応用例が報告されています。

**（１）半構造化文書の生成  
**複数のエージェントを組み合わせたフレームワークが開発された事例では、意味認識、情報検索、コンテンツ生成のタスクを効率的に処理することが可能と示されました。

**（２）AI支援ソフトウェア開発（AISD）フレームワーク  
**ユースケースと生成されたコードを継続的に改善・最適化するフレームワークが提案された事例では、人間の介入なしで24.1%だったユースケースの合格率が、人間の関与により75.2%まで向上しました。

**（３）自動運転の安全要件生成  
**LLMエージェントを既存のHARA（Hazard Analysis and Risk Assessment）プロセスに統合した事例では、安全関連要件の自動生成が可能と示されました。なおHARA（Hazard Analysis and Risk Assessment）とは、危険分析とリスク評価を行うプロセスのことです。

**（４）アジャイル開発におけるユーザー体験の品質向上  
**ユーザー体験の明確性、理解しやすさ、ビジネス目標との整合性が向した事例もあります。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74375_8-1024x949.jpg)

ユーザー体験改善におけるLLMエージェントとLLMの比較

### LLMとLLMエージェントの違い

シンプルなLLMと比較して、LLMエージェントは要求工学において以下の点で優れていると考えられます。

1. 複数のエージェントが協調して作業を行うことで、人間の介入を最小限に抑えつつ、高品質な要件文書の生成が可能となる
2. エージェントシステムが要件文書の欠陥を分析し、改善を繰り返すことで、品質の向上が図られる
3. 自動運転の安全要件生成など、テキスト以外の情報も活用した要件生成が可能となる

## コード生成とソフトウェア開発

コード生成とソフトウェア開発とは、プログラムコードの作成と全体的なソフトウェア構築プロセスです。

### ①LLMの活用

**（１）自然言語からのコード生成  
**GPT-4を用いた実験結果によると、意味解析や数学的推論、Pythonプログラミングなどのタスクで優れた性能が確認されています。

**（２）データベース管理とクエリ最適化  
**SQL-PaLMフレームワークの評価では、テスト精度77.3%、実行精度82.7%という成果が報告されています。

**（３）多言語コード生成  
**CodeGeeXモデルの性能評価において、HumanEval-Xベンチマークで他の多言語モデルを上回る結果が得られています。

**（４）プログラミング効率の向上  
**GitHub Copilotなどの統合開発環境（IDE）連携ツールにより、リアルタイムのコード補完や提案が可能になったことが示されています。

**（５）マルチターンプログラム合成  
**CODEGENモデルの導入により、複数の対話を通じたプログラムの段階的生成が実現しています。

### ②LLMエージェントの活用

**（１）自己協調フレームワーク  
**複数のChatGPTエージェントによる協調的コード生成タスク処理の実験では、HumanEvalとMBPPベンチマークでの性能が最大２９.９％改善したことが判明しています。

**（２）大規模コードベース生成  
**L2MACフレームワークの性能評価では、HumanEvalベンチマークにおいて９０.２％のPass@１スコアを記録しています。

**（３）ソフトウェア開発プロセスの自動化  
**MetaGPTフレームワークの分析結果から、標準操作手順（SOP）を通じた問題解決能力の強化が確認されています。

**（４）外部ツールとAPIの活用  
**ToolformerモデルとToolLLMフレームワークの開発により、LLMの外部ツールやAPI利用能力の向上が実証されています。

### LLMとLLMエージェントの違い

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74375_10-975x1024.jpg)

コード生成とソフトウェア開発におけるLLM-based AgentとLLMの比較フレームワーク

LLMとLLMエージェントには以下のような違いがあると考えられます。

1. LLMは単一のモデルで特定のタスクを処理するのに対し、LLMエージェントは複数のエージェントが協力して複雑なワークフローを処理する
2. LLMエージェントは、タスクの分割、マルチエージェントシステム、ツール統合を通じて、より複雑で広範なタスクに対応できる
3. LLMエージェントは、コード生成の品質と効率を向上させ、プログラマーをテストスイート生成などの退屈なタスクから解放する可能性がある

なお、効率とコストの観点からは、単純なタスクにはLLMの使用で十分な場合が多いと考えられます。一方、ソフトウェアメンテナンスや根本原因分析のような複雑なタスクには、マルチターン対話、知識グラフ、RAG（検索拡張生成）技術などを活用したより複雑な [アーキテクチャ](https://ai-data-base.com/archives/26562 "アーキテクチャ") で実装したLLMエージェントが必要とされる可能性があります。

## ソフトウェア設計と評価

ソフトウェアの構造設計とその品質評価プロセスでは、LLMおよびLLMエージェントに期待される役割にどのような違いがあるでしょうか。

### ①LLMの活用

**（１）自動化と最適化  
**ChatGPTを用いた実験では、ログの要約や代名詞解決、コードの要約などで100%の成功率が報告されています。一方、コードレビューや脆弱性検出などの複雑なタスクでは課題が残されているようです。

**（２）評価手法の革新  
**[EvaluLLM](https://dl.acm.org/doi/abs/10.1145/3640544.3645216) フレームワークの研究では、従来の参照ベースの評価指標の限界を克服する新たな評価手法が提案されています。この手法は、評価プロセスの簡素化と人間の評価との一貫性確保を目指しています。

**（３）エンジニアリング設計への応用  
**高レベル合成（HLS）設計の機能検証にLLMを応用した研究では、量子化、剪定、操作レベルの最適化を通じて、電子設計自動化（EDA）分野でのエラー検出と修正の可能性が検討されています。

**（４）GUIプロトタイピングの効率化  
**[RaWi](https://link.springer.com/article/10.1007/s10515-023-00377-x) というデータ駆動型のGUIプロトタイピングアプローチの研究では、高精度のプロトタイプを迅速に作成する方法が提案されています。precision@k指標で40%の改善が報告されています。

**（５）教育分野での活用  
**ソフトウェアテスト教育におけるChatGPTの調査では、約77.5%の質問に回答でき、55.6%の [正解率](https://ai-data-base.com/archives/25930 "正解率") または部分的な正解率を示したとされています。ただし、説明の正確さには改善の余地があるようです。

### ②LLMエージェントの活用

**（１）自律エージェントの可能性探求  
**[Auto-GPT](https://arxiv.org/abs/2306.02224) の性能評価研究では、詳細なコンテキストプロンプトが複雑なソフトウェア工学タスクでのエージェントのパフォーマンス向上に寄与する可能性が示唆されています。

**（２）仮想ソフトウェア開発会社の実現  
**有名な研究プロジェクトである [ChatDev](https://arxiv.org/abs/2307.07924) では、チャットベースのマルチエージェントフレームワークを通じて、ソフトウェア開発プロセスの構造化と効率化が試みられています。平均409.84秒、コスト0.2967ドルでのソフトウェアの設計と生成が可能だったと報告されています。

**（３）AIタスクの管理と実行  
**[HuggingGPT](https://arxiv.org/abs/2303.17580) システムの研究では、ChatGPTを使用して様々なAIモデルの実行を調整する方法が提案されています。LLMの適用範囲拡大の可能性が示唆されています。

**（４）動的マルチエージェント環境での評価  
**動的で対話的なマルチエージェント環境でのLLMの能力評価方法を提案する [LLMARENA](https://arxiv.org/abs/2402.16499) ベンチマークフレームワークの研究もあります。このフレームワークでは、LLMの空間設計、戦略的計画、チームワーク能力の評価が試みられています。

**（５）AIモデルと人間の相互作用の構造化  
**AIモデルと人間の相互作用を構造化し、推論と協調能力の向上を目指す”Flows”概念フレームワークという研究事例があります。競争的コーディングタスクでの実験では、AIモデルの問題解決率が21パーセントポイント、人間とAIの協調率が54パーセントポイント向上したと報告されています。

### LLMとLLMエージェントの違い

ソフトウェア設計と評価におけるLLMとLLMエージェントには以下のような違いがあると考えられます。

1. LLMは特定のタスク（コード生成、ログ要約など）の自動化に焦点を当てているのに対し、LLMエージェントはより複雑なワークフローを知的な意思決定とタスク実行を通じて処理することを目指している
2. LLMエージェントは、タスクの分割、マルチエージェント協力、動的調整を通じて、タスクの効率化と設計品質の向上を図ろうとしている
3. LLMエージェントは、ソフトウェア開発プロセス全体のシミュレーションを試みており、実際の開発チームの動きを模倣することを目指している

## ソフトウェアテスト生成

ソフトウェアの品質を検証するためのテストケース自動生成プロセスです。

### ①LLMの活用

**（１）セキュリティテストの生成  
**GPT-4を使用したセキュリティテスト生成の研究では、依存関係の脆弱性を悪用するサプライチェーン攻撃の実施方法が検討されています。ChatGPTによって生成されたテストは、55のアプリケーションで24の概念実証脆弱性を発見し、既存のツールを上回る性能が報告されています。

**（２）バグ再現の自動化  
**[AdbGPT](https://arxiv.org/abs/2306.01987) フレームワークの研究では、Android のバグレポートからエラーを自動的に再現する手法が提案されています。S2Rエンティティ抽出で90.4%と90.8%の精度、エラー再現で81.3%の成功率が報告されています。

**（３）多言語対応のバグ再現  
**[LIBRO](https://arxiv.org/abs/2209.11515) フレームワークの研究では、バグレポートからバグ再現テストを生成する方法が提案されています。Defects4Jデータセットで33.5%、GHRBデータセットで32.2%のバグの再現に成功したと報告されています。

**（４）ユニバーサルファジング  
**[Fuzz4All](https://arxiv.org/abs/2308.04748) というファジングツールの研究では、LLMを使用して様々なソフトウェアシステムの入力を生成および変異させる方法が提案されています。テストされたすべての言語で最高のコードカバレッジを達成し、平均36.8%の増加が報告されています。

**（５）高カバレッジテストケース生成  
**[SymPrompt](https://arxiv.org/abs/2402.00097) というコード認識プロンプト戦略の研究では、CodeGen2とGPT-4のカバレッジがそれぞれ26%と105%向上したと報告されています。

### ②LLMエージェントの活用

**（１）マルチエージェントフレームワーク  
**AgentCoderのマルチエージェントフレームワークの研究では、複数の専門化されたエージェントを活用してコード生成を反復的に最適化する方法が提案されています。MBPPデータセットで89.9%のパス率が報告されています。

**（２）会話型テスト自動化  
**S [ocr](https://ai-data-base.com/archives/26261 "光学文字認識（OCR）") aTestフレームワークの研究では、会話型インタラクションを通じてテストプロセスを自動化する方法が提案されています。GPT-4を使用してテストケースの生成と最適化を行う手法が検討されています。

**（３）テストチェーン手法  
**TestChainフレームワークの研究では、多様なテスト入力の生成、ReAct形式の対話チェーンを用いた入出力のマッピング、Pythonインタープリタとの対話によって正確なテスト出力を取得する方法が提案されています。LeetCode-hardデータセットで71.79%の精度を達成し、ベースライン手法から13.84%の改善が報告されています。

**（４）ユーザー受け入れテストの自動化  
**XUAT-Copilotというマルチエージェント協調システムの研究では、LLMを使用してテストスクリプトを自動生成する方法が提案されています。WeChat Pay UATシステムの450のテストケースで評価され、88.55%のPass@1率と93.03%のComplete@1率が報告されています。

### LLMとLLMエージェントの違い

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74375_15-1024x860.jpg)

ソフトウェアテスト生成におけるLLMエージェントとLLMの比較

LLMとLLMエージェントには以下のような違いがあると考えられます。

1. LLMは主に単一タスクの実装に適しており、プロンプトエンジニアリングやフューショット学習などの技術を通じてテストケースを生成する
2. LLMエージェントは、マルチエージェント協調システムを通じてタスクを分解し、専門的な処理を行うことで、テスト生成と実行の効果性と効率性の向上を図っている
3. コスト面では、単純なテスト生成タスクにはLLMの使用で十分な場合が多いが、LLMエージェントはより複雑で多様なタスクに対応できる可能性がある

LLMエージェント（を用いたアプローチ）は、複雑なテストシナリオや長期的なテスト戦略の設計において優れた性能を示す可能性があると考えられています。

## ソフトウェアセキュリティとメンテナンス

ソフトウェアの安全性確保と継続的な改善・保守活動に関する分野においても、LLMとLLMエージェントそれぞれ異なる研究事例があります。

### ①LLMの活用

**（１）脆弱性検出  
**[WizardCoder](https://arxiv.org/abs/2306.08568) モデルの微調整により、ソースコードの脆弱性検出タスクにおいて性能向上が確認されました。ContraBERTモデルとの比較では、ROC [AUC](https://ai-data-base.com/archives/26250 "AUC") とF1スコアの両方で優位性が示されています。特に、Java関数の脆弱性検出におけるROC [AUC](https://ai-data-base.com/archives/26250 "AUC") が0.66から0.69に改善されたことが注目されます。

**（２）自動プログラム修復  
**[MOREPAIRフレームワーク](https://arxiv.org/pdf/2404.12636) は、LLMを用いた自動プログラム修復（APR）の新たな可能性を示しています。QLoRAやNEFTuneといった先進的な技術の導入により、効率的な微調整手法が実現しました。

**（３）マルチ言語プログラム修復  
**RINGシステムの開発により、6つのプログラミング言語に対応したマルチ言語プログラム修復が可能となりました。特筆すべきは、Pythonにおいて94%のエラーを初回試行で修復できた点です。

**（４）関数レベルの自動プログラム修復  
**SRepairフレームワークは、デュアルLLMアプローチによる修復性能の向上を実現しました。Defects4Jデータセットを用いた評価では、300の単一関数エラーを修復し、既存のAPR技術と比較して85%以上の改善が観察されています。

**（５）自動ペネトレーションテスト  
**PENTESTGPTツールは、LLMを活用した革新的な自動ペネトレーションテスト手法を提案しています。13のターゲットと182のサブタスクを含むベンチマークによる評価では、GPT-3.5より228.6%、GPT-4より58.6%高いタスク完了率を記録しました。

### ②LLMエージェンの活用

**（１）アクセス制御脆弱性の修復  
**ACFIXフレームワークは、ロールベースアクセス制御（RBAC）の実践とLLMを組み合わせたスマートコントラクトのアクセス制御脆弱性修復方法を提案しています。94.92%の修復成功率を達成し、ベースラインのGPT-4の52.54%を大きく上回りました。

**（２）スマートコントラクトの脆弱性検出  
**GPTLENSフレームワークによる生成と判別の2段階プロセスを通じた脆弱性検出精度向上方法が注目を集めています。スマートコントラクトの脆弱性検出において76.9%の成功率を記録し、従来手法の38.5%を上回る結果となりました。

**（３）自動デバッグ  
**LLMベースのマルチエージェントシステムを活用した [FixAgentフレームワーク](https://arxiv.org/abs/2404.17153) が、障害特定、修復生成、エラー分析の改善に貢献しています。QuixBugsデータセットで79個中78個、Codeflawsデータセットでは3982個中2780個の欠陥修正に成功しました。

**（４）自動プログラム修復エージェント  
**動的なプロンプト生成とツール統合方法であるRepairAgentが、バグ情報収集、修復材料収集、修復検証の効率化を実現しています。Defects4Jベンチマークでは186個のバグ中164個の正確な修復を達成しました。

**（５）スマートコントラクト監査  
**LLMの能力をスマートコントラクトコードの特定要件に適応させる手法TrustLLMフレームワークが開発されています。F1スコア91.21%、精度91.11%を記録し、他のモデルを凌ぐ性能を示しています。

### ソフトウェアセキュリティとメンテナンスにおけるLLMとLLMエージェントの違い

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74375_17-1024x895.jpg)

ソフトウェアセキュリティとメンテナンスにおけるLLMエージェントとLLMの比較

1. LLMは主に特定のセキュリティタスク（脆弱性検出、コード修復など）に焦点を当てているのに対し、LLMエージェントはより複雑なワークフローを処理し、自律的な意思決定と動的な調整を行う
2. LLMエージェントは、マルチエージェント協力、ランタイム情報の追跡、動的な分析ツールの統合などを通じて、より効果的なデバッグと修復プロセスの実現を目指している
3. LLMエージェントは、セキュリティ分析と設計プロセスの改善において、より柔軟で適応性の高いアプローチを提供できる可能性がある

ソフトウェアセキュリティとメンテナンスにおいては、LLMエージェントを用いたアプローチは複雑なセキュリティ課題や長期的なメンテナンス戦略の設計で優れた性能を示す可能性があると考えられています。

## まとめ

本記事では、LLMとLLMベースのエージェントがソフトウェア工学分野に与える影響について研究を紹介しました。

研究者らは、ソフトウェア工学の主要分野におけるLLMとLLMエージェントの応用を分析しました。117の関連論文を調査し、性能、ベンチマーク、評価指標を比較しました。

調査結果から、LLMエージェントが複雑なタスクや長期的な問題解決で優れた性能を示すことが明らかになりました。一方、単純なタスクでは従来のLLMの方がコスト効率が良い場合もあることが指摘されています。

LLMエージェントの研究はまだ初期段階にあり、標準化されたベンチマークの不足や実際の開発環境での有効性検証は課題として挙げられます。

- 参照論文URL： [https://arxiv.org/abs/2408.02479](https://arxiv.org/abs/2408.02479)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[LLMの出力をJSON形式などに構造化すると「思考の柔軟性」や精度に影響することが示唆される](https://ai-data-base.com/archives/74336)

[LLMの事前学習とファインチューニングの関係についての新視点　まるで「アムロ」と「シャア」？](https://ai-data-base.com/archives/73532)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)