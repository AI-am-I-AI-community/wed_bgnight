---
title: "LLMエージェントとはそもそも何か どのような仕組みか 何に使うのか【前編】"
source: "https://ai-data-base.com/archives/79214"
author:
  - "[[AIDB Research]]"
published: 2025-04-11
created: 2025-06-13
description: "本記事では、LLMエージェントの体系的な分類と方法論に関する研究を紹介します。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、LLMエージェントの体系的な分類と方法論に関する研究を紹介します。

LLMを使ったエージェントは単に質問に答えるだけでなく、状況を理解し、考え、行動する能力を持つようになり、DeepResearchなどのシステムは専門家レベルの複雑な作業を自力で行えるようになっています。

このような発展の中、社会一般としてはLLMエージェントについて理解が追いついていません。そこでLLMエージェントの種類や分類方法について体系的に整理する調査が行われました。

エージェントの構築法、協力の方法、成長の仕組みという観点など包括的な分析が提供されています。

![](https://ai-data-base.com/wp-content/uploads/2025/04/AIDB_79214-1-1024x576.png)

## 背景

LLMを活用したエージェント、いわゆる「LLMエージェント」の進化が著しくなっています。LLMエージェントとは、従来のように単純な質問に答えるだけの存在ではなく、自分が置かれた状況を理解して、考え、自発的に行動までできるようになったAI技術の呼称です。

例えば、最近開発された「DeepResearch」のようなシステムは、以前であれば人間の専門家しかこなせなかったような複雑な作業を、自律的に行う能力を備え始めています。

従来型のエージェント技術と比べると、LLMエージェントは推論能力が飛躍的に向上しています。また、多様なツールやサービスを柔軟に活用しながら環境と相互作用できるほか、自分の経験を長期的に記憶し、過去の経験を踏まえて成長する仕組みも取り入れられるようになりました。

こうして、LLMエージェントは単なるアシスタントを超えて、人間と協力し合うパートナー的な存在として認識されるようになりつつあります。

一方で、この急激な進化は社会の理解を大きく上回るスピードで進んでいるため、「そもそもLLMエージェントにはどんな種類があるのか」「どうやって分類・整理すれば良いのか」などの混乱や疑問が広がっているのが現状です。

こうした課題を踏まえ、研究チームはLLMエージェントを体系的に分析・整理する研究を行いました。LLMエージェントがどのように作られているか、どのように協調して活動するか、さらには時間の経過とともにどのように成長・進化していくかが明確にまとめられています。

以下で、研究の内容を詳しく見ていきましょう。

![](https://ai-data-base.com/wp-content/uploads/2025/04/AIDB_79214_1-1024x486.png)

LLMエージェント全体像の俯瞰図

## LLMエージェントとはそもそもどんなものなのか？

研究者たちは、LLMエージェントという新しいタイプのAIを理解するために、「構築」「協力」「進化」の3つの視点から整理しています。

![](https://ai-data-base.com/wp-content/uploads/2025/04/AIDB_79214_2-927x1024.png)

LLMエージェントの方法論を整理した分類図

まずは「構築」、つまりエージェントを作るプロセスから説明します。

### エージェントをどうやって構築するか？

LLMを使ったエージェントを構築するには、自分で判断し行動できる仕組みを整える必要があります。そこで、「プロファイル設定」「記憶の仕組み」「計画を立てる能力」「行動を実行する能力」という4つの要素を組み合わせます。以下で、これら4つの要素について順番に見ていきましょう。

#### ① エージェントのプロファイル設定

プロファイル設定とは、エージェントの性格や行動傾向を決めることです。現在は主に二通りの方法があります。

ひとつ目の方法は、人間が事前に役割やルールを明確に決めるやり方です。 [Camel](https://github.com/camel-ai/camel) や [AutoGen](https://arxiv.org/abs/2308.08155) 、 [OpenAgents](https://github.com/xlang-ai/OpenAgents) のようなエージェントでは、「ユーザー代理」「アシスタント」など明確な役割があらかじめ設定されており、それに基づいてタスクを遂行します。この方法は、特定のルールや規制が求められる場面に向いています。

もうひとつの方法は、プロファイルを自動で生成し、多様な性格や価値観をもつエージェントを作るやり方です。エージェント同士の複雑な相互作用が起きるため、人間社会のシミュレーションやユーザー行動のデータ収集などに活用できます。

#### ② エージェントの記憶の仕組み

エージェントが経験した情報を蓄え、整理し、必要なときに引き出す仕組みが記憶メカニズムです。主に短期記憶、長期記憶、そして外部の知識にアクセスするタイプの記憶に分かれます。

短期記憶は、エージェントが現在の会話やタスクの状況を一時的に覚えておく仕組みです。例えば、 [ReAct](https://arxiv.org/abs/2210.03629) や [ChatDev](https://aclanthology.org/2024.acl-long.810/) 、 [AFlow](https://arxiv.org/abs/2410.10762) といったシステムがこのタイプで、タスク終了後には情報が消える一時的な記憶として使われています。

参考： [多様な役割のAIエージェント達に協力してソフトウェアを開発してもらう『ChatDev』登場。論文内容＆使い方を解説](https://ai-data-base.com/archives/54863)

長期記憶は、経験や学習を体系的に記録し、将来の行動に活かす仕組みです。マインクラフト内でスキルを自動的に発見し、その経験を蓄える [Voyager](https://github.com/MineDojo/Voyager) や、成功・失敗のパターンを保存して次の行動改善に活用する [ExpeL](https://arxiv.org/abs/2308.10144) 、 [Reflexion](https://arxiv.org/abs/2303.11366) といったシステムがこの仕組みを活用しています。

また、外部の情報をリアルタイムで取り込んだり、外部知識ベースを活用するタイプの記憶もあります。テキストや知識グラフ、あるいは他のエージェントとの対話を通じて情報を集め、推論プロセスに役立てるというものです。

#### ③ 計画を立てる能力

LLMエージェントが複雑なタスクを効率よく解決するには、計画を立てる能力が欠かせません。この能力は大きく「タスク分解」と「フィードバックを使った改善」の二つの視点から理解されています。

タスク分解とは、複雑な問題を細かいサブタスクに分けて対処する方法です。一度にすべてを処理するのは難しいため、問題を小さく分けて順番に取り組み、それらを最終的にまとめて解決に至ります。例えば、単純な方法ではエージェントが最初に一連の手順を立て、それを順番に実行するという手法があります。ただし、このやり方は柔軟性に欠け、途中で問題が起きたときに修正しにくいという課題があります。

より柔軟な方法として、複数の可能な道筋を探索しながら進む方法もあります。途中で問題が発生したら前の段階に戻り、別の経路を試すなど、「試行錯誤」によって複雑な課題に対応することができます。

フィードバックを使った改善とは、エージェントが行動後のフィードバックをもとに自分の計画を見直し、改善する仕組みです。このフィードバックは、人間から得られる場合もあれば、環境やエージェント自身の内省から得られることもあります。フィードバックを使って計画を柔軟に調整し、より効果的な成果を出せるようになります。

#### ④ 行動を実行する能力

エージェントが実際に行動できるようになるためには、「ツールを活用する力」と「現実世界との相互作用」という二つの側面を整える必要があります。

ツールの活用とは、外部の便利なサービスやアプリケーションを使ってエージェントの能力を高めることです。エージェント自身が問題を解決できない場合に、どのツールを使えばよいのかを判断し、状況に適したツールを選んで利用します。エージェントが自信を持てない状況や専門的な問題にぶつかったときに、この仕組みが役立ちます。

また、現実世界との相互作用とは、実世界で活動するロボットのようなエージェントが、物理的な環境や他者との関わり合いを踏まえて行動できる能力を指します。ロボットや社会的ルール、また他のエージェントとのコミュニケーションを考慮しながら、柔軟に環境に対応できる仕組みです。

### LLMエージェントをいかに「協力」させるか

単体のエージェントだけで複雑な課題を解決するのには限界があります。そこで、複数のLLMエージェントが連携して互いに協力し、より難しい問題に取り組む方法が注目されています。

研究者らはLLMエージェント同士の協力方法を3つのパターンに分けて整理しました。「中央集権型」「分散型」「ハイブリッド型」の [アーキテクチャ](https://ai-data-base.com/archives/26562 "アーキテクチャ") です。それぞれの特徴と具体的な事例を順に説明していきます。

#### ①中心となる司令塔がいる「中央集権型」の仕組み

中央集権型とは、企業の組織のように、中心となるエージェントが指揮役を担い、ほかのエージェントに役割やタスクを割り当てる仕組みです。この方式では、エージェント間の情報伝達はすべて中央を経由します。

中央集権型には大きく2種類の実装方法があります。

まず、「専用のコントローラー（調整役）」が明確に存在する方法があります。例えば、科学実験のプロジェクトを支援する「 [Coscientist](https://www.nature.com/articles/s41586-023-06792-0) 」というシステムでは、人間が中央の司令官となり、専門分野のエージェントやツールに作業を割り当てて実験を効率的に進めています。

参考： [LLM科学者と人間の協力で実験の効率化　Googleなど](https://ai-data-base.com/archives/84823) （類似の事例）

また、「 [LLM-Blender](https://arxiv.org/abs/2306.02561) 」というシステムは複数のエージェントが出した回答を中央のエージェントが評価し、より優れた回答へとまとめ直します。「 [MetaGPT](https://arxiv.org/abs/2308.00352) 」では、実際のソフトウェア開発のプロセスに沿って中央マネージャーが複数の役割を持つエージェントを統括しています。

参考： [大規模言語モデル同士に上手く協力してソフトウェア開発をしてもらうフレームワーク「MetaGPT」](https://ai-data-base.com/archives/54189)

もうひとつは、「役割分担」を通じて中央制御を実現する方法です。「 [AutoAct](https://arxiv.org/abs/2401.05268) 」のように、一つのメインエージェントを計画担当、ツール操作担当、振り返り担当など複数の役割に分け、それらを一元的に管理するパターンがあります。

「 [Meta-Prompting](https://arxiv.org/abs/2401.12954) 」という仕組みでは、中央エージェントが専門性を持つエージェントに小さなタスクを振り分け、最後に結果を集めて最終的な回答を作り出しています。さらに、「 [WJudge](https://arxiv.org/abs/2402.06782) 」という研究では、必ずしも能力の高くないエージェントが中央の役割を担っても、全体の性能が向上する可能性が示されています。

#### ② 司令塔を置かず、対等に協力する「分散型」の仕組み

中央集権型とは異なり、分散型の協力システムでは、エージェント同士が直接コミュニケーションを取りながら、自律的に協力して問題を解決します。主に2つのパターンがあります。

一つ目は、「修正ベースの協力」です。このパターンでは、各エージェントがそれぞれの判断を順番に共有し、他のエージェントの出した結果を段階的に改善していきます。

医療診断を行う「 [MedAgents](https://arxiv.org/abs/2311.10537) 」というシステムでは、複数の専門エージェントが独自に診断案を提案し、それらを相互に修正し、最後は投票で最終的な診断を決定します。「 [ReConcile](https://ai-data-base.com/archives/Round-table%20conference%20improves%20reasoning%20via%20consensus%20among%20diverse%20llms,) 」でも同様に、エージェントが相互に回答を吟味し合い、段階的に質を高めています。

参考： [異なるLLMが円卓を囲み議論した結果の回答は品質が高いとの検証報告。円卓ツールも公開](https://ai-data-base.com/archives/55853)

二つ目は、「対話ベースの協力」です。この方法は、より柔軟で、エージェント同士が直接対話し、相手の考えを理解しながら協力します。人間同士の社会的なやり取りを模倣できる点が特徴です。

例えば、「 [MAD](https://arxiv.org/abs/2305.19118) 」という研究では、固定化された思考から脱却するためにエージェントが対話形式で意見を交わします。また、「 [MADR](https://arxiv.org/abs/2402.07401) 」では、エージェントが互いの主張を批評し、議論を深めていくことで、最終的に信頼性の高い回答を生み出しています。さらに、「 [MDebate](https://arxiv.org/abs/2305.14325) 」や「 [AutoGen](https://arxiv.org/abs/2308.08155) 」のような仕組みでは、複数のエージェントが討論し、段階的にコンセンサスを形成します。

#### ③ 中央集権と分散型の長所を組み合わせるハイブリッド型

ハイブリッド型の協力は、中央集権型と分散型のメリットを融合させた仕組みです。中央での調整と、各エージェントの自主性を組み合わせて、より柔軟で効率的な協力を目指します。

ハイブリッド型にも二つのパターンがあります。

ひとつは、「静的ハイブリッド型」で、あらかじめ協力の形を固定して設計する方法です。例えば、「 [CAMEL](https://github.com/camel-ai/camel) 」ではエージェントを小さなチームに分け、それらを中央エージェントが統括しています。「 [AFlow](https://arxiv.org/abs/2410.10762) 」では中央で戦略を決定し、実際の行動はエージェント間の自律的な交渉によって進めるなど、複数の協力パターンを事前に組み合わせています。「 [EoT](https://arxiv.org/abs/2312.01823) 」という研究も、タスクの特性に応じて事前に決められたパターン（BUS、STAR、TREE、RING）を利用しています。

もうひとつは、「動的ハイブリッド型」で、状況に応じてエージェント間の協力関係をリアルタイムで再構成する方法です。

例えば、「 [DiscoGraph](https://arxiv.org/abs/2111.00643) 」では教師エージェントが全体の状況を把握し、生徒エージェントを動的に指導しながら協力構造を柔軟に調整しています。また、「 [DyLAN](https://arxiv.org/abs/2310.02170) 」ではタスクの進行に合わせて最も貢献度の高いエージェントを特定し、リアルタイムで協力関係を組み直しています。さらに、「 [MDAgents](https://arxiv.org/abs/2404.15155) 」ではタスクの難易度に応じて単独で行動したり、階層的なチームを編成したりと、動的に協力の仕組みを切り替えます。

![](https://ai-data-base.com/wp-content/uploads/2025/04/AIDB_79214_3.png)

エージェント協調手法の要点一覧表

### LLMエージェントをどのように「進化」させるか

LLMエージェントは構築され、協力して問題を解決するだけでなく、時間とともに経験を積み、成長することができます。この成長プロセスを研究者は「進化」と呼んでいます。

研究チームは、この「進化」を次の3つの側面から分析しています。「自律的な学習」「エージェント同士の共進化」「外部リソースの活用」です。それぞれの特徴について見ていきましょう。

#### ① 自律的な学習と自己改善の仕組み

エージェントは必ずしも人間が教えなくても、自分自身の経験やデータを活用して、自律的に学び改善することができます。その代表的な方法は3つあります。

まず、自己教師あり学習という手法があります。これはエージェントが自分自身で生成したデータを使い、人間が用意したデータへの依存を減らしながら学習を進める方法です。例えば、自己進化学習（SE）という方法では、学習時に一部の情報を隠したり、動的に学習戦略を調整したりすることで、モデルが自らを効率的に改善します。他にも、進化的最適化や、多様性のあるデータを効率よく選ぶ [DiverseEvol](https://arxiv.org/abs/2311.08182) など、エージェントが自ら環境に適応し成長できる研究が行われています。

また、エージェントが自分の行動を振り返りながら改善する自己修正型の学習方法もあります。代表的なものとして [SELF-REFINE](https://arxiv.org/abs/2303.17651) がありますが、これは人間が指摘しなくても、エージェントが自らの回答を再評価し、間違いを修正する仕組みを備えています。さらに [STaR](https://arxiv.org/abs/2203.14465) や [V-STaR](https://arxiv.org/abs/2402.06457) と呼ばれる手法では、エージェント自身が自分の推論プロセスを見直し、問題解決力を高めることができます。

さらに、自己報酬を使った [強化学習](https://ai-data-base.com/archives/26125 "強化学習") という方法もあります。これはエージェントが自分自身に「報酬」を与えることで、自律的により良い行動を選ぶようになる仕組みです。例えば対比蒸留という手法では、エージェントは自分が生成した結果に報酬を与え、その報酬をもとにさらに良い判断ができるように学習します。 [RLC](https://jingchengpang.github.io/files/pdf/jair_rlc.pdf) という技術も同様で、自らの評価と生成した結果のギャップを強化学習で改善し、自律的に性能を向上させることが可能です。

#### ② エージェント同士の共進化（協力や競争による成長）

複数のエージェントが互いに影響を与え合いながら、協力したり競争したりすることで成長する方法もあります。

まず協力的な共進化では、複数のエージェントが知識を共有し、協力して問題を解決することで互いに成長していきます。例えば [ProAgent](https://arxiv.org/abs/2308.11339) では、エージェントがチームメンバーの意図を推測し、それに応じて自分の考えを更新していきます。 [CORY](https://arxiv.org/abs/2410.06101) では、エージェント同士が役割を交換しながら協調して学習を進め、協力する能力が向上します。さらに [CAMEL](https://github.com/camel-ai/camel) というシステムでは、複数のエージェントが役割を演じながら互いにコミュニケーションをとり、協力タスクを効率的に達成します。このように、協力的共進化ではエージェント同士が助け合いながら進化します。

一方で競争的な共進化という方法もあり、これはエージェント同士が意見をぶつけ合ったり議論したりする中で進化するものです。例えば [Red-team LLM](https://arxiv.org/abs/2310.00322) というシステムでは、エージェントが互いに挑戦的な課題を投げかけ合うことで弱点を克服し、より強い推論力を身に付けていきます。また、マルチエージェント討論フレームワークでは、エージェントたちが何度も議論を繰り返しながら、正確で信頼性の高い結論へとたどり着きます。さらに [MAD](https://scholar.google.com/scholar_url?url=https://arxiv.org/abs/2305.19118&hl=ja&sa=T&oi=gsr-r&ct=res&cd=0&d=18211174412621306883&ei=wozzZ8iRGIC96rQP_N-doQU&scisig=AFWwaeYHdIhoMWIoOdthu2Dg8Kut) という研究では、エージェントが議論を通じて多様な意見を持ち寄り、論理的な推論を深めていく仕組みを提供しています。こうした競争的共進化では、議論や討論を通じてエージェントがより高度な推論能力を身に付けます。

#### ③ 外部リソースを活用した進化（知識とフィードバックによる成長）

エージェントが進化する際には、外部の知識やフィードバックを積極的に取り入れる方法もあります。

外部の知識を活用する方法としては、構造化された情報を取り込み、推論力やタスク実行能力を高める手法があります。例えば [KnowAgent](https://arxiv.org/abs/2403.03101) は、外部の行動知識を計画プロセスに取り入れることで、誤った判断を防ぎ、正確な行動を取れるようになります。また、世界知識モデル（WKM）では、専門家が提供する知識や一般的な経験を統合し、複雑な問題への理解力を高めています。

また、外部からのフィードバックを取り入れて改善する方法もあります。 [CRITIC](https://arxiv.org/abs/2305.11738) というシステムでは、外部ツールを使ったフィードバックによって、自分の出力を検証し、エラーを修正できるようになっています。 [STE](https://arxiv.org/abs/2403.02502) という手法では試行錯誤や記憶を利用したフィードバックを通じて、ツールの使用能力を向上させます。さらに [SelfEvolve](https://arxiv.org/abs/2306.02907) という研究は、人間が関与しなくてもエージェント自身が実行結果を分析し、コードの生成やデバッグを繰り返して改善していく仕組みを開発しています。

このようにエージェントは、自らの経験による学習、エージェント同士の相互作用、そして外部からの情報やフィードバックを組み合わせることで、時間とともに進化していくことができます。こうした成長プロセスを経て、エージェントはますます複雑で高度な課題にも対応できるようになっています。

![](https://ai-data-base.com/wp-content/uploads/2025/04/AIDB_79214_4.png)

エージェント進化手法の要点一覧表

## 後編に続きます。

[LLMエージェントとはそもそも何か　どのような仕組みか　何に使うのか【後編】](https://ai-data-base.com/archives/88052)

**参照文献情報**

- タイトル：Large Language Model Agent: A Survey on Methodology, Applications and Challenges
- URL： [https://doi.org/10.48550/arXiv.2503.21460](https://doi.org/10.48550/arXiv.2503.21460)
- Github： [https://github.com/luo-junyu/Awesome-Agent-Papers](https://github.com/luo-junyu/Awesome-Agent-Papers)
- 著者：Junyu Luo, Weizhi Zhang, Ye Yuan, Yusheng Zhao, Junwei Yang, Yiyang Gu, Bohan Wu, Binqi Chen, Ziyue Qiao, Qingqing Long, Rongcheng Tu, Xiao Luo, Wei Ju, Zhiping Xiao, Yifan Wang, Meng Xiao, Chenwu Liu, Jingyang Yuan, Shichang Zhang, Yiqiao Jin, Fan Zhang, Xian Wu, Hanqing Zhao, Dacheng Tao, Philip S. Yu, Ming Zhang
- 所属：Peking University, University of Illinois at Chicago, Great Bay University, Chinese Academy of Sciences, Nanyang Technological University, University of California Los Angeles, University of Washington, University of International Business and Economics, Harvard University, Georgia Institute of Technology, Tencent YouTu Lab

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[会話メモやマニュアルをワークフロー化するLLMマルチエージェントシステムの仕組み](https://ai-data-base.com/archives/87661)

[IBMの最新決算から見るエンタープライズAIビジネスの動向と関連キャリアを考察](https://ai-data-base.com/archives/88391)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)