---
title: "科学者はLLMをどう使っているのか、何を好むのか"
source: "https://ai-data-base.com/archives/80509"
author:
  - "[[AIDB Research]]"
published: 2024-12-12
created: 2025-06-13
description: "本記事では、816名の研究者を対象とした大規模調査から明らかになった「研究活動におけるLLM活用の現状と課題」を紹介します。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、816名の研究者を対象とした大規模調査から明らかになった「研究活動におけるLLM活用の現状と課題」を紹介します。

研究効率の向上や新しいアイデアの創出が期待されるLLMですが、誤情報の生成や研究の透明性への影響など、様々な懸念も指摘されています。

そこで今回、研究者の属性（国籍、言語、経験年数、分野、性別など）による認識の違いに注目し、LLM活用における公平性の問題にも焦点を当てた調査が行われました。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80509-1024x576.jpg)

**発表者情報**

- 研究者：Zhehui Liao, et al.
- 研究機関：ワシントン大学, 人工知能パイオニアセンター（Pioneer Centre for Artificial Intelligence）, コペンハーゲン大学, プリンストン大学, アレン人工知能研究所

## 背景

研究者らは長年、「膨大な知識を整理して効率的に活用できるツール」を夢見てきました。LLMの登場により、この夢の実現に近づきつつあります。実際、ChatGPTなどのツールの普及により、多くの研究者がすでに研究活動にLLMを取り入れ始めています。

しかし、LLMの活用には研究効率の向上や新しいアイデアの創出といった利点が期待される一方でいくつかの懸念も指摘されています。例えば、誤った情報の生成や引用、研究の透明性や再現性への影響、盗作やデータ捏造のリスク、研究者の本質的なスキル低下の可能性などです。

これまで、特定分野に限定した調査や小規模なインタビューなどによって、”研究でのLLM活用”が調査されてきました。

そこで今回研究者らは、幅広い分野・背景を持つ816名の研究者を対象とした、より網羅的な調査で、以下の点を明らかにすることを目指しました。

1. 研究者によるLLMの具体的な使用方法
2. 研究者の背景（分野、経験など）とLLM利用の関係
3. LLMの利点とリスクに対する研究者の認識
4. 商用/非営利のLLMに対する研究者の好み

研究者の属性（国籍、言語、経験年数、分野、性別など）による認識の違いに注目し、LLM活用における公平性や課題について検討しているのが本研究の大きな特徴です。

以下で詳しく見ていきましょう。

## 研究者のLLM活用の実態調査方法

### 調査の設計と参加者募集

研究者らは、既存の研究文献や予備調査を基に調査票を作成しました。LLMの利用方法は6つのカテゴリーに分類され、それぞれに具体的な使用事例が設定されました。

LLMの利用方法6つのカテゴリー

1. 情報収集
2. 編集
3. アイデア出しと構成
4. 直接的な文章作成
5. データクリーニングと分析
6. データ生成

参加者は、Semantic Scholarと提携し、同プラットフォームで少なくとも1本の研究論文を発表している著者から募集されました。107,346人の検証済み著者にメールが送信され、クリック率は約1.6%でした。クリックした参加者の71.6%が調査に同意し、そのうち60.6%が調査を完了しました。1,226件の回答から、最終的に816件の有効回答が分析対象となりました。

### 分析手法

定量分析において、回答者の背景は5つの人口統計学的カテゴリー（性別、人種、研究経験年数、母国語、研究分野）から分析されました。例えば性別は男性（79%）と女性・ノン [バイナリ](https://ai-data-base.com/archives/26314 "バイナリ") ー（自らの性自認や性表現を「男性」「女性」といった枠組みには当てはめようとしないセクシュアリティ）・その他（21%）に、研究経験年数は11年以上（57%）、4-10年（32%）、0-3年（11%）に分類されました。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80509_1-1024x448.png)

デモグラフィック変数間の関連を示す分割表

研究者らは、一人の回答者から複数の評価が得られる特性を考慮し、線形混合効果モデルを採用しました。モデルを用いてLLMの使用頻度や認識と人口統計学的要因との関連が分析され、各要因のレベル間で平均評価値の比較が実施されました。

自由記述形式の回答については、3人の研究者が独立してコード化を行い、議論を重ねて最終的なテーマを決定する反復的なオープンテーマ分析が採用されました。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80509_2.png)

参加者1人あたりのデータ収集の概要を示す図。デモグラフィック情報と、LLM使用頻度・認識に関するLikertスケール評価（合計36の評価）のデータ構造を図示。

## 調査結果

研究者らは、816名の研究論文著者を対象とした大規模調査から、LLMの利用状況と研究者による認識について分析を行いました。その結果を見ていきます。

### LLM利用の実態

調査の結果、研究者の約8割（816名中660名）が研究プロセスにおいてLLMを利用していることが明らかになりました。その中でも論文作成に関連するタスクでの利用が顕著で、情報収集では49%、編集では45%の研究者が少なくとも時々LLMを使用していると回答しました。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80509_3-1024x314.png)

LLM使用頻度の分布を示すダイバージングバーチャート。

一方、データ関連のタスクでは利用が限定的でした。データのクリーニングと分析では69%、データ生成では73%の研究者がLLMを全く使用していないと回答しました。

研究者らは各カテゴリーの詳細な利用状況も分析しました。情報収集に関しては、4分の1以上の研究者がすべてのタスクでLLMを活用していました。編集作業では、文法やぎこちない表現の修正が最も一般的な利用方法となりました。データ関連のタスクでは、分析が主な用途となり、シミュレーションや合成データ生成での利用は限られていました。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80509_4-1024x416.png)

各LLM使用カテゴリー内の具体的なタスクの内訳を示すバーチャート。 各カテゴリーで何人の研究者がどのタスクにLLMを使用したかを示す。

### 研究者の背景とLLM利用の関係

人種による利用頻度の違いは顕著に見られました。非白人研究者（平均値=2.68、標準偏差=1.73）は、白人研究者（平均値=2.06、標準偏差=1.52）と比較して、より頻繁にLLMを利用する傾向が示されました（推定値=0.616、p値<0.0001）。

言語背景による違いも見られ、英語を母国語としない研究者は、編集作業においてLLMを有意に多く利用していました（推定値=0.5069、p値<0.0001）。ただし、直接的な文章作成など、他のカテゴリーではこの差は認められませんでした。

### LLM利用に関する認識

調査結果から、情報収集（平均値=3.2）と編集（平均値=3.4）のカテゴリーは（他の4つのカテゴリー（平均値≤2.6）と比較して）、LLM利用のメリットが大きいと認識されていることが明らかになりました。

具体的なメリットとして、言語の公平性（つまり非英語話者でも英語ができるようになる）、効率性、日常的なタスクの支援、検索、文献レビュー、編集、ライターズブロック（文章を書く際にアイデアが浮かばなかったり、筆が進まなくなったりする状態）の克服、視点の拡大、プログラミング、ブレインストーミングを挙げています。中でも編集、文献レビュー、効率性、言語の公平性への言及が多く見られました。

また、文法修正や表現の改善といった編集作業、またプログラミングなど、小規模で日常的なタスクでLLMを活用する傾向を示しました。英語を母国語としない研究者や若手研究者、プログラミング経験の少ない研究者など、構造的な障壁に直面している研究者にとって、これらの基本的な利用は重要な意味を持っていました。

なお研究者らは新しいアイデアの創出や文章の執筆支援といった高度な用途にもLLMを活用していますが、こうした使用は「出力を常に検証する」「アイデアの出発点としてのみ使用する」など、慎重な姿勢が求められています。

### リスクと倫理的な懸念

研究者らは、LLMの利用における研究の質に関するリスクと倫理的な懸念の両方を指摘しました。編集での利用は比較的リスクが低く（平均値=2.5）、直接的な文章作成は中程度のリスク（平均値=3）、その他のカテゴリーは高リスク（平均値≥3.2）と認識されていました。

倫理面では、アイデア出しと構成（平均値=2.9）やデータのクリーニングと分析（平均値=2.96）に対する懸念が強く示されました。

研究者らが具体的に懸念したのは、

- 幻覚と誤情報、不正確さ
- バイアス
- 情報源の欠如
- 盗作、著作権の侵害
- 捏造
- 創造性の低下
- 研究エコシステムの汚染
- 勤勉さの低下
- スキル低下

などでした。

### LLM利用と認識の関係

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80509_5-1024x779.jpg)

調査結果の包括的なヒートマップ。デモグラフィック特性ごとのLLM使用頻度と認識を可視化。 統計的有意差を星印(\*)で表示。

リスク、メリット、倫理、利用の開示に対する認識は、すべてLLMの利用頻度に有意な影響を与えていることが判明しました（p値<0.0001）。リスクと倫理的な懸念が高いほど利用頻度は低く、メリットの認識が高いほど利用頻度は高くなりました。

メリットの認識は利用頻度と最も強い相関を示し（ [相関係数](https://ai-data-base.com/archives/26481 "相関係数") =0.62、p値<0.0001）、開示への快適さも弱いながら正の相関を示しました。

### メリットに関する認識の違い

人種と研究経験年数は、LLMのメリット認識に有意な影響を与えていました。非白人の研究者（平均値=3.14、標準偏差=1.31）は白人の研究者（平均値=2.67、標準偏差=1.35）と比べ、LLMの利用価値をより高く評価しました。

研究経験による違いも顕著で、若手研究者（0-3年、平均値=3.20、標準偏差=1.29）はベテラン研究者（11年以上、平均値=2.76、標準偏差=1.38）よりもLLMの有用性を高く評価しました。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80509_6-1024x252.png)

LLM使用頻度と各種認識（リスク、利点、倫理など）の相関を示すヒートマップ。 Kendallのタウ係数で相関の強さを示す。

### 倫理観と情報開示

性別による倫理観の違いも明らかになりました。女性、ノン [バイナリ](https://ai-data-base.com/archives/26314 "バイナリ") ー、その他の性別に属する研究者（平均値=3.24、標準偏差=1.58）は、男性（平均値=3.6、標準偏差=1.47）と比較して、研究におけるLLM利用への倫理的な懸念が強く示されました。

研究分野によってLLM利用の情報開示への姿勢も異なりました。コンピューターサイエンスの研究者（同僚への開示：平均値=4.07、標準偏差=1.39；査読者への開示：平均値=3.91、標準偏差=1.47）は、社会科学・人文科学や生物学・医学の研究者より、LLM利用の開示に積極的でした。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80509_7-1024x233.png)

デモグラフィック群間のLLM認識の差の統計検定結果

### LLMの提供元に対する好み

研究者の過半数（54.81%、359名）は、LLMの提供元（非営利団体か営利企業か）によって認識が変わると回答しました。自由回答の分析から、59.07%（228名）がオープンソース/非営利団体のLLMを好み、営利企業のLLMを選好したのはわずか2.85%（11名）でした。

研究者らは非営利団体を選好する理由として、組織のインセンティブ、モデルの透明性、倫理的配慮を挙げました。一方、営利企業のLLMを支持する少数派は、企業のリソースと顧客サポート体制を評価していました。

研究者の中には「技術は提供元に関係なく同じ」という中立的な立場や、ソースよりもモデルの質を重視する意見も見られました。また、非営利/営利の区分よりもオープンソースであることを重視する声も聞かれました。

## 考察

調査結果をもとに深い洞察がいくつか得られました。

### LLMがもたらす研究活動の変化と課題

LLMには研究の公平性と生産性を向上させる可能性がある一方で、研究の完全性や質の低下、学術的成果の画一化といった懸念も示されました。分野やキャリアステージによってLLMの利用度や開示への姿勢に違いが見られ、学術界で新たな社会規範が形成されつつある状況が明らかになりました。

### 研究活動へのLLMの浸透状況

多くの研究者が文献レビューからデータ分析、論文執筆まで、現行の研究活動にLLMを取り入れ、その利点を実感していることが判明しました。研究者らはLLMとの関係性を様々に捉えており、単なるツールとしての認識から、データソース、共同研究者、自律的な研究支援システムまで、その捉え方は多岐にわたりました。AIとHCI（Human-Computer Interaction、ヒューマン・コンピュータ・インタラクション）分野での新しいツール開発が進むにつれ、研究手法自体にパラダイムシフトが起きる可能性も示唆されました。

### LLMによる研究の公平性向上

研究者らにとって意外な発見は、LLMが研究の公平性向上に貢献しているという点でした。英語を母国語としない研究者からは、LLMによって編集作業の負担が軽減され、英語での自由な表現が可能になったという声が聞かれました。研究において不利な立場にある集団（非白人、若手、非英語母語話者）は、LLMの利点をより強く認識し、活用する傾向が見られました。

なお、LLMは言語以外の面でも公平性に寄与していました。プログラミングの専門知識がない研究者のデータ処理支援、異分野論文の理解促進、高額な編集サービスの代替など、様々な場面での活用が報告されました。さらに発達障害を持つ研究者からは、LLMの活用で執筆への自信が高まったという報告もありました。

しかし、倫理的な懸念から普及が妨げられる可能性も指摘されました。女性やノン [バイナリ](https://ai-data-base.com/archives/26314 "バイナリ") ーの研究者は、LLM使用に対してより強い倫理的懸念を示し、使用頻度も低い傾向にありました。学術界で既に不利な立場にあるこれらの研究者が、倫理的懸念からLLM活用を控えることで、さらなる不平等が生じる可能性が危惧されます。研究者らは、こうした懸念に対応したLLMツールの開発が必要だと指摘しています。

### 研究の生産性と完全性の葛藤

LLMの生産性向上への期待と同時に、深刻な懸念も示されました。誤情報の生成、盗作、データ捏造などのリスクが指摘され、将来の研究者のスキルや創造性への悪影響を危惧する声も聞かれました。NIH（国立衛生研究所）は、「思考の独創性」が損なわれる可能性を警告し、申請書や審査でのLLM使用に警鐘を鳴らしています。

注目すべき点ですが、LLMのリスク認識は研究者の属性による差がほとんど見られませんでした。例えば誤情報生成の問題は、すべての研究者に共通する重要な懸念事項となっていました。この共通認識は、LLMの使用基準を確立する上で重要な示唆を与えています。

### LLMの規範とガイドライン形成

研究者らは、LLMの全面禁止ではなく、倫理的な使用に関するガイドライン策定が現実的なアプローチだと指摘しています。

下記のような提案が可能とのことです。

- 査読者向けのチェックリスト作成
- 使用状況の透明な開示
- 再現性の担保

また、LLMを補助ツールとして位置づけ、生成コンテンツの後処理を推奨するなど、具体的な実践方法も示されています。

### LLM使用の開示に関する課題

学術界では、LLM使用の透明性確保に向けた取り組みが進められています。研究者らの調査では、多くの研究者がLLM使用の開示に前向きな姿勢を示しました。分野による違いも見られ、コンピューターサイエンスの研究者は他分野と比べて開示により積極的でした。

一方で、LLM使用を「学術的な恥」と捉える声も聞かれ、一部の研究コミュニティでスティグマ化（特定の個人や集団に対して社会的な偏見や烙印を押し、その結果として差別や疎外を引き起こす現象）されている現状も明らかになりました。また、機関ごとのポリシーの違いは研究者の負担となっています。研究者らは、科学の発展のために新技術を活用しつつ、その弊害を避けるための継続的な議論が必要だと指摘しています。

### オープンソースと商用LLMの議論

研究者らの調査から、LLMの提供形態をめぐる複雑な課題が浮かび上がりました。商用モデルは品質とサポート面で評価される一方、透明性や再現性への懸念、さらに営利企業と研究コミュニティの目的の不一致が指摘されています。

多くの研究者は技術や計算資源の制約から商用モデルに依存していますが、企業のモデル廃止により研究の再現性が損なわれるリスクも存在します。研究者らは、研究の妥当性と完全性を高めるため、オープンソースモデルを支持する傾向にあります。医学、法律、公共政策など、社会的影響の大きい分野では特に慎重な検討が必要とされています。

### 自己認識と他者認識のギャップ

さらに、興味深い心理的傾向が見つかりました。研究者は自身のLLM利用については適切な判断ができると考える一方、他者による不適切な利用を懸念する傾向が見られました。この『自分は大丈夫だが他人は心配』という認識は、社会心理学における『平均以上効果』や『第三者効果』と一致しているかもしれません。しかし他者への懸念が強いことは、研究コミュニティ全体でのガイドライン策定への支持につながる可能性があります。

## まとめ

816名の研究者を対象とした大規模調査から、研究活動におけるLLMの現状と課題が明らかになりました。回答者の約8割がLLMを利用し、非白人研究者、若手研究者、非英語母語話者がより積極的に活用していました。一方、女性やノン [バイナリ](https://ai-data-base.com/archives/26314 "バイナリ") ーの研究者からは強い倫理的懸念も示されました。

研究者らは、LLMが研究の独創性、厳密さ、倫理性を維持しつつ、より生産的で多様性のある研究コミュニティの形成に貢献する可能性を指摘しています。そのためには、技術面だけでなく、社会的、倫理的な影響の理解を深め、長期的な影響を見据えた検討が必要だと結論付けています。

**参照文献情報**

- タイトル：LLMs as Research Tools: A Large Scale Survey of Researchers’ Usage and Perceptions
- URL： [https://arxiv.org/abs/2411.05025](https://arxiv.org/abs/2411.05025)
- 著者：Zhehui Liao, Maria Antoniak, Inyoung Cheong, Evie Yu-Yen Cheng, Ai-Heng Lee, Kyle Lo, Joseph Chee Chang, Amy X. Zhang
- 所属：University of Washington, Pioneer Centre for Artificial Intelligence, University of Copenhagen, Princeton University, Allen Institute for Artificial Intelligence

## 理解度クイズ（β版）

1\. 調査に参加した研究者のうち、LLMを研究プロセスで利用していると回答した割合は？

調査では816名中660名（約80%）の研究者がLLMを研究プロセスで利用していると回答しました。

解説を見る

2\. LLMの利用において、最も活用度が高かったカテゴリーは？

調査結果から、情報収集では49%の研究者が少なくとも時々LLMを使用しており、他のカテゴリーと比較して最も高い活用率を示しました。

解説を見る

3\. 非白人研究者のLLM利用頻度の平均値はいくつでしたか？

調査結果では、非白人研究者のLLM利用頻度は平均値2.68（標準偏差1.73）を示しました。白人研究者の平均値2.06と比較して高い値でした。

解説を見る

4\. LLMの提供元について、研究者はどのような選好を示しましたか？

自由回答の分析から、59.07%（228名）の研究者がオープンソース/非営利団体のLLMを好むと回答し、営利企業のLLMを選好したのは2.85%（11名）のみでした。

解説を見る

5\. 女性・ノン [バイナリ](https://ai-data-base.com/archives/26314 "バイナリ") ー研究者のLLMに対する倫理的懸念の平均値は？

調査では、女性・ノン [バイナリ](https://ai-data-base.com/archives/26314 "バイナリ") ー・その他の性別に属する研究者の倫理的懸念の平均値は3.24（標準偏差1.58）を示しました。男性研究者の平均値3.6と比較して低い値でした。

解説を見る

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[LLMの開発トレンドに新たに見出された『密度化の法則』および『能力密度』の概念](https://ai-data-base.com/archives/80454)

[LLMを利用した「自動データクリーニング」方法](https://ai-data-base.com/archives/80508)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)