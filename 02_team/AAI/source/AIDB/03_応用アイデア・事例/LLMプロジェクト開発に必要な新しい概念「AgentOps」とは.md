---
title: "LLMプロジェクト開発に必要な新しい概念「AgentOps」とは"
source: "https://ai-data-base.com/archives/78733"
author:
  - "[[AIDB Research]]"
published: 2024-11-19
created: 2025-06-13
description: "本記事では、LLMエージェントを安全に開発・運用するための新しい考え方「AgentOps」を紹介します。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、LLMエージェントを安全に開発・運用するための新しい考え方「AgentOps」を紹介します。

大規模言語モデルを使ったAIエージェント（LLMエージェント）はできることが増えるにつれて中身が複雑になり、何をどう処理しているのか把握しづらくなるという問題があります。

そこで研究者たちは、LLMエージェントを作る段階から実際に使う段階まで、きちんと中身を確認できる仕組みが必要だと考えました。そこで既存のツールを調べ、体系化しました。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78733-1024x576.jpg)

**参照論文情報**

- タイトル：A Taxonomy of AgentOps for Enabling Observability of Foundation Model based Agents
- 著者：Liming Dong, Qinghua Lu, Liming Zhu
- 所属：CSIRO’s Data61

## 背景

大規模言語モデルを活用したさまざまな応用が生まれています。中でも、「作業を自動化したい」というニーズが高まり、LLMを使って自律的に動作するエージェント（LLMエージェント）の開発が盛んになってきました。しかし複雑な作業に取り組むにあたっては、いくつかの問題が見えてきました。

現在のLLMエージェントは、あまり確認をせずに自動的に判断を下しています。そのため、選べる行動が多すぎたり、様々な形でフィードバックが返ってきたりすると、エージェントが混乱して適切でない行動を取ってしまうことがあります。また、ふだんLLMをシンプルに使用する際には「文章を要約する」といった単純な作業だけを行いますが、LLMエージェントは1つの指示に対してもっと複雑な作業を行う必要があります。そのため、エージェントがどのように判断を下しているのかを理解するのは難しく、問題を修正したりすることも容易ではありません。

また、世界的に言語モデルの管理や規制が重要視される中、法律への対応も必要になってきました。リスクの高いシステムについては、システムが動いている間のすべての記録を自動的に残すことや、システムの動きを後から確認できるようにすることが求められています。

以上のような課題を解決するために、LLMエージェントの開発から実際の運用までの全体を管理する新しい仕組み（DevOpsやMLOpsに似た仕組み）として、「AgentOps」を作ることが必要になっています。開発、評価、テスト、導入、監視といった一連の作業を支援し、エージェントプロジェクトを適切に運用できるようにする考え方です。

今回研究者らはAgentOpsの全体観と既存ツールを整理しました。

## 研究手法

オープンソースプロジェクトプラットフォームや学術以外の文献を含む多くの関連情報源をもとに調査が実施されました。

### データ収集

研究者たちは、AgentOpsという概念と関連ツールの市場における理解がまだ初期段階にあると考えました。そのため、エージェントのライフサイクル全体、つまり「開発（dev）」から「運用（ops）」までに関連するツールを幅広く探索することにしました。

データ収集には主に3つの情報源が活用されました。

1つ目は、GitHubのオープンソースプロジェクト検索です。「AgentOps」というキーワードで検索を行い、注目に値するプロジェクトを発見しました。中でも「 [Awesome-LLMOps](https://github.com/tensorchord/Awesome-LLMOps) 」プロジェクトは、開発者向けのLLMOpsツールのキュレーションリストで、AIエージェントプロジェクトにも適用可能な監視ツールが含まれており有用でした。

2つ目の情報源は、ベンチャーキャピタル企業やソフトウェア投資家によってまとめられたAIエージェントツールスタックなどの文献（学術でない文献）です。代表的な例として、Insight Partnersの [AI Automation Market Map](https://www.insightpartners.com/ideas/ai-agents-disrupting-automation/) やMadronaの初期段階の [The Rise of AI Agent Infrastructure](https://www.madrona.com/the-rise-of-ai-agent-infrastructure/) （AIエージェントインフラツールリスト）が挙げられます。

そして、以下の2つの重要な選定基準に基づいてツールが選ばれました。

1つ目の基準は、”AgentOpsとの関連性”です。エージェントの開発または運用をサポートしているかどうか、エージェント構築フレームワークやライフサイクルの主要な段階をカバーしているかどうかが見られました。

2つ目の基準は、”オンラインドキュメントの利用可能性”です。ツールのウェブサイト上で、整理された文書が容易にアクセス可能であるかどうかが確認されました。

### AgentOps関連ツール

調査により、エージェントの構築、評価、特に観察可能性の監視をサポートする一連のAgentOps関連ツールが特定されました。

#### AgentOpsツール

まず、GitHubにある「 [AgentOps](https://github.com/AgentOps-AI/agentops) 」というプロジェクトは大きな存在感を持っています。このプロジェクトは、開発者がAIエージェントを構築、評価、監視し、プロトタイプから本番環境への移行を支援することを目的としたものです。

[https://github.com/AgentOps-AI/agentops](https://github.com/AgentOps-AI/agentops)

このAgentOpsプロジェクトで重要となるのは「イベント」データです。イベントには、LLMとの対話、ツールの使用、アクションなどが含まれます。各アクション（ステップ）にかかる時間を定義し追跡することが肝となります。エージェントは主にLLM呼び出しを開始し、その先にAPIやツールの呼び出しにつながることがあります。アクションには、関数の実行やスクリーンショットの取得なども含まれます。

なおこのプロジェクトは、エージェントのパフォーマンス、セッションの再生、カスタムパフォーマンスレポートを追跡するための包括的なダッシュボードも提供しています。セットアップすると、エージェントの複数の実行が各セッションで記録され、データは自動的に開発者のために記録されます。

#### LLMアプリケーション観察ツール

LLMアプリケーションのプロトタイプを構築するのは比較的容易ですが、プロトタイプの性能は本番環境での使用には不十分なことが多いです。そこで研究チームは、ツールスタック全体をカバーする様々なLLMアプリケーション観察可能性プラットフォームの情報を収集しました。

2つの重要なカテゴリーがあります。

1つは言語モデル固有のトレーシングツールです。

- [Langtrace](https://www.langtrace.ai/)
- [LangSmith](https://www.langchain.com/langsmith)
- [Langfuse](https://langfuse.com/) 　など

LLMの入出力、トークン使用量、レイテンシーなどを詳細に追跡するものです。

もう1つは、より広範なAIシステムのパフォーマンス監視ソリューションです。

- [Arize](https://arize.com/)
- [Datadog](https://docs.datadoghq.com/) 　など

システム全体のパフォーマンス指標、エラー検出、コスト管理などを提供します。

なお、上記のツールが提供する機能と収集するデータの詳細については、後の研究結果のセクションで詳しく説明します。

#### エージェント構築フレームワーク

AgentOpsでは、エージェントを作るための基盤システム（フレームワーク）と観察ツールが組み合わされている必要があります。

具体例を見てみましょう。 [SuperAGI](https://github.com/TransformerOptimus/SuperAGI) というフレームワークは、エージェントがどのような構造になっているか、どのような手順で動くのか、どんなツールを使うのか、またどんなデータを扱うのかを、分かりやすく見ることができます。詳細な情報が見えることで、「どんなデータを追跡すべきか」という課題に対する手がかりが得られます。

また、 [Crew AI](https://github.com/crewAIInc/crewAI) という別のフレームワークは、複数のエージェントが協力して働くためのシステムです。各エージェントが異なる役割を演じながら協力するように設計されており、複雑なシステムでどのようなデータが生まれ、やり取りされるのかを調べるのに役立ちます。

さらに、 [Dify](https://github.com/langgenius/dify) というオープンソースのプラットフォームはアプリケーションを作るためのものですが、こちらもLLMOps（LLMの運用管理）の機能を組み込んでおり、プログラミングの専門家でない人でも、生成AIを使ったソリューションを効率的に開発できるように工夫されています。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78733_figure1-1024x772.jpg)

### AgentOpsツールに見られる主な機能

上記のような現在公開されている主要なAgentOpsツールには、以下のような機能が一般的に実装されています。

（１）エージェント作成に関する機能  
本番環境対応で拡張可能なエージェントの構築と展開に関わる機能が実装されています。マーケットプレイスからのツールキット追加によるワークフロー拡張や、複数のベクターデータベース接続による性能向上、ビジネス固有のユースケース向けカスタムファインチューニングモデルの活用などが可能となっています。

（２）プロンプト管理に関する機能  
プロンプトの異なるバージョンを追跡する機能が実装されています。プロンプトプレイグラウンドを提供し、展開前の異なるプロンプトやモデルのテストと比較が可能です。また、セキュリティ面でのコードインジェクションやシークレット漏洩の検出機能も備えているケースが見られます。

（３）評価とテストに関する機能  
複数レベルでの評価機能が実装されています。最終応答の評価、個別エージェントステップの評価、ツール呼び出しの軌跡などを通じた期待パスの到達評価などが可能となっています。

（４）ヒューマンフィードバックに関する機能  
多くのツールで、ユーザーからの直接的なフィードバック収集と、ページ滞在時間やクリックスルー率などのユーザー行動測定による間接的なフィードバック収集の両方の機能が実装されています。

（５）モニタリングに関する機能  
エージェントの分析ダッシュボードを通じた各種統計指標の監視機能があります。また、基盤モデルプロバイダーとのトークンコスト追跡機能も見られます。

（６）トレーシングに関する機能  
エージェントの実行プロセス全体（チェーン、検索、LLM呼び出し、ツール呼び出しなど）、評価の実行、ユーザーフィードバックの追跡機能が実装されています。

なお、下記の表にまとめられています。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78733_1-984x1024.png)

## 調査結果

研究チームは、AgentOpsプラットフォームの主な構成要素を詳細に分析し、ライフサイクル全体で生成されるデータ項目を体系化しました。

### エージェント作成レジストリ

まず、エージェント作成時に定義される基本情報として「エージェント作成レジストリ（または登録カード）」があります。エージェントのIDや名前、目標、使用するモデルなど、以降のすべての活動の基礎となる情報を記録するものです。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78733_figure2-1024x636.jpg)

エージェントの識別情報、ロール、ツールキット、モデル、プロンプトなどの登録情報を体系化した図

このレジストリをもとに、エージェントは実際に動作を始めます。以下では、エージェントが動作する際の各フェーズで、どのようなデータが生成され記録されるのかを見ていきましょう。

### コンテキスト強化

エージェントシステムにおけるコンテキスト強化は、「インコンテキスト学習」と「検索拡張生成（RAG）」という2つの主要アプローチに分かれて整理されます。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78733_figure3-1024x471.png)

文脈内学習とRAGに関連する入力データの構造を示す図

インコンテキスト学習（文脈内学習）は、再訓練やファインチューニングを必要としない動的適応メカニズムとして特徴づけられます。このアプローチは、タスク記述の解釈と例示に基づく出力生成という構造化された枠組みを提供します。

一方、RAGは外部知識の統合メカニズムです。クエリマッチング、コンテンツ取得、プロンプト統合という3段階のプロセスとして整理されます。プライベートな領域知識や最新情報を動的に取り込むことを可能にする技術です。

### プロンプト

プロンプトに関するデータ項目は、効果的なエージェントのパフォーマンスを実現するための重要な構成要素として位置付けられています。プロンプトレジストリには、基本的な識別情報（ID、名前、バージョン）に加え、以下の階層的な構造が含まれます。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78733_figure4-1024x933.jpg)

プロンプトの識別情報、テンプレートタイプ、最適化技術などを体系化した図

プロンプトテンプレートは、その用途に応じて「チャットスタイル」と「指示スタイル」の2つの基本カテゴリーに分類されます。

チャットスタイルのプロンプトは、一連のメッセージを入力として受け取り、アシスタント形式のメッセージで応答する会話型エージェント向けに設計されます。

一方、指示スタイルのプロンプトは、単一の入力文字列を扱い、より単純なタスクに用いられます。

プロンプト最適化技術も重要な体系の一部を形成します。Chain-of-Thought（思考の連鎖）、Few-Shot学習、Zero-Shot学習、Tree-of-Thought（思考の樹形図）、Self-Consistency（自己一貫性）、Plan-and-Solve（計画と解決）などの技術が含まれます。エージェントの推論能力と出力品質を向上させるために適用されます。

### ガードレール

ガードレールは、エージェントの操作を制御するための制約メカニズムとしての位置付けです。以下の3つの主要な次元で構成されます。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78733_figure5-1024x183.png)

ガードレールのターゲット、ルール、アクションを体系化した図

（１）ガードレールのターゲット

プロンプト、LLM、外部データセット、RAG、そしてエージェント固有の要素（目標、コンテキスト、アクション、ツール、中間結果、最終出力など）が含まれます。

（２）ガードレールのルール

統一ルール、優先度ベースのルール、コンテキスト依存ルール、交渉可能ルールなど、異なる制御メカニズムが存在します。

（３）ガードレールのアクション

ブロック、フィルタリング、フラグ付け、フォールバック、人間の介入、遅延、分離などの具体的な制御メカニズムが含まれます。エージェントの振る舞いを安全かつ効果的に制御するために体系的に適用されます。

### エージェント実行

エージェントの実行プロセスは「プランニング」「推論」「メモリ」「ワークフロー」という4つの主要な次元で整理されます。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78733_figure6-1024x1016.jpg)

プランニング、推論、メモリ、ワークフローなどの実行要素を体系化した図

（１）プランニング

与えられたタスクから具体的なアクションを導き出すプロセスです。入力要素（エージェントの目標、役割、タスクの説明、期待される出力、利用可能なツールなど）と、出力要素（サブタスクのキュー、具体的なアクション）が含まれます。アクションモジュールは外部ツールの利用を可能にし、以下の要素で構成されます。

- アクショントリガー（ユーザーからのリクエストなど）
- アクション実行（ツールの実行、ウェブ閲覧、応答生成など）
- 入力データやパラメータ
- アクションの結果や応答

（２）推論

既存の知識を活用して結論を導き、予測を行い、説明を構築する機能です。単一エージェントでは推論タスクの効果が限定的であるため、複数のLLMをエージェントとして活用し、問題について集合的に議論・推論するマルチエージェント方式が採用されます。

（３）メモリ

短期メモリと長期メモリという2つの主要なコンポーネントで構成されます。短期メモリは最近のインタラクションと結果を一時的に保存し、現在のコンテキストに関連する情報の即時利用を可能にします。長期メモリは過去の実行からの価値ある知見と学習を保持し、エージェントが時間をかけて知識を蓄積・改良することを可能にします。

（４）ワークフロー

複雑なタスクをより小さなステップ（ [ノード](https://ai-data-base.com/archives/26470 "ノード") ）に分解することで、システムの複雑さを軽減します。プロンプトエンジニアリングとモデル推論能力への依存を減らし、複雑なタスクにおけるエージェントのパフォーマンスを向上させます。ノードは異なる機能を接続することで、ワークフロー内で一連の操作を実行できるようにする重要な構成要素です。

### 評価とフィードバック

評価とフィードバックのプロセスは、エージェントの出力品質を体系的に評価するための重要な要素です。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78733_figure7-1024x672.jpg)

評価の登録情報、人間からのフィードバック、フィードバックループを体系化した図

#### 評価プロセス

以下の主要なコンポーネントで構成されます。

（１）評価データセット

自動評価または人間による評価を実施するためのテストセットが必要です。評価テンプレートは、評価基準の定義と適切な集計メトリクスの選択を通じて生成されます。タスクを指定し、エージェントの効果を評価するための実験テストスクリプトの作成が含まれます。

（２）評価者（エバリュエーター）

エージェントやLLMアプリケーションのパフォーマンスを測定する機能を持ちます。評価者への入力には、エージェントの出力、参照回答（期待される出力や正解）、エージェントへの入力（プロンプト、タスクの説明など）、その他の関連データが含まれます。評価結果は、評価メトリクスに対応するキーと値のペアとして提示され、数値スコアが付与されます。

#### フィードバック

LLMエージェントにおいては、パフォーマンスを理解するためにユーザーフィードバックの収集が重要です。フィードバックメカニズムは以下のように構造化されます。

（１）人間のフィードバックフォーム

開発者はフィードバックタグを定義し、カテゴリー（有害性、人間による正確性、回答の関連性など）のリストを作成します。各カテゴリーにはスコアが関連付けられ、ユーザーがフィードバックを提供する際に、これらのカテゴリーから選択してスコアを割り当てます。

（２）フィードバックループ

例えばLangSmithでは、トレースに手動でフィードバックを付与し、各エージェント実行の値とスコアの両方を記録できます。評価テストセットと正解データを動的に更新する際に特に有用で、各実行からの人間のフィードバックを組み込むことができます。

### トレーシング（追跡）

エージェントの本番環境への展開後は、その実行プロセスを理解し監視するためのトレーシングが重要です。リクエスト処理における全ステップの包括的な可視化を提供し、エージェントのパフォーマンス評価と問題特定を支援するものです。

トレーシングは以下の3つの階層で整理できます。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78733_figure8-1024x881.jpg)

セッション、トレース、スパンなどのトレース要素を体系化した図

（１）セッション

最上位の階層として、AIエージェントワークフローの実行など、一連の操作があります。ワークフロー実行の単一インスタンスを包含し、すべてのエージェント、LLM、アクション、関連コンポーネントを統合的に可視化します。固有のセッションIDによって定義され、関連するトレースをグループ化し、総実行時間、トークンコスト、成功/失敗状態などの重要なデータを提供します。ユーザーIDと組み合わせることで、ユーザー関連のトレース、インタラクション、メトリクス、コストのさらなるグループ化、フィルタリング、可視化が可能になります。

（２）トレース

リクエストの実行パスの詳細な記録を表します。AIアプリケーションにおいて、ユーザーがクエリを送信してから最終応答が返されるまでの全プロセス（システムが取るアクション、取得される文書、モデルに送られる最終プロンプトなど）を明らかにします。各ステップにかかる時間とそれに関連するコストも示されます。

（３）スパン（実行）

トレースを構成する最小単位です。最初のスパンはルートスパンとして機能し、リクエストの開始から終了までを表現します。親スパンの下位にあるスパンは、リクエスト中に発生する各ステップの詳細なコンテキストを提供します。スパン全体は以下のように分類できます。

- LLMスパン：テキストとして表現される入出力を持つLLMへの呼び出し
- エージェントスパン：LLMが入力に基づいてアクションを決定・実行する動的な操作シーケンス
- ワークフロースパン：ツール呼び出し、データ検索など、静的な操作シーケンス
- ツールスパン：外部プログラムやサービスへの呼び出し
- タスクスパン：外部サービスを含まない単独のステップ
- 検索スパン：外部ナレッジベースからの文書返却を伴うベクトル検索操作
- エンベディングスパン：エンベディング生成のためのLLM呼び出し
- チェーンスパン：LLMアプリケーションのステップ間の開始点または連携

### モニタリング

エージェント運用の効果、エンゲージメント、コスト効率を継続的に改善するためのモニタリングは、以下のように構成されます。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_78733_figure9-1024x604.jpg)

モニタリングを体系化した図

（１）モニタリングメトリクス

エージェントシステムの異なる側面を追跡するための指標です。次の3つの基本カテゴリーに分類されます。

1\. 共通メトリクス

トークン使用量、コスト、レイテンシーなど、基本的な運用指標を含みます。

2\. 品質メトリクス

有害性、人間による正確性、回答の関連性などの品質指標です。ユーザーフィードバック、モデルベースの採点、人間介在の評価、またはカスタム採点システムを通じて評価されます。

3\. エラーメトリクス

実行プロセスにおけるレイテンシーやプライバシーの問題などのエラーを追跡し、その原因となったトレースまで遡って調査できるようにします。

（２）モニタリングの次元

様々なレベルで測定され分類されます。

- セッションレベル
- トレースレベル
- スパンレベル
- ユーザー別
- モデル別
- プロンプトバージョン別

例えば、エージェントのプロンプトの変更が上記のメトリクスにどのような影響を与えるかを追跡することができます。

## 妥当性についての留意事項

本研究におけるAgentOpsの整理においては、いくつかの留意事項があります。

まず、様々なツールやAIプラットフォームが急速に普及している状況において、AgentOpsツールをすべて特定できているかは分かりません。しかし研究者らは最大限の努力をすべく、複数のデータソースから、AgentOpsやLangfuseなどのオープンソースツールと、Datadogなどの商用観察可能性プラットフォームの両方を選びました。

またこの研究では、AgentOpsのライフサイクル全体で生まれるデータについて、できるだけ広く説明しようと試みられました。しかし、AIエージェントに関連するすべてのデータの特徴を完全に網羅できているわけではありません。そのため、今後は以下の2つの方向で研究を進める予定とのことです。

1. より詳しい学術文献の調査を行う
2. ユーザーのリクエストから最終出力までの過程を追跡する方法や、異なるステップ間のつながりなど、重要と思われるデータについて、より深い調査を行う

## まとめ

本記事では、LLMエージェントの信頼性向上を目指す「AgentOps」に関する研究を紹介しました。研究チームは、LLMエージェントの開発から運用まで、どのようなデータを記録・監視すべきかを整理しました。その中で、エージェントの各実行段階で生成されるデータの種類や、モニタリングの方法について体系化を行いました。

研究チームは今後、実際のAgentOpsプラットフォームから実データを収集し、エラーの原因追跡やデバッグの迅速化に向けた事例研究を進める予定です。LLMエージェントの信頼性確保に向けた取り組みは、今後も継続的に発展していくと見られます。

- 参照論文URL： [https://arxiv.org/abs/2411.05285](https://arxiv.org/abs/2411.05285)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[オープンソースのコード生成LLMが商用LLMに追いつく　Qwen2.5-Coderの能力値全容](https://ai-data-base.com/archives/78609)

[LLMが長々と説明するときは自信がない傾向にある　14個のモデルで検証](https://ai-data-base.com/archives/78828)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)