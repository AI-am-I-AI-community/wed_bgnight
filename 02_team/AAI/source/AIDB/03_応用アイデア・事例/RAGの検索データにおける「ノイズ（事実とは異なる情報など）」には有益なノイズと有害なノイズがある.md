---
title: "RAGの検索データにおける「ノイズ（事実とは異なる情報など）」には有益なノイズと有害なノイズがある"
source: "https://ai-data-base.com/archives/75220"
author:
  - "[[AIDB Research]]"
published: 2024-09-05
created: 2025-06-13
description: "本記事では、RAGシステムにおける”ノイズ”の役割を分析した研究を紹介します。研究者らは、RAGシステムにおいて検索されるデータにおけるノイズのタイプを7つに定義して評価しています。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、RAGシステムにおける”ノイズ”の役割を分析した研究を紹介します。研究者らは、RAGシステムにおいて検索されるデータにおけるノイズのタイプを7つに定義して評価しています。結果、ノイズの中にも有益なノイズがあり、LLMの性能向上に寄与する可能性が示されました。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75220-1024x576.jpg)

**参照論文情報**

- タイトル：Pandora’s Box or Aladdin’s Lamp: A Comprehensive Analysis Revealing the Role of RAG Noise in Large Language Models
- 著者：Jinyang Wu, Feihu Che, Chuyuan Zhang, Jianhua Tao, Shuai Zhang, Pengpeng Shao
- 所属：Tsinghua University, Beijing National Research Center for Information Science and Technology

## 背景

LLMはさまざまなタスクで優れた力を見せていますが、古い知識に頼りすぎたり、間違った情報を作り出したりすることがあります。これらの課題を解決するため、（ご存じの方も多いと思いますが）RAGという方法が注目されています。RAGは、LLMが答えを出す前に外からの新しい情報を参照する手法です。

しかし、RAGで取得される情報には正確な事実以外にもさまざまなノイズ（事実とは異なる情報やフェイクニュース、古い内容、スペルミスなど）があり、それらノイズがLLMの働きに影響を与える可能性があります。  
Web検索によって情報を取得するタイプのRAGだけに限らず、独自のデータベースを構築する場合においてもノイズは同様に発生します。

これまでの研究では、RAGシステムを実際の複雑な場面で使うことで、ノイズの影響や、システムを強くする方法が調べられてきました。しかし以下の点で不十分でした。

1. 調べたノイズの種類が少なく（だいたい3種類以下）、はっきりとした分け方がなかった
2. ノイズは悪いものだと決めつけていて、良い影響の可能性があまり考慮されていなかった
3. 評価のための資料が足らなかった

このままでは現実的なRAG環境（ノイズが含まれうる状況）を検証できているとは言えません。

そこで今回研究者らは、RAGにおけるノイズの種類を新しく7つに定義し直し、検索時のノイズの具体的な影響を詳しく調べました。

以下でアプローチや実験結果の詳細を紹介します。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75220_1.jpg)

異なるRAGノイズの影響を示す会話例

## RAGノイズの分類

研究者たちはまず、RAGノイズを7種類に定義し、2つのグループに分けました。以下、それぞれのノイズの種類について説明します。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75220_2-1024x527.jpg)

(A) RAGにおける7種類のノイズ (B) RAGノイズの詳細

### 意味的ノイズ (Semantic Noise, SeN)

検索された文書には、質問に対してあまり関係のない内容が含まれることがあります。トピックから外れていたり、意図した質問と異なる内容などです。こうした関係の薄い文書を意味的ノイズとして分類しています。

### データ型ノイズ (Datatype Noise, DN)

例えばWikipediaではリンクと文章が一緒に載っているように、さまざまな種類のデータが混ざっていることがあります。このような、複数データ種類が混在したものはデータ型ノイズと定義されました。基本的に文章、URL、コードの3種類のデータを考えています。

### 不適切な文ノイズ (Illegal Sentence Noise, ISN)

文書の中には、文法的に正しくない部分が含まれることがあります。文法的におかしな文を不適切な文ノイズと呼んでいます。

### 反事実ノイズ (Counterfactual Noise, CN)

うそや古い知識などの間違った情報はRAGシステムにとって大きな問題となります。言葉の研究では「反事実」が事実と違う表現を指すことから、事実と違う情報を「反事実ノイズ」と呼ぶことにしました。

### 支持的ノイズ (Supportive Noise, SuN)

あるアイデアに対してとても関係が深く、アイデアを支えるために必要な情報というものがあります。そこで、質問に深く関係しているものの答えの情報が足りない文書を「支持的ノイズ」としています。

### 表記ノイズ (Orthographic Noise, ON)

「表記法」という言葉は、ギリシャ語の「正しい」と「書く」に由来し、言葉の研究では単語の書き方を指します。表記法に由来して、スペルミスや単語を長く書きすぎるなどの書き方の間違いを表記ノイズと定義されました。

### 前提ノイズ (Prior Noise, PN)

「事前知識」とは問題を解く前に既に知っていることを指します。そこで今回の研究では、間違った思い込みや前提に基づく質問を前提ノイズと定義しています。例えば、「2017年にGoogleがAlphabetに再編されたときの社長は誰でしたか？」という質問には前提ノイズが含まれています。なぜなら、再編は2017年ではなく2015年に行われたからです。

## ノイズRAGベンチマーク構築

研究者らはRAGのためのノイズベンチマークを作成しました。

### データセットの構築

データセットは次の4つの手順で作成されました。

1. 質問と回答のセットを作る
2. 回答が質問に合っているか確認する
3. ノイズ（間違った情報など）を入れる
4. テスト用のデータセットを作る

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75220_3-1024x416.jpg)

全体的なフレームワーク

#### 手順1: 質問と回答のセットを作る

このステップでは、前提ノイズについては作り方が特殊でした。有名な新聞やWikipediaからスポーツ、政治、お金の話など、さまざまな時期や分野の記事が集められました。そして、ChatGPTを使って、それぞれの記事に関連する出来事、質問、回答を作りました。作られた質問には、わざと間違った前提が含まれています。

他の6種類のノイズについては、すでにある質問と回答のデータセットから取りました。ChatGPTを使って、分かりにくい質問や答えを除きました。その後、人の手でもう一度確認しました。

#### 手順2: 回答が質問に合っているか確認する

良いエビデンスは、その回答をしっかりと支えるものでなければいけません。例えば、デビッド・ベッカムについての良いエビデンスは、彼がLAギャラクシーに入る前にレアル・マドリードでプレーしていたという回答を支持するはずです。

そこで、bart-large-mnli-407Mという自然言語推論モデルを使って、証拠が適切に回答を支持しているかを確認しました。支持する確率が80%以上の例だけを残しました。

#### 手順3: ノイズを入れる

各ノイズの種類に従って異なる作り方が試されました。

反事実ノイズ  
Google検索結果から関連する人や物、関係を取り出し、事実と違う回答を作りました。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75220_4.png)

反事実ノイズ生成のためのLLM入力例。プロンプトは指示、例、候補カウンターファクチュアルQAで構成されている

支持的ノイズと意味的ノイズ  
2018年の英語版Wikipediaを使い、特別な検索モデルで関連する文章を探し、軽い文章埋め込みモデルで意味的な関連性をチェックしました。

不適切な文ノイズ  
モデルの語彙からランダムに単語を選んで、意味のない文を作りました。

データ型ノイズ  
ChatGPTを使ってURLやコードの一部を入れながら、大切な回答情報は残しました。

表記ノイズ  
textnoisrというオープンソースのツールを使って、文字の追加、削除、置き換え、入れ替えという4種類の変更を加えました。

#### 手順4: テスト用のデータセットを作る

質の高い質問と回答のセットと、さまざまなノイズを含む検索文書を得た後、異なるノイズ状況でのモデルの性能を評価するためのテストデータセットを作りました。

各質問と回答のペアに対して、LLMが4つの選択肢（正解、2つの間違った選択肢、「分からない」）から選ぶ形式です。

最終的に、NoiserBenchという名前の8つのデータセットができました。各データセットからランダムに500個のサンプルをテストケースとして選び、500個未満の場合はすべてのサンプルを使いました。

### 評価方法

今回作成されたベンチマークは、RAGにおけるノイズがLLMにどのような影響を与えるかを明らかにすることを目的としています。そのため主な評価基準として「正確さ」を使い、データセット全体の重み付き平均正確さを報告しています。各データセットの正確さを合わせて計算されています。

## 実験

### 実験の準備

#### データセット

実験では、質問回答データセットを4種類使っています。それぞれ、LLMに求める推論能力の強さが異なります。

（１）単一ステップの推論  
1回の推論で答えられる質問のデータセット。Natural QuestionsとR [GB](https://ai-data-base.com/archives/26343 "勾配ブースティング") を使用。

（２）明確な複数ステップの推論  
複数の推論ステップがはっきりと示されている質問のデータセット。HotpotQA、2WIKIMQA、Bamboogleを利用。

（３）暗黙の複数ステップ推論  
中間ステップが明確でなく、しばしば一般常識を必要とする推論を要する質問のデータセット。StrategyQAとTempQAを採用。

（４）混合ステップ推論  
単一ステップまたは複数ステップの推論が必要な質問データセット。本研究の研究チームが作ったPriorQAを使用。

#### 基本となるモデル

さまざまな構造と規模のLLMを評価しています。

- Llama3-Instruct (8B, 70B)
- Qwen2-7B-Instruct
- Mistral (7B, 8x7B)
- Vicuna-13B-v1.5
- Llama2-13B
- Baichuan2-13B

#### 実装の詳細

以下のコンピューター環境で行われました。

- NVIDIA A100 80 [GB](https://ai-data-base.com/archives/26343 "勾配ブースティング") [GPU](https://ai-data-base.com/archives/26570 "GPU") × 2
- 256 [GB](https://ai-data-base.com/archives/26343 "勾配ブースティング") RAM

なおPython 3.10.0を使用し、vllmというライブラリを使って計算を高速化しています。

### 主な結果

研究チームは、RAGノイズの悪い影響に加えて、良いノイズにも注目しています。モデルの構造、規模、RAGシステムの設計など、さまざまな面から良いノイズの効果を評価しています。

#### さまざまなRAGノイズの影響

以下の表に、Llama3-8B-InstructとQwen2-7B-Instructという2つの最新のオープンソースモデルに対する、さまざまな種類のノイズの影響が示されています。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75220_5-1024x511.jpg)

複数のデータセットと検索ノイズにわたって、一貫した性能の傾向が見られました。この結果に基づいて、ノイズを2つの種類に分けています。

1. 悪いノイズ：反事実、支持的、表記ノイズ
2. 良いノイズ：意味的、データ型、不適切な文ノイズ

ただし、事前ノイズは明確に「良いノイズ」または「悪いノイズ」のカテゴリーに分類されていません。事前ノイズが模型の性能にどのように影響するかを分析しましたが、明確に「良い」または「悪い」とは分類されません。事前ノイズの影響は、モデルが質問の誤った前提を認識し、それに適切に対応できるかどうかに大きく依存します。下の表は、8つのLLMのPriorQAデータセットでの事前ノイズに対する評価です。事前ノイズの影響が%で示されています。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75220_6.png)

Misleadingは事前ノイズの直接的な影響を示し、Backgroundは事前ノイズを含む質問に対して多くの情報を提供した場合の影響を示しています。つまりBackgroundは事前ノイズの影響を緩和する工夫が取られた結果です。

結果を見ると、Misleadingの場合は性能が大幅に低下していますが、Backgroundの場合は多くのモデルで性能が向上または維持されています。適切な背景情報の提供が事前ノイズの悪影響を軽減する可能性があることを示唆しています。

#### 良いノイズがモデルの性能を向上させる

研究チームは、モデルの構造とRAGシステムの設計の両方を考慮して、良いノイズの肯定的な効果を示しています。特に不適切な文ノイズ（ISN）の結果が強調されています。

下の図は、8つのLLM（さまざまな構造と規模）に対するISNの影響を示しています。ISNは、すべての場合でモデルの性能を大きく向上させ、悪いノイズがある時に最も顕著な改善が見られました。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75220_7.png)

R GB データセットにおける8つの代表的なLLMの平均精度に対する不適切な文ノイズ（ISN）の影響

下の表は、特殊なRAGモデルであるSelf-RAGに不適切な文ノイズを入れると、さまざまなデータセットと状況で一貫してモデルの性能が向上することを示しています。なお、DNは不適切な文ノイズ、ONは表記ノイズを意味しています。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75220_10-1.png)

下の図は意味的ノイズ（SeN）と表記ノイズ（ON）の影響を分析するためのグラフです。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75220_8.png)

R GB における3種類のノイズが精度（%）に与える影響を示す

以上の分析に基づいて、研究チームは不適切な文ノイズ、データ型ノイズ、意味的ノイズを良いものとし、反事実、支持的、表記ノイズを悪いものとして分類しています。

#### 他のノイズがある時も良いノイズは効果的

下の図は、5つの典型的なノイズの種類がある場合の、不適切な文ノイズの影響を示しています。不適切な文ノイズは一般的にすべてのデータセットで性能を向上させ、特に反事実ノイズなどの悪いノイズと組み合わせた場合にも、平均して10%以上の正確さの向上が見られました。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75220_9-1024x402.png)

Llama3-8B-instructとQwen2-7B-instructモデルに対する違法な文章ノイズの影響を、4つのデータセットにわたる5つの典型的なノイズカテゴリーで示す

#### 良いノイズの効果は統計的に意味がある

研究チームは、良いノイズがある場合とない場合の違いを統計的に評価するために、「ウィルコクソンの符号順位検定」を行いました。下の表に示されているように、すべてのp値が0.05未満ですが、これは良いノイズがモデルの性能を向上させるという強い統計的証拠を提供しています。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75220_11.png)

なお、有益なノイズの有無によるLLMの出力例の違いが以下に示されています。

有益なノイズなしの回答ではモデルは誤った情報に惑わされ、不正確な回答（A: 1931年6月14日）を選択しています。推論過程も不明確で、誤った情報を正しいと判断しています。一方で有益なノイズありの回答では、モデルは正しい情報を識別し、正確な回答（C: 1932年5月29日）を選択しています。推論過程がより明確になり、異なる情報源を比較し、正しい情報を選択する能力を示しています。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75220_12-1024x343.png)

最後に、有益なノイズがLLMの出力の不確実性（反自信）に与える影響も調査され、以下の図に示されています。全体的に、有益なノイズ（ISNとDN）を導入すると、モデルの出力の不確実性が減少する傾向が見られます。特に不適切な文ノイズ（ISN）の効果が顕著で、ほとんどのモデルで不確実性が大幅に低下しています。

有益なノイズがモデルの決定プロセスを強化し、より確実な出力を促進している可能性を示唆しています。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75220_13.png)

有益なノイズがLLM出力の不確実性に与える影響

## まとめ

本記事では、RAGシステムでのノイズの役割を調べた研究を紹介しました。研究者たちは7種類のノイズを定義し、良いものと悪いものの2つのグループに分けました。また、これをもとに「NoiserBench」というテストを作り、8つのLLMを評価しました。

結果として、良いノイズがモデルの性能を向上させる可能性があることが分かりました。研究者たちは今後、ノイズの良い面を活かしながら、悪い影響を避ける方法の研究が進むといいと考えています。

この研究は、ノイズを単に避けるべきものとしてではなく、うまく活用できる可能性のあるものとして捉え直すきっかけとなるかもしれません。

- 参照論文URL： [https://arxiv.org/abs/2408.13533](https://arxiv.org/abs/2408.13533)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[RAGの検索精度を実務レベルに高めるには、「情報ごとに ”質問文” を作りデータベースに入れる」のが効果的との報告](https://ai-data-base.com/archives/75110)

[ロングコンテキストLLM台頭の今もRAGを使用する理由](https://ai-data-base.com/archives/75289)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)