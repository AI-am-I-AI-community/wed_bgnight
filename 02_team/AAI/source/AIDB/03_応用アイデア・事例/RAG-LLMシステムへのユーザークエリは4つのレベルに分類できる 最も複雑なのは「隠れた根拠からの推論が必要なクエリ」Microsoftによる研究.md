---
title: "RAG-LLMシステムへのユーザークエリは4つのレベルに分類できる 最も複雑なのは「隠れた根拠からの推論が必要なクエリ」Microsoftによる研究"
source: "https://ai-data-base.com/archives/76241"
author:
  - "[[AIDB Research]]"
published: 2024-09-27
created: 2025-06-13
description: "本記事では、Microsoftの研究者たちが行った、LLMを外部情報で強化する必要がある質問に関する調査結果を紹介します。研究者たちは、ユーザーからの質問を4つの難易度に分け、それぞれの難易度に合った解決方法を提案しています。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、Microsoftの研究者たちが行った、LLMを外部情報で強化する必要がある質問に関する調査結果を紹介します。研究者たちは、ユーザーからの質問を4つの難易度に分け、それぞれの難易度に合った解決方法を提案しています。

また、外部情報をモデルに取り込む3つの主な方法についても説明し、それぞれの特徴を明らかにしています。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_76241-1024x576.jpg)

**参照論文情報**

- タイトル：Retrieval Augmented Generation (RAG) and Beyond: A Comprehensive Survey on How to Make your LLMs use External Data More Wisely
- 著者：Siyun Zhao, Yuqing Yang, Zilong Wang, Zhiyuan He, Luna K. Qiu, Lili Qiu
- 研究機関：Microsoft Research Asia

## 背景

LLMをそのまま使うだけでは、特定の分野や最新の情報に対応することが難しい場合があります。

そこで登場したのが、外部データを活用してLLMの能力を強化する手法です。外部データを活用すると、根拠のない情報を生成してしまう「ハルシネーション」と呼ばれる問題も減らすことができます。

外部データを活用する手法には、主に2つの方法があります。1つは「検索拡張生成（RAG）」で、質問に応じて関連する情報を検索し、それをLLMに与えて回答を生成します。もう1つは「ファインチューニング」と呼ばれる方法で、特定の分野のデータを使ってLLMを追加学習させます。

どちらの手法も非常に効果的ですが、実際に使いこなすのは簡単ではありません。例えば、法律や医療、製造業など、専門性の高い分野で使う場合、適切なデータの選び方や、LLMの推論能力を最大限に引き出す方法など、さまざまな課題があります。

また、質問の種類によっても最適な対処法が異なります。単純な事実を尋ねる質問もあれば、複雑な推論を必要とする質問もあります。それぞれの質問タイプに応じて、適切なデータの選び方や、LLMの使い方を変える必要があります。

このような背景から、Microsoftの研究グループはクエリ（質問）タイプを体系的に整理し、より効果的に対応するための研究を行いました。

以下で詳しく紹介します。

## 「データ拡張型LLMアプリケーション」

データ拡張型のLLMアプリケーションは、様々な形で私たちの生活に役立っています。例えば、

1. 特定分野の質問に答えるチャットボット
2. 複雑なデータ処理システムの一部として働くプログラム

などです。アプリケーションは、次のような簡単な式で表すことができます。

f: Q → D → A

それぞれの意味は、

- Q：ユーザーが入力する質問
- A：アプリケーションが出力する回答
- D：アプリケーションが参照するデータ
- f：QとDを使ってAを作り出す機能

です。要するに、ユーザーが入力する質問をもとにデータを参照し、回答を出力する機構となっています。

### 従来のLLMとの違い

データ拡張型LLMアプリケーションの特徴は、外部データ（D）を使って質問（Q）に正確に答えることです。以下のような能力を持ちます。

1. 最新の専門知識を使える
2. 特定の分野について深く理解できる
3. 専門家のような考え方ができる

### 質問の種類分け

質問は、外部データの使い方（以下）によって、簡単なものから難しいものまで分けることができます。

- 単純な事実を探す
- 隠れた情報を読み取る
- 複雑な推論をする

どんな難易度かによって、LLMが回答を作るために必要な「考える力」の深さが変わります。

今回研究者らは、難易度に応じてユーザークエリを4タイプに分類しました。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_76241_1-1024x534.jpg)

4つのレベルのクエリ（明示的事実、暗黙的事実、解釈可能な根拠、隠れた根拠）の主な焦点を示す図

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_76241_2-1024x625.jpg)

クエリレベルの概要と例を示す図

以下では、クエリのタイプ別に、概要と課題そして解決策を列挙していきます。

## クエリタイプ1. 明示的事実クエリ

明示的事実クエリは、質問の中で最も簡単なタイプです。与えられた文書や文書の一部から直接答えを見つけることができます。多くの場合、答えは文書の中にはっきりと書かれていて、難しい推論をしなくても答えられます。

このレベルの特徴は、質問の答えが外部データの特定の部分に明確に書かれていることです。

### データの使い方

データセットDは、いくつかの小さな部分（セグメント）に分けられます。

D = {D₁, D₂, …, Dₙ}

各セグメントDᵢは短く、具体的な内容を含んでいます。

質問qに答えるとき、すべてのセグメントが必要なわけではありません。δ(q, d)という関数で、質問qに答えるためにセグメントdが必要かどうかを表します（1なら必要、0なら不要）。

質問qに必要なデータの集まりDep(q)は、次のように定義されます。

Dep(q) = {d | d ∈ D かつ δ(q, d) = 1}

つまり、質問に答えるために必要なセグメントだけを集めたものです。

### 「明示的事実クエリ」の定義

明示的事実クエリQ₁は、データセットDの中から直接答えを見つけられる質問です。以下の二つで定義されます。

1. 検索コンポーネントrDは、質問qに答えるために必要なDの関連部分を見つける
2. 応答生成器θ（通常はLLM）は、見つけた情報だけを使って回答aを作る

つまり、明示的事実クエリが複雑な推論を必要とせず、データの中にある事実を直接使って答えられるということです。

### 「明示的事実クエリ」の例

- 「論文Xで問題Yを解決するために使った方法は何ですか？」（学術論文のコレクションがある場合）
- 「会社Xの人工知能戦略は何ですか？」（会社Xに関する最新のニュースや記事がある場合）

### 課題

明示的事実クエリに答えるには、LLMが正確な回答を出すために適切なデータを見つける必要があります。この課題に対しては、もちろんRAGがよく使われます。

しかし、RAGを使っても、高品質なシステムを作るには課題があります。まず、外部データは整理されていないことが多く、表や画像、動画なども含まれているため、処理が難しいです。また、データを適切な大きさに分割するのも簡単ではありません。次に、大量の整理されていないデータから関連情報を探すのは、時間がかかり間違いも起きやすいです。さらに、RAGシステムの性能を、特に部品ごとに評価するのは複雑な作業です。

そこで、RAGを改善するための方法がいくつかあります。

### 解決策1. 「データ処理」の改善

テキスト、表、図から情報を一貫性のある方法で抽出し、関連する部分を正確に特定して取り出すことが求められます。そこで多様な形式のデータ処理には、表をテキストに変換する方法や、視覚的な内容をテキストや属性ベースの説明に変換する技術が有効です。また、多様な形式のデータを扱える埋め込み技術も活用されます。

長い文章を適切な大きさに分割するチャンキングの最適化も重要です。固定サイズ、再帰的、 [スライディングウィンドウ](https://ai-data-base.com/archives/26349 "スライディングウィンドウ") など、様々な戦略が使われています。さらに、クエリの詳細さに応じて適切な粒度のテキスト部分を選択する方法や、情報の完全性を保ちつつ、テキストをより小さな部分に加工・洗練する手法も開発されています。

### 解決策2. データ検索の改善

情報検索技術の工夫は、そのままRAGアプリケーションに応用できます。主な工夫ポイントは以下のとおりです。

1. データインデックスの確立
2. クエリの処理
3. 検索とマッチング
4. 再ランク付け
5. 評価

インデックス作成では、スパース検索、密ベクトル検索、ハイブリッド検索などの方法が使われます。スパース検索では [TF-IDF](https://ai-data-base.com/archives/26539 "TF-IDF") やBM25などの手法を用いてテキスト部分の代表的な単語を特定し、密ベクトル検索では事前学習済みや微調整済みのテキストエンコーダーを使用します。

クエリと文書の整合には、従来の整合、文書領域の整合、クエリ領域の整合などの方法があります。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_76241_4-1024x510.jpg)

クエリとドキュメントのアライメントの3つの方法（従来型、ドキュメントドメイン、クエリドメイン）を示す図

検索結果の改善のため、再ランク付けと修正も行われます。上位の検索結果をフィルタリングし並べ替えたり、LLMを使用して検索結果の信頼性と有用性を評価したりします。また、誤った検索結果をフィルタリングするための事実検証モデルも使用されます。

さらに、複数回の検索を行う再帰的または反復的検索も有効です。

### 解決策3. 応答生成の改善

回答を生成する際には、取得した情報が十分かどうか、追加の外部データが必要かどうかを判断する必要があります。また、取得した知識とモデルの内部の事前知識との矛盾を処理することも重要です。

そこで、監督付き微調整はRAGシステムの生成性能を向上させるための効果的です。不適切または誤った情報が検索コンテキストとして与えられた場合の対処法を学習させることができます。

また、RAGシステム内の検索器と生成器の一貫した性能を確保するため、これらを共同で訓練する方法も開発されています。

## クエリタイプ2. 暗黙的事実クエリ

次に、答えがすぐには見つからない質問タイプを「暗黙的事実クエリ」とします。質問に答えるには、常識的な考え方や簡単な論理的推論が必要です。必要な情報が複数の場所に散らばっていたり、少し考える必要がある場合もあります。

このレベルの質問には、複数の文書から情報を集めて処理する必要があります。一回の検索では足りないこともあるので、質問を小さな部分に分けて何度も検索し、結果をまとめて答えを作ることもあります。

例えば、「いくつ」や「最も〜なのは何」といった質問がこれに当たります。数を数えたり、比べたり、傾向を分析したり、重要な部分だけをまとめたりする作業がよく必要になります。

### 「暗黙的事実クエリ」の定義

暗黙的事実クエリQ₂は次のように定義されます。

1. いくつかの明示的事実クエリ {q₁, q₂, …, qₘ} に分解できる。これらは一つずつなら直接答えが見つかる質問である
2. これらの小さな質問の答えを組み合わせることで、元の大きな質問に答えらる
3. 応答生成器θは、これらの部分的な答えをまとめ、データに直接書かれていない答えを導き出すために常識的な推論を使う

つまり、暗黙的事実クエリは、いくつかの簡単な質問に分けて答えを見つけ、それらを組み合わせて解決する質問だと言えます。

### 「暗黙的事実クエリ」の例

- 「サンプル数が1000を超える実験はいくつありますか？」（実験記録のコレクションがある場合）
- 「最もよく出てくる症状の上位3つは何ですか？」（医療記録のコレクションがある場合）
- 「会社XとYの人工知能戦略の違いは何ですか？」（会社XとYに関する最新のニュースや記事がある場合）

### 課題

「暗黙的事実クエリ」も事実に基づいていますが、答えは一か所にまとまっては書かれていません。代わりに、複数の事実を常識的に考えて組み合わせ、結論を導き出す必要があります。

主な課題は以下の通りです。

1. 質問によって必要な情報量が違うため、適切な量の情報を探す必要がある
2. 考えることで次に何を探せばいいか分かり、探した結果からさらに考えを深められる

この課題に対処するには、繰り返し検索する方法（反復的RAG）や、情報のつながりを図や木のように表現して処理する方法（グラフ/ツリー上のRAG）、データベース用の言語SQLを使う方法などがあります。それぞれの説明を以下で述べます。

### 解決策1. 反復的RAG

暗黙的事実クエリは、多段階のRAGタスクに似ています。正しい答えにたどり着くまで、情報収集や修正を繰り返し行うというのが特徴です。

まず計画ベースのアプローチでは、検索の前や検索中に段階的な計画を立てて、各段階での検索の焦点を絞り、効率的に情報を集めていきます。例えばReActという方法では、各段階で目標を更新し、必要な知識を少しずつ埋めていきます。

一方で情報ギャップ埋めベースのアプローチでは、既存の知識で回答を生成し、分からない部分について追加で検索と生成を行います。例えば、FLAREという方法では、各回の回答で確信度が低い部分を見直し、修正します。

### 解決策2. グラフ/ツリーによる質問応答

暗黙的事実クエリは複数の参考資料から情報を統合する必要があります。グラフやツリー構造は、このタイプのデータ検索問題に適しています。テキスト間の関係を自然に表現できるためです。

知識グラフでは、各 [ノード](https://ai-data-base.com/archives/26470 "ノード") が実体を表し、エッジがそれらの関係を示します。そのためLLMは複雑な関係性を理解しやすくなります。

データチャンクグラフ/ツリーでは、テキストの塊やデータの塊をノードとして扱い、エッジで高レベルな関係や詳細な関係を表現します。LLMの優れた読解能力を活かし、テキストを細かく分解せずに理解することができます。

### 解決策3. 自然言語からSQLクエリへの変換

構造化されたデータを扱う場合、自然言語をSQLに変換する（NL2SQL）アプローチが効果的です。Chat2DBなどのツールを使用すると、ユーザーのクエリをデータベースクエリに変換できます。

LLMはText to SQL（自然言語をSQLクエリに変換する）能力が高く、構造化データベースにアクセスし、より正確で文脈に沿った応答を生成できるようになりました。

### 明示的事実クエリと暗黙的事実クエリに関する考察

まず、ファインチューニングを使うべきかどうかについて議論があります。新しい事実知識をファインチューニングで獲得することは難しく、LLMの全体的な性能を低下させる可能性があります。また、新しい事実データでファインチューニングすると、LLMが事実文を機械的に暗記してしまい、表現を少し変えただけで最近学んだ知識が使えなくなる可能性があります。

明示的事実クエリと暗黙的事実クエリを区別することも重要です。明示的事実クエリを暗黙的事実クエリと誤認すると、質問に答えるのに役立たない表面的な情報を大量に取得してしまい、LLMを混乱させたり計算資源を無駄にしたりする可能性があります。逆に、暗黙的事実クエリを明示的事実クエリと誤認すると、十分で包括的な外部補助データを取得するための適切な方法を使用できなくなります。

したがって、対象タスクを十分に理解した上で、クエリのレベルを事前に区別することが重要だと考えられます。また、 [self-RAG](https://arxiv.org/abs/2310.11511) のようなアプローチを使用して、取得した情報が十分かどうかを自動的に評価するモデルを訓練する努力も行われています。

## クエリタイプ3. 解釈可能な根拠クエリ

次に、外部データを利用して「回答の根拠を提供する必要がある」クエリの中で、比較的単純なカテゴリーが「解釈可能な根拠クエリ」です。

問題解決のための思考プロセスが外部データに明確に説明されているパターンです。データは以下のような形式で整理されていることが多いです。

（１）プレーンテキスト

最も一般的な形式です。ハンドブックやガイドライン、専門マニュアルなどが含まれます。複雑なシナリオでの意思決定プロセスを説明します。

例：FDAガイダンス文書や医師向け投薬ガイド

（２）構造化された指示

より明示的な推論関係や決定経路を示します。テキスト条件付きMooreマシンやMealyマシンとして理解できます。ワークフロー、 [決定木](https://ai-data-base.com/archives/26121 "決定木") 、擬似コードなどの形式で表現されることがあります。

例：顧客サポートエージェントが製品変更や返金要求を処理するためのハンドブック

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_76241_5-1024x422.png)

根拠クエリ（解釈可能な根拠と隠れた根拠）のデモンストレーションを示す図

### 「解釈可能な根拠クエリ」の例

- 「胸痛と特定の症状の説明がある患者をどのように診断し治療すべきか」（胸痛管理ガイドラインが与えられた場合）
- 「実際のシナリオでユーザーの質問にどう答えるべきか」（顧客サービスワークフローが与えられた場合）

### 課題

解釈可能な根拠クエリの主な課題は、特定分野の根拠をLLMが理解できる形で組み込むことです。問題は２つに分けられます。

（１）プロンプト最適化のコスト

プロンプトを最適化するには多くの時間と計算資源が必要です。異なる質問には異なる背景知識や判断基準が必要なため、様々な例を用意する必要があります。手作業でプロンプトを設計すると効果的ですが、労力がかかります。また、様々な質問に対応したプロンプトを生成するモデルを訓練するには、大きな計算負荷がかかります。

（２）解釈可能性の限界

プロンプトがLLMにどのような影響を与えるかが不透明です。多くの場合、LLMの内部パラメータにアクセスできないため、異なるプロンプトがLLMの応答にどのような影響を与えるかを一貫して理解し検証することが難しいです。

### 解決策1. プロンプトチューニング

解釈可能な根拠クエリに対応するには、外部データの情報をLLMにうまく取り込み、その情報に基づいて正確に応答できるようにすることが大切です。

例えば、Text2MDTという研究事例では、医療ガイドラインや教科書から自動的に「医療 [決定木](https://ai-data-base.com/archives/26121 "決定木") 」を作り、長い医療テキストの論理的な流れが分かりやすくする取り組みがされています。  
また、MedDMという事例では、LLMが使える「臨床ガイダンスツリー」を開発し、このツリーを使って推論する方法や、患者とLLMが会話するしくみを提案しています。

しかし、LLMに単純に指示を与えても最高の性能は得られないため、「プロンプトチューニング」という技術を使って、LLMが特定の情報をよりよく理解できるようにするのが有効です。  
そこで、例えば [TEMPERA](https://arxiv.org/abs/2211.11890) という方法があります。指示や例を含むプロンプトを設計し、LLMが正しい応答をする確率を報酬として、最適なプロンプトを見つけ出す手法です。  
ほかにも、 [GrIPS](https://arxiv.org/abs/2203.07281) という方法では、小さなデータセットを使って、プロンプトの削除や入れ替えなどを試し、最も効果的なプロンプトを素早く見つけます。

なお最近では、LLM自体を使ってプロンプトを改善する方法も登場しています。 [OPRO](https://arxiv.org/abs/2309.03409) という方法では、LLMが過去のデータを基に新しいプロンプトを作り、それを評価することで、プロンプトの改善を効率的に行います。

### 解決策2. 思考の連鎖（CoT）プロンプティング

複雑な根拠に対応するには、LLMが長い推論の連鎖を行う必要があります。Chain-of-Thoughts（思考の連鎖）などの方法が効果的です。

もし問題について多くの知識があるなら、手動でCoTプロンプトを設計することが有効です。

しかし、手動でのプロンプト設計は時間がかかるため、 [Automate-CoT](https://arxiv.org/abs/2302.12822) のような方法で、少ないデータから自動的に推論の連鎖を生成する技術も開発されています。

また、LLMを中心としたエージェントシステムを構築する方法もあります。LLMエージェントは、プロファイリング、メモリ、計画、行動などの要素を組み合わせた包括的なシステムと定義されることが多いです。

## クエリタイプ4. 隠れた根拠クエリ

最も対応が難しいタイプの質問は、隠れた根拠クエリです。これは、「解釈可能な根拠クエリ」とは違って、質問に答えるのに必要な情報がはっきりと書かれていない場合です。必要な情報は、データの中に暗黙的に含まれている専門知識のような形で存在しています。

ここで必要になるデータには、以下のようなものがあります。

（１）同じ分野のデータ

1. 過去に質問されたことと、それに対する答え
2. わざわざ作られたデータ

例：Pythonプログラミングの難問とその解答集（よく使われる解き方や問題を解くコツが含まれています）

（２）基礎知識

1. 広い範囲にわたる様々な知識
2. 状況によって使い方が変わる知識

例：ある地域の法律全体（法的な判断を下す際の基礎となります）、数学の証明を簡単にするための中間的な結論

### 「隠れた根拠クエリ」の例

- 「今の経済の状況は、会社の将来にどんな影響を与えるでしょうか」（たくさんの財務報告書が与えられた場合）
- 「5、5、5、1という数字を使って、計算して24にするにはどうすればいいですか」（24を作る数字ゲームの例がたくさん与えられた場合）
- 「アフガニスタンでは、外国で生まれた子供に親の国籍を与えることができますか」（世界中の国籍法に関するデータが与えられた場合）

### 課題

主な問題は以下の2つです。

まず、普通の検索方法では、質問の本当の意図や、問題に論理的に似ているテキストを見つけるのが難しいです。そのため、表面的な似ている部分だけでなく、論理の構造を理解できる、より賢い検索方法が必要です。

次に、外部データに質問の答えがはっきり書かれていないことがあります。代わりに、関連情報が散らばった知識や例の中に隠れていることがあります。こういう場合、LLMがバラバラの情報から筋の通った答えを作り出す能力が必要です。

そして問題を解決するために、以下のような方法が提案されています。

### 解決策1. オフライン学習

このタイプの質問に答えるための一般的な方法は、データからルールや指針を見つけ出し、それを使って関連する情報を探すことです。

例えば、 [STaR](https://openreview.net/pdf?id=_3ELRdg2sgI) やLXSという方法では、LLMを使って推論の根拠を作り出します。STaRは少ないデータから始めて徐々に多くのデータを使う方法を取る一方で、LXSは一つのLLMが説明を作り、もう一つのLLMがそれを評価するという方法を使います。

間違いを見つけて、それを将来の課題のための指針に変えるGLという方法も考案されています。また間違い、簡単な原則、複雑な原則を作り、これらを最終的な推論に使うLEAPという手法もあります。

### 解決策2. 文脈内学習

例を使って文脈の中で学習することは、隠れた根拠を見つける一般的な方法です。事前に学習した大きなLLMは、この能力がかなり高く、似た例を探すことで、少ない情報からでも学習できます。

ただし、関係ない情報をLLMに与えると、簡単に混乱して間違った答えを出す可能性があります。そこで [OpenICL](https://arxiv.org/abs/2303.02913) という方法は、異なる例の探し方や推論の仕方がどのように学習に影響するかを調べています。

また、LLMの反応を見て小さなモデルを訓練し、特定の課題に最適な例を選ぶことで、より効果的に学習できるようになります。

### 解決策3. ファインチューニング

LLMの強力な文脈内学習能力にもかかわらず、複雑で長い論理の連鎖に対する正確な根拠や最適な例を特定することは依然として大きな課題です。また、大量の外部の事前知識を提供することもLLMの推論能力に課題を提示する可能性があります。

これらの要因を考慮すると、ファインチューニングが有望なアプローチとなります。ファインチューニングを行うと、LLMが事前学習で獲得した広範な基礎知識を活用しつつ、新しい分野の根拠を迅速に理解できるようにします。この方法は、LLMが高度で専門的なタスクに適応し、効果的に対処する能力を向上させる可能性があります。

指示チューニングは、LLMに新しい能力を注入するための一般的な方法で、通常は（指示、出力）のペアデータを使用した監督付きファインチューニングを含みます。指示データセットを構築する主な方法には、既存のデータセットからの派生、手作業での作成、強力なLLMを使用した合成データの生成があります。

最近では、大規模モデルのファインチューニングに関連するコストを削減するためのいくつかの取り組みがなされています。例えば、アダプターチューニングでは、LLMに小さなアダプターモデルを統合し、ファインチューニング中はLLMのパラメータを凍結し、アダプターの重みのみを最適化します。

また、プレフィックスチューニングとプロンプトチューニングは、入力の前に一連のトレーニング可能なベクトルを追加し、これらを訓練中に最適化してLLMの性能を向上させます。低ランク適応は、各密な層に低ランク制約を課すことで、ダウンストリームタスクに適応するために必要なトレーニング可能なパラメータの数を削減します。

近年、監督付きファインチューニングを使用して、数学的推論、金融、法律、ヘルスケアなどの専門分野でのLLMの能力を強化する多くの研究がなされています。例えば、ChatTimeLlamaは解釈可能な時間推論指示チューニングデータセットを導入し、LLaMAにファインチューニングを行うことで、モデルの複雑な時間推論、未来の事象予測能力、解釈可能性を大幅に向上させました。

以上、4つのユーザークエリタイプの詳細でした。

## まとめ

本記事では、外部情報を活用するLLMアプリケーションについての広範な調査を紹介しました。研究者らは、質問の難しさと外部情報の使い方に基づいて、質問を4つのタイプに分類し、それぞれのタイプに適した技術的なアプローチを見つけ出しています。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_76241_6-1024x528.jpg)

異なるクエリレベルに対する主要な技術のまとめ

また、モデルに新しい知識を教える3つの主な方法も示されており、それぞれの方法の特徴が説明されています。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_76241_7.png)

LLMに特定のドメインデータを注入する3つの方法（コンテキスト入力、小規模モデル、ファインチューニング）を示す図

なお、実際のアプリケーションでは様々な種類の質問が混ざっているため、開発者は複数の手法を組み合わせて質問を適切に処理する仕組みを作る必要があることも指摘されています。

- 参照論文URL： [https://arxiv.org/abs/2409.14924](https://arxiv.org/abs/2409.14924)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[OpenAIの新しいモデルo1-preview、従来のLLMと比べて「計画能力」で圧倒的な性能向上](https://ai-data-base.com/archives/76177)

[LLMの論理的推論能力をステップバイステップ以上に向上させる手法『Logic-of-Thought』プロンプティング（テンプレートつき）](https://ai-data-base.com/archives/76306)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)