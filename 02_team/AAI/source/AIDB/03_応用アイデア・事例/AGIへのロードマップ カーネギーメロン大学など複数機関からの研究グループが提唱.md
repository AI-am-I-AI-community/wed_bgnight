---
title: "AGIへのロードマップ カーネギーメロン大学など複数機関からの研究グループが提唱"
source: "https://ai-data-base.com/archives/70005"
author:
  - "[[AIDB Research]]"
published: 2024-05-30
created: 2025-06-13
description: "AIの飛躍的な進展は多くの分野で成果をもたらしつつありますが、次の大きなステップ、すなわちAGIに到達するためには、まだ多くの課題があると言われています。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

AIの飛躍的な進展は多くの分野で成果をもたらしつつありますが、次の大きなステップ、すなわちAGIに到達するためには、まだ多くの課題があると言われています。

本記事では、AGIに至るためのロードマップに焦点を当て、今後辿られるステップや考慮すべき要素について紹介します。テクノロジーは今AGIにどれだけ近づいているのか、そしてどのようにして目標を達成するかについての洞察です。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_70005-1024x576.jpg)

**参照論文情報**

- タイトル：How Far Are We From AGI
- 著者：Tao Feng, Chuanyang Jin, Jingyu Liu, Kunlun Zhu, Haoqin Tu, Zirui Cheng, Guanyu Lin, Jiaxuan You
- 所属：University of Illinois Urbana-Champaign, Johns Hopkins University, University of Chicago, University of California Santa Cruz, Carnegie Mellon University

## 背景

最近は言語処理や画像認識などの領域で優れた性能を示すAIシステムが次々と登場し、人間の能力を上回るレベルに達しつつあります。

しかし、現在のAIシステムの多くは何らかのタスクに特化したものです。  
そんな中、人工汎用知能(AGI: Artificial General Intelligence)の実現が期待されています。人間と同等かそれ以上の知的能力を備え、様々な実世界のタスクを効率的かつ効果的にこなせるAIシステムを意味する言葉です。現状のAIシステムはまだ、人間のような汎用的な知性とは程遠いのが実情です。

AGIの実現に向けては、知覚・推論・記憶・メタ認知などの能力面と、インターフェースの両面において、高度な実装が求められます。さらに、それらを支える基盤システムも重要な要素です。

今回複数の機関からなる研究者らのグループは、AGIの実現に対して現在のテクノロジーはどれほど距離があるのかを網羅的に調査した結果を報告しています。以下は、彼らが整理した、AGIに向けたロードマップです。

## AGIのレベル定義

AGIへの道のりを明確にするために、研究者らは3つのAGIレベルとその主要な特徴を定義しています。分類の目的は、現在のAI技術の位置づけと限界を明確にすることです。

### レベル1：初期段階のAGI

レベル1のAGIは、特定の課題において人間と同等、もしくはそれを超える性能を発揮します。現在の最先端のAIシステムは、このレベルに相当します。大量の人間が厳選したデータがあれば、特定の分野において人間を支援できる能力を示しています。研究によると、多くの分野で既にこのレベルに到達していると考えられています。

### レベル2：人間を超えるAGI

レベル2のAGIは、人間を完全に置き換え、現実世界の問題を解決できるようになる段階です。このレベルのAGIは、人間を凌駕する効果性、効率性、信頼性を持ち、限られたデータから学習し、知識を異なる分野に適用することができます。また、人間の介入をほとんど必要とせず、新しい状況に適応し、創造的で革新的なアプローチをとることができます。さらに、複雑な意思決定にも関与することが可能です。レベル2のAGIは人間が現在抱える複雑な問題を、人間の介入なしに解決できるようになると言われています。

ただし、囲碁など非常に限定された分野を除き、レベル2に到達したAIシステムはまだほとんどありません。

またレベル2のAGIは多くのタスクで人間を代替できますが、その開発には依然として人間の努力が必要です。

### レベル3：究極のAGI

レベル3のAGIは、与えられた目標（たとえそれが曖昧で高度なものであっても）、人間の介入なしに自己進化できる段階です。これはAGI開発の頂点であり、人間の能力をはるかに超える学習、推論、意思決定能力を持つ、理想的で、おそらく到達不可能なAIシステムを表しています。  
このような究極のAGI（レベル3）は、人間の感情、共感、社会的認識、さらには自己意識の萌芽さえも示す可能性があります。

しかし、このレベルの実現は理論的な概念であり、その可能性は継続的な研究と議論の対象となっています。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_70005_1.png)

AGIを評価するための4つの領域（内部、インターフェース、システム、アライメント）に基づく多面的アプローチを示すレーダーチャート

現在はまだAGIの初期段階であるため、上記の定義は抽象的なものになってしまっていますが、理論的なガイドラインとしての役割は果たします。なお、各レベルにおけるAIシステムの具体的な例は以下のとおりです。

- **レベル1：** パーソナルアシスタント（SiriやAlexaなど）、自動運転
- **レベル2：** AI搭載のビデオゲーム

## AGIの評価

### AGI評価の歴史

AGIの評価という概念は、1950年にアラン・チューリングが提唱した「チューリング・テスト」に端を発します。チューリング・テストでは、人間が機械と対話を行い、その相手が人間か機械かを見分けられない場合、その機械は知能を持っていると判断されます。この考え方が、後のAGI評価の基礎となっています。

その後、AIシステムの能力を評価する様々なアプローチが提案されました。初期の試みでは、人間の知能指数（IQ）に相当する指標でAIの性能を評価したり、大学の学位取得といった教育目標の達成可能性を探ったりしていました。

### AGI評価に期待されること

理想的なAGI評価パイプラインには、以下の特性が求められます。

**（１）包括性**

評価対象の多様性と一般性を確保し、様々な側面を評価できること。

**（２）公平性**

偏りのない評価を行い、客観的で透明性の高いベンチマークを使用すること。

**（３）効率性**

自動化と低分散性を追求し、限られたリソースで統計的に有意な評価を行うこと。

### AGI評価のフレームワーク

評価においては人間のような会話能力だけでなく、推論、学習、適応、複雑な問題解決など、幅広い認知能力を考慮する必要があります。それぞれ、AGIの内部レベル（知識表現と処理）、インターフェースレベル（外部世界の認識と相互作用）、システムレベル（全体的な振る舞い、意思決定）に対応しています。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_70005_2-1024x471.png)

AGIのレベル1から3までの特徴を比較し、それぞれのレベルに達しているかを評価する基準を示す（「L1」、「L2」、「L3」は、それぞれ「レベル1」、「レベル2」、「レベル3」）

### AGI評価の設計における課題

現在は評価の上で以下のような課題があります。

1. 複合的なモダリティや創造性を伴う出力の評価が難しい。
2. 多様な正解の可能性を考慮する必要がある。
3. : 個人の嗜好をどのように考慮するか。
4. 長期的な相互作用を伴うタスクへの対応。
5. 自動化された環境生成と測定の必要性。
6. 人間を超える能力をどのように評価するか。

現状の評価手法は、言語処理、画像認識、ロボティクスなど、様々な分野で利用されているベンチマークやフレームワークに基づいています。しかし、以下の限界があることが指摘されています。

1. 真の知能を数値で完全に表現することは難しい。
2. 真の目的と評価指標が乖離している可能性がある。
3. 失敗の原因を深く分析する必要がある。
4. 日常生活における複雑な問題を扱う能力の評価が不足している。

これらの課題を踏まえ、AGIの評価に向けては、人間的な知性の多面的な理解に基づく、より柔軟で包括的な評価体系の確立が急務です。

## ステップアップの方法

技術水準を正確に理解し、段階的に進化させていくことでAGIが次のレベルに到達すると考えられています。研究者らは、レベル間をステップアップするために必要なことを以下のようにまとめています。

まず、初期段階のAGI (レベル1) から人間を超えるAGI (レベル2) への移行には、以下の進展が不可欠です。

- モデルの規模とスケーラビリティの大幅な向上
- より大量で質の高いトレーニングデータの獲得
- 自己改善と自律的なイノベーションの実現
- 堅牢な安全性と倫理的な枠組みの確立

次に、レベル2から究極のAGI (レベル3) への移行は、さらに高度な知的能力の実現を目指します。以下のような課題に対処する必要があります。

- 複数の分野にわたる知識の統合と活用
- 継続的な学習と環境への適応力の強化
- 人間の価値観や倫理観への深い理解と尊重
- AIシステムの進化に合わせて厳格な監督体制を構築

なお、究極のAGIの実現に向けて、2つの具体的なアプローチが提示されています。

**（１）高度なコードマシンを活用**

[自然言語処理](https://ai-data-base.com/archives/26319 "自然言語処理（NLP）") と現実世界とのインタラクションを融合することで、AGIの自律的な進化を促進します。

****（２）** 超リアルなシミュレーションを導入**

現実世界を高精度に再現することで、AGIのトレーニングと評価を効果的に行います。

さらに、究極のAGIの実現には、以下のような根本的な課題があることも指摘されています。

- 計算資源やデータの限界
- 社会的な受容性の獲得
- 物理法則に基づく本質的な制約
- AGIの定義と目標の再考

## 著名人たちの議論

AGIの実現可能性と時期については、研究者の間でも意見が分かれるところです。以下は、著名な研究者たちによる考えが紹介されています。

### Oriol Vinyals氏の見解

（AlphaGoやAlphaStarなどの画期的なAIプロジェクトに貢献している人物。ゲームにおけるAIの開発において重要な役割を果たしており、その研究はAIが複雑な問題を解決する能力を示している）

**（１）AIとAGIの定義には違いがある**

- AI: 特定の認知タスクを行うシステム
- AGI: 人間のような汎用的な知的能力を備えたシステム

**（２）現在のAIは進歩の一方で限界もある**

- AlphaGoやAlphaStarなどの事例では、特定の領域で大きな進歩が見られる。
- しかし、これらのAIは汎用性の点ではまだ限定的である。

****（３）** AGIの実現には、特化型AIから汎用型AIへの移行が必要**

- 現在のAIは特定のタスクに特化しているが、AGIは幅広い認知タスクを行える必要がある。
- これは、AIシステムの [アーキテクチャ](https://ai-data-base.com/archives/26562 "アーキテクチャ") や学習アルゴリズムの設計に大きな変革が必要であることを意味する。

****（４）** AGIの定義と評価基準が重要**

- AGIの明確な定義なくして、その実現に向けた取り組みは難しい。
- AGIの評価基準は、人間の知的能力を多面的に捉えたものでなければならない。

**（５）現在のAI技術とAGIの間のギャップを認識することが重要**

- AIの進歩を過度に楽観視せず、AGIの実現までには多くの課題が残されていることを理解する必要がある。
- 同時に、AIの潜在的な可能性を探求し、AGIに向けた着実な歩みを進めることが重要である。

### Yejin Choi氏の見解

（ [NLP](https://ai-data-base.com/archives/26319 "自然言語処理（NLP）") における大規模なデータセットの解析とモデルの開発において重要な貢献をしている人物。AIが人間の言語を理解し生成する能力を向上させることを目指している）

**（１）生成AIにはパラドックスがある**

- 高品質の画像やテキストを生成できる一方で、生成物の理解力には疑問がある。
- 常識的な推論においても、AIシステムは時として驚くほど稚拙な振る舞いを見せる。

（編集部注：関連記事はこちら→ [LLMなどの生成AIの背後にある思考プロセスは人間とは全く異なるかもしれないことを示す仮説『生成AIのパラドックス』](https://ai-data-base.com/archives/58414) ）

**（２）AGIの到来時期は、タスクの種類によって異なる**

- 言語のみのタスクでは、数年以内に30%の人々が満足するレベルに達する可能性がある。
- 自律的な長期的インタラクションが求められる状況では、2050年までかかるかもしれない。

**（３）AGIの実現には、言語的な能力だけでなく、常識的な推論や長期的なインタラクションの能力が重要**

- 現在のAIシステムは、言語的なタスクでは高い性能を示すが、常識的な推論では脆弱である。
- AGIには、言語理解と生成に加えて、世界知識や因果関係の理解、長期的な計画能力などが必要とされる。

**（４）AGIの到来を予測する際には、タスクの複雑さや自律性の程度を考慮する必要がある**

- シンプルな言語タスクでのAGIの実現は比較的近い将来に可能かもしれない。
- しかし、複雑なインタラクションや自律的な意思決定が求められるタスクでは、まだ長い道のりがある。

### Andrew Gordon Wilson氏の見解

（機械学習におけるベイズ推論の専門家であり、特に不確実性のモデリングに関する研究で知られている。より堅牢で信頼性の高いAIシステムの開発に寄与している）

**（１）深層学習モデルの一般化能力は確率論的な観点から考察できる**

- モデルの性能は、サポートする仮説の範囲と事前分布の設計に大きく依存する。
- 現実世界のデータは比較的単純な構造を持つことが多いため、適切な事前分布の設計が重要である。

**（２）柔軟な仮説空間と適切な単純性のバイアスを組み合わせることで、少数のサンプルからでも効果的な学習が可能**

- 現実世界のデータは低次元の構造を持つことが多いため、単純性のバイアスを持つモデルが有効である。
- 同時に、モデルの仮説空間は十分に柔軟であることが求められる。

**（３）AGIの実現には、深層学習モデルの一般化能力の向上が不可欠**

- 現在のモデルは特定のタスクでは高い性能を示すが、汎用的な知能としてはまだ不十分である。
- AGIには、少数の事例からの学習、領域間の知識転移、因果関係の理解などの能力が必要とされる。

**（４）AGIの実現までには、まだ長い時間がかかる可能性がある**

- 現在のAI技術は急速に進歩しているが、人間レベルの汎用知能の実現にはまだ多くの課題が残されている。
- 特に、因果関係の理解や抽象的な推論など、高度な認知能力の実現には長期的な研究が必要である。

### Song Han氏の見解

（ディープラーニングモデルの圧縮技術やハードウェアの効率化に関する研究で知られている。モデルをより小型で高速、かつエネルギー効率の高いものにすることを目指している）

**（１）計算の効率性がAGIへの鍵を握る**

- AGIの実現には、膨大な計算リソースが必要とされる。
- 現在のハードウェアの限界を踏まえると、計算の効率化が不可欠である。

**（２）ハードウェアとソフトウェアの協調設計が重要**

- AGIシステムを効率的に動作させるには、ハードウェアとソフトウェアの密な連携が必要である。
- 特に、メモリ使用量の削減と、長い文脈を扱うための工夫が重要である。

**（３）エッジデバイス上でのモデルの効率的な動作が必要**

- クラウドに依存するのではなく、エッジ側で分散的にAIを処理することが望ましい。
- これにより、レイテンシの低減、プライバシーの保護、システムの堅牢性の向上などが期待できる。

**（４）計算の効率化に向けた具体的な取り組みがある**

- ハードウェアとソフトウェアの協調設計による効率的なモデル圧縮と推論の実現。
- エッジデバイス上でのモデルの分散的な訓練と推論の実現。

### Yoshua Bengio氏の見解

（ディープラーニングの先駆者の一人であり、多層 [ニューラルネットワーク](https://ai-data-base.com/archives/26117 "ニューラルネットワーク") の理論と実践に大きな貢献をしている）

**（１）AGIの安全性と倫理的配慮が重要**

- AGIは人間の知能を超える可能性があるため、慎重な開発と安全性の確保が不可欠である。
- AGIが人間の価値観から逸脱し、意図しない悪影響を及ぼすリスクを最小化する必要がある。

**（２）AGIシステムの意図と振る舞いの理解可能性と制御可能性が重要**

- 人間がAGIシステムの意思決定プロセスを理解し、制御できることが重要である。
- ブラックボックス化したAGIは、予期せぬ振る舞いにつながるリスクがある。

**（３）説明可能性、解釈性、価値の学習、倫理的規範の組み込みなどの技術的アプローチが必要**

- AGIシステムの振る舞いを人間が理解し、制御するためには、これらの技術が不可欠である。
- 特に、人間の価値観をAGIに学習させ、倫理的な意思決定を可能にすることが重要である。

**（４）AGIの開発には国際的な協調と政治的な調整が必要**

- AGIは世界中に影響を及ぼす可能性があるため、各国の協力と合意形成が不可欠である。
- 技術的な側面だけでなく、倫理的・社会的な問題についても、国際的な議論が求められる。

## AGIの開発において熟慮すべきこと

本研究では、倫理面などを中心に、懸念点を以下のようにまとめています。

### 1\. AGIの実現時期

研究者たちは、AGIの実現時期に関して、楽観的な見解と慎重な見解の両方を持っています。ある調査では、回答者の37%が「20年以上先」と回答したという結果が出ています。これは、AGIへの期待と同時に、その実現に向けた慎重な姿勢が表れていると言えるでしょう。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_70005_3.png)

AGIの達成時期に関する研究者の意見をまとめた投票結果

### 2\. 自己回帰モデルの限界

現在の主流である自己回帰型の生成モデルは、膨大なデータから世界の知識を学習することができます。しかし、因果関係や暗黙知の理解については、依然として疑問が残ります。AGIの実現には、新たなアプローチが必要とされています。

### 3\. スケーリング則の限界

モデルの規模とデータ量の単なる拡大では、創造性や直感、倫理的判断といった高次の知的能力を獲得することは難しいと指摘されています。AGIの開発においては、質の高いデータの活用と、スケーリングの法則の再検討が求められます。

### 4\. 合成データのリスク

そんな中、合成データは、AGIの開発を加速する可能性を秘めています。しかし、同時にバイアスや誤情報の増幅といったリスクも懸念されています。データの質と多様性を確保し、慎重な取り組みを進める必要があります。

### 5\. 計算能力と知性の関係

計算能力が知性を意味するのかという議論も、興味深い視点です。囲碁や将棋では、AIが人間のトッププレイヤーを凌駕していますが、これは巨大な探索空間を効率的に探索する能力によるものであり、純粋な知性とは異なる側面があると言えます。

### 6\. 自律性と安全性

AGIシステムの自律性を高めるためには、自己評価や自己改善のメカニズムが不可欠です。しかし、完全な自律性を実現するには、安全性や倫理性の担保、リスク管理などの高度な仕組みが必要となります。

人間の価値観をAGIにどのように組み込むかも、重要なテーマです。AIシステムが人間社会に調和的に溶け込むためには、倫理的規範や社会的慣習を深く理解し、尊重することが求められます。

### 7\. リスクと利益のバランス

AGIの開発においては、リスクと利益のバランスを適切に保つことが重要です。AIの研究を全面的に停止するのは現実的ではありませんが、十分な安全性と倫理性を確保する必要があります。

### 8\. オープンソース化の議論

AIシステムのオープンソース化は、研究の促進と民主化に寄与する一方で、悪用のリスクも高まります。研究者コミュニティには、便益とリスクを適切に評価し、責任あるオープンソース戦略を策定することが求められています。

## まとめ

本記事はAGIに関する包括的な調査論文より、ロードマップについてのセクションを紹介しました。AGIの段階や多角的な評価基準を確立すること、技術的ブレークスルーだけでなく、倫理的・社会的な考察も必要であることなどが述べられています。

研究者の見解では、AGIの実現可能性と時期に関して意見が分かれていますが、技術的、倫理的、社会的課題については共通認識があります。多角的な検討が必要です。

AGIの開発は社会全体で向き合うべき課題だと考えられています。多様なステークホルダーを巻き込み、建設的な議論を通じてAGIの望ましい姿を模索することが重要とされています。

- 参照論文URL： [https://arxiv.org/abs/2405.10313](https://arxiv.org/abs/2405.10313)
- [https://github.com/ulab-uiuc/AGI-survey](https://github.com/ulab-uiuc/AGI-survey)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[多くの「長いコンテキストを要するタスク」を、短いコンテキストウィンドウのLLMで解決する手法](https://ai-data-base.com/archives/69938)

[LLMエージェントの認知バイアス](https://ai-data-base.com/archives/70084)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)