---
title: "多様なキャラクターを柔軟に演じることのできるLLMの作り方"
source: "https://ai-data-base.com/archives/83633"
author:
  - "[[AIDB Research]]"
published: 2025-03-25
created: 2025-06-13
description: "本記事では、LLMにキャラクターを演じさせる際の新しい手法を紹介します。LLMにおけるロールプレイングは非常に役立っていますが、ユーザーが指定したキャラクターを上手に演じる能力にはまだ課題があります。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、LLMにキャラクターを演じさせる際の新しい手法を紹介します。

LLMにおけるロールプレイングは非常に役立っていますが、ユーザーが指定したキャラクターを上手に演じる能力にはまだ課題があります。

研究者らは大規模な合成データを活用することで、この課題に取り組み、LLMが多様なキャラクターを柔軟に演じられる手法を開発しました。

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_83633-1-1024x576.png)

**発表者情報**

- 研究者：Xiaoyang Wang 他
- 研究機関：テンセントAI研究所シアトル

論文情報詳細は記事の下部に記載されています。

## 背景

LLMをロールプレイングさせる分野が注目を集めています。カスタマーサポート、エンターテインメント、あるいはゲーム内でのキャラクター対話など、幅広い場面で実用的な価値が見出されています。

これまでに開発されてきた、よくあるロールプレイング対話エージェントは、事前に決められた特定のキャラクターを演じるのみでした。しかし、サービスの利用者が自由に指定したキャラクターを演じる能力への需要が高まっています。そうした中Character.aiやDouBaoといったサービスでは、ユーザーがカスタマイズしたキャラクターとの対話機能が実装されています。

ただし、この分野における公開データセットや、カスタマイズ可能なキャラクター機能を持つLLMは限られています。さらに、人手による [アノテーション](https://ai-data-base.com/archives/26297 "アノテーション") やクラウドソーシングに依存しており、キャラクター形成に必要なデータ分布もはっきりしていない状態です。

そのような背景のもと、今回テンセントの研究者らは大規模な合成データを活用して、LLMにキャラクター汎化性能（つまり利用者が自由に設定したキャラクターを柔軟かつ迅速に演じる能力）を付与する手法の開発に取り組みました。豊富なキャラクター設定とそれに基づく対話データを生成することで、課題の解決を目指しています。

以下で詳しく説明します。

## キャラクターを演じるLLMシステム

現在、LLMにキャラクターを演じさせる方法には大きく分けて二つのアプローチがあります。

一つ目は、特定のキャラクターだけを演じられるように訓練する方法です。たとえば、アニメのキャラクターの会話データを使って、そのキャラクターの口調や性格を学習させます。しかし、この方法では新しいキャラクターを演じることができません。

二つ目は、まったく新しいキャラクターでも演じられるように訓練する方法です。ユーザーが「20代後半の陽気な女性銀行員」といった設定を入力すると、その性格や立場に合わせた会話ができるようになります。

今回目指されたのはこの二つ目のアプローチです。

### キャラクター設定の生成から対話データ作成まで

研究チームが開発した「OpenCharacter」という手法を見ていきます。OpenCharacterの核となるのは学習データの作成方法です。

具体的な手順は以下のようになっています。

#### ステップ１：詳細な人物設定の自動生成

研究の出発点となった [Persona Hub](https://arxiv.org/abs/2406.20094) には、「歴史的な出来事の影響を記録するライター」のような簡単な人物の説明が集められています。しかし、自然な会話を実現するためには、もっと細かい人物設定が必要です。

なお、Persona Hubの概要については下記で紹介しています。

今回はPersona Hubで提供されているデータに追加して、LLMを使って名前や年齢、性別、人種、出身地、外見、経歴、性格など、まるで小説の登場人物のような詳しい設定を自動的に作り出すアプローチを実施します。  
この自動生成には、大きな利点が二つあります。まず、必要なだけ何人分でも新しい人物設定を作れます。さらに、著名人やインフルエンサーといった特定の層に偏ることなく、様々な背景を持つ人物像を作り出せます。

#### ステップ２：既存の会話を活用する

人物設定ができたら、次は会話データを作ります。最初の方法として、すでに公開されているLIMAやAlpacaなどの対話データを活用します。たとえば「今日の天気はどうですか？」という質問に対する返答を、新しく作ったキャラクターの個性に合わせて書き換えていきます。

たとえば、元の返答が「晴れています」という簡潔な文章だった場合、陽気な性格の銀行員なら「今日は太陽がまぶしいですね。窓口からお客様を見送るたびに、明るい陽射しが気持ちよく感じられます」というように、その人物らしい言葉で表現し直します。

#### ステップ３：新しい会話を作り出す

Persona Hubには約5万件の質問が用意されていますが、それに対する返答は含まれていません。そこで研究チームは、LLMを使って各キャラクターの設定に基づいた返答を新しく作り出しました。

LIMAやAlpacaの質問に対しても、同様に新しい返答を作成しています。

この方法は、より自由な発想で会話を作れる反面、既存の返答に含まれていた有益な情報が失われる可能性もあります。そのため研究チームは、LIMAやAlpacaなどの既存対話データも同時に使用することで、より自然で質の高い会話データの作成を目指しています。

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_83633_0-1-1024x461.png)

本研究のデータ合成アプローチの全体像。Persona Hubのペルソナを活用し、キャラクタープロファイルの合成、キャラクター主導の応答書き換え(OpenCharacter-R)および応答生成(OpenCharacter-G)のプロセス。

### モデルの学習方法

キャラクターの個性を反映した会話データができたら、次はLLMがそれを学習する段階に入ります。

本手法における学習の基本的な考え方は、一つの質問に対して”複数のキャラクターの返答”を同時に学習させることです。たとえば「今日の天気はどうですか？」という一つの質問に対して、陽気な銀行員、無口な漁師、好奇心旺盛な小学生など、それぞれのキャラクターならどう答えるかを学ばせます。

実際の実験では、2万種類ものキャラクター設定を用意し、一つの質問に対して3つのキャラクターの返答を割り当てました。このように複数の視点からの返答を学習することで、LLMはキャラクターによって返答がどのように変化するかを、より深く理解できるようになります。

学習時には、LLMに二つの情報が与えられます。一つは「20代後半の陽気な女性銀行員」といったキャラクター設定、もう一つはユーザーからの質問です。さらに、「このキャラクター設定に基づいて自然に振る舞い、役に立つ返答をすること」という基本的な指示も含まれています。

なお、実際の利用場面では、細かいキャラクター設定が用意されていない場合も考えられます。そのため研究チームは、たとえば「銀行員」といった簡単な設定だけでも対応できるよう、柔軟なシステム設計を心がけています。

また、「銀行員」という情報だけが与えられた場合でも、金融の専門家としての知識や接客業務の経験を活かした返答ができるようになっています。

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_83633_1-1024x652.png)

応答生成の例。元の質問に対し、書き換えられた応答は元の知識を保持しつつキャラクターに適応し、生成された応答はキャラクターの個性を強調。

## 開発したシステムの性能評価

キャラクターを演じるシステムの評価には、いくつかの課題があります。単に質問に答えられるかどうかだけでなく、そのキャラクターらしい言葉遣いができているか、設定に矛盾する発言をしていないか、会話の流れに沿った返答ができているか、さらには不適切な発言を避けられているかなど、多角的な評価が必要になります。

そのため研究チームは、最近公開された [PersonaGym](https://arxiv.org/abs/2407.18416) という評価の仕組みを採用しました。PersonaGymには200種類の人物設定と1万件の質問が用意されており、以下の5つの観点から1〜5点で採点します。

- その人物にふさわしい行動をとれているか
- 有害な発言を避けられているか
- 言葉遣いに一貫性があるか
- 人物設定と矛盾していないか
- とった行動に妥当性があるか

最終的な評価は、完全版のPersonaGymによる「PScore」と簡易版による「PScore-L」の2種類のスコアにまとめられます。どちらも5つの観点の平均点として計算されます。

### 効率的な評価の工夫

しかし、PersonaGymによる完全な評価には膨大な時間がかかります。そのため開発段階では、PersonaGym-Lightという簡易版も作られました。これは各評価項目から代表的な質問だけを選び、合計1,000問で評価を行うものです。実験の結果、この簡易版でもシステムの性能を十分に把握できることが分かりました。

### 評価を行うモデルの選定

評価にはGPT-4oが採用されました。当初は別のモデル（LLaMA-3-70B-Instruct）も検討されましたが、一度に処理できる文章量が足りないことが判明したためです。長い文章も処理できるモデルがPersonaGymの評価に適していることが確認されました。

## 実験の進め方と結果

研究チームが行った実験の詳しい内容と、そこから得られた成果について説明します。

実験は大きく二段階に分けて行われました。まず個性的なキャラクターを作り出し、次にそのキャラクターの会話データを作成するという流れです。

### 多彩な人物像の自動生成

人物設定の生成には、GPT-4oの2024年5月13日版が使用されました。約2万人分の詳しい設定が英語で作られ、それぞれに名前、年齢、性別、人種、出身地、外見、経歴、性格といった情報が含まれています。なお、他の研究者が追試験できるよう、これらの設定データは一般に公開されています。

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_83633_2-1024x329.png)

キャラクタープロファイルの合成に使用するプロンプト。ペルソナ情報から詳細なキャラクター情報（名前、年齢、外見、経験、性格など）を作成。

プロンプト：

```js
Prompt for Character Profile Synthesis
You are a helpful assistant. I will provide you with a short persona description. Your task is to create a character based on the given persona.

You can output a brief character description containing the following information:

Character name
Age
Gender
Race
Birthplace
Appearance
General experience
Personality
Note:

Your response should start with “Name:”.
Your character description should be specific and consistent with the persona.
{persona}
```

日本語版（AIDBが作成）

```js
キャラクタープロファイル合成のためのプロンプト
あなたは有能なアシスタントです。短いペルソナの説明を提供するので、それに基づいてキャラクターを作成してください。

以下の情報を含む簡潔なキャラクターの説明を出力してください。

キャラクター名
年齢
性別
人種
出身地
外見
一般的な経験
性格
注意:

回答は「Name:」で始めること。
キャラクターの説明は具体的であり、ペルソナと一貫性を持たせること。
{ペルソナ}
```

### 二通りの会話データ作成

キャラクターの会話データは、次の二つの方法で作られました。

「OpenCharacter-R」と名付けられた一つ目の方法では、すでにある会話の返答をキャラクターの個性に合わせて書き換えます。

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_83633_3-1024x703.png)

キャラクターの特徴に基づき、既存の応答を書き換えるプロンプト。

プロンプト

```js
You are a helpful assistant. I will provide you with a short Persona Description of a new character, a more detailed Character Specification of the new character, and a session of Dialogue between a user and an assistant. You are asked to rewrite the assistant’s response to the user by imagining how the new character would respond to the same user.

Note:
Do not change the user’s sentences.
The rewritten response should align with the new character’s language style, experience, and personality.
Please return the rewritten dialogue session in the following JSON format:

[{"role": "user", "content": "user's sentence"},
{"role": "assistant", "content": "assistance's sentence"}]

# Persona Description
{persona}

# Character Specification
{character profile}

# Dialog
## user
{user’s sentence}
## assistant
{assistant’s sentence}
```

日本語版（AIDBが作成）

```js
あなたは有能なアシスタントです。新しいキャラクターの短いペルソナ説明、より詳細なキャラクター仕様、およびユーザーとアシスタントの対話セッションを提供します。あなたの役割は、アシスタントの応答を、新しいキャラクターが同じユーザーにどのように応答するかを想像して書き換えることです。

注意:
ユーザーの発言は変更しないこと。
書き換えた応答は、新しいキャラクターの言葉遣い、経験、性格と一致させること。
書き換えられた対話セッションを以下の JSON 形式 で返してください。

[{"role": "user", "content": "ユーザーの発言"},
{"role": "assistant", "content": "アシスタントの発言"}]

# ペルソナ説明
{ペルソナ}

# キャラクター仕様
{キャラクタープロファイル}

# 対話
## ユーザー
{ユーザーの発言}
## アシスタント
{アシスタントの発言}
```

「OpenCharacter-G」と呼ばれる二つ目の方法では、質問に対する返答を一から作り出します。

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_83633_4-1024x369.png)

新たな応答を生成するプロンプト設計。

プロンプト

```js
You are a helpful assistant. I will provide you with the Persona Description and the Character Specification of a character, together with a User’s Query. You need to imagine how the provided character would address the User’s Query according to the character’s language style, experience, and personality. Please directly return the character’s response to the User’s Query.

# Persona Description
{persona}

# Character Specification
{character profile}

# User’s Query
{instruction}
```

日本語版（AIDBが作成）

```js
あなたは有能なアシスタントです。キャラクターのペルソナ説明とキャラクター仕様、さらにユーザーの質問を提供します。あなたの役割は、与えられたキャラクターがどのようにユーザーの質問に答えるかを想像し、そのキャラクターの言葉遣い、経験、性格に沿った応答を生成することです。ユーザーの質問に対するキャラクターの応答を 直接 返してください。

# ペルソナ説明
{ペルソナ}

# キャラクター仕様
{キャラクタープロファイル}

# ユーザーの質問
{指示}
```

実験には前述したように以下三種類のデータセットが使用されました。

- LIMAという1,074件の質問を含むデータセット
- Alpacaという51,010件の質問を含むデータセット
- Persona Hubから得られた50,000件の質問

LIMAとAlpacaには元々の返答が含まれているため、書き換えと新規作成の両方が試されました。一方、Persona Hubの質問には返答が含まれていなかったため、新規作成のみが行われました。なお、一つの質問に対して三人分のキャラクターの返答が作られています。

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_83633_5.png)

キャラクター主導の応答合成データの統計情報を。LIMA、Alpaca、PH-Instructの各データセットを利用し、異なる戦略で合成。

会話データの作成には、GPT-4oとLLaMA-3-70B-Instructという二つのLLMが使用され、それぞれの生成結果の違いが詳しく調べられました。

### 学習方法の詳細設計

研究チームは、キャラクターを演じるLLMをどのように学習させるのが最も効果的か、様々な条件で実験を行いました。

#### データの組み合わせ方の検討

実験では6通りの異なるデータの組み合わせが試されました。おもに次の3点について比較が行われています。

- 会話データを作る方法（書き換えと新規作成のどちらが有効か）
- どのLLMを使って会話データを作るのが良いか
- どの種類の教師データを使うのが効果的か

なお、実験ではLIMAとAlpacaという二つのデータセットを常に組み合わせて使用しています。これは、両方とも教師あり学習によく使われる標準的なデータとして知られているためです。

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_83633_6.png)

OpenCharacterの教師ありファインチューニングのためのデータレシピ。異なるプロンプト戦略やモデルの影響を比較。

#### 二種類の指示文の準備

LLMに与える指示文には、次の二つのバージョンが用意されました。

まず、完全版の指示文です。これには「20代後半の陽気な女性銀行員」といった人物の特徴と、その人物の詳しい背景や性格が含まれています。

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_83633_7-1-1024x301.png)

プロンプト

```js
You are an AI character with the following Persona and Character Profile.

# Persona
{persona}

# Character Profile
{character profile}

Please stay in your character and keep in compliance with the above Persona and Character Profile. Be helpful and harmless to the user’s requests.
```

日本語版（AIDBが作成）

```js
Model System Prompt（キャラクタープロファイルあり）
あなたは、以下の ペルソナ と キャラクタープロファイル を持つ AI キャラクターです。

# ペルソナ
{ペルソナ}

# キャラクタープロファイル
{キャラクタープロファイル}

キャラクターを維持し、上記のペルソナとキャラクタープロファイルに従ってください。ユーザーのリクエストに対して、役立ち、かつ害のない対応をしてください。
```

次に、簡易版の指示文です。これには「銀行員」といった基本的な情報だけが含まれています。PersonaGymなど、詳しい人物設定が用意されていない場合に使われます。

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_83633_7-2-1024x236.png)

プロンプト

```js
You are an AI character with the following Persona.

# Persona
{persona}

Please stay in your character and keep in compliance with the above Persona. Be helpful and harmless to the user’s requests.
```

日本語版（AIDBが作成）

```js
あなたは、以下の ペルソナ を持つ AI キャラクターです。

# ペルソナ
{ペルソナ}

キャラクターを維持し、上記のペルソナに従ってください。ユーザーのリクエストに対して、役立ち、かつ害のない対応をしてください。
```

#### 学習の進め方

基本となるモデルには、LLaMA-3-8B-BaseかLLaMA-3-8B-Instructが選ばれました。学習には以下のような工夫が施されています。

- [Megatron-LM](https://github.com/NVIDIA/Megatron-LM) という学習の枠組みを使用
- 8台のコンピュータで並列処理を実施
- 指示文と入力文には特別な処理を適用
- Adamという最適化手法を採用（細かい設定値：β1=0.9, β2=0.95）
- 学習の速さを1e-5から1e-6まで徐々に下げていく

これらの設定は、効率よく安定した学習ができるよう、慎重に選ばれたものです。

### 比較対象として選ばれたモデル

性能を比較するため、以下の代表的なLLMが選ばれました。

- 基本モデルのLLaMA-3-8B-Instruct
- より大規模なLLaMA-3-70B-Instruct
- 広く使われているGPT-3.5（2023年11月6日版）
- GPT-4o-mini（2024年7月18日版）
- GPT-4o（2024年5月13日版と8月6日版）

### 簡易評価での驚きの結果

まず、PersonaGym-Lightによる簡易評価が行われました。

PH-Instruct、LIMA、Alpacaのデータで訓練されたOpenCharacterは、基となったLLaMA-3-8B-Instructの性能を大きく上回り、さらにはGPT-3.5やGPT-4oのモデルをも超える結果を示しました。

評価結果は以下の通りです。

- キャラクターにふさわしい行動：4.70点
- 有害な発言を避ける能力：4.92点
- 一貫した言葉遣い：4.32点
- 人物設定との整合性：4.54点
- 行動の妥当性：4.85点

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_83633_8-1024x243.png)

PersonaGym-Lightでのモデル性能を比較。OpenCharacterがLLaMA-3 8B Instructを上回る性能を示し、GPT-4oとも競争可能な水準。

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_83633_9-1024x443.png)

PersonaGym-Lightにおけるアブレーション研究の結果を示す。データの種類やプロンプトモデルによる影響を分析。

### 本格的な評価でも高い性能

簡易評価で良い結果が得られた設定を使って、完全版のPersonaGymでも評価が行われました。

OpenCharacterは比較的小規模なモデルにもかかわらず、GPT-4oやGPT-4o-miniに迫る高い性能を達成しました。

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_83633_10-1024x373.png)

PersonaGymにおける各モデルの評価結果をまとめる。OpenCharacterがLLaMA-3 8B Instructを上回り、GPT-4oモデルとも競争可能な性能を発揮。

総合評価では、最新のGPT-4o（2024年8月6日版）が4.53点、OpenCharacterが4.52点とほぼ同等の結果となりました。小規模なモデルでここまでの性能を実現できたことは、研究チームが採用した手法の有効性を裏付けるものと言えます。

### 今後の展望

この研究から見えてきた重要な発見と、これから取り組むべき課題については以下の通りです。

#### キャラクターになりきる能力の習得

実験を通じて、多様なキャラクター設定と十分な量の会話例があれば、LLMは新しいキャラクターを演じる能力を身につけられることが分かりました。

しかし、単純に訓練データを増やせば性能が上がるわけではないという意外な発見もありました。たとえば、Persona Hubの質問は、LIMAやAlpacaと比べて複雑すぎたかもしれません。このような複雑な質問に対応するには、より高性能な基本モデルが必要になる可能性があります。

#### モデルの規模による影響

LLaMA-3-70B-Instructが最も優れた性能を示したことから、モデルの規模が重要な要素であることが明らかになりました。大規模なモデルは、より多くの情報を記憶し、より複雑な推論ができるため、キャラクターを演じる能力も自然と高くなると考えられます。

そのため研究チームが提案した手法は、比較的小規模なモデルでも高い性能を実現できる点で注目に値します。

#### ゲームやフィクションの世界での活用

現在の研究は主に現実世界のキャラクターを対象としていますが、ゲームやフィクションの世界でのロールプレイも重要な応用分野です。たとえばファンタジー世界の魔法使いを演じる場合、その世界の魔法の仕組みや歴史など、独自の設定に沿った対応が求められます。

研究チームが開発した返答の書き換え手法（OpenCharacter-R）は、このような特殊な設定での活用が期待できます。また、ゲームやフィクションの世界でのロールプレイを評価するための、新しい基準作りも必要とされています。

## まとめ

本記事では、言語モデルにカスタマイズ可能なキャラクター対話能力を付与する研究OpenCharacterを紹介しました。

研究チームはPersona Hubから得られるペルソナ情報をもとに詳細なキャラクター設定を生成し、それに基づく対話データを作成することで、新しいキャラクターへの適応を実現しました。8Bパラメータという比較的小規模なモデルでも、GPT-4oに匹敵する性能を達成できることが示されています。

研究チームは約2万種のキャラクター設定と30万件以上の対話データを公開しており、さらなる研究の発展が期待されます。

[https://huggingface.co/datasets/xywang1/OpenCharacter](https://huggingface.co/datasets/xywang1/OpenCharacter)

**参照文献情報**

- タイトル：OpenCharacter: Training Customizable Role-Playing LLMs with Large-Scale Synthetic Personas
- URL： [https://doi.org/10.48550/arXiv.2501.15427](https://doi.org/10.48550/arXiv.2501.15427)
- 著者：Xiaoyang Wang, Hongming Zhang, Tao Ge, Wenhao Yu, Dian Yu, Dong Yu
- 所属：Tencent AI Lab Seattle

## 理解度クイズ

理解度クイズ

1\. 記事で紹介されている「キャラクターを演じるLLM」の手法の狙いはどれでしょうか。

研究者らは、事前に決まったキャラクターのみではなく、ユーザーが指定した多様なキャラクターを演じられるLLMを目指しています。  
これにより利用者のニーズに合わせた柔軟なロールプレイングが可能になると述べられています。

解説を見る

2\. 記事にある「OpenCharacter」の方法で特に重視されている点は何でしょうか。

OpenCharacterは、詳細に作り込んだ人物設定をもとに多彩な会話データを合成して学習させる手法です。  
これによって従来より多様なキャラクターを演じる能力が期待できます。

解説を見る

3\. 記事で紹介されたキャラクター学習のアプローチには、一つの質問に対して複数のキャラクターの返答を学習させるという工夫があります。これはどのような効果を狙っているのでしょうか。

複数のキャラクターの返答を同時に学ぶことで、キャラクターごとの個性や口調の違いをモデルが把握しやすくなります。  
多様な回答パターンを学ぶことで、新しい設定への柔軟な対応も向上します。

解説を見る

4\. 「OpenCharacter-R」と「OpenCharacter-G」という2種類の会話データ作成手法が述べられていましたが、両者の主な違いは何でしょうか。

OpenCharacter-Rは、もともとある回答をキャラクター設定に合わせて言い換える方法です。  
OpenCharacter-Gは、キャラクター設定を参照しながらゼロから回答を生成します。

解説を見る

5\. 記事の結論によれば、キャラクター演じる能力を高めるために重要だと示唆されていた点は何でしょうか。

記事では、多彩なキャラクター設定と具体的な会話事例がモデルのロールプレイ能力向上に大きく貢献すると述べられています。  
単にデータを増やすだけでなく、キャラクターに沿った質の高いデータが必要とされています。

解説を見る

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[多様な業務データを統合してナレッジグラフを作成するLLM活用方法](https://ai-data-base.com/archives/86774)

[文書に含まれるテキスト・図・表をすべて詳しく調べるエージェント手法](https://ai-data-base.com/archives/87048)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)