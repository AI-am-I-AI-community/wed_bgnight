---
title: "100個の事例を分析して明らかになったLLM-RAGアプリケーション「19の欠陥パターン」"
source: "https://ai-data-base.com/archives/73120"
author:
  - "[[AIDB Research]]"
published: 2024-07-19
created: 2025-06-13
description: "本記事では、LLMとRAGのソフトウェア開発における課題の調査研究を紹介します。GitHub上の100のアプリケーションを分析し、19の欠陥パターンが特定されました。そして多くのアプリケーションが複数の問題を抱えています。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、LLMとRAGのソフトウェア開発における課題の調査研究を紹介します。

GitHub上の100のアプリケーションを分析し、19の欠陥パターンが特定されました。そして多くのアプリケーションが複数の問題を抱えています。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_73120-1024x576.jpg)

**参照論文情報**

- タイトル：Vortex under Ripplet: An Empirical Study of RAG-enabled Applications
- 著者：Yuchen Shao, Yuheng Huang, Jiawei Shen, Lei Ma, Ting Su, Chengcheng Wan
- 所属：East China Normal University, The University of Tokyo, University of Alberta

## 背景

過去6ヶ月間（論文発表は2024/7/6）で、GitHubには36,000以上のオープンソースLLM対応ソフトウェアが作成されました。

しかし、LLMとRAGを組み込んだソフトウェアには、まだ多くの課題が残されています。主に以下のようなものです。

1. インターフェース仕様の不足
2. LLMの生成するランダムな出力とソフトウェア要件の不一致
3. パフォーマンスを確保するためのシステムレベルの管理

今回研究者らは、課題解決の糸口を探るため、100のGitHubアプリケーション（2024年5月22日時点）を対象とした調査を行いました。そして3,000以上のissue（GitHub上の問題報告）が手動で調査され、19の欠陥パターンがまとめられました。

調査の結果、アプリケーションの98%が複数のタイプの欠陥を含んでいることが判明しました。欠陥は、予期しない動作停止・不正確なソフトウェア動作・実行速度の低下・ユーザーインターフェースの不便さ・トークンコストの増加・セキュリティの脆弱性など、様々な問題を引き起こしています。

また欠陥は、4つのカテゴリーに分類できることが明らかになりました。

1. プロンプトを構築しLLMの応答を生成するLLMエージェント
2. RAGをサポートするベクトルデータベース
3. LLMエージェントとベクトルデータベースとやり取りするソフトウェアコンポーネント
4. 実行を行うシステム

多くの欠陥は、簡単なコード修正で解決できるかもしれません。そこで本研究では、開発者が参考にできるガイドも提供されています。

## RAGアプリケーションにおける前提知識

### RAGとは

RAGは、LLMの能力を強化するために開発された技術です。外部の知識源から関連情報を提供することで、LLMが知識集約型のタスクを解決する役に立ります。LLMは、学習時に見たことのない最新の、信頼できる関連知識を簡単に活用できるようになります。微調整を必要とせずに、LLMを様々な応用シーンに拡張し、最新の知識に更新することを可能にします。

外部知識の保存先としては、MongoDB、ChromaDB、Faissなど、いくつかのベクトルデータベースが提案されています。

### RAGの仕組み

RAGには、以下二つの段階があります。

（１）保存段階

- ソースファイルからテキストが抽出される
- テキストは複数のチャンク（知識エントリ）に分割される
- LLMの埋め込みモジュールを使用して、各知識エントリが意味ベクトルに変換される
- これらの意味ベクトルは、ベクトルデータベースに保存される際の知識エントリのインデックスとして機能する

（２）クエリ段階

- 同じ埋め込みモジュールを使用してクエリ質問を意味ベクトルに変換する
- 意味ベクトル間の距離に基づいて、関連する知識エントリが検索される
- 検索された知識がLLMのコンテキストを構築し、元の知識集約型タスクを理解タスクに単純化する

### 対応ソフトウェアの発展

開発のためにLangChain、LlamaIndexなどのフレームワークが登場しました。開発者が様々なLLMとベクトルデータベースをシステムに統合するためのインターフェースを提供するものです。

その結果、LLM対応ソフトウェアが急増し、GitHub上に大量のLLM対応ソフトウェアアプリケーションが作成されました。

### LLMソフトのワークフロー

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_73120_1-1024x431.jpg)

LLM対応ソフトウェアのワークフロー図

LLMに対応するソフトウェアのワークフローは一般的に以下の通りです。

（１）準備段階

デプロイ前に、様々なファイルから慎重に抽出されたテキストでベクトルデータベースが初期化されます。

（２）実行段階

- ソフトウェアコンポーネントがユーザー入力を収集し、変換する
- キーフレーズが抽出され、クエリ質問を構築する
- ベクトルデータベースから関連知識を検索する
- LLMエージェントが検索された知識と元のユーザー入力を使用してプロンプトを構築する
- 実行履歴が管理され、LLMのコンテキストが維持される
- ソフトウェアコンポーネントがLLMの応答を処理し、ユーザーに回答する

場合によっては、ソフトウェアコンポーネントがデータ処理、ユーザーインタラクション、その他の機能を支援するためにサードパーティのライブラリを呼び出すこともあります。

### 具体例：キャラクターシミュレーションアプリケーション

例として、音声会話をサポートするキャラクターシミュレーションアプリケーションを挙げます。以下のような特徴をもつものです。

- キャラクター設定を格納するためにベクトルデータベースが利用される
- 音声とテキストの変換にサードパーティのライブラリが使用される
- ユーザーがキャラクターについて質問すると、アプリケーションはベクトルデータベースから関連情報を取得してプロンプトを構築する
- ベクトルデータベースに十分なキャラクター設定情報が保存されている限り、LLMエージェントは任意のキャラクターとして振る舞い、質問に正確に答えることができる

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_73120_2-1024x318.jpg)

RealCharというキャラクターシミュレーションアプリケーションの概要図

## 本研究がいかに進められたか

### アプリケーションの選定

研究対象として、GitHub上の100個のオープンソースLLM対応ソフトウェアアプリケーションが収集されました。全て2024年5月22日時点での最新バージョンです。GitHubには多くの試験的なアプリケーションが存在するため、約500個のランダムに選択されたオープンソースアプリケーションが手動で確認され、その中から100個が選ばれました。

**選定基準**

1. 具体的な実世界の問題を対象としていること
2. LLMとベクトルデータベースがワークフローに密接に統合されていること（単なるUIラッパーではない）
3. アクティブなユーザーコミュニティを維持していること

**アプリケーションの特徴**

選定されたアプリケーションは以下の特徴を持っています。

プログラミング言語

- Python（71%）
- TypeScript（24%）
- その他（5%）

使用フレームワーク

- LangChain（90%以上）
- その他（独自フレームワークなど）

使用LLM

- OpenAIサービス（85%）
- LLaMA（10%）
- ChatGLM（残り）

使用ベクトルデータベース

- ChromaDB（45%）
- MongoDB（29%）
- Faiss（19%）
- その他（7%）

アプリケーションが開発されてからの期間

40%が調査時点で12ヶ月以内に作成

人気度

半数以上が135以上のスター数を獲得（最大163,000）

開発活動

過去6ヶ月間で平均500回（中央値374回）のコミット

### アプリケーションの分類

選定されたアプリケーションは、以下の5カテゴリに分類されました。

質問応答（QA）（39%）

タスク管理（23%）

チャットボット（19%）

プラットフォーム（13%）（複数のタスクをスケジューリングするもの）

その他のテキスト関連タスク（6%）（事実確認など）

### 欠陥パターンの特定プロセス

（１）問題報告の収集

- 対象アプリケーションの約10,000件のGitHub問題報告（issue）が調査された
- そのうち3,000以上のバグ関連報告が抽出された

（２）欠陥の確認

- 各報告がソフトウェアの欠陥によるものか、エンドユーザーの誤用によるものかが手動で確認された
- 閉じられた問題は開発者のパッチで確認された
- 開いている問題はテストによる再現で確認された

（３）欠陥のクラスタリング

- 確認された320件のバグ関連問題が、原因に基づいてクラスタリングされた
- 各クラスターについて、他のアプリケーションにも類似の欠陥がないか手動で検証され、クラスタリングが洗練された
- このプロセスは、論文の結果に収束するまで数回繰り返された

（４）結果

- 19の欠陥パターンと495の欠陥が特定された
- 全ての問題と欠陥は3人の著者によって検証され、共著者全員で議論・確認された

### パフォーマンス分析手法

欠陥がソフトウェアのパフォーマンスにどのように影響するかを以下の手順で分析が行われました

1. アプリケーションのエンドツーエンドレイテンシが、欠陥修正前後で測定
2. アプリケーションのマニュアルや問題報告を参考に、実世界のデータ（テキスト/音声クエリ、様々な形式のファイルなど）が使用された
3. デフォルトでは、各テストが10回実行され、平均レイテンシが報告された

**実験環境**

- CPU：16コアApple M3 Max（4.05GHz）
- L2キャッシュ：32MB
- RAM：64 [GB](https://ai-data-base.com/archives/26343 "勾配ブースティング")
- SSD：2TB
- ネットワーク接続：1000Mbps

なお、ほとんどのアプリケーションはクラウドサービスを通じてLLMタスクを実行していました。

## 19の欠陥パターン

研究を通じて、100のLLM対応アプリケーションから495の欠陥が特定され、19の欠陥パターンにまとめられました。欠陥は、ソフトウェアの品質に様々な面で悪影響を及ぼしていました。

（１）機能性の問題

- 予期しない動作停止
- 不正確なソフトウェア動作
- 使いにくいユーザーインターフェース

（２）効率性の問題

- 実行速度の低下
- トークンコストの増加

（３）セキュリティの問題

### 欠陥の分布

研究の結果、欠陥は広範囲に及んでおり、調査対象のアプリケーションの98%が複数の種類の欠陥を含んでいました。LLM対応ソフトウェアは4つのカテゴリに分けられ、それぞれ全てに欠陥がありました。

1. LLMエージェント  
	プロンプトを構築し、LLMの応答を生成する
2. ベクトルデータベース  
	RAGアルゴリズムをサポートし、LLMエージェントを強化する
3. ソフトウェアコンポーネント  
	上記2つのコンポーネントと相互作用して特定のタスクを実行する残りのソフトウェア部分
4. システム  
	リソースと権限を管理して実行する

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_73120_3-1024x515.png)

LLM対応ソフトウェアで特定された欠陥のリストと影響、発生割合

LLM-RAGアプリケーションの「欠陥パターン」19点を一覧で列挙すると以下の通りです。

1. 指示（プロンプト）が曖昧　23%
2. LLMの応答に対する制限の不足　25%
3. 会話履歴を適切に記録しない　29%
4. ユーザー入力のチェック不足　23%
5. LLMの出力形式が次の処理と合わない　13%
6. 必要以上の情報をLLMが出力してしまう　23%
7. LLMの処理できるトークン数を超える　31%
8. 複数のエージェントが管理できない　14%
9. ベクトルDBにおけるデータ不足　28%
10. 埋め込みが不適切　34%
11. データの重複または矛盾　20%
12. 関連データを適切に検索できない　19%
13. 会話の最終的なまとめが足りない　該当する24アプリケーションのうち21個で発生
14. エラー検出ができていない　10%
15. サーバー接続が切れがち　該当する29のアプリケーションのうち26個で発生
16. プライバシーが漏洩　該当する19アプリケーションのうち11個で発生
17. メモリ管理が非効率　9%
18. 計算リソースが足りない　該当する13アプリケーションのうち2個で発生
19. LLMと別モジュールの処理速度が合わない　該当する13アプリケーションのうち2個で発生

### LLMエージェントに関する欠陥

#### 不明確な指示による誤った回答

LLMを使ったアプリケーションでは、LLMに与える指示（プロンプト）が不明確だと、誤った情報を生成してしまう問題があります。この現象は「幻覚」または「ハルシネーション」と呼ばれ、LLMの重要な課題の一つです。

この問題はなぜ起こるのか？LLMは、文法的に正しく、文脈に合った文章を生成するのが得意です。しかし、与えられた情報が不十分な場合、事実に基づかない内容を作り出してしまいます。そのため存在しない引用や間違った歴史的事実、偽の科学的情報などが生成される可能性があります。

LLMの誤った回答は、アプリケーション全体の信頼性を低下させる可能性があります。

**調査の結果、今回調査対象のアプリの約25%がこの問題を抱えていました。**

具体例としてSlackのチャットボット「ChatIQ」では、内陸都市が海産物を生産しているなど、事実と異なる回答をすることがありました。

解決策は以下の通りです。

1. より詳細で明確なプロンプトを設計する
2. RAG技術を使用して、外部の正確な情報源を活用する
3. プロンプトに「与えられた情報に基づいて正確に答えてください」などの明確な指示を含める

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_73120_4-1024x223.png)

h2oGPTで期待されるLLMエージェントの出力フォーマット例

### ベクトルデータベースに関連する欠陥

LLM対応アプリケーションにおいて、ベクトルデータベースはモデルの長期記憶として機能する重要なパーツです。ベクトルデータベースの不適切な使用は、ソフトウェアの誤動作を引き起こし、サービス品質とユーザー体験を損なう可能性があります。

**調査対象アプリケーションの約35%でベクトルデータベースの正しい使用がなされていないことが判明しました。**

#### 1\. 知識の不整合

ベクトルデータベースは知識エントリを保存・管理します。これらのエントリを作成するプロセスは以下の通りです。

1. 様々な形式の文書からテキストが抽出される
2. テキストは複数のチャンクに分割され、各チャンクは一貫した知識単位を含む
3. 各チャンクはトークン化され、意味ベクトルに埋め込まれる
4. 元のテキストチャンクと意味ベクトルが組み合わさって知識エントリを形成する

上記のチャンク分割とトークン化が正確かつ堅牢に行われない場合、LLM対応ソフトウェアアプリケーションは誤動作したり、非効率なメモリ管理によってメモリオーバーフローに悩まされたりする可能性があります。 **調査対象アプリケーションの約28%で知識の不整合問題が見られました。**

例えば、AutoGPTは大小様々なファイルの処理に失敗することがあります。大きなJSONファイルからデータチャンクをトークン化する際に、チャンクサイズが大きすぎるためにメモリ不足エラーが発生します。一方で、150文字未満の小さなファイルはデータが含まれていないと誤って判断され、無視されてしまいます。

この問題に対処したい場合は、キーワード抽出、 [TF-IDF](https://ai-data-base.com/archives/26539 "TF-IDF") 、クラスタリングなどの軽量なアプロー チを利用して知識単位の一貫性を測定し、必要に応じてより細かい粒度でデータチャンク化を適用することが推奨されます。

#### 2\. 知識エントリが重複する

ベクトルデータベースでは、意味ベクトルが知識エントリの識別子とインデックスの両方の役割を果たします。リレーショナルデータベースと同様に、開発者はソフトウェアの正確性と信頼性を確保するためにこれらの識別子を慎重に設計する必要があります。

また、異なるテキストデータを同じ特徴ベクトルに埋め込むと、深刻な正確性の問題が生じる可能性があります。以前のデータが上書きされ、データ損失が発生する可能性があるためです。 **調査対象アプリケーションの20%にこのような欠陥が含まれていることが分かりました。**

#### 3\. 不適切なテキスト埋め込み

知識エントリは、ベクトルデータベースに保存される際に意味ベクトルによってインデックス付けされます。正確な検索は、正確な埋め込みに大きく依存します。つまり、類似した知識トピックを含むエントリは類似した意味ベクトルを持つべきであり、その逆も同様です。

一般に、開発者は3つの異なるレベルでテキストの特性に対処する必要があります。

1. エンコーディング形式（エンコーディングと自然言語）
2. 表面レベルのパターン（文体や構造）
3. 深層レベルのパターン（意味やトピック）

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_73120_5-1024x205.png)

Anything-LLMにおける不適切なテキスト埋め込みの修正例

**調査対象アプリケーションの約34%で、テキスト埋め込みの不適切な管理が見られました。**

#### 4\. 不適切な類似性検索

LLMを使ったアプリでは、必要な情報を正確に探し出すことが重要です。このプロセスで問題が起きると、アプリ全体の性能に影響を与えます。主な問題点として、曖昧な検索と過剰な情報取得があります。

曖昧な検索の例として、タスク管理アプリ「babyAGI」があります。例えば「送別会の準備」という漠然とした指示では適切な情報が見つからず、LLMが不適切または的外れな回答をする可能性があります。

一方、過剰な情報取得の問題では、関連情報と共に不要な情報まで取得してしまい、LLMが混乱して誤った回答を生成する可能性があります。

**この問題は、調査対象アプリの約19%で見られました。** 解決策としては、検索キーワードをより具体的にすること、取得した情報の関連性をチェックすること、そして検索アルゴリズム自体を改善することが挙げられます。例えば、「送別会の準備」を「送別会の招待状作成」「送別会の会場予約」などに細分化したり、LLMに情報を渡す前に不要なデータを除外する仕組みを作ったりすることが効果的です。

このように開発者は、単にLLMを組み込むだけでなく、適切な情報提供の仕組みづくりにも注力する必要があります。

### ソフトウェアに関連する欠陥

LLMを取り巻くソフトウェアコンポーネントも、システム全体のパフォーマンスに大きな影響を与えます。以下が例です。

- データ/制御フローロジック
- UIコンポーネント
- 異なるモジュール間の調整

例えば、UIコンポーネントの欠陥は応答しないボタンを引き起こす可能性があり、データフローの欠陥はデータの損失や破壊を引き起こす可能性があります。

以下はLLMやベクトルデータベースと相互作用する部分に起因する欠陥のパターンです。

#### 1\. 最終出力の欠如

LLMを使ったチャットアプリは、ユーザーと複数回のやりとりを行いながら会話を進められる便利な機能を持っています。しかし、多くのアプリには重要な問題点があります。それは、会話の最後に全体のまとめが提供されないことです。

ユーザーが求めているのは、会話全体の結論や要約です。しかし、多くのアプリはただ最後の回答で終わってしまいます。これが原因でユーザーは会話全体の要点を把握しにくくなる問題が生じています。さらに、途中で会話が終わったように見え、アプリが突然終了したと勘違いされる可能性もあります。

この問題は非常に広範囲に見られます。 **調査した24個のマルチターン会話アプリのうち、22個でこの問題が確認されました。** つまり、ほとんどのアプリがこの課題を抱えているのです。

解決策としては、開発者は会話の「終了時」に特別な処理を加えるべきです。例えばこれまでの会話の内容をまとめて、最終的な結論や要約を提供する機能を追加するのは一つのアイデアです。

#### 2\. 不適切なエラー処理

LLMを使ったアプリケーションでは、エラー処理が特段難しい課題となっています。言語モデルは柔軟なデータ形式を扱う一方で、従来のソフトウェア部分は厳密な形式を要求するためです。このギャップにより、予期せぬエラーが発生しやすくなります。多くのアプリが対策を実装していますが、完璧ではありません。 **調査の結果、約10%のアプリで深刻な動作停止が確認されました。**

#### 3\. 低頻度の相互作用

LLMやデータベースがクラウド上にある場合、長時間操作がないとサーバーとの接続が切れてしまう問題があります。するとアプリが突然終了したり、会話の履歴が失われたりする可能性があります。LLMは過去の会話内容を記憶する必要があるため、接続が切れると会話の文脈が失われ、ユーザー体験が大きく損なわれます。この問題は非常にありふれており、 **調査したアプリの約90%で観察されました** 。開発者は、定期的に信号を送るなどの対策を講じる必要があります。

#### 4\. プライバシー侵害

LLMを使ったアプリでは、プライバシー保護が大きな課題となっています。従来のソフトウェアでは、オペレーティングシステムがユーザーの認証を行いますが、LLMアプリではLLM自体が高い権限を持ってデータにアクセスします。しかし、LLMには厳密な認証機能がありません。そのため、異なるユーザーのデータが適切に分離されていないと、許可されていないデータにアクセスしてしまう可能性があります。 **調査した19個のアプリのうち11個でこの問題が確認されました。** 開発者は、LLMのアクセス権限を適切に制限し、ユーザーデータの厳格な分離を実装する必要があります。

### システムに関連する欠陥

LLMを使ったアプリは、通常のアプリよりも多くのコンピューターリソースを必要とします。そのため、システムの管理が特に重要になります。

#### 1\. リソースの競合

アプリが必要とするリソース（メモリやCPUパワーなど）が、システムが提供できる量を超えてしまう状況を指します。特に、ユーザーの個人用コンピューターのような、リソースが限られた環境で起こりやすい問題です。

リソースの競合が起こると、アプリの動作が遅くなったり、最悪の場合はフリーズしてしまったりします。例えば、PrivateGPTというアプリでは、ユーザーが同時に処理できるデータの量を設定できますが、この設定が高すぎると、システムのリソースが不足して動作が遅くなる可能性があります。

この問題を解決するために、開発者は例えば、アプリが使用するリソースの量を制限したり、リソースが不足した場合にサービスの一部を一時的に停止したりする機能を実装することが考えられます。また、同時に利用できるユーザー数を制限するのも一つの方法です。

調査の結果、 **LLMを直接コンピューター上で動かす11のアプリのうち2つでこの問題が見られました。** これは少ない数字に見えるかもしれませんが、LLMを直接動かすアプリが増えれば、この問題も増加する可能性があります。

#### 2\. 非効率的なメモリ管理

LLMとそれに関連するデータベースは、大量のメモリを必要とします。メモリを適切に管理できないと、アプリの動作が遅くなったり、最悪の場合はクラッシュしたりする可能性があります。

**調査したアプリの約9%でこの問題が見つかりました。** 例えば、ChatGLM-Webというアプリでは、複数のLLMを切り替えて使用する際にメモリ不足のエラーが発生しました。これは、使い終わったLLMのデータがメモリに残ったままになっているためです。

この問題を解決するには、使い終わったデータをきちんとメモリから削除する仕組みが必要です。クラウドサービスを使う場合でも、データの処理や転送にはやはり多くのメモリが必要なので、注意が必要です。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_73120_6-1024x239.png)

ChatGLM-Webにおける非効率的なメモリ管理の修正例

#### 3\. 処理速度の不一致

LLMは大量のデータを連続して処理できますが、そのデータを受け取る側（下流タスク）の処理速度とうまく合わないことがあり、様々な問題を引き起こす可能性があります。

- LLMの方が速すぎると、処理待ちのデータが大量に溜まってしまう
- 逆に、下流タスクの方が速すぎると、データの入出力が滞ったり、最悪の場合はアプリが動作を停止したりする可能性がある

この問題は、時間に敏感な処理を行う13のアプリのうち2つで見つかりました。

例えば、langchain-chatbotというアプリでは、LLMの処理が下流タスクより常に速いと仮定していますが、ネットワークの遅延などでLLMの処理が遅くなると、アプリがクラッシュする可能性があります。

また、FastGPTというアプリでは、データの処理方法の問題でLLMの処理が終わるまで他の処理が待たされ、全体的な性能が低下してしまいます。

問題を解決するには、LLMと下流タスクの間でデータの流れを慎重に管理する必要があります。データを一時的に保存したり、非同期で処理したりする技術を使うことが有効です。また、システムの各部分の処理速度を常に監視し、必要に応じて調整できる仕組みも重要です。

## 研究の妥当性に関する注意点

本研究の結果を解釈する際には、いくつか考慮する点があります。

### テストデータの代表性

今回の分析に使用されたテスト入力が、実際のエンドユーザーのユースケースと一致していない可能性もあります。すると以下のような問題が発生します。

- 実際のユースケースで発生する可能性のある問題が見逃される
- 特定の欠陥パターンの重要性が過大評価または過小評価される
- パフォーマンス測定が実世界のシナリオを正確に反映しない

### 問題報告の網羅性

研究で収集され確認された問題が、ソフトウェアに存在するすべての欠陥を代表していない可能性があります。すると、以下のような問題が発生します。

- 一部の欠陥パターンが見落とされる
- 特定の欠陥の頻度が正確に推定されない
- 重要だが報告されていない問題が分析から除外される

### 対象LLMの限定

この研究では、一般的な言語およびコードタスク用に設計されたLLMのみが調査されました。以下のタイプのLLMは除外されています。

- マルチモーダルLLM
- 特定のタスク用に微調整されたLLM

すると特定のタイプのLLMに固有の問題が見逃される可能性があります。

### ベクトルデータベースとフレームワークの範囲

調査対象のベクトルデータベースとフレームワークは限られています。すると以下の問題が生じる可能性があります。

- 特定のデータベースやフレームワークに固有の問題が見落とされる
- 結果の一般化可能性が制限される

### オープンソースプロジェクトの限界

GitHubのオープンソースプロジェクトのみが調査対象とされました。そのため、

- 非公開の商用プロジェクトにアクセスできない
- 企業環境で発生する可能性のある固有の問題が捉えられない

といった問題が生じます。

### サンプル数の制限

103のアプリケーションという限られたサンプルサイズが使用されました。そのため、

- 結果が全てのLLM対応アプリケーションを代表していない可能性がある
- まれな欠陥パターンが検出されない可能性がある
- 特定の欠陥の頻度推定の精度が低下する

上記の問題が発生する可能性があります。

## まとめ

本記事では、LLMとRAG技術のソフトウェアにおける問題の研究を紹介しました。100のアプリケーションの分析から、19の欠陥パターンが特定され、4つの主要コンポーネントに分類されました。

調査の結果、98%のアプリケーションが複数の欠陥を含み、機能性、効率性、セキュリティに影響を与えていることが判明しました。

研究者らは、開発者がこの調査報告をアプリケーション開発の参考にできると考えられています。

- 参照論文URL： [https://arxiv.org/abs/2407.05138](https://arxiv.org/abs/2407.05138)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[エージェントなしで行うLLMによるソフトウェアのバグ修正手法](https://ai-data-base.com/archives/73060)

[LLMで心理評価をゲーミフィケーションする方法](https://ai-data-base.com/archives/73161)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)