---
title: "LLMが思考のネットワークを構築し、人間の推論プロセスを模倣する『THOUGHTSCULPT』プロンプティング"
source: "https://ai-data-base.com/archives/67755"
author:
  - "[[AIDB Research]]"
published: 2024-04-17
created: 2025-06-13
description: "UCバークレーの研究者たちは、LLMがより効果的に情報を処理し、最適な解決策を導き出すための手法を考案しました。問題解決の過程で中間修正や検索を行いながら解に辿り着くといった方法論です。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

UCバークレーの研究者たちは、LLMがより効果的に情報を処理し、最適な解決策を導き出すための手法を考案しました。

問題解決の過程で中間修正や検索を行いながら解に辿り着くといった方法論です。

実験では、物語のアウトラインの改善、ミニクロスワードの解決、そして制約された生成という3つの難しいタスクで有効性が検証されました。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_67755-1024x576.jpg)

**参照論文情報**

- タイトル：THOUGHTSCULPT: Reasoning with Intermediate Revision and Search
- 著者：Yizhou Chi, Kevin Yang, Dan Klein
- 所属：UC Berkeley

**本記事の関連研究** ：

- [LLMにタスクに応じた推論プロセスを自ら考えるようにするプロンプト手法『SELF-DISCOVER』Google DeepMindなどが開発](https://ai-data-base.com/archives/64136)
- [LLMに敢えて間違わせてルールを覚えさせるプロンプト手法　Google DeepMindなどが考案](https://ai-data-base.com/archives/64057)
- [LLMに非線形的な思考を与えてCoTを上回る性能を引き出す手法『IEP』と実行プロンプト　CoTと組合せでさらに強力になる場合も](https://ai-data-base.com/archives/57628)
- [LLMにまず前提から尋ることで出力精度を向上させる『ステップバック・プロンプティング』と実行プロンプト](https://ai-data-base.com/archives/56671)

## 背景

LLMの性能は高いものの、同じタスクに対しても、プロンプトの与え方や指示の内容によって結果が大きく変わることが分かっています。代表的なものとして、Chain-of-Thought（CoT）や、Self-consistencyといった、LLMの推論能力を引き出すためのプロンプティング手法があります。  
CoTなどは、LLMに中間的な推論の過程を出力させることで、最終的な出力の質を向上させる手法です。しかし原理的に、初期段階で生成された回答に大きく精度が依存するという問題があります。つまり、途中で解決アプローチの根本的な修正や編集を行うわけではないのです。

そこで、Tree-of-Thoughts（ToT）やGraph-of-Thoughts（GoT）といった、LLMの推論過程をツリーやグラフ構造で表現する手法も提案されてました。異なる思考の経路を探索し、バックトラッキングやグラフ探索アルゴリズムを用いて、より良い出力を見つけるものです。  
しかし、ToTやGoTでも、中間段階での修正や編集は相変わらず難しいと考えられています。そのため、頻繁な修正や変更が必要な問題に対しては、新たな効果的な手法が求められています。

そこで今回研究者らは、THOUGHTSCULPTと呼ばれる新しいグラフベースの推論フレームワークを提案しました。LLMが思考のネットワークを構築し、人間の推論プロセスを模倣することを目指したものです。  
THOUGHTSCULPTの特徴は、”自己修正機構”です。思考 [ノード](https://ai-data-base.com/archives/26470 "ノード") を生成しながら、以前の出力を繰り返し修正し、改善します。  
思考の評価、思考の生成、意思決定の3つのコアモジュールが連携することで、LLMの推論能力を引き出す手法と述べられています。

以下で詳細を説明します。

## 方法論

THOUGHTSCULPTの基本的な考え方として、LLMの出力を「思考ノード」と呼ばれる単位で扱います。最初の出力を根ノードとし、そこから枝分かれしていく思考の流れを表現します。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_67755_1.png)

THOUGHTSCULPTのモンテカルロ木探索を用いた図解。選択、拡張、シミュレーション、バックプロパゲーションの各フェーズを示している。

思考ノードを処理し、より良い出力を探索するために、THOUGHTSCULPTは3つの主要なモジュールを扱います。思考評価器、思考生成器、意思決定シミュレーターです。

### 思考評価器

各思考ノードの状態を評価し、改善のためのフィードバックを提供します。フィードバックは、探索アルゴリズムのヒューリスティック※として機能するだけでなく、新しい候補を生成するための方向性や指針も与えてくれます。

（※ヒューリスティックとは、問題解決のための経験則や発見的手法のこと。最適解を保証しないが、実用的な解を効率的に見つけるために用いられる。）

なおフィードバックには、数値的なフィードバックとテキストによるフィードバックの2種類があります。数値的なフィードバックは、現在のノードの評価スコアとして使用され、テキストによるフィードバックは、子ノードを生成するためのコンテキストとして使用されます。

研究者らは、2つのテキストフィードバック戦略を提案しています。1つは全体的な評価で、ノード全体を分析し、包括的なフィードバックを提供します。もう1つは項目化された評価で、ノード内の各サブユニットを個別に評価し、各コンポーネントに合わせたフィードバックを提供します。

（概念を言葉だけで説明されても分かりづらいかもしれませんので、前後の図と後ほどのプロンプトテンプレートもご参照ください）

### 思考生成器

思考生成器は、現在のノードの評価フィードバックをもとに、新しい思考ノードを生成します。

タスクの説明、現在の解、思考評価器が提供するテキストフィードバックを用いて、事前学習済みのLLMが新しい候補を生成します。

### 意思決定シミュレーター

より深い層での意思決定をシミュレートし、現在の決定のスコアを更新します。つまり、現在のノードにおける報酬をより正確に見積もるためのロールアウト※を行うものです。

（※ロールアウトとは、ゲーム木探索において、ある局面から終局までをランダムに進めることで、その局面の評価値を見積もる方法）

なお意思決定シミュレーターの動作は、モンテカルロ木探索（MCTS）のプロセスに似ています選択、拡張、シミュレーション、バックプロパゲーションの4つのフェーズに分かれています。複雑な探索空間を効率的に探索できるため、計算上の利点があるとしています。

## プロンプト例

以下に、論文内容をもとにデモンストレーションを日本語で具体化します。なお、「面白いストーリーを作る」というタスクを例にとっています。

（１）タスク説明

```js
# タスクの説明
あなたは人気のある小説家です。読者を引き付ける興味深いストーリーのアウトラインを作成しています。
魅力的なキャラクターや予想外の展開を導入することで、読者を引き込む方法を知っています。
また、ストーリーのアウトラインを一貫性のあるものにする方法も知っています。
```

（２）新しい候補

```js
タスクの説明:
{outline}

# フィードバック
{feedback}

フィードバックとタスクの説明に基づいて、フィードバックで提案された項目を置き換えることで、
より良いストーリーのアウトラインを作成できますか?

以下の形式で、[1]から[{num}]までのアウトラインを書いてください:
[1] ...
[2] ...
...

# あなたの回答:
```

（３）現在の評価

```js
タスクの説明:
{outline}

このアウトラインは十分に良いと思いますか?
タスクの説明に基づいて、1から100までのスコアを付けてください。
100は、アウトラインが完璧であることを意味します。
また、長所と短所について説明を提供してください。具体的にお願いします。

# 以下の形式で書いてください:
[スコア: 1 - 100] [理由] xxx (50語以内)

# 例:
[スコア: 50] [理由] 現在のアウトラインは予測可能すぎる

# あなたの回答:
```

## 実験と結果

研究者らは、THOUGHTSCULPTの性能を評価するために、3つの異なるタスクを用いて実験を行いました。ストーリーアウトラインの改善、ミニクロスワードパズルの解決、制約付き文生成です。

実験では、Chain-of-Thought（CoT）、Self-Refine（※）、Tree-of-Thoughts（ToT）with DFSを比較対象として用いました。

DFSとはDepth-First Searchの略です。今回はTHOUGHTSCULPTの有効性を検証するために、探索アルゴリズムとしてMCTSの代わりにDFSを用いた場合の性能も調べました。

なお、実験の全体を通してGPT-3.5とGPT-4をベースラインとしました。

（※Self-Refineは、言語モデルが自身の出力に対してフィードバックを生成し、そのフィードバックに基づいて出力を改善する手法です。）

### 実験1：ストーリーアウトラインの改善

LLMが生成したアウトラインの面白さを向上させるタスクです。研究者らは、 [WhatsThatBookデータセット](https://github.com/kl2806/whatsthatbook) から500件の書籍の説明文を [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") し、GPT-3.5を用いてアウトラインを生成しました。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_67755_2-1024x877.jpg)

ストーリーアウトラインの改善タスクを示す図。各ステップでは、思考評価器を用いてストーリーアウトラインを項目ごとに評価し、思考生成器を用いて改善されたストーリーアウトラインの候補セットを生成します。

生成されたアウトラインの面白さを評価するために、Flan-T5モデルを微調整して、アウトラインコンテンツ評価器を作成しました。面白いアウトラインを1、つまらないアウトラインを0と評価するように学習されています。

実験の結果、THOUGHTSCULPTは、GPT-3.5とGPT-4のどちらを基礎LLMとして使用した場合でも、他の手法よりも高いアウトラインの面白さスコアを達成しました。特に、MCTSを用いたTHOUGHTSCULPTは、最も高い平均面白さ割合を示しています。

下の表を見るとわかる通り、数値の差がかなり大きいです。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_67755_3.png)

ストーリーアウトラインの平均面白さ。THOUGHTSCULPTの出力は、他の手法と比較して面白いと判断される割合が高い。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_67755_4.png)

各ステップにおけるストーリーアウトラインの平均面白さ。THOUGHTSCULPTの面白さは、他の手法と比較して、ステップを重ねるごとに向上している。

### 実験2：ミニクロスワードパズルの解決

次に、5×5のクロスワードパズルを解くタスクです。研究者らは、各思考ノードをクロスワードパズルの部分的な解として表現し、LMにヒントに対する入力された文字の評価を促しました。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_67755_5-1024x350.png)

ニクロスワードタスクの思考プロセスの図解。現在のクロスワードボードを評価し、候補単語のセットを提案している。

実験の結果、MCTSを用いたTHOUGHTSCULPTは、GPT-3.5を基礎LLMとした場合には、最高の文字 [正解率](https://ai-data-base.com/archives/25930 "正解率") を、GPT-4を基礎LLMとした場合には最高の単語正解率とゲーム正解率を達成しました。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_67755_6-1024x224.png)

ミニクロスワードの結果（文字、単語、ゲームの正解率）。THOUGHTSCULPTは、全般的に最高の性能を示すか、最高の性能に匹敵する。

興味深いことに、探索ステップ数を制限した状況では、GPT-4を使用したToTがSelf-refineよりも低い性能を示しました。自己修正メカニズムがこのタスクにおいて重要であることを示唆しています。

### 実験3：制約付き文生成

制約付き文生成タスクでは、 [CommonGen-Hard](https://arxiv.org/abs/1911.03705) と呼ばれるデータセットを用いて、モデルが20〜30個の概念を含む文を生成する能力が評価されました。

実験の結果、THOUGHTSCULPTは、GPT-3.5とGPT-4のどちらを基礎LLMとした場合でも、他の手法を上回る性能を示しました。DFSを用いたTHOUGHTSCULPTは最高の概念網羅率を達成しましたが、MCTSを用いたTHOUGHTSCULPTも同等の性能を示しています。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_67755_7.png)

制約付き文生成の結果（概念の網羅率）。THOUGHTSCULPTは、両方の基礎LLMにおいて、他の手法を上回る性能を示している。

さらに、GPT-4を用いて概念網羅率と適切性の両方に基づいて包括的な評価を行ったところ、MCTSを用いたTHOUGHTSCULPTの出力が大幅に評価されることが明らかになりました。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_67755_8-1024x371.png)

制約付き文生成の最終出力に対するGPT-4の包括的な選好度。MCTSを用いたTHOUGHTSCULPTの出力が大幅に評価されている。

## まとめ

本記事では、LLMの推論能力と問題解決能力を向上させるフレームワーク「THOUGHTSCULPT」に関する研究を紹介しました。

THOUGHTSCULPTは、MCTSアルゴリズムを用いて効率的な探索を行い、自己修正プロセスにより出力の反復的な改善を可能にするものです。THOUGHTSCULPTの有効性は多様なタスクを通じて実証されました。

なお実験の透明性と再現性を確保するため、下記のページに公開データセットとオープンソースモデルが掲載され、コードベースも公開される予定です。

- URL： [https://arxiv.org/abs/2404.05966](https://arxiv.org/abs/2404.05966)
- GitHub： [https://github.com/cyzus/thoughtsculpt](https://github.com/cyzus/thoughtsculpt)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[ChatGPTは学術論文の文章スタイルをどう変えているか？大規模な調査の結果](https://ai-data-base.com/archives/67681)

[Appleが開発　スマホに特化したマルチモーダルLLM『Ferret UI』](https://ai-data-base.com/archives/67840)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)