---
title: "自然言語タスクをコードタスクに変換してLLMに高度な推論を実行させる"
source: "https://ai-data-base.com/archives/83997"
author:
  - "[[AIDB Research]]"
published: 2025-03-03
created: 2025-06-13
description: "LLMが複雑な推論や問題解決にも使えると期待される一方で、自然言語には曖昧さやノイズが多く、正確に評価するのが難しいとされています。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

LLMが複雑な推論や問題解決にも使えると期待される一方で、自然言語には曖昧さやノイズが多く、正確に評価するのが難しいとされています。  
そこで今回オックスフォード大学などの研究者らは、同じ課題をコードとして提示し、手順を一つずつ正しく実行できるかどうかを大規模に検証する方法を考案しました。

本記事の内容は、今後LLMに仕事をさせるときのヒントになるかもしれません。もしLLMが自然言語の課題をコードに変えた形でうまく処理できるなら、一般的なタスクであってもコード化した上で与えるといった選択肢が生まれるためです。

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_83997-1024x576.png)

**発表者情報**

- 研究者：Emanuele La Malfaほか
- 研究機関：オックスフォード大学, サレルノ大学, チューリッヒ工科大学, リーズ大学

論文情報詳細は記事の下部に記載されています。

## 背景

LLMの進化はめざましく、単純なテキスト生成の枠を超えて、より高度な思考プロセスの実現が期待されています。そのため、研究者たちの関心は、LLMがどこまで複雑な推論や問題解決を達成できるのかという点に向けられています。

一般に、多くの推論タスクや計画立案の課題には、明確な手順やアルゴリズムが存在します。しかしながら、そうした課題を自然言語で表現しようとすると、細部まで丁寧に作り込む必要が生じ、多大な労力を要します。

そうした状況を打開すべく、新たなアプローチが注目を集めています。それは、自然言語による推論タスクをプログラムコードに置き換えることで、必要なデータを効率的かつ大規模に収集する手法です。

プログラムコード上でアルゴリズムや変数の変化を追跡できれば、LLMが正確に手順を実行しているかどうかの検証が容易になります。とりわけ、自然言語特有の曖昧さやノイズを排除した、より厳密な評価基準の確立が期待されています。

さらに、LLMが単なるパターン認識や記憶の再生ではなく、実際に段階的な処理を行っているかを確認する上でも、コードによる形式的なタスクは有効と考えられます。

このような背景を踏まえ、オックスフォード大学などの研究チームは自然言語とコードの両方で同等の課題を設計し、以下の2点について検証を行いました。

- LLMが高度な推論を”自然言語だけでなくコードで”でどの程度確実に実行できるのか
- コードベースのベンチマークが自然言語タスクの代替として機能し得るのか

このような技術者であれば多くの方が興味をもつであろう疑問に取り組んだ実験の結果、さまざまな新しい知見が得られました。以下で詳しく紹介します。

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_83997_1-1024x340.png)

自然言語で描かれる二者間の物品交換と、それに対応するコード例を並列。両者が本質的に同じ手続きを共有している点を可視化。

## 研究手法

まず、研究の前提となる考え方を整理します。

やや繰り返しになりますが、LLMに問題を与える際、自然言語の代わりにプログラムコードを用いることで、より正確な評価が可能になると考えられています。なぜなら、コードには自然言語特有の曖昧さやノイズが少なく、演算や変数の変化を明確に追跡できるためです。  
そのため、研究チームは問題をコードと自然言語の両方で作成し、LLMの応答を比較する手法を採用しました。  
プログラミング言語にはPython 3が選ばれ、インタプリタ（研究内でΩと呼称）による実行結果が正解の基準とされました。

LLMは、入力されたテキストから次のトークンを予測する関数として定義されています。  
与えられた問題（自然言語またはコード）に対する応答と、実際のプログラム実行結果を照合することで、 [正解率](https://ai-data-base.com/archives/25930 "正解率") や誤差が測定されます。なお、複数の中間値を求める必要がある場合には、レーベンシュタイン距離などの文字列距離も評価指標として活用されています。

とりわけ注目すべき点は、モデルの誤答分析です。たとえば、コードの一部実行の見落とし、変数の誤用、既知パターンの安易な流用といった失敗要因を詳しく見る必要があります。コードには明確な構文規則と実行順序があるため、どの段階で誤りが生じたのかが把握しやすいのが良いところです。

### ベンチマークの構成

評価用のタスクは、以下の5つの主要グループに分類されています。

1. 単純な直列計算から、
2. 不要な情報を含む問題、
3. 複数変数の追跡、
4. 深いネスト構造による複雑な処理、
5. そしてソートアルゴリズムの実装まで、

段階的に難易度が上がるよう設計されています。

たとえば、最も基本的なタスクでは、一つの変数に対する連続した加減算の最終結果を求めます。  
より複雑なタスクでは、複数の変数を同時に追跡したり、余分な情報の中から重要な操作だけを見極めたりする能力が試されます。

コードベースのタスクは、すべて実行可能なプログラムとして実装されており、前述した通りインタプリタによる実行結果が正解となります。  
一方、自然言語版では、同じ論理構造を物語形式に置き換え、登場人物や物体の状態変化を通じて同様の問題を提示します。

いずれも「決められた手順を順番に実行すれば答えにたどり着ける」という特徴を持っています。また、各段階の処理がコードで明確に示されているため、モデルがどの部分で混乱するのかを特定しやすいという利点があります。

それでは、五つのベンチマークタスクについて詳しく見ていきましょう。

#### 1\. 基本的な直列処理（タスク名：Straight line and Good exchange（単純な直列操作と物品交換））

単純な足し算や引き算など、一つの値に対する操作を順番に行い、最終的な結果を求めます。

自然言語版では、たとえば「AさんがBさんと物を交換する」といった物語として表現されます。

一見単純に見えますが、各段階で数値や物の状態がどう変化したかを正確に記憶していないと、正解にたどり着けない仕組みになっています。

#### 2\. 重要な処理の抽出（タスク名：Critical path and Critical good exchange（重要な経路と重要な物品交換））

余計な操作が混ぜられており、本当に必要な手順だけを見極めれば解ける問題です。

たとえば、プログラムの中に不要な命令が紛れ込んでいたり、物語の中に関係のない出来事が描かれていたりします。

正解へのカギとなる手順を見つけられるかどうかが試されます。

#### 3\. 並行処理の追跡（タスク：Parallel path and Clique exchange（並行する経路とクリーク形式の交換））

複数の値や登場人物が同時に動く状況を正確に把握する必要があります。

たとえば、プログラムでは複数の変数が同時に変化し、物語では複数の人物が別々のタイミングで行動します。

近道をして計算をまとめようとすると、重要な変化を見落として誤った結論に至りやすい特徴があります。

#### 4\. 繰り返し処理の理解（タスク名：Nested loops and Recurring calculation（入れ子ループと繰り返し計算））

プログラムでは「入れ子構造のループ」、物語では「繰り返される行動」として表現されます。

たとえば、「平日5日間、毎日同じ行動を繰り返す」といった設定で、その結果を問う形式です。

繰り返しの回数が増えるほど、手順も長くなっていきます。そのため、単純な暗記やパターン認識では対応が難しくなります。

#### 5\. 並べ替えと順位付け（タスク：Sorting and Ranking objects（ソートと対象の順位付け））

要素の並べ替えや順位付けを行うタスクです。

プログラムではソートアルゴリズムを使用し、物語では「重さの順に物を並べる」といった形で表現されます。

ソートの手順は広く知られているため、LLMが既存の知識を単に暗記して答えているのか、それとも実際に一つ一つの手順を理解しているのかが明確になりやすいという特徴があります。

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_83997_2-1024x519.png)

タスクの自然言語説明文とそれらをコード化した例。タスク構造の類似性と変数操作の対応を示す。

こうしたベンチマークタスクを用いて実験が行われました。その詳細な実験設定や結果を次のセクションで説明します。

## 実験による検証

LLMの推論能力を厳密に評価するため、オープンソース・クローズドソース双方のモデルを対象とした実験が実施されました。

実験に使用されたモデル一覧

- GPT-4
- GPT-4o
- Llama-3.1-405B
- GPT-3.5-Turbo
- Jurassic2-Ultra
- Llama-2-70B
- CodeLLaMA-34b-Instruct

各モデルには、先述のコード形式と自然言語形式の両方でタスクが与えられ、その出力結果が比較されました。

実験の信頼性を高めるため、同一条件下で複数回の試行が行われ、平均性能と標準偏差が算出されています。なお、タスクの難易度は、「操作の数」や「処理の複雑さ」を段階的に変化させることで調整されました。

後述する実験結果からは、コード形式と自然言語形式のタスク間に一定の相関が確認されています。とりわけ、単純な直列的操作のタスクでは、両形式における正解率や誤差の傾向が顕著に一致しました。

ただし、モデルによっては興味深い特徴も観察されています。たとえば、プログラム操作では高い正解率を示すものの、同じ内容を自然言語で問われると性能がやや低下するケースが見られました。さらに、単純な累積計算と比べ、余分な操作を含むタスクや複数変数の並行処理では、コード形式のほうが理解しやすい傾向が示唆されています。つまりタスクをコードに変換することのメリットが発見されたのです。

以下で詳しく見ていきます。

### 自然言語タスクの代替としてのコードシミュレーションの可能性

複雑な自然言語タスクをコードで表現する手法の有効性を検証するため、両形式での比較実験が実施されました。背景には、正しい手順さえ踏めば解答可能なタスクであれば、形式によらず同程度の正答率が得られるはずだという仮説がありました。

実験の結果、自然言語タスクで高い正解率を示すモデルは、コード形式でも同様に優れた性能を発揮する傾向が確認されました。

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_83997_3-1024x833.png)

各タスクに対応する自然言語版（Good exchange・Critical good exchange・Clique exchange）での精度比較をグラフ化

一方、GPT-4oなどのモデルでは、形式による得手不得手がより顕著に表れました。

処理手順が長くなったり、同様の操作が繰り返されるタスクでは、コードのシミュレーションが途中で破綻するケースも報告されています。自然言語形式でも同様の段階的推論が必要とされるため、同じように誤答が生じることがあります。

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_83997_4-1024x826.png)

Nested loopsとRecurring calculation、およびSortingとRanking objectsに対するモデルの正答率や出力の類似度を、処理の複雑度や要素数ごとに可視化

しかしながら、コード形式には重要な利点があります。  
どの命令が実行されなかったか、あるいは変数の値がどの時点で誤って解釈されたかを具体的に追跡できるのです。そのような詳細な分析により、LLMが単なるパターンマッチングを行っているのか、それとも各ステップの論理を実際に理解しているのかを、より正確に判断できるようになります。

### LLMの推論における問題点、それは「近道」と「暗記」

LLMにコード実行を課す際の重要な論点として、モデルが実際に各ステップを丁寧に追跡しているのか、それとも最終結果だけを一括で出力しているのかという問題があります。

たとえば、ソートアルゴリズムのタスクでは、要素数が少ない場合には正確なステップ実行が観察されます。しかしながら、要素数が増加すると、中間過程を省略する傾向が顕著になります。研究チームは、このような本来の処理手順を省略する振る舞いを”lazy execution regime”（怠惰な実行体制）と名付けています。

#### “怠惰な”コードシミュレーション（近道の問題）

一見すると、大規模な入力に対しても素早く正解を導き出せる点は優れているように思えます。しかし、提示されたコードの各ステップを忠実に実行していない可能性が大きな問題として指摘されています。

とりわけ、アルゴリズムが複雑化すると、正確な中間過程を省略して結論を導く傾向が強まります。そのため、珍しいパターンや重複要素を含む入力では、顕著な誤りが生じやすくなります。

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_83997_5-1024x457.png)

GPT-3.5-Turboのソート実行結果から、要素数が増加するとステップを省略し、最終的な順序だけを出力する“lazy execution regime”の兆候を捉えた例を提示

#### コード暗記の問題

もう一つの重要な懸念は、広く知られたアルゴリズムが単に暗記されている可能性です。たとえば、よく使われる再帰関数やソートアルゴリズムは、大規模 [コーパス](https://ai-data-base.com/archives/26324 "コーパス") にも頻出するため、LLMが手順を追うことなく、既知のパターンに即座に反応してしまう可能性があります。

実際、有名なアルゴリズムに微細な変更を加えると（たとえばフィボナッチ数列の変形や、昇順ソートから降順ソートへの変更など）、暗記に依存したモデルの正解率は著しく低下することが確認されています。

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_83997_6.png)

一般的なアルゴリズムと微妙に変更したバージョンを提示し、GPT-3.5-TurboやGPT-4、Llama-3-70Bが暗記や近道に頼る挙動を見せるかどうか、Chain of Simulationの効果とともに比較

![](https://ai-data-base.com/wp-content/uploads/2025/02/AIDB_83997_7.png)

GPT-3.5-Instructの補完パターンを例に、フィボナッチ数列やその改変例などを入力した際のトークン予測を可視化。コードに対する暗記検知の困難さを示唆。

この問題に対処するため、「命令を手順どおり実行するように」と促すプロンプト（Chain of Simulation, CoSm）の活用が試みられています。このような追加指示によって性能が向上するモデルは、段階的なコード実行の能力を備えていると考えられます。一方、指示を加えても誤りが多いモデルは、手続き的なシミュレーションそのものに課題を抱えている可能性があります。

以上のように、コードを用いた評価手法はLLMの推論過程を解明する上で有用です。ただし、暗記やパターン認識への依存度を慎重に見極める必要があり、そうでなければ誤った結論を導く危険性が指摘されています。

## まとめ

本記事では、LLMの高次推論能力を評価する新たな手法として、「Code Simulation as a Proxy for High-order Tasks in Large Language Models（大規模言語モデルにおける高次タスクの代替手段としてのコードシミュレーション）」という研究を取り上げました。

研究の核心は、自然言語による問題をプログラムコードに置き換えることで、LLMの思考プロセスをより精密に評価できるという点にあります。

注目すべき成果として、コードと自然言語の両面からタスクを比較することで、大規模なデータ収集と評価がより効率的に実施できることが明らかになりました。また、多くのモデルは自然言語をコードで置き換えてもうまくタスクを完了できる傾向にありました。

まるで東野圭吾の探偵ガリレオのごとく、言葉で示されたタスクを数理的に解いていくことがLLMならば得意なのかもしれません。

しかしモデルによっては「近道」や「暗記」に頼ってしまう現象が確認されているので、問題を回避するアプローチを整理することが課題となりそうです。

**参照文献情報**

- タイトル：Code Simulation as a Proxy for High-order Tasks in Large Language Models
- URL： [https://doi.org/10.48550/arXiv.2502.03568](https://doi.org/10.48550/arXiv.2502.03568)
- 著者：Emanuele La Malfa, Christoph Weinhuber, Orazio Torre, Fangru Lin, X. Angelo Huang, Samuele Marro, Anthony Cohn, Nigel Shadbolt, Michael Wooldridge
- 所属：University of Oxford, University of Salerno, ETH Zurich, University of Leeds

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[Transformerの基礎【クイズ】](https://ai-data-base.com/archives/85996)

[LLMはシステムプロンプトをどれほど守れるか](https://ai-data-base.com/archives/86276)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)