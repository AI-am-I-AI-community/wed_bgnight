---
title: "LLM同士による人工言語コミュニケーションで発見された「言語構造の創発」"
source: "https://ai-data-base.com/archives/80658"
author:
  - "[[AIDB Research]]"
published: 2024-12-16
created: 2025-06-13
description: "本記事では、LLMが人工言語を学習・使用する過程で言語構造がどのように創発するかを調査した研究を紹介します。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、LLMが人工言語を学習・使用する過程で言語構造がどのように創発するかを調査した研究を紹介します。

人間の言語は歴史的に学習と使用の繰り返しによって自然と構造化されてきましたが、LLMが言語を進化させる過程でも同様の現象が起きるのかという問いが研究の出発点となっています。

研究者らは「LLMの持つ暗黙的なバイアス」が言語構造の形成にどう影響するか、また、その結果生まれる構造が人間の言語とどのような共通点や相違点を持つのかを明らかにすることを目指しました。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80658_thum2-1024x576.jpg)

**発表者情報**

- 研究者：Tom Kouwenhoven et al.
- 研究機関：ライデン大学　高度計算科学研究所（オランダ）ケント大学　コンピューティング学部（イギリス）

**本記事の関連研究**

- [実在する人間1052人の態度と行動をAIでモデル化　インタビューベースのエージェントが人間の回答を85%再現](https://ai-data-base.com/archives/80107)
- [人間とGPT-4の社会的知能を測定するツール『SOTOPIA』登場　GPT-4は秘密を守る力で人間より優れるとの結果も](https://ai-data-base.com/archives/57932)
- [100万体のLLMエージェントによるシミュレーションを実験できる環境が登場](https://ai-data-base.com/archives/76640)

## 背景

人間の言語は学習と使用を繰り返す過程で自然と構造化され、歴史的に効率的なコミュニケーションを実現してきました。また、われわれ人間は言語を習得し使用する中で特定のバイアスを形成し、そのバイアスが言語システムをより効果的なものへと導いてきた歴史があります。

そんな中、昨今のLLMは人間のような言語能力を習得し、道徳的判断や行動パターンを示すことが明らかになり、さらには人間の文化形成にも影響を及ぼす可能性が指摘されています。しかし重要な課題も浮かび上がってきています。LLMが生成するコンテンツには、時間の経過とともに人間ではなくモデル自身が理解しやすい形に最適化されていく「モデルの崩壊」という現象が確認されています。言語進化の観点からは、言語が学習方法や使用方法に適応していくのは自然なプロセスと言えますが、現代社会においては人間とモデルの双方にとって理解しやすい言語の発展が不可欠となっています。

また、最近の研究ではLLMが人間と同様に、不自然な語順や階層構造を欠く言語の学習に苦心することが判明しています。LLMの言語処理メカニズムは人間とは異なるものの、構造化された言語に対する選好性において人間との共通点が見出されています。

このような科学的・社会的背景の中で、今回研究者らはLLMが人工言語を学習・使用する過程で人間の言語と同様の構造が創発するかどうかを探究することに取り組みました。彼らは「人工言語が”LLMの持つ暗黙的なバイアス”によって最適化された場合にどのような言語構造が生まれるのか」、また「その構造が人間の言語とどのような共通点や相違点を持つのか」を明らかにすることを目指し実験を行いました。

## 実験アプローチ

人間の言語がどのように進化して構造化されてきたのかを理解するための実験が設計されました。2つのLLMエージェントが人工的な言語を使ってコミュニケーションを取り、その過程で言語がどのように変化していくかを観察するといった内容です。

### ”刺激”の設計

実験では「刺激」と呼ばれる概念が使用されます。形状、色、数量という3つの属性を持つ視覚的な対象物です。形状は3種類、色は3種類、数量は1から3までの値を取り、これらを組み合わせることで27種類の異なる刺激が作られました。これらの刺激を表現するための人工言語として、8種類の子音と5種類の母音を組み合わせた2〜4音節の単語が初期シグナルとして用意されました。

### コミュニケーションゲームの仕組み

シミュレーションの中では、一方のLLMが「話し手」となり、提示された刺激を言語で表現します。もう一方の「聞き手」となるLLMは、その言語表現を聞いて、5つの選択肢（正解の刺激1つと紛らわしい刺激4つ）の中から正しい刺激を特定しなければなりません。このやり取りを30回行うことで1ラウンドとし、計4ラウンドのゲームを実施します。各ラウンドで話し手と聞き手の役割は交代され、両方のLLMが全ての刺激について表現と理解の経験を積みます。

### 訓練とテストの設計

27種類の刺激のうち、15個が訓練用として使用され、残りはテスト用として確保されました。訓練用の刺激は、全ての属性値（形状、色、数量）が均等に分布するように、シミュレーションの開始前にランダムに選択されます。こうすることで、LLMが特定の属性に偏ることなく、バランスの取れた言語学習を行えるようになっています。

以上の設計によって、LLMが効率的なコミュニケーションのためにどのように言語を構造化していくのかを観察することができます。

### シミュレーションの実施手順

研究者らは「推論」「ラベリング」「コミュニケーション」「テスト」の手順でシミュレーションを進めました。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80658_1-1024x297.png)

実験ブロックの図解 。推論、ラベリング、コミュニケーション、テストの4段階の流れ

まず推測ブロックでは、エージェントが提示された刺激に対して正しいシグナルを推測できるか評価されました。  
続くラベリングブロックでは、初期訓練語彙に基づいて各刺激へのシグナル生成が繰り返し行われ、これがエージェントの学習語彙として扱われました。下記が、実際のプロンプトの例です。  

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80658_6-1024x570.png)

次にコミュニケーションブロックでは、エージェント間の相互作用を通じて個々の語彙が徐々に変化していく過程が観察されました。  
そして最後のテストブロックでは、最適化された訓練語彙を用いて全27個の刺激に対するシグナル生成能力が評価されました。

### 実験の評価方法

研究者らは言語の進化を4つの観点から分析しました。

1つ目は「コミュニケーションの成功率」で、メッセージが正しく伝わった割合を測定します。

2つ目は「トポグラフィック類似性」で、例えば「赤い丸が2つ」と「赤い丸が3つ」のように似た意味を持つものに対して、似た単語が使われているかを評価します。

3つ目は「Nグラム多様性」で、作られる単語のパターンの多様さを測ります。この値が低く、かつトポグラフィック類似性が高い場合、言語に規則性が生まれていることを示します。

4つ目は「一般化スコア」で、学習していない新しい対象物に対しても適切な単語を作れるかを測定します。

### 使用された大規模言語モデルの仕様

Llama 3 70Bという大規模言語モデルが、特定の指示に従うように調整を加えられ使用されました。このモデルは文脈から学習する能力を持っており、研究者らはこの特徴を活用して言語学習を行いました。

モデルに与える情報は、視覚的な特徴（形や色など）と、それを表現する単語の対応関係を学習できるように慎重に設計されました。実験中、モデルは大きく分けて2つの作業を行います。1つは単語を作り出すこと、もう1つは単語の意味を推測することです。また、学習順序による影響を避けるため、各作業の前に使用する語彙の順番がランダムに入れ替えられました。

## 評価方法

### シミュレーションの基本設計

研究者らは、15回の異なるシミュレーションを実施しました。各シミュレーションでは新しいランダムシードを用い、それぞれ独自の人工言語が使用されました。この人工言語は、初期状態では特に規則性や構造を持たない形で設計されています。

### 期待される結果のパターン

人間の言語学習実験で観察されるような結果が得られるかどうかを確認するため、以下の3つの変化に注目しました。

まず、コミュニケーションの成功率が上昇すること。

次に、類似した意味には類似した表現が使われる傾向（TopSimスコア）が強まること。

そして、使用される言語パターンの種類（Ngram多様性）が減少することです。

これらの変化が見られれば、大規模言語モデルが人間のように言語を構造化し、未知の状況にも対応できるようになったと判断できます。

### データ分析手法

研究者らは、統計手法として線形混合効果モデルを採用しました。線形混合効果モデルを使用すると、各シミュレーションで使用された異なる語彙の影響を考慮しながら、全体的な傾向を分析することが可能になります。

モデルの分析結果は、「傾き(β̂)」と2種類の [R2](https://ai-data-base.com/archives/26434 "決定決定係数（R2）") 値で表されます。

傾きは変化の方向と速さを示します。正の値なら増加傾向、負の値なら減少傾向を表し、数値が大きいほど変化が急激だということです。

[R2](https://ai-data-base.com/archives/26434 "決定決定係数（R2）") 値は0から1の間の数値で、モデルの説明力を示します。 [R2](https://ai-data-base.com/archives/26434 "決定決定係数（R2）") c値は実験全体の説明力で、意図的な実験条件と予期せぬ影響の両方を含みます。一方、 [R2](https://ai-data-base.com/archives/26434 "決定決定係数（R2）") m値は実験条件のみの説明力を表します。  
（例えば [R2](https://ai-data-base.com/archives/26434 "決定決定係数（R2）") c=0.8、 [R2](https://ai-data-base.com/archives/26434 "決定決定係数（R2）") m=0.3 という結果は「実験全体では結果の80%を説明できるが、意図的な実験条件だけでは30%しか説明できない」ということを意味します）

## 実験結果

### 人工言語の学習性能について

大規模言語モデルは予測タスクにおいて極めて高い精度（97.3%）を示しました。しかし、同じ刺激に対して新しい表現を生成するラベリングタスクでは、正解が示されているにもかかわらず、精度は45.3%まで低下しました。

これは大規模言語モデルの特性を示す興味深い結果です。なお、表現生成の難しさは、各モデルが独自の語彙を発展させることにつながり、これは実験において望ましい結果となりました。

### コミュニケーションの成功率

モデル同士のコミュニケーションは、当初から比較的高い成功率を示しました。互いに異なる言語を使用していたにもかかわらず、第1ラウンドで70%の成功率を達成し（偶然の確率は25%）、その後75%まで向上しました。ただし、この成功率は安定せず、時にはかなりの低下も見られました。

### 言語構造の発展過程

初期の非構造化言語は、繰り返しの使用を通じて徐々に構造化されていきました。類似した意味には類似した表現が使われるようになり、使用されるパターンの種類も減少していきました。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80658_2-1024x349.png)

(a) 各ブロックとラウンドでのTopSimスコアの変化と (b) Ngram多様性スコアの推移を示すグラフ

ただし、人間の実験結果とは異なり、表現は時間とともに長くなる傾向を示しました。人間の場合、表現は簡潔になりながら十分な情報量を保つ方向に進化するのが一般的です。

### 汎化能力の評価

構造化された言語を持つモデルは、未知の状況により適切に対応できることが示されました。また、類似した意味に類似した表現を使用する傾向が強いモデルほど、新しい状況での対応力が高いことが統計的に確認されました。この結果は、モデルが言語の規則性を学習し、それを活用できていることを示唆しています。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80658_3.png)

TopSimスコアと汎化能力の相関を示す散布図。構造化が進んだ言語ほど未知の刺激への対応が改善

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80658_4-edited.png)

最高のTopSimスコアを記録したシミュレーションにおける訓練用とテスト用の刺激／シグナルのマッピング例

以上の結果から、大規模言語モデルには”構造化された言語”を好む傾向があり、それが学習と使用の過程で自然に現れることが分かりました。

## 反復学習実験の設計

次に研究者らは、「前世代の言語を次世代が学習する」という世代交代の仕組みを実験に導入しました。シミュレーションは8世代にわたって6回実施され、第一世代には無作為に構築された言語が与えられました。各世代では、最も高い成績を示したモデルの言語が次世代に引き継がれる仕組みです。

社会的な学習過程で小さな傾向が徐々に増幅されていく可能性を検証するための実験です。

### 学習効率の向上

実験結果から、世代を重ねるごとに言語の学習しやすさが向上することが明らかになりました。第一世代では言語の再現に苦労していたモデルが、わずか一世代を経ただけで大幅に成績が向上しました。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80658_5.png)

世代を重ねるごとの学習効率（Levenshtein距離）の変化を示すグラフ

この結果は人間を対象とした同様の実験結果と類似しており、言語が大規模言語モデルの特性に合わせて最適化されていく過程を示しています。

### 言語の変化と課題

しかし、言語の学習効率は向上したものの、いくつかの予想外の現象も観察されました。顕著だったのは、表現が徐々に長くなり、曖昧になっていく傾向です。

また、異なる対象に同じ表現を使用する例も増加しました。

これは人間の言語進化とは異なる特徴です。人間の場合、表現は簡潔さと明確さのバランスを保つ方向に進化するのが一般的だからです。研究者らは、この違いは大規模言語モデルが人間とは異なる記憶容量を持つことが原因かもしれないと考えています。

こうした実験を続けることで、言語の進化過程を研究できる可能性があります。モデルは人間とは異なる方法で言語を発展させますが、その過程を詳しく観察することで、言語の進化メカニズムについての新しい知見が得られるかもしれません。

## 考察と将来展望

### LLMの言語習得と進化に関する発見

研究者らは、参照ゲームのシミュレーションを通じて、LLMが人工言語を習得・使用できることを実証しました。

LLMは初期の全体的な語彙を自身の言語モデルの特性に合わせて最適化し、規則性と構造を向上させていきました。研究過程では人間のような構成的構造も確認され、汎化能力の向上につながることが示唆されました。

一方で、信号の長さが増加する傾向など、人間とは異なる特徴も観察されています。反復学習によって語彙の習得効率は向上したものの、LLM固有の特徴も同時に強化される結果となりました。

### 言語構造の形成過程における課題

また、入力における色属性などの特定の属性がLLMによって無視される傾向を見出されました。原因としてLLMのプライマシー効果（入力の最初の部分をより重視して処理する傾向）とレセンシー効果（入力の最後の部分により強く反応する傾向）が考えられます。

また、LLMが他のエージェントから理解されるための十分な圧力を受けていない可能性も指摘されています。信号生成における貪欲デコードの使用は、必ずしも人間らしい表現を生成せず、非人間的な合成につながる場合があることが判明しました。反復学習による学習効率の急速な向上は、言語モデルの弱い学習バイアスが世代間伝達によって増幅された結果だと考えられます。

### 研究の展望と応用可能性

今後の展望としては、命令文の最適化によって関連属性への注目度を高められる可能性を示唆しています。ディストラクタ（実験において正しい答えの選択を難しくするために提示される誤った選択肢のこと）やインタラクションパートナー（言語進化の実験において、お互いにコミュニケーションを取り合う参加者）の数を増やしてコミュニケーションの難易度を上げることで、メモリ制約が言語習得に与える影響の解明が期待されます。

またモデルのサイズやトレーニングデータ、デコード戦略といった要素を体系的に検証することで、長い信号生成の傾向などの原因究明が可能になると考えられます。人間とLLMの協調実験を実施することで、双方に最適化された言語の進化プロセスの解明も期待されます。

総じて研究成果から、LLMは人工言語の進化を研究する有用なツールとなることが示されました。非構造化言語をより規則的な形に進化させる能力は、言語処理と進化の理解を深める重要な知見となっています。

## まとめ

本記事では、LLMを用いた人工言語進化の研究について紹介しました。研究者らはLLMを使って参照ゲームのシミュレーションを実施し、LLMが人工言語を学習・使用できることを実証するとともに、その過程で言語が構造化されていく様子を観察しました。実験結果から、LLMは言語進化研究の有効なツールとなる可能性が示されましたが、同時に人間とは異なる言語処理特性も明らかになり、今後の研究課題も提示されました。

**参照文献情報**

- タイトル：Searching for Structure: Investigating Emergent Communication with Large Language Models
- URL： [https://arxiv.org/abs/2412.07646](https://arxiv.org/abs/2412.07646)
- 著者：Tom Kouwenhoven, Max Peeperkorn, Tessa Verhoef
- 所属：Leiden Institute of Advanced Computer Science, School of Computing

## 理解度クイズ（β版）

1\. LLMを用いた実験で使用された「刺激」の属性として正しいものは？

実験では形状(3種類)、色(3種類)、数量(1〜3)の3つの属性を組み合わせて刺激が作成されました。これらの属性は人工言語の学習と構造化を研究する上で重要な要素となっています。

解説を見る

2\. LLMの言語学習実験で観察された人間との重要な違いは？

人間の言語進化では表現が簡潔になる傾向がありますが、LLMは反対に表現が長くなる傾向を示しました。これは人間とLLMの言語処理メカニズムの本質的な違いを示唆しています。

解説を見る

3\. LLMの言語進化実験から明らかになった重要な特徴は？

実験により、LLMは独自の方法で言語を構造化し、効率的なコミュニケーションを実現できることが示されました。ただし、その過程は人間とは異なる特徴を持っています。

解説を見る

4\. 実験結果から示唆されたLLMの言語学習における課題は？

LLMはプライマシー効果とレセンシー効果により、入力の特定の属性（特に色属性など）を無視する傾向が確認され、これが言語学習における重要な課題として指摘されています。

解説を見る

5\. 反復学習実験から得られた主要な知見は？

反復学習により言語の学習効率は向上しましたが、同時に表現の長大化や曖昧性の増加といったLLM特有の課題も強化されることが明らかになりました。

解説を見る

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[LLMを利用した「自動データクリーニング」方法](https://ai-data-base.com/archives/80508)

[文脈内学習は「少数事例からの単純な学習だけでなく、言語モデルが持つ幅広い適応能力」](https://ai-data-base.com/archives/80765)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)