---
title: "LLMの出力をJSON形式などに構造化すると「思考の柔軟性」や精度に影響することが示唆される"
source: "https://ai-data-base.com/archives/74336"
author:
  - "[[AIDB Research]]"
published: 2024-08-15
created: 2025-06-13
description: "本記事では、LLM生成テキストの構造化が性能に与える影響の調査を紹介します。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、LLM生成テキストの構造化が性能に与える影響の調査を紹介します。JSONやXMLなどの標準化されたフォーマットで出力を生成するとLLMの能力は変化するのでしょうか？

研究者たちは、構造化された出力を行いつつLLMの推論能力のバランスを探ることも目的としています。LLMの産業応用においては構造化された出力は魅力的であるため、一貫性と性能のトレードオフを理解するのは重要なことです。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74336-1-1024x576.jpg)

**参照論文情報**

- タイトル：Let Me Speak Freely? A Study on the Impact of Format Restrictions on Performance of Large Language Models
- 著者：Zhi Rui Tam, Cheng-Kuang Wu, Yi-Lin Tsai, Chieh-Yen Lin, Hung-yi Lee, Yun-Nung Chen
- 所属：Appier AI Research, National Taiwan University

## 背景

文脈内学習や指示追従などの機能により、LLMは多くのダウンストリームタスクに適用できるようになりました。しかし、産業応用においては、LLMの出力が標準化されたフォーマットに従わないことが大きな障壁となってきました。標準化されたフォーマットとはすなわち、テキストを整理するための予め定められた構造のことです。

そこで、”構造化生成”が使用されるようになりました。構造化生成とはJSONやXMLなどの標準化されたフォーマットで出力を提供する手法です。プロンプトで指示したり、JSON mode（OpenAIやGeminiが提供）を実行するのが方法です。

しかし、これまである重要な疑問が見過ごされていました。それは、出力の構造化が生成コンテンツの質にどのような影響を与えるかという点です。言い換えれば、フォーマット制限がLLMのパフォーマンスを低下させる可能性があるかどうかは、ビジネスに大きな影響を与える問題であるにもかかわらず、十分に調べられていませんでした。

結果として、構造化出力とLLMの性能はトレードオフの関係にある可能性が示唆されています。以下で詳しく紹介します。

なお下の図は、GPT-3.5-turboが標準的な自然言語で正しく回答したものの、フォーマット制限を適用すると失敗した例を示しています。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74336_1-693x1024.png)

## 構造化生成の方法

本研究ではダウンストリーム性能に対するフォーマット制限の影響を調査するために、以下3つの一般的な方法が比べられました。

### 方法１　制約付きデコーディング（JSON-mode）

制約付きデコーディングは、生成プロセス中に事前に定義されたトークン空間を強制することで、LLMの出力を制限する技術です。OpenAIやGoogleがJSON modeで実装されている技術です。主に産業環境での使用が想定されています。APIでハイパーパラメータフラグとして利用可能で、出力がJSONであることを保証します。

### 方法２　フォーマット制限指示（FRI）

フォーマット制限指示とは、LLMに対して、JSON、XML、YAMLなどの標準化されたフォーマットで応答を生成するよう指示する方法を意味します。プロンプトによって指定されたスキーマに従うことを要求して、出力が構造化フォーマットに従うようにします。

制約付きデコーディングよりも柔軟で、事前に定義されたトークン空間を強制するわけではありません。

### 方法３　自然言語からフォーマットへの変換（NL-to-Format）

まずLLMに自然言語で質問に答えるよう指示し、その後、その応答を目標のフォーマットスキーマに変換するよう指示するといった段階的な方法です。

構造化生成の中で最も柔軟なメソットで、コンテンツとフォーマットを切り離すことを目的としています。パフォーマンスを維持しつつ、構造化された出力を提供することが可能と考えられています。

## 実験

### データセット

推論タスク

1. GSM8K： 日常生活で遭遇しそうな数学の問題集である。AIがどのように段階を踏んで問題を解くか、その思考過程を観察できる
2. Last Letter Concatenation（最後の文字の連結）： 複数の単語が与えられ、それぞれの最後の文字をつなげて新しい言葉を作る課題である。AIが言葉の構造をどれだけ理解しているかを評価する
3. Shuffled Objects（シャッフルされたオブジェクト）： 物の初期配置と、その後の移動情報が与えられる。AIはそれを基に、最終的な配置を推論する必要がある

分類タスク

1. DDXPlus：患者の症状などの情報が与えられ、49種類の疾病から正しい診断を選択する医療診断タスクである
2. MultiFin：金融に関する文章が与えられ、その内容を5つの分野のいずれかに分類するタスクである
3. Sports Understanding（スポーツ理解）：スポーツに関する文が提示され、その文が現実世界で妥当かどうかをAIが判断する
4. Natural Instructions – Task 280（自然言語指示 – タスク280）：ステレオタイプが書かれた文章を読み、それがどの種類のステレオタイプなのかを分類する。質問の形式を少し変えるだけでAIの回答が大きく変わることがある課題として知られている

### モデル

以下のモデルが実験で使用されました。（追加の実験でgpt-4o-miniが使用されていますが、結果の分析や考察が限られているため最後に記載しています）

- gpt-3.5-turbo-0125
- claude-3-haiku-20240307
- gemini-1.5-flash
- LLaMA-3-8B-Instruct
- Gemma-2-9B-Instruct

オープンモデルについては、JSON modeをサポートするText-Generation-Serverを使用して推論が行われました。

なお、これら実験されたモデルの中で、Gemini 1.5 FlashとClaude 3 Haikuは、最先端であり、サイズも比較的大きなモデルです。また、GPT-3.5-turboは現在他の最先端モデルに対して性能が劣りますが、なおベンチマークにされる強力なモデルであり、サイズも大規模です。一方で、LLaMA-3-8BとGemma-2-9Bは比較的小さいモデルであり、また高性能なモデルとして普及しています。

### 評価方法

#### 評価指標

タスクの多様性に対応するため、タスク特有の評価指標が採用されました。分類ベースのタスクでは、正確性が主要な指標として使用されました。Last Letter Concatenation（最後の文字の連結）とGSM8Kでは、完全一致メトリクスが採用され、最終的な回答が実際の答えと完全に一致する必要がありました。

#### 完全テキストパーサー

フォーマットエラーと生成されたコンテンツの実際のパフォーマンスを切り離すために、正規表現や文字列パーサーに頼るのではなく、LLMをプロンプトして最終的な回答をテキストから抽出する方法が採用されました。これで、異なるモデル間で切り替える際に導入されるエラーが最小限に抑えられました。

#### プロンプトの感度への考慮

LLMがプロンプトのわずかな変化に敏感であることが先行研究で示されていることを踏まえ、9つのプロンプトパターンが評価されました。

- 3つのタスク説明
- 文言やフォーマットにわずかな変更を加えた3つのJSON、XML、YAMLスキーマ

これらの組み合わせ（3通り×3通りで9パターン）です。

## 主な結果

フォーマット制限がLLMの性能に与える影響を調査するため、前述した3つの手法が比較されました：JSON-mode、FRI（フォーマット制限指示）、NL-to-Format（自然言語からフォーマットへの変換）です。

完全一致スコアを持つデータセット（GSM8Kと最後の文字の連結タスク）で評価されたところ、驚くべきことに、JSON-modeは最後の文字タスクにおいてFRI（JSON）よりも著しく低い性能を示しました。詳細な調査の結果、GPT 3.5 TurboのJSON-modeレスポンスの100%が”answer”キーを”reason”キーの前に配置していたことが判明しました。そのためゼロショット直接回答が行われ、ゼロショット思考連鎖推論が行われなかったことが分かりました。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74336_2-756x1024.png)

GSM8K、Last Letter、Shuffled Objectsなどの推論関連タスクにおいて、より緩やかなプロンプトが一般的により良い結果をもたらすことを示す

NL-to-Formatと制限のない自然言語応答を比較すると、ほとんどのモデルで性能がほぼ同一であることが観察されました。これは、両者が同じ初期の自然言語応答から答えを導き出しているためです。しかし、NL-to-Formatでは時折生成エラーが発生し、LLaMA 3 8B Instructのスコアがわずかに低下しました。一方、他のモデルは両方の設定で一貫したスコアを維持しました。

上記の結果から、フォーマット制限の程度と実装方法がLLMの性能に大きな影響を与える可能性があることが示唆されました。特に推論タスクにおいては、構造化出力におけるキーの順序や、推論とフォーマット遵守の分離が、LLMの能力を維持しつつ構造化された応答を提供する上で重要な要因であることが明らかになりました。

分類データセットによる評価では、推論タスクとは異なる傾向が観察されました。特筆すべきは、DDXPlusデータセットにおいて、Gemini 1.5 FlashがJSON-modeを有効にした際に大幅な性能向上を示したことです。他の分類データセットでも、JSON-modeは競争力のある性能を示し、場合によっては他の3つの手法を上回りました。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74336_3-1024x296.jpg)

DDXPlus、Sports、Task280、Multifinなどの分類関連タスクにおける異なるレベルのフォーマット制限の結果を示す

この現象について、JSON-modeが可能な回答を制限することで、回答選択のエラーを減少させている可能性が推測されました。対照的に、自然言語による応答は注意を逸らす要素を導入し、解析エラーにつながる可能性があります。このことは、フォーマット制限がLLMの性能に与える影響がタスクに依存することを示唆しています。厳格なフォーマットは推論を必要とするタスクでは障害となる可能性がありますが、構造化された出力を必要とする分類タスクでは精度を向上させる可能性があります。

つまり、タスクの性質に応じて適切なフォーマット制限戦略を選択することの重要性が示唆されています。LLMの能力を最大限に引き出しつつ、必要な構造化出力を確保するバランスを取ることが求められています。

## 考察

### フォーマットの縛りを緩めるとどうなるか

研究者たちは、LLMに対する指示の出し方を少し変えてみました。例えば、「こういう形で答えてください」といった細かい指示をなくし、単に「JSONという形式で答えてね」とだけ言うようにしてみました。

その結果、GSM8K（数学の問題を解くテスト）では、いくつかのモデル（Claude 3 Haiku、GPT-3.5 Turbo、LLaMA 3 8B Instruct）の成績が良くなりました。また、質問の仕方を少し変えても結果があまり変わらなくなりました。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74336_5-1024x981.png)

キーマ制約の有無による結果の比較。スキーマを追加することで、プロンプトに対する感度が増加し、平均パフォーマンスが低下することを示す

これは何を意味するのでしょうか。

LLMの答えを簡単に理解できる形にすることは大切ですが、LLM「こう答えなさい」と細かく指示しすぎると、かえってAIの本来の能力を発揮できなくなる可能性があるということです。じっくり考える必要がある問題では、特にこの傾向が強いようです。

つまり、LLMに答え方を指示する際は、人間が理解しやすい形式を保ちつつも、LLMが自由に考える余地を残すことが大切だということがわかりました。

### 異なるフォーマット間の比較

研究者たちは、LLMに答えを求める際に使う3つの形式（JSON、XML、YAML）を比べてみました。形式にはそれぞれ独自のルールがあるので、LLMの答え方に違いが出るかもしれないと考えたのです。

しかし、結果を見てみると、どのLLMでも特定の形式が常に優れているということはありませんでした。Geminiというモデルでは、JSONという形式が比較的安定していましたが、他の形式より必ず良いというわけではありませんでした。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74336_4-1024x272.jpg)

DDXPlus、Sports、Task280、Multifinの分類関連タスクにおける異なるフォーマット（JSON、YAML、XML）の比較

面白いことに、選択肢から答えを選ぶような問題では、JSONモードを使うと普通のテキストより良い結果が出ました。これは、答えの選択肢が限られているからだと考えられます。

しかし、じっくり考える必要がある問題では、JSONモードはあまりうまくいきませんでした。なぜなら、このモードでは「まず考えて、それから答える」という順序を守れなかったからです。そのため、結果が大きく悪くなってしまいました。

つまり、問題の種類によって、LLMにどんな形式で答えてもらうかを考える必要がありそうです。

### 答え方の形式と間違いの関係

初めは、研究者たちは、「LLMの答えを特定の形式（例えばJSON）で出してもらうと、その答えを読み取る時に間違いが起きやすくなり、それが性能の差につながっているのではないか」と考えていました。

しかし、調べてみると、そうではないことがわかりました。例えば、Gemini 1.5 FlashとGPT 3.5 Turboは、どんな形式で答えても、ほとんど読み取りミスは起きませんでした。

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74336_7-1024x483.png)

異なるモデルにおける各タスクとフォーマットのパーシングエラー率（パーセンテージ）を示す

![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74336_6-1024x843.png)

パーシングエラーの高い例を、2回目のプロンプトで修正できることを示す

面白いことに、LLaMA 3 8Bでは、JSONという形式で答えを出した時、読み取りミスはほとんどありませんでした（0.148%）。にもかかわらず、成績は38.15%も悪くなったのです。

これは何を意味するのでしょうか？

LLMの答えの形式を制限すると、LLMが考えたり答えを作ったりする過程そのものに影響を与えてしまうようです。つまり、読み取りミスが問題なのではなく、LLMの考え方自体が変わってしまうのが問題だということです。

ただし、読み取りミスが起きた場合でも、簡単な方法で修正できることもわかりました。例えば、Claude-3-Haikuというモデルを使って、間違いのある答えを修正すると、成績が良くなりました。

上記の分析や考察をまとめると、”答えの形式を決める時は、LLMが自由に考えられるようにしつつ、人間が理解しやすい形にすることが大切である”となります。

#### 追加の実験

この論文では、追加のモデルとしてGPT-4o-miniの結果が示されています。

GPT-4o-miniとMistral 7B v0.3の2つの追加モデルについて、以下のタスクでの性能が比較されています。

1. GSM8K
2. Last Letter
3. Shuffled Object
4. Sports Understanding
5. MultiFin
6. NL Task 280
7. DDXPlus
![](https://ai-data-base.com/wp-content/uploads/2024/08/AIDB_74336_figure8-1024x306.png)

結果を見ると、GPT-4o-miniは全体的に良好なパフォーマンスを示しており、特に形式制限(JSON、YAML、XML)を加えた場合でも一貫して高いスコアを維持しています。これは他のモデルとは対照的です。

なお、この研究では主にコスト的な制約から、リーズナブルなモデルで実験されています。

## まとめ

この記事では、LLMに特定の形式で答えを出すよう指示すると、どんな影響があるかを調べた研究を紹介しました。

研究でわかったこととしては、LLMに厳密な形式（例えばJSONモード）で答えるよう指示すると、深く考える必要がある問題では、LLMの性能が下がる傾向があるということです。また、一方で、選択肢から答えを選ぶような問題では、逆に成績が良くなることがありました。また、LLMにあまり厳しくない形式で答えるよう指示すると、深く考える問題で、LLMの性能が上がり、結果のばらつきも減りました。

興味深いことに、LLMの答えを読み取る時の間違い（解析エラー）は、思ったほど大きな問題ではありませんでした。もし間違いが起きても、追加の指示で修正できることがわかりました。  
そのため、LLMを使う時は、答えの形式、LLMの考える能力、そしてコストのバランスを考えることが大切だとわかりました。

今後の研究では、難しさの異なる様々な問題で、LLMに形式を指定することの影響を調べる必要があります。また、LLMの性能低下を防ぐため、様々な形式の指示を含む幅広いデータでLLMを訓練することも重要です。

LLMにどう答えてもらうかは、使う目的や状況によって慎重に選ぶ必要があるという結果でした。これからのLLM開発では、LLMの能力を最大限に引き出しつつ、人間にとって使いやすい答え方を見つけることが課題となりそうです。

- 参照論文URL： [https://arxiv.org/abs/2408.02442](https://arxiv.org/abs/2408.02442)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[Sakana AIが科学研究自動化フレームワーク『The AI Scientist』開発](https://ai-data-base.com/archives/74257)

[LLMから「LLMエージェント」へ　ソフトウェアエンジニアリングにおける今後の展開](https://ai-data-base.com/archives/74375)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)