---
title: "科学研究の自動化だけでなく人間と協働する「コパイロットモード」も備えるLLMエージェント登場"
source: "https://ai-data-base.com/archives/81883"
author:
  - "[[AIDB Research]]"
published: 2025-01-10
created: 2025-06-13
description: "本記事では、研究者のアイデアを自動的に実装・検証する自律システムの研究事例を紹介します。科学的発見には多大な時間とリソースを要するため、価値のある研究アイデアであっても未探索のまま残されているケースが多く存在します。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、研究者のアイデアを自動的に実装・検証する自律システムの研究事例を紹介します。

科学的発見には多大な時間とリソースを要するため、価値のある研究アイデアであっても未探索のまま残されているケースが多く存在します。

そこで研究者らは、人間の研究者が持つアイデアを効率的に実装できるシステムの開発に取り組み、論文調査から実験実施、レポート作成までを自動化する技術を開発しました。

このような研究の先行事例にはSakana AIの「The AI Scientist」プロジェクトがありますが、今回の研究では「The AI Scientist」との違いが明確に言及されています。例えば、「The AI Scientist」は基本的には研究の完全自動化を目指していますが、今回考案された仕組みは人間のフィードバックにより更に柔軟に動作する「コパイロットモード」を実装しています。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_81883_thum2-1024x576.jpg)

**発表者情報**

- 研究者：Samuel Schmidgall et al.
- 研究機関：AMD, ジョンズ・ホプキンズ大学

## 背景

科学研究は、アイデアの構想から最終結果に至るまで、多くの時間とリソースを必要とする長期的なプロセスです。実験室での作業、データ分析、論文執筆など、一つの研究を完遂するには数か月から数年を要することも珍しくありません。研究者たちは、限られた時間と予算、人材といったリソースの中で、最も影響力が高いと予測される研究アイデアを優先的に選択しています。そのため、興味深く価値のある研究アイデアであっても、リソースの制約により未探索のまま残されているのが現状です。

探索に関する制約が少なければ、研究者たちは複数のアイデアを同時に調査でき、科学的発見の可能性が広がります。

最近では、研究のプロセスを自動化する試みが進められており、LLMを活用した取り組みが注目を集めています。例えば研究アイデアの生成や論文の自動執筆などが試みられています。

LLMによって生成されたアイデアは、人間の専門家が生み出したものよりも斬新であると評価されることがある反面、実現可能性や具体的な実装方法において課題があることが指摘されています。つまり、LLMは研究者の代替というよりも、研究者の作業を支援し補完する役割として活用されるべきだと考えられています。

そのような背景の中、今回研究者らは新たに、人間の研究者が持つアイデアの実装を支援する自律的なシステムの開発に取り組みました。人間の研究アイデアを入力として受け取り、関連する学術論文の調査、実験の実施、研究レポートの作成という3段階を経て、研究成果とプログラムのコードを自動的に生成します。研究者は各段階で必要に応じてフィードバックを提供できる設計となっています。

以下で詳しく紹介します。

## 提案システム『Agent Laboratory』の概要

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_81883_f1-1024x503.jpg)

システムのイメージ

今回考案されたシステムAgent Laboratoryは、人間の研究アイデアを自動的に実装へと変換する自律的な仕組みとして設計されました。従来の自動研究システムがLLMのみで研究を完結させようとしていたのに対し、Agent Laboratoryは人間の研究者が持つアイデアを出発点とし、その実現を支援することに焦点を当てています。

コードは下記に格納されています。

[https://github.com/SamuelSchmidgall/AgentLaboratory](https://github.com/SamuelSchmidgall/AgentLaboratory)

### プロセスの3段階

Agent Laboratoryは研究プロセスを「文献調査」「実験」「レポート作成」の3つの主要な段階に分けて進めます（詳細は後述します）。各段階では専門的な役割を持つLLMエージェントが協力して作業を行います。たとえば文献調査では博士課程の学生の役割を持つエージェントが、実験段階では機械学習エンジニアの役割を持つエージェントが中心となって作業を進めます。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_81883_f2-1024x438.png)

ワークフローの概要図

### 人間とシステムの協調

研究者は各段階でフィードバックを提供することができ、必要に応じて方向性の修正や追加の指示を行うことができます。完全自動モードと協調モード（コパイロットモード）の2つの動作モードが用意されており、研究者は自身の必要性に応じて関与の度合いを選択できます。

### コンピューティングリソースへの対応

Agent Laboratoryは、利用可能なコンピュータリソース（CPU、 [GPU](https://ai-data-base.com/archives/26570 "GPU") 、メモリ）や予算に応じて柔軟に設定を調整できるように設計されています。研究機関や個人によって異なるリソース環境に対応できる点が特徴です。

## 動作プロセス

### （１）文献調査段階

文献調査段階では、博士課程の学生の役割を持つエージェントがarXivと呼ばれる学術論文データベースを検索し、関連論文を収集します。エージェントは論文の要約を20件取得し、各論文の内容を評価して、研究テーマに最も関連性の高い論文を選定します。選ばれた論文の全文を取得し、後続の段階で参照できるように整理します。

### （２）実験計画と準備段階

実験計画段階では、博士課程学生の役割を持つエージェントと博士研究員（ポスドク）の役割を持つエージェントが対話を通じて実験計画を練ります。使用する機械学習モデルの種類、必要なデータセット、実験の具体的な手順などが検討されます。計画が確定すると、機械学習エンジニアの役割を持つエージェントがデータの準備作業を行います。HuggingFace（データセットやモデルのプラットフォーム）から適切なデータセットを探し、実験用に整形します。

### （３）実験実行段階

実験用のプログラムコードを生成し、実行、評価、改善を繰り返します。具体的には以下のような流れで動作します。

1. 研究計画に基づいて初期のプログラムコードを生成
2. コードをコンパイルして実行し、エラーがあれば修正
3. 実行結果をスコアリングし、計画との一致度を評価
4. 結果を分析して改善点を特定し、コードを更新

上記のプロセスが繰り返され、目標とする実験結果が得られるまで継続されます。

この動作全体はモジュール化されており「mle-solver」と呼ばれます。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_81883_f3.png)

mle-solverのワークフロー概要

### （４）レポート作成段階

レポート作成では、学術論文の標準的な構成（要旨、序論、手法、実験、結果、考察など）に従って論文を組み立てます。作成された論文は複数の査読者の役割を持つエージェントによって評価され、必要に応じて改訂が行われます。

なお、LaTeXと呼ばれる文書作成システムが使用され、学術雑誌や国際会議の投稿規定に沿った形式の論文が生成されます。また、実験で使用したプログラムコードも整理され、再現性を確保するためのリポジトリとして提供されます。

このプロセス全体は「paper-solver」モジュールと呼ばれます。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_81883_f4-1024x289.png)

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_81883_s1.jpg)

o1-miniを用いた査読の例

## LLMバックエンドの性能評価

Agent Laboratoryの性能を評価するため、5つの研究課題に対して実験が行われました。

1. 言語モデルにおける認知バイアスの研究
2. 画像変換器とCNNのノイズ耐性の比較
3. 医療質問応答における精度向上の研究
4. 多肢選択問題における単語順序の影響
5. 数学問題解答における性別役割の影響

これらの課題それぞれに対して、3種類のLLM（gpt-4o、o1-mini、o1-preview）を用いて研究が実施されました。結果として計15本の研究論文が自動生成され、10名の博士課程学生によって評価が行われました。

なお、今回行われた実験は主に機械学習（ML）分野の検証に焦点が当てられており、他の分野での有効性については詳細に触れられていないようです。「Agent Laboratory」は主にデータ駆動型の科学的問題を解決するために設計されており、物理学、化学、生物学、社会科学などの分野に適用可能かどうかについての議論や実験的検証は特に含まれていません。この点に関しては今後の課題になる可能性があります。

### 評価基準と結果

評価は5段階で行われ、以下の3つの観点から判断されました。

- 実験の質（実験手法の妥当性、結果の信頼性）
- 論文の質（論文としての完成度、説明の明確さ）
- 有用性（研究支援ツールとしての実用価値）

gpt-4oは実験の質で2.6/5、論文の質で3.0/5、有用性で4.0/5という結果でした。o1-miniは実験の質で3.2/5（+0.6）、論文の質で3.2/5（+0.2）、有用性で4.3/5（+0.3）と、全体的にgpt-4oを上回りました。o1-previewは有用性で4.4/5と最高スコアを記録し、論文の質も3.4/5と高評価でしたが、実験の質は2.9/5とo1-miniには及びませんでした。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_81883_t1-1024x437.jpg)

人手による評価結果

## NeurIPSスタイルの査読評価

### 評価基準の詳細

学術会議NeurIPSの査読基準に基づく評価が実施されました。評価項目には以下が含まれます：

- 革新性：1から4段階（低、中、高、非常に高い）
- 品質：1から4段階（低、中、高、非常に高い）
- 明確さ：1から4段階（低、中、高、非常に高い）
- 重要性：1から4段階（低、中、高、非常に高い）
- 総合評価：1から10段階（強い却下から受賞レベルまで）

### 人間査読者による評価結果

各LLMバックエンドの平均スコアは以下のようになりました：

gpt-4oは総合評価3.5/10を獲得し、特に品質面で1.8/4と低い評価でした。o1-miniは総合評価3.8/10で、品質面では2.3/4と最高スコアを記録しました。o1-previewは総合評価4.0/10を獲得し、3つのモデルの中で最も高い評価となりました。

参考として、NeurIPSで採択される論文の平均スコアは5.9/10とされています。つまり、完全自動モードで生成された論文は、トップレベルの学術会議の基準には現時点では到達していないことが分かります。

### 自動査読システムと人間査読の比較

興味深い発見として、論文の自動査読システムと人間査読者の評価には大きな乖離が見られました。自動査読システムは平均して6.1/10というスコアを付与しましたが、人間査読者の評価は3.8/10と、2.3ポイントもの差が生じました。

明確さの評価においても、自動査読は3.6/4を付与する一方、人間査読者は2.4/4としており、評価基準に大きな違いがあることが示されました。これらの結果から、研究の質を評価する際には、自動評価システムだけでなく、人間の専門家による査読が依然として重要であることが示唆されています。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_81883_f6.png)

NeurIPSスタイルでの評価スコア

## 協調モードの評価結果

### 評価の設計と方法

協調モード（コパイロットモード）の評価では、2つの異なる条件で実験が実施されました。

1. 研究者が自由にトピックを選択できる条件
2. 事前に用意された5つのトピックから選択する条件

すべての実験でo1-miniをバックエンドとして使用し、文献調査フェーズのみ別のモデルが採用されました。評価者は実際にシステムを使用した研究者自身と、外部の査読者の両方が担当しました。

### ツールとしての評価結果

実際の利用者による評価では、以下の4つの観点から5段階評価が行われました。

- 有用性：3.5/5
- 継続利用の意向：3.75/5
- 満足度：3.63/5
- 使いやすさ：4.0/5

自由トピックと事前設定トピックを比較すると、自由トピックの方が全体的に高いスコアを獲得しました。ただし、使いやすさに関しては事前設定トピックの方が0.5ポイント高い評価を得ています。

### 生成された論文の品質評価

協調モードで生成された論文は、完全自動モードと比較して以下のような改善が見られました：

- 品質評価：0.75ポイント向上
- 実験の堅実性：0.48ポイント向上
- 全体評価：0.58ポイント向上

ただし、研究の新規性に関しては-0.05ポイント、研究の貢献度は+0.03ポイントと、大きな変化は見られませんでした。これは、人間の介入が論文の表現や実験の正確性を向上させる一方で、研究の革新性自体への影響は限定的であることを示唆しています。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_81883_t2-1024x647.jpg)

## 処理時間とコストの分析

### 全体的な処理性能

3つのLLMバックエンドの処理時間を比較すると、以下のような結果が得られました。

- gpt-4o：1論文あたり約1,165.4秒（約19分）
- o1-mini：1論文あたり約3,616.8秒（約60分）
- o1-preview：1論文あたり約6,201.3秒（約103分）

gpt-4oは他のモデルと比較して3.2倍から5.3倍高速に処理を完了できました。

### コスト効率性の分析

処理にかかる金銭的コストは以下の通りです。

- gpt-4o：1論文あたり2.33ドル
- o1-mini：1論文あたり7.51ドル
- o1-preview：1論文あたり13.10ドル

従来の自動研究システムが1論文あたり約15ドルを要していたことと比較すると、gpt-4oは84%のコスト削減を達成しています。

### 処理フェーズごとの詳細分析

文献調査フェーズでは、o1-miniが56.8秒と最も高速でしたが、コストは0.16ドルとgpt-4o（0.12ドル）より高くなっています。

実験の実行フェーズでは、処理時間に大きな差が見られました。

- gpt-4o：417.8秒
- o1-mini：2,082.5秒
- o1-preview：4,036.2秒

レポート作成フェーズでは、gpt-4oが572.5秒で完了するのに対し、o1-previewは1,854.2秒を要しました。

### 処理の成功率

全体的な処理の成功率は以下の通りです。

- o1-preview：95.7%
- gpt-4o：94.3%
- o1-mini：92.8%

文献調査フェーズでは全モデルで比較的低い成功率（60-80%）が記録された一方、他のフェーズでは90-100%の高い成功率が維持されました。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_81883_f8-1024x683.jpg)

## MLE-Benchによる評価結果

### MLE-Benchとは

MLE-Benchは機械学習エージェントの性能を評価するための標準的なベンチマークテストです。実際のKaggleコンペティションから75の課題を選出し、データの準備から、モデル開発、結果の提出までの一連のプロセスを評価します。

### 評価の設定

Agent Laboratoryの性能評価のため、低い複雑性を持つテキストデータと表形式データに関する10の課題が選択されました。評価では以下の情報が入力として与えられました：

- Kaggleデータセットの説明文
- Kaggleのノートブックから抽出された知見
- アクセス可能な訓練データと開発用データ

### 他システムとの比較結果

Agent Laboratoryのmle-solverモジュールは、既存の3つのシステム（MLAB、OpenHands、AIDE）と比較されました。評価結果では：

- 10個の課題すべてに対して2時間以内に有効な解決策を提出
- 4つのメダル（金メダル2つ、銀メダル1つ、銅メダル1つ）を獲得
- 10課題中6つで人間の中央値を上回る性能を達成

比較対象のシステムでは：

- OpenHandsは2つの金メダルを獲得
- AIDEは金メダル1つと銅メダル1つを獲得
- MLABはメダル獲得なし

また、開発環境への依存度が低く、より安定した結果を出せることが確認されました。実験の再現性という観点からも、Agent Laboratoryの mle-solverは優位性を示しています。

このベンチマーク結果は、Agent Laboratoryが実践的な機械学習タスクにおいて、信頼性の高いソリューションを提供できることを示唆しています。

![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_81883_f9-1024x406.jpg)

## 研究の限界と課題

### 評価システムの限界

論文品質の自動評価システムには大きな課題が存在します。LLMを用いた査読システムは人間の査読者と比べて一貫して高いスコアを付与する傾向が見られ、実際の論文の質を正確に反映できていない可能性があります。また、図表の質や視覚的な表現力において、他の自動研究システムより劣る結果となっています。

### システム構造上の制約

論文の構成が固定的で、独創的な構成や章立てが困難となっています。また、論文中に含められる図表の数が2つに制限されており、研究結果の十分な視覚化が妨げられています。加えて、リポジトリレベルでのコード管理機能が不足しており、各フェーズで生成されたファイルは個別に保存される仕組みとなっています。

### 実行時の問題点

より高性能なLLMを使用した場合、文献レビューフェーズでの指示理解に問題が発生する傾向が確認されています。また、実験結果が0%の精度となるケースや、システムコマンドの誤用による予期せぬ終了なども報告されています。mle-solverモジュールには、システムコマンドを実行できる権限が与えられており、セキュリティ上のリスクが存在します。

### 幻覚の問題

性能の低いLLMを使用した場合、実際には行われていない実験結果や存在しない参考文献が記載されるといった「幻覚」の問題が発生することがあります。研究の信頼性を確保するためには、人間の研究者による注意深い確認が必要です。

これらの限界は、Agent Laboratoryが完全な自動研究システムではなく、人間の研究者を支援するツールとして位置づけられるべきことを示唆しています。

## Agent Laboratory と The AI Scientist (Sakana AI）との主な違い

両者における最も根本的な違いは、研究のアプローチ方法です。The AI Scientistは完全に自律的に研究アイデアを生成し実行するのに対し、Agent Laboratoryは人間の研究アイデアを実行支援するように設計されています。

Agent Laboratoryでは「Co-pilot mode」と呼ばれるモードがあり、各フェーズ（文献レビュー、実験、レポート作成など）の終了時に人間がフィードバックを提供し、必要に応じてエージェントにタスクをやり直させることができます。

各フェーズの終了時に、人間は生成された成果物を確認し、必要に応じて修正指示を行います。例として、文献レビューでは「特定のキーワードの文献を追加してほしい」、実験計画では「ベースラインモデルを含めてほしい」などの具体的なフィードバックを行います。エージェントはこの指示をもとに成果物を修正または再生成します。

なぜそのようなアプローチの違いを選んだのかについて。The AI Scientistの報告ではLLMは実現可能性や実装の詳細面で依然として弱点があることが示されており、LLMは研究の代替というよりも補完的な役割を果たすべきだと考えられたためです。

また、報告書の生成に関して、The AI Scientistは完全な学術論文の生成を目指すのに対し、Agent Laboratoryの paper-solver は、人間研究者が何が達成されたかを理解できるよう、研究成果を人間が読める形式で要約することに重点を置いています。

## まとめ

本記事では、研究者の研究アイデアを効率的に実装へと変換するAgent Laboratoryという自動化システムの研究を紹介しました。

実験の結果、完全な自動化よりも人間の研究者との協調モードで運用した場合に、より質の高い研究成果が得られることが明らかになりました。研究者がアイデアの創出や実験デザインにより多くの時間を費やせるよう支援する補助ツールとして、今後の発展が期待されます。

ただし、まだデータサイエンスやML分野以外での活用が検証されていないため、そのあたりは今後の課題になると考えられます。

**参照文献情報**

- タイトル：Agent Laboratory: Using LLM Agents as Research Assistants
- URL： [https://arxiv.org/abs/2501.04227](https://arxiv.org/abs/2501.04227)
- コード： [https://github.com/SamuelSchmidgall/AgentLaboratory](https://github.com/SamuelSchmidgall/AgentLaboratory)
- プロジェクトページ： [https://agentlaboratory.github.io/](https://agentlaboratory.github.io/)
- 著者：Samuel Schmidgall, Yusheng Su, Ze Wang, Ximeng Sun, Jialian Wu, Xiaodong Yu, Jiang Liu, Zicheng Liu, Emad Barsoum
- 所属：AMD, Johns Hopkins University

## 理解度クイズ（β版）

1\. Agent Laboratoryの主な特徴として最も適切なものは？

Agent Laboratoryは人間の研究アイデアを出発点とし、その実装を支援することに焦点を当てている。Sakana AIのThe AI Scientistとは異なり、完全自動化ではなく人間との協調を重視している。

解説を見る

2\. コパイロットモードの機能として正しいものは？

コパイロットモードでは、各研究段階の終了時に人間がフィードバックを提供でき、必要に応じて修正指示を出すことができる。人間研究者との協調を重視した設計となっている。

解説を見る

3\. Agent Laboratoryの研究プロセスの正しい順序は？

Agent Laboratoryは「文献調査」「実験」「レポート作成」の3段階で研究を進める。各段階で専門的な役割を持つLLMエージェントが協力して作業を行う。

解説を見る

4\. 評価実験で明らかになった点として正しいものは？

実験結果から、協調モードは完全自動モードと比較して論文の品質評価が0.75ポイント向上した。人間の介入が論文の表現や実験の正確性を向上させることが示された。

解説を見る

5\. 評価システムについて明らかになった課題は？

LLMを用いた査読システムは人間の査読者と比べて一貫して高いスコアを付与する傾向が見られ、実際の論文の質を正確に反映できていない可能性が指摘されている。また、図表の質や視覚的な表現力においても課題が報告されている。

解説を見る

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[LLMエージェントによって自然言語をゲーム理論モデルに変換する方法](https://ai-data-base.com/archives/81866)

[マルチモーダルLLMによる表やグラフの理解力を向上させる方法](https://ai-data-base.com/archives/82014)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)