---
title: "オンラインアンケートをLLMチャットボットで行う利点と実践時のポイント"
source: "https://ai-data-base.com/archives/86808"
author:
  - "[[AIDB Research]]"
published: 2025-03-21
created: 2025-06-13
description: "本記事では、オンラインアンケートの回答が表面的になりがちな問題を改善するために、LLMチャットボットを活用した研究を紹介します。オンラインアンケートは手軽に多くの人から回答を集められますが、深い情報を得るのは難しいこともあります。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、オンラインアンケートの回答が表面的になりがちな問題を改善するために、LLMチャットボットを活用した研究を紹介します。  
オンラインアンケートは手軽に多くの人から回答を集められますが、深い情報を得るのは難しいこともあります。  
そこで、回答者が自然な対話を通じて、無理なく詳しく語れるような工夫が求められていました。

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_86808-1024x576.png)

参照論文情報は記事の下部に記載されています。

**本記事の関連研究**

- [外部LLMを利用するときに機密情報を含む可能性のあるプロンプトからの情報漏洩を防ぐ方法](https://ai-data-base.com/archives/86644)
- [生涯にわたりユーザーに寄り添いパーソナライズし続けるAIアシスタントの設計](https://ai-data-base.com/archives/80936)

## 背景

私たちが普段使っているインターネットのアンケートは、たくさんの人に手軽に質問できる便利なツールとして広く使われています。どこからでも簡単に参加でき、すぐに回答できるため、多くの調査で役立っています。ただ、アンケートには大きな課題もあります。それは、自由に書き込める質問があっても、回答する人がじっくり考えずに、短く簡単に済ませてしまったり、途中で疲れて適当に答えてしまったりすることがあるという問題です。

また、普通のアンケートでは、回答者が何か面白いことを言ったとしても、それについて詳しく聞く追加の質問ができないという弱点があります。インタビューであれば、話を聞きながら「もう少し詳しく教えてください」「それはどうしてですか？」と自然に掘り下げることができますが、ネットのアンケートではそれが難しいのです。

そこで注目され始めたのがチャットボットの活用です。チャットボットは、人と自動で会話ができるプログラムで、参加者の回答に合わせて質問を変えたり、さらに詳しい話を引き出したりできます。アンケートが単調な質問の繰り返しではなく、まるで会話をするように進められるため、回答する人が楽しんで積極的に参加できるのではないかと期待されています。

しかし、チャットボットは完璧ではありません。相手が言ったことをちゃんと理解して、適切な質問を返すのは意外と難しいものです。質問の仕方によっては、「このチャットボットの質問は面倒だな」と感じたり、「会話がかみ合わないな」とイライラしたりすることもあります。どのような質問方法がアンケートで役立つのか、まだよく分かっていません。

そうした状況を踏まえて、研究者らは、これまでにインタビュー研究で使われてきた質問テクニックを参考に、チャットボットでのアンケートに最適な質問方法を探る研究に取り組みました。参加者が楽しみながらも、深く考えて答えられるような、新しいアンケート手法の開発を目指したのです。

以下で詳しく紹介します。

## 課題の整理

### オンラインアンケートの課題

オンラインアンケートは、人々の考えや経験、意見を調べるために広く用いられる調査手法の一つです。アンケートは大きく分けて、選択肢から回答を選ぶタイプ（「はい／いいえ」や5段階評価など）と、回答者が自由に記述できるタイプ（自由記述形式）の2つに分類できます。  
自由記述形式の質問は、回答者自身が自分の言葉で自由に表現できるため、より深い内容や予想外の回答を得ることが可能になります。しかしながら、このような自由記述式質問には回答者の負担が大きいという難点もあります。  
回答する際には自分の考えを整理し、言葉を選んでタイプする作業が求められるため、参加者は疲れやストレスを感じやすくなります。その結果、途中でアンケート回答を放棄したり、意味のない言葉を書き込んだり、簡単すぎて十分な情報を含まない回答が増える傾向があります。

こうした問題に対処するために、研究者はこれまでにもさまざまな工夫を行ってきました。例えば、アンケート回答者が以前に答えた内容を参考にして次の質問を柔軟に変化させる方法や、回答者のSNSなどの個人情報を参考に質問内容を個別に調整する方法などが試されてきました。  
その中でも特に効果が見込まれている手法として、「回答者が先ほど述べたことに基づいて、すぐに関連する質問を行う」という方法があります。対面のインタビューでは自然に行われるこのような追加質問を、オンラインアンケートにも組み込むことで、回答者が深く考えて答えられる環境を整えることが狙いです。

### チャットボットを用いる方法の課題

アンケートを改善するもう一つの試みとして、チャットボットの利用が注目されています。チャットボットとは、人間とコンピューターが自然な対話形式でコミュニケーションできるように開発されたプログラムのことです。  
これまで、チャットボットは顧客サポート、オンラインショッピング、健康相談、教育支援など、さまざまな場面で活用されてきました。チャットボットの大きな利点は、決まった画面のボタンやメニューではなく、自然な会話の流れに沿ってユーザーが自由に質問をしたり、意見を述べたりできる点です。

チャットボットがアンケートに利用された場合、回答者との間で自然な会話が生まれ、参加者がより深い内容を話してくれることが期待されています。実際に、これまでの研究から、チャットボットとのやり取りでは通常のアンケートよりも回答者が積極的に情報を提供したり、より誠実で詳しい回答をしたりすることが報告されています。  
チャットボットは人間の調査員とは違い、24時間いつでも即座に対応可能であるため、参加者が感じる心理的なハードルが下がり、話しにくいテーマでも抵抗なく話せることも利点です。

その一方で、チャットボットには回答者の発言内容を正確に理解し、適切な質問を返す難しさも存在しています。回答者が使う言葉や表現は多様であり、その全てを理解して自然に会話を進めることは容易ではありません。  
時には、チャットボットが意図を誤解してしまったり、不適切な返答を行ったりすることで、回答者が不快感を覚えるケースも報告されています。そのため、回答者の発言に対する適切な反応を可能にする技術的な工夫や設計が重要な課題となっています。

### インタビューでの追加質問（プローブ）とは？

インタビューでは、相手の話を深く掘り下げるために「プローブ」と呼ばれる追加質問が使われます。プローブをうまく使えば、相手の体験や考えを詳しく自然に引き出すことができます。

プローブには4つの種類があります。  
①「記述的プローブ」は、「その時どんなことがあったか？」などと、相手が自分の体験や感情を詳しく語れるように促します。  
②「個別的プローブ」は、「最近経験した具体的な例を教えてください」と質問し、話し手が実際にあった特定のエピソードを思い出し、より具体的に話せるよう手助けします。  
③「明確化プローブ」は、相手が曖昧な言葉を使った時に「それはどういう意味？」と聞き返すことで、相手の意図を明確に引き出します。  
④「説明的プローブ」は、「なぜそう感じましたか？」と尋ねることで、相手が自分の行動や感情の理由を掘り下げて話せるよう促します。

このようなプローブを使い分けることで、インタビューで得られる回答の質が高まります。今回研究者らは、LLMチャットボットによってこれらを使用する設計を考えています。

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_86808_1-1024x234.png)

調査の各段階（探索・要件収集・評価）でチャットボットが尋ねた質問の例

## アンケートに使えるLLMチャットボットの設計

チャットボットをアンケートに取り入れるには、特別な難しい技術は必ずしも必要ではありません。まずは、普段から使い慣れているアンケートツールに連携しやすいチャットボットシステム（本研究ではNext.jsを使用）を用意します。  
新たなアンケートを作るのではなく、既存のオンライン調査システムとチャットボットを連携させることで、回答者が特別な違和感なく使えるようになります。

### インターフェースを整える

チャットボットのインターフェース（見た目）は、複雑にしすぎないことが推奨されます。普段使っているメッセージアプリのように、シンプルな会話型のデザインが理想です。  
特別なキャラクターや凝った装飾はあえて使わず、質問内容に回答者が自然に集中できるような環境をつくりましょう。質問は一度に一つずつ表示し、回答もシンプルに送信できるように工夫すると、参加者の心理的な負担が軽減されます。

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_86808_2-1.png)

チャットボットとの実際の会話画面（インターフェースの具体例）

### 「適切な質問」をする

チャットボットが回答者の話をうまく引き出すためには、質問の生成方法がとても重要になります。本研究では「GPT-4o」を使用しましたが、LLMをそのまま使うと質問があいまいになったり、アンケートの目的からずれたりする恐れがあります。  
そのため、LLMチャットボットが適切な質問を生成するためには、質問の仕方や会話ルールを事前に明確に指示することが大切です。

そのためには、「質問は短くシンプルに、一つずつ提示する」「参加者の意見に対して中立的に反応し、批判や誘導をしない」といった基本ルールをLLMチャットボットに教えます。また、アンケートのテーマや会話の目的を事前にLLMチャットボットに明示的に伝えることで、質問が的確になりやすくなります。

### 「追加質問（プローブ）」を取り入れる

LLMチャットボットが相手の答えを深掘りするには、インタビュー技術の一つである「追加質問（プローブ）」を使います。具体的には、次の4つのプローブを使い分けることが勧められています。

**記述的プローブ**  
「そのとき何がありましたか？」など、回答者が自然に自分の経験を語れるような質問

**個別的プローブ**  
「最近実際に経験したことを教えてください」など、具体的なエピソードを話してもらう質問

**明確化プローブ**  
「それはどういう意味ですか？」と尋ね、曖昧な表現をはっきりさせる質問

**説明的プローブ**  
「なぜそう感じましたか？」と、理由や原因を掘り下げる質問

これらの質問パターンを事前に具体例とともにLLMチャットボットに教えておきます。

### 実践するポイントまとめ

アンケートでチャットボットを使うために意識するべきポイントは、次のように整理できます。

- 参加者が話しやすい、自然な会話形式のデザインを用意する。
- 質問は短く明確にし、一度に一つずつ提示する。
- LLMを使う際は、チャットボットが目的に合った質問をできるよう、明確なルールを事前に設定する。
- インタビューの追加質問（プローブ）のテクニックを活用し、回答者が自分の体験を自然に掘り下げられるようにする。

## 実験方法

本研究では、オンラインアンケートにチャットボットを取り入れた場合、質問の方法（プローブの種類）が参加者の回答の質や感じ方にどのように影響するかを調査しました。チャットボットが使った追加質問（プローブ）の種類は「記述的プローブ」「個別的プローブ」「明確化プローブ」「説明的プローブ」の4つで、それぞれの効果を比較しました。  
また、これらのプローブの効果がアンケート調査の一般的な3段階（探索段階・要件収集段階・評価段階）ごとに異なるかどうかも調べました。

### インタビューの3つの段階について

調査では、「探索段階」「要件収集段階」「評価段階」という3つの段階に分けてプローブの効果が調べられました。これは人間とコンピュータの相互作用（HCI）分野で一般的に使われる考え方です。

#### 探索段階

探索段階では、参加者が普段どのように技術を使っているか、またどのような問題や感情を持っているかを広く理解します。この段階で得られた情報が、その後の技術や製品の開発の基礎となります。

#### 要件収集段階

要件収集段階では、新しい技術や製品を作る際に必要な機能や特徴を明らかにします。参加者が現状の技術に感じている不満や、改善のための具体的なニーズを聞き出すことを目的とします。

#### 評価段階

評価段階では、実際に作成した技術や製品を参加者に使ってもらい、その使用感や問題点についての意見を集めます。ここで得られたフィードバックは、製品や技術の改善に直接活かされます。

### アンケートテーマ

本調査では、「テクノストレス」と呼ばれる、デジタル機器を使用することで感じるストレスがテーマとして選ばれました。スマートフォンやパソコンが日常生活に広く普及する中で、これらの機器を使うことによって感じられる精神的負担が注目されています。例えば、絶え間ない通知による心理的圧迫感などが知られており、身近で具体的なこのテーマは、チャットボットによる追加質問（プローブ）の効果を評価するために適切な題材として設定されました。

### 調査参加者の募集方法と特徴

調査参加者は、オンラインの調査プラットフォーム（Prolific）を通じて募集されました。参加条件として、回答精度95%以上であること、英語が母語であること、アメリカ合衆国在住であることが設定されました。また、回答が困難になるのを避けるため、デスクトップパソコンからの参加に限定されました。調査時間（約15分）に対し、報酬として3ドルが支払われています。最終的に64名が募集され、参加者は4つのプローブタイプにそれぞれ16名ずつ割り当てられました。

### 評価方法

調査では、以下の3つのポイントに基づいてチャットボットの効果が評価されました。本研究の仕組みを実践する際には、この評価アプローチも踏襲することも一つの手です。

#### （1）回答の質の評価

参加者が提供した回答内容について、どのくらい具体的で分かりやすく、また質問に適切であったかが評価されました。「回答に含まれる情報量」「具体性」「質問との関連性」「明確さ」という4つの観点から分析が行われました。

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_86808_3-1-1024x166.png)

会話型アンケートの質を分析するためのグライスの協調原理（Gricean Maxim）。これに基づいて上記の評価が行われた

#### （2）参加者の主観的な体験の評価

チャットボットとのやり取りについて、参加者がどのように感じたかを評価するため、「会話がスムーズだったか」「質問が役立ったか」「同じ質問が繰り返されたと感じたか」などの項目を使って参加者自身が評価しました。この評価は、標準化されたアンケート尺度（SEQ）を用いて測定されています。

#### （3）参加者からの自由記述による感想の分析

チャットボットを使ったアンケートに対する参加者の自由な意見や感想も収集されました。特に、「チャットボットの質問がどのように影響したか」「普段のアンケートと比べて感じた違いは何か」「チャットボットに話しやすいテーマ、話しにくいテーマは何か」など、参加者自身の言葉で詳しく記述してもらい、それらの意見が質的に分析されました。

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_86808_4-1-1024x233.png)

主観的体験評価（会話中に感じた役立ち感や繰り返し感など）に使われた質問項目の概要

### データ分析の方法

収集したデータは、大きく分けて以下の4つの視点で分析されました。

#### （1）回答の質の分析

参加者からの回答内容は、「情報量」「具体性」「的確さ」「明確さ」の4つの基準で評価されました。これらのデータは、統計的な手法（線形混合効果モデル）を使って分析され、質問プローブの種類や調査段階が回答の質に与えた影響を確認しました。

#### （2）参加者の体験評価の分析

参加者がチャットボットとの会話をどのように感じたか（スムーズさや役立ち感など）については、ART法（Aligned Rank Transform）という統計手法を使って分析しました。この分析により、使用したプローブの種類によって参加者の印象や体験がどのように異なったかが調べられました。

#### （3）自由記述回答の質的分析

参加者が自由に書いた感想については、共通の話題や特徴を整理し、テーマごとに分類しました。この質的な分析により、参加者がチャットボットを使ったアンケートについてどのように感じていたか、またその利点や改善点などが詳しく検討されました。

#### （4）会話パターンの探索的な分析

チャットボットとの会話ログ全体を見直し、どのような質問や回答のやり取りが起きていたかについて探索的に調べました。この分析は、チャットボットとの会話が実際にどのように進むのか、またプローブによる質問方法の違いが会話の流れにどう影響するかを具体的に把握する目的で実施されました。

## 実験結果

調査の結果、チャットボットによるアンケートの回答の質や参加者の印象は、追加質問（プローブ）の種類によって差が生じることが分かりました。

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_86808_5-1.png)

各プローブ条件でやりとりされたメッセージ数

### 回答の質に関する結果

チャットボットが行った追加質問（プローブ）の種類によって、参加者の回答の質に違いが生じました。ここでの「回答の質」とは、「情報量」「具体性」「的確さ」「明確さ」の4つの観点で評価されたものです。

「個別的プローブ（Idiographic）」や「記述的プローブ（Descriptive）」は、参加者が自分の体験をより具体的かつ自然に語ることを促し、他のプローブよりも質の高い回答を引き出しました。一方、「説明的プローブ（Explanatory）」は、理由や原因を繰り返し尋ねる形式のため、回答が抽象的になったり、回答者が負担を感じたりすることがあり、回答の質がやや低下しました。

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_86808_7-1024x327.png)

自由記述コメントから分析した、チャットボットに「話しやすいテーマ」「話しにくいテーマ」の分類と具体例を示した図

また、参加者がチャットボットとの会話をどのように感じたかという主観的評価（役立ち感や繰り返し感など）を比較したところ、プローブの種類間に差が見られました。中でも「説明的プローブ」は他のプローブよりも「質問が繰り返しに感じられる」という印象が強くなりました。反対に、「明確化プローブ（Clarifying）」は参加者にとって繰り返し感が少なく、比較的心地よい会話が行われました。

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_86808_8-1024x330.png)

使用したプローブ（記述的・個別的・明確化・説明的）の種類ごとに、参加者が提供した回答の質（情報量・具体性・的確さ・明確さ）を比較した結果を示したグラフ

さらに、参加者が自由記述で回答した感想の分析からは、チャットボットが通常のアンケートよりも回答を深く考えるきっかけを提供するという利点が明らかになりました。一方、一部の参加者は、特に説明的プローブを使った際に「質問が単調に感じられ、回答がつらくなった」と指摘しています。

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_86808_6-1-1024x506.png)

回答の質に関する分析結果（情報量・的確さ・具体性・明確さ）。各要因（プローブタイプや調査段階）ごとに、係数、標準誤差（括弧内）、有意性を示す。推定値の符号（＋／−）は、各要因と結果変数の関係の方向性を表す

実際の会話のパターンを分析すると、「個別的プローブ」や「記述的プローブ」を使用した場合、参加者が自然に自分の経験を掘り下げて語れるスムーズな会話の流れが多く見られました。これに対して、「説明的プローブ」を使った場合は、理由を何度も問う質問によって会話が停滞したり、参加者が回答に困惑したりする場面が多くなりました。

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_86808_10-1024x408.png)

インタビューの各段階（探索段階・要件収集段階・評価段階）における回答の質の分析結果

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_86808_9-1024x333.png)

使用したプローブの種類別に、参加者がチャットボットとの会話をどう感じたか（役立つと感じたか、質問が繰り返しに感じたか、押しつけがましいと感じたか）を比較した結果を示したグラフ

### 参加者の主観的な体験評価の結果

参加者がチャットボットとの対話をどのように感じたかを分析したところ、全体としては、質問タイプによる大きな違いは見られませんでした。ただし、「説明的プローブ」は「質問が繰り返されている」と感じられやすく、回答者の負担感がやや高まることが示されました。一方で、会話のスムーズさや、回答しやすさといった快適性に関しては、どのプローブでも概ね高評価でした。

### 自由記述による参加者の感想から得られた結果

参加者自身が自由に書いた感想からは、多くの人がチャットボットを使ったアンケートを「楽しい」「普通のアンケートよりも考えやすい」と肯定的に評価していることがわかりました。その理由として、自然な会話形式で質問されることで自分の考えを整理しやすかった点が挙げられています。しかし一部の参加者からは、会話が進むにつれて「同じような質問が繰り返されて疲れる」という指摘もありました。チャットボットを利用する場合は、質問が単調にならないような工夫が必要だと分かりました。

また、健康や人間関係など個人的な話題については、「チャットボットのほうが人間に比べて話しやすい」という意見がある一方で、「チャットボットには感情がないため深刻な話題を話しづらい」という意見もありました。参加者が話しやすいと感じるテーマによって、チャットボットの有効性が変わる可能性があることも示されています。

### チャットボットと参加者との会話パターンの特徴

会話のやり取りを詳しく分析すると、「個別的プローブ」や「記述的プローブ」を使った場合には会話が自然でスムーズに進む傾向がありました。一方、「説明的プローブ」では会話が停滞し、参加者が回答に困る場面が多く見られました。さらに、参加者がチャットボットを人間のように扱い、感情を込めて自然に対話するケースも多く確認されました。この結果から、チャットボットが自然な会話を生み出すためには、参加者が具体的なエピソードを話しやすい質問の仕方が特に重要だと考えられます。

![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_86808_11-1.png)

各プローブが、インタビューの3つの段階ごとに特に高い効果を示した評価指標のまとめ

## 研究から得られた示唆

今回の調査から、オンラインアンケートにチャットボットを導入する際には、質問方法（プローブ）の選び方が重要であることが分かりました。回答の質を高めるためには、参加者が自分の経験を具体的に語れるように促す質問が特に効果的です。  
例えば、「個別的プローブ」や「記述的プローブ」を使うと、回答者はより詳しく、かつ自然に体験を語れる傾向がありました。一方、「説明的プローブ」は、理由を繰り返し尋ねるため、参加者が疲れたり、回答が曖昧になったりする場合があり、使い方に注意が必要です。

また、チャットボットとの会話形式は、多くの参加者から「通常のアンケートよりも答えやすく、考えやすかった」と好意的な評価を受けました。ただし、質問が単調になった場合、参加者に負担感が生じる可能性も指摘されました。  
そのため、参加者が自然に会話を続けられるように、質問の繰り返しを避ける工夫や柔軟な質問設計が必要になります。

## まとめ

本記事では、オンラインアンケートにチャットボットを取り入れ、回答者がより具体的で深い回答をできるよう工夫した研究を紹介しました。

調査の結果、チャットボットの質問方法によって回答の質や参加者の体験に差が生じることがわかりました。

中でも「個別的プローブ（Idiographic）」を使った質問は、回答者が自分の経験を具体的かつ自然に話せるため効果的でした。一方、「説明的プローブ（Explanatory）」のように理由を繰り返し問う質問では、回答者が疲れたり会話が停滞したりする可能性も示されました。

回答者に応じて柔軟に調整する工夫が求められそうです。

**参照文献情報**

- タイトル：Chatbots for Data Collection in Surveys: A Comparison of Four Theory-Based Interview Probes
- URL： [https://doi.org/10.48550/arXiv.2503.08582](https://doi.org/10.48550/arXiv.2503.08582)
- 著者：Rune M. Jacobsen, Samuel Rhys Cox, Carla F. Griggio, Niels van Berkel
- 所属：Aalborg University

この論文は、 [ACM CHI 2025](https://chi2025.acm.org/) に採択されています。

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[エンジニアの個性やスタイルに合わせてLLMに説明の仕方を変えさせるのは有効か](https://ai-data-base.com/archives/86965)

[Microsoftの決算資料から読み解くクラウドとAIの価値トレンド](https://ai-data-base.com/archives/87164)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)