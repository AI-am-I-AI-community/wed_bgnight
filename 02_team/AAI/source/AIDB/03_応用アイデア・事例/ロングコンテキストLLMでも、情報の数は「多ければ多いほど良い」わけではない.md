---
title: "ロングコンテキストLLMでも、情報の数は「多ければ多いほど良い」わけではない"
source: "https://ai-data-base.com/archives/77127"
author:
  - "[[AIDB Research]]"
published: 2024-10-17
created: 2025-06-13
description: "本記事では、長い文脈を扱えるLLMをRAGシステムで活用する際の課題と可能性についての研究結果を紹介します。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、長い文脈を扱えるLLMをRAGシステムで活用する際の課題と可能性についての研究結果を紹介します。

より多くの関連情報を提供すればLLMの回答の質が向上すると考えられがちですが、実際にはそう単純ではないことが明らかになってきました。

そこで研究者たちは、長い文脈を扱えるLLMの特性を活かすための新しいアプローチの開発に取り組んでいます。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77127-1024x576.jpg)

**参照論文情報**

- タイトル：Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG
- 著者：Bowen Jin, Jinsung Yoon, Jiawei Han, Sercan O. Arik
- 研究機関：Google Cloud AI Research, University of Illinois at Urbana-Champaign

## 背景

RAGはLLMの能力を拡張する手法として注目されています。外部の知識ソースを活用して、より正確で信頼性の高い回答を生成できるようにする技術です。

さらに、最近登場しつつある「長い文脈を処理できるLLM」を使えば、RAGシステムで多くの情報を一度に取り込むことができます。一般的には、多くの情報をもとにすれば、LLMの回答の質が向上すると考えられがちです。

しかし、実際の長文脈LLMを用いたRAGシステムの設計については、まだ十分な研究がなされていません。

また、長文脈LLMの能力を評価するためのベンチマークは、実際のRAGシステムで直面する課題を十分に反映していないという問題もあります。

このような背景から、今回Googleなどの研究者たちは長文脈LLMを用いたRAGシステムの性能を詳細に分析し、その課題を明らかにする必要があると考えました。さらに、課題を解決するためのアプローチの開発に取り組みました。

以下で詳しく紹介します。

## RAGにおける長文脈LLMの課題

RAG（Retrieval-Augmented Generation）システムに長文脈LLMを利用するのはメリットばかりではありません。システムの効率性や性能に影響を与える可能性のある課題もあります。

### 課題１：検索された文脈の大きさがRAGの性能に与える影響

RAGシステムでは、適切な量の関連情報を提供することがとても重要です。単に多くの情報を与えれば良いというわけではありません。検索される文脈が大きすぎると、以下のような問題が生じる可能性があります。

1. モデルが重要な情報を見落としてしまう恐れがある
2. 関連性の低い情報が含まれることで、生成される回答の質が低下する可能性がある
3. 処理すべき情報量が増えることで、システムの応答時間が長くなる可能性がある

一方で、文脈が小さすぎると、以下のような問題が起こりかねません。

1. 必要な情報が不足し、適切な回答を生成できない可能性がある
2. 限られた情報に基づいて回答を生成するため、精度が低下する恐れがある

#### 最適な文脈サイズをどう見つけるか

RAGシステムの性能を最大化するためには、最適な文脈サイズを見つけることが重要です。以下のようなアプローチが取られています。

1. 異なる文脈サイズでシステムをテストし、最も高いパフォーマンスを示すサイズを特定する
2. クエリの複雑さや要求される情報の深さに応じて、文脈サイズを動的に調整する
3. 検索された情報を関連性や重要度でフィルタリングし、最も価値のある情報のみを提供する

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77127_1-1024x419.png)

4つの異なるLLMにおけるRAG性能への検索コンテキストサイズの影響を示す。検索数の増加が最初は性能を向上させるが、その後低下させることを示している。

#### 長文脈LLMの活用で得られる恩恵

長文脈LLMの登場により、より大きな文脈を扱えるようになりました。以下のようなメリットが得られています。

1. より多くの関連情報を一度に処理できるため、複雑なクエリにも対応しやすくなっている
2. 長い文脈を維持できるため、一貫性のある回答を生成しやすくなっている
3. より多くの情報を考慮できるため、回答の精度が向上する可能性がある

ただし、長文脈LLMを活用する際にも、適切な文脈サイズの選択は依然として重要な課題です。

### 課題２：検索品質とLLM能力の相互作用

RAGシステムの性能は、情報の検索品質とLLMの能力が密接に関連しています。両者のバランスが重要です。

#### 検索品質の重要性

高品質な検索システム（LLMに対してより適切な文脈を提供する）には、以下のような特徴があります。

1. ユーザーの質問に対して、最も関連性の高い情報を提供する
2. 必要な情報を漏れなく取得する
3. 最新の情報を提供する
4. 異なる視点や側面からの情報を提供する

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77127_2-1024x419.png)

Gemma-2-9B-ChatとE5およびBM25リトリーバーを使用した際のRAG性能と検索品質の関係を分析。

#### LLM能力の影響

提供された文脈をより効果的に活用し、質の高い回答を生成する高性能なLLMは、以下のようなものです。

1. 与えられた文脈を正確に理解し、解釈する
2. 文脈から適切な推論を行い、新しい知識を生成する
3. 自然で流暢な文章を生成する
4. ノイズや不完全な情報にも対応できる

#### 検索品質とLLM能力のバランス

RAGシステムの最適な性能を実現するためには、検索品質とLLM能力のバランスが重要です。

考えられる組み合わせごとに特徴を整理していきます。

（１）高品質な検索 + 高性能LLM  
理想的な組み合わせで、最も高い性能が期待できます。関連性の高い情報が提供され、LLMがそれを効果的に活用します。

（２）高品質な検索 + 低性能LLM  
良質な情報が提供されても、LLMがそれを十分に活用できない可能性があります。システム全体の性能は、LLMの能力に制限されます。

（３）低品質な検索 + 高性能LLM  
LLMの高い能力を活かしきれない状況です。不適切または不十分な情報に基づいて回答が生成される恐れがあります。

（４）低品質な検索 + 低性能LLM  
システム全体の性能が大きく低下する可能性があります。不適切な情報と低い処理能力の組み合わせにより、誤った或いは的外れな回答が生成されるリスクが高まります。

#### システム最適化の方向性

RAGシステムの性能を向上させるためには、3つの施策があります。

（１）検索システムの改善  
より関連性の高い情報を効率的に抽出する技術の開発。検索アルゴリズムの精度向上。

（２）LLMの能力強化  
より大規模なモデルの開発。特定のタスクに特化した事前学習やファインチューニングの実施。

（３）検索とLLMの統合最適化  
検索結果の品質に応じてLLMの振る舞いを調整する機能の実装。LLMのフィードバックを活用した検索システムの改善。

### 課題３：長文脈LLM評価における「ハードネガティブ」の重要性

長文脈LLMの評価において、「ハードネガティブ」と呼ばれる特殊なテストケースが非常に重要な役割を果たしています。以下、「ハードネガティブ」とは何かを見ていきます。

#### ハードネガティブとは

1. 一見すると質問に関連しているように見えますが、実際には正しい答えを含んでいない
2. 正しい情報に非常に似ているが、微妙に異なる情報を含んでいる
3. モデルに高い理解力と判断力を要求する

以上から、LLMの能力を厳密にテストする上で非常に有効なツールとなっています。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77127_3-1024x312.png)

長文脈LLMに対するハードネガティブの影響を評価。異なるリトリーバーの性能と、それらが生成するハードネガティブのLLMへの影響を示す。

#### ハードネガティブの重要性

ハードネガティブが長文脈LLMの評価において重要視される理由には、以下のようなものがあります。

（１）精度の厳密な測定  
簡単な例だけでは、モデルの真の能力を測ることができません。ハードネガティブを用いることで、モデルの限界をより正確に把握できます。

（２）過剰自信の検出  
LLMが誤った情報に対して高い確信度を示す傾向（過剰自信）を明らかにします。モデルの信頼性を評価する重要な指標となります。

（３）文脈理解能力の評価  
長い文脈の中から本当に関連する情報を見分ける能力を測定します。単に情報を羅列するのではなく、適切に解釈し活用する能力を評価できます。

（４） [ロバスト](https://ai-data-base.com/archives/26590 "ロバスト") 性の検証  
紛らわしい情報が存在する状況下でのモデルの性能を確認できます。実世界の複雑な状況により近い条件でテストすることができます。

#### ハードネガティブの設計と活用

ハードネガティブを効果的に活用するためには、以下のような点に注意が払われます。

（１）慎重な設計  
専門家の知識を活用し、本当に「難しい」ネガティブ例を作成します。単なる誤情報ではなく、微妙な違いを含む例を設計します。

（２）多様性の確保  
さまざまな分野や文脈でハードネガティブを用意します。モデルの汎用的な能力を評価するためです。

（３）段階的な難易度  
簡単なネガティブ例から非常に難しい例まで、段階的に難易度を上げていきます。モデルの能力の限界を正確に把握することが目的です。

（４）継続的な更新  
モデルの進化に合わせて、ハードネガティブも更新していきます。常に最新のモデルを適切に評価するためです。

ハードネガティブの活用は、長文脈LLMの評価において今後さらに重要性を増すと考えられています。

## 簡単で効果的で訓練不要、RAGの改善方法

RAGシステムを改善するには、複雑な訓練プロセスが必要とされることも多いです。しかし、今回研究者らは追加の訓練を必要としない、シンプルかつ効果的な改善方法を考案しています。

### 一つ目の方法　コンテキスト圧縮の活用

RAGシステムの性能を向上させる一つの方法として、コンテキスト圧縮が挙げられます。以下の観点で行います。

（１）情報の凝縮  
検索された情報から最も重要な部分を抽出します。冗長な情報や不要な詳細を削減します。

（２）スペースの有効活用  
LLMに与えられる文脈のスペースを効率的に使用します。より多くの関連情報を含めるためです。

（３）ノイズの削減  
関連性の低い情報を除去することで、LLMの判断をより正確にします。誤った情報に惑わされるリスクを低減します。

### 二つ目の方法　プロンプトエンジニアリングの最適化

プロンプトの設計を工夫することで、RAGシステムの性能を大きく向上させることができます。以下が基本的なテクニックになります。

（１）明確な指示  
LLMに対して、タスクの目的や期待される出力を明確に指示します。曖昧さを排除し、モデルの理解を助けます。

（２）関連情報の強調  
検索された情報の中で、特に重要な部分を強調します。LLMがより適切に情報を活用できるようにするためです。

（３）構造化されたプロンプト  
情報を整理し、論理的な順序で提示します。LLMが情報をより効果的に処理できるようにするためです。

### 三つ目の方法　反復的なアプローチの導入

単一の回答を生成するのではなく、複数のステップを経て回答を洗練させていく方法もあります。

1. まず、基本的な回答を生成する
2. 回答の分析と改善 初期回答を分析し、不足している情報や改善点を特定する
3. 必要に応じて追加の情報検索を行う
4. 回答の洗練 新たな情報や分析結果に基づいて、回答を改善する

このプロセスを複数回繰り返すことで、より質の高い回答を生成します。

### 四つ目の方法　リランキングの活用

検索結果のリランキング（再順位付け）を行うことで、より適切な情報をLLMに提供することができます。以下はリランキングの特徴です。

（１）関連性の再評価  
LLMを用いて、検索結果の関連性を再評価します。より質問に適した情報を優先的に使用します。

（２）多様性の確保  
類似した情報の重複を避け、多様な視点を含めます。より包括的な回答を可能にするためです。

（３）動的な調整  
質問の内容や複雑さに応じて、リランキングの基準を調整します。各質問に最適化された情報選択を可能にすることが目的です。

これらの改善策を組み合わせることで、RAGシステムの性能を大幅に向上させることができ、より正確で関連性の高い回答を生成することが可能になると考えられています。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77127_4-1024x473.jpg)

様々なRAG構成における検索結果の並べ替えの効果を評価。特に検索数が多い場合に性能が向上することを示す。

## ファインチューニングでRAGを強くする

次に、LLMベースのRAGシステムの性能を向上させる方法として、微調整（ファインチューニング）の重要性が提唱されています。

微調整は、事前学習済みのLLMを特定のタスクや領域に適応させるプロセスです。以下のような効果があります。

（１）タスク特化型の適応  
モデルを特定のタスクや領域に特化させることで、そのタスクにおける性能が向上します。例えば、医療分野の質問応答に特化させることで、医療関連の質問に対する回答の精度が高まります。

（２）ドメイン知識の統合  
特定分野の専門知識をモデルに組み込むことができます。すると、その分野に関する質問に対して、より深い理解に基づいた回答が可能になります。

### その１　堅牢性を強くする

#### “堅牢性”の改善

微調整プロセスを通じて、LLMの”堅牢性”が向上することが分かっています。堅牢性とは、モデルが様々な入力や状況に対して安定して高い性能を発揮する能力を指します。安定性と近いニュアンスかと考えられます。

（１）多様なデータに適応  
微調整の過程で、モデルはより多様なデータや事例に触れることになります。その結果、様々な形式の入力や質問に対応する能力が向上します。

（２）エラーパターンの学習  
微調整データに含まれる誤りや難しい事例を通じて、モデルは一般的なエラーパターンを学習します。そのため似たような状況での誤りを回避する能力が培われます。

（３）文脈理解の深化  
特定のドメインに関する微調整を通じて、モデルはその分野特有の文脈や言い回しをより深く理解するようになります。曖昧な質問や複雑な文脈においても適切に対応できるようになります。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77127_5.jpg)

RAG特有のデータで微調整したLLM（RAG FT）の汎化能力を示す。RAG FTが既存のチャットLLMや直接微調整したモデルを一貫して上回ることを示す。

#### 具体的な改善例

微調整によるLLMの堅牢性向上は、以下のような形で現れます。

- 不完全な情報や誤字脱字を含む質問に対しても、正確な回答を生成できるようになる
- 関連する複数の質問に対して、矛盾のない一貫した回答を提供できるようになる
- 情報が不足している場合や、確実な回答ができない状況において、適切に不確実性を表現できるようになる

### 注意点と課題

微調整には、いくつか注意しなければいけないことがあります。

（１） [過学習](https://ai-data-base.com/archives/26427 "過学習") のリスク  
特定のデータセットに過度に適応してしまい、汎用性が失われる可能性があります。これを防ぐためには、多様なデータを用いた慎重な微調整が必要です。

（２）バイアスの増幅  
微調整データにバイアスが含まれている場合、そのバイアスが増幅される可能性があります。データの選択と前処理に十分な注意を払う必要があります。

（３）計算リソースの要求  
高品質な微調整には、大量のデータと計算リソースが必要となる場合があります。効率的な微調整手法の開発が課題となっています。

### その２　関連性識別の強化

LLMが情報の関連性をより正確に識別できるようにするための方法として、推論能力の強化が挙げられています。ここでは推論拡張と言い換えています。

#### 推論拡張とはなにか

RAGシステムでは、検索された情報が質問に本当に関連していることが重要です。「推論拡張」は、この判断をより正確に行うための方法です。

推論拡張を行うことができれば、キーワードの一致だけでなく、文脈や意味的な関連性を理解することで、より深い次元での関連性判断を行えるようになります。また、質問と情報の間に直接的な関連がない場合でも、論理的な推論を通じて関連性を見出すことができます。

### 推論拡張の手法

いくつかの手法が提案されています。

（１）段階的推論プロセス  
複雑な問題を小さなステップに分解し、各ステップで推論を行います。すると、より透明で追跡可能な推論プロセスが実現します。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77127_6.png)

RAG微調整LLMの性能に対する中間推論の影響を評価。中間推論ステップを含む微調整（RAG FT w. Int）が更なる改善をもたらすことを示す。

（２）自己質問戦略  
LLMが自身に対して質問を投げかけ、それに答えることで推論を深めていきます。すると、より多角的な視点から問題を検討することができます。

（３）外部知識の統合  
LLMの内部知識だけでなく、外部の知識ベースや最新の情報源を活用して推論を行います。より広範囲で最新の情報に基づいた判断が可能になります。

#### 関連性識別の改善例

推論拡張による関連性識別の改善は、以下のような形で現れます。

（１）間接的な関連性の発見  
一見無関係に見える情報でも、推論を通じてその重要性を見出すことができるようになります。例えば、歴史的な出来事と現代の問題の間の類似性を発見するなど。

（２）文脈依存の関連性理解  
同じキーワードでも、文脈によって異なる意味を持つ場合があります。そのような場合もより正確に理解できるようになります。

（３）多段階の関連性チェーン  
直接的な関連性がなくても、複数のステップを経て関連性を見出すことができます。より複雑な質問に対しても適切な情報を提供できるようになります。

#### 実装上の課題と解決策

推論拡張を組み込む際には、いくつか課題があります。

（１）計算コストの増加  
複雑な推論プロセスは、処理時間とリソースの増加を招く可能性があります。これに対しては、効率的なアルゴリズムの開発や、必要に応じて推論の深さを調整する方法が検討されます。

（２）過剰推論のリスク  
推論を過度に行うと、関係のない情報を誤って関連付けてしまう危険性があります。これを防ぐためには、推論の信頼度を評価し、一定のしきい値を設ける方法などが採用されています。

（３）説明可能性の確保  
複雑な推論プロセスは、その判断根拠を人間が理解しにくくなる可能性があります。これに対しては、推論の各ステップを明示的に示す「推論チェーン」の可視化技術が開発されています。

### RAGのためのLLM微調整における「データ中心」アプローチとは

LLMの性能向上において、モデルの構造や学習アルゴリズムの改善だけでなく、使用するデータの質と量が極めて重要であるという認識が広まっています。

単に大量のデータを用いるだけでなく、高品質で適切なデータを使用することが、効果的な微調整につながります。また、様々な種類の質問や文脈を含む多様なデータセットを使用することで、モデルの汎用性が向上します。

#### 効果的なデータセット作成の方法

RAGシステムのためのLLM微調整に適したデータセットを作成するには、以下のような方法が提案されています。

- 対象分野の専門家が監修したデータセットを使用する
- LLMを使って大量のデータを自動生成し、それを人間がチェックして精選する
- 実際のユーザーから寄せられた質問や要求を分析し、それに基づいてデータセットを構築する

#### データ拡張技術の活用

限られたデータをより効果的に活用するために、以下のようなデータ拡張技術が使用されています。

（１）パラフレージング  
同じ意味を持つ異なる表現を生成することで、モデルの言語理解の幅を広げます。

（２）難易度の調整  
簡単な質問から複雑な質問まで、段階的に難易度を上げたデータセットを作成します。そうするとモデルの能力を段階的に向上させることができます。

（３）ノイズの導入  
意図的に誤字や曖昧な表現を含むデータを追加することで、実際の使用環境での堅牢性を向上させます。

#### データセットの評価と改善

効果的なデータセットの構築には、以下のように継続的な評価と改善が必要です。

- 精度、関連性、多様性などの観点から、データセットの質を評価するための指標を設定する
- モデルが誤った回答を生成した事例を詳細に分析し、データセットの弱点を特定する
- 新しい情報や傾向を反映させるため、定期的にデータセットを更新する

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77127_7.png)

(a)訓練データ分布の影響、(b)リトリーバーの選択の影響、(c)最適な訓練パッセージ数の調査結果を示す。

#### 倫理的配慮とバイアス軽減

データ中心アプローチにおいては、倫理的な側面にも十分な注意が払われています。

たとえば、

- 様々な文化、背景、視点を反映したデータを含めることで、モデルの公平性を高める
- データセット内のバイアスを積極的に特定し、それを軽減するための措置を講じる
- 個人情報を含むデータの取り扱いに細心の注意を払い、必要に応じて匿名化やデータの加工を行う

などが挙げられます。

## まとめ

本記事では、長い文脈を扱えるLLMを用いたRAGシステムに関する研究を紹介しました。

まず、取得する情報量を増やすことが必ずしもRAGシステムの性能向上につながらないという課題がありました。研究者たちは、この課題に対処するため、3つのソリューションを提案しました。1つ目は検索結果の並べ替え、2つ目はLLMの微調整、3つ目は中間推論を含むRAG指向の微調整です。

今後は、より高度な検索結果の並べ替え方法の探索や、より細かな推論チェーンを用いたLLMの微調整など、さらなる研究の発展が期待されます。

- 参照論文URL： [https://arxiv.org/abs/2410.05983](https://arxiv.org/abs/2410.05983)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[OpenAIのo1-previewモデル、Kaggleのグランドマスター基準を上回るデータ分析性能を発揮](https://ai-data-base.com/archives/77077)

[「o1-preview」は自己評価メカニズムを持つ　計画立案中に自分の行動をチェックして修正](https://ai-data-base.com/archives/77179)　

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)