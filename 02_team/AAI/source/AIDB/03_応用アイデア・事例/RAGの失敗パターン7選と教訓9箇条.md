---
title: "RAGの失敗パターン7選と教訓9箇条"
source: "https://ai-data-base.com/archives/69154"
author:
  - "[[AIDB Research]]"
published: 2024-05-16
created: 2025-06-13
description: "研究者らは、RAGの7つの失敗パターンを報告しています。また、システムの設計時に考慮すべきポイントを整理しました。今後の研究開発における方向性も提案しています。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

研究者らは、RAGの7つの失敗パターンを報告しています。また、システムの設計時に考慮すべきポイントを整理しました。今後の研究開発における方向性も提案しています。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69154_thum-1024x576.jpg)

**参照論文情報**

- タイトル：Seven Failure Points When Engineering a Retrieval Augmented Generation System
- 著者：Scott Barnett, Stefanus Kurniawan, Srikanth Thudumu, Zach Brannelly, Mohamed Abdelrazek
- 所属：Applied Artificial Intelligence Institute

**本記事の関連研究** ：

- [小さなRetrieverとLLMの組み合わせによる実用的なワークフロー生成システム　またはRAGで幻覚を減らす手法](https://ai-data-base.com/archives/68219)
- [RAG（検索拡張生成）において約半分のトークン数でタスクを実行できるフレームワーク『FIT-RAG』](https://ai-data-base.com/archives/66427)
- [RAGにおいてLLMが「役立たない情報を無視」できるようにする『RAFT』QAタスクで従来の手法を大幅に上回る結果を達成](https://ai-data-base.com/archives/66269)
- [RAGにおいて取得された情報と事前知識が矛盾しても、情報に説得力があるときLLMは受け入れる](https://ai-data-base.com/archives/64979)

## 背景

LLMは最新の知識や特定のドメインの知識を持ち合わせていないことがあります。この問題に対処するには、LLMをファインチューニング（追加学習）するか、検索拡張生成（RAG）を用いるかの2つの選択肢があります。

ファインチューニングは、特定のドメインのデータを使ってLLMを再学習させる方法です。  
一方、RAGは、LLMを再学習させずに、検索システムと組み合わせて利用する方法です。ユーザーの質問に関連する情報を検索し、その情報をLLMに渡して回答を生成します。

RAGシステムは、すぐに利用可能であるというメリットがあります。また、検索対象のドキュメントを更新することで、最新の知識を反映させることができます。しかし一方で、情報検索システム特有の課題があることが指摘されています。例えば、クエリの書き換えや、ドキュメントの再ランク付けなどです。また、正確さの評価が難しいという課題もあります。

今回研究者らは、RAGシステムの実装における課題を明らかにすることを目的として調査を行いました。3つのケーススタディを通じて、RAGシステムを構築する際に直面する7つの失敗パターンと9つの教訓、そして今後の研究課題を整理しています。

## RAGとは

RAGは、LLMの生成能力と情報検索技術を組み合わせたアプローチです。ユーザーの質問に対して、関連するドキュメントを検索し、その情報をLLMに渡して回答を生成します。LLMの知識不足や事実と異なる生成（ハルシネーション）の問題を緩和することが期待されています。

システムは大きく分けて「インデックス処理」と「クエリ処理」の2つの処理から構成されています。

### インデックス処理

まずドキュメントを小さなチャンク（断片）に分割します。チャンクは、埋め込みモデル（Embeddingモデル）を用いてベクトル表現に変換されます。埋め込みは、数値のベクトルとして表現され、チャンクの意味的な特徴を捉えています（技術的にはそうあるべきです）。チャンクと埋め込みは、データベースにインデックス化されます。

チャンクをどのように分割するか、チャンクサイズをどの程度にするかなどの設計が重要になります。チャンクが小さすぎると特定の質問に答えられなくなる一方、大きすぎると生成される回答にノイズが混入する可能性があります。

### クエリ処理

クエリの処理は、システムを実行する時に行われます。ユーザーが自然言語で入力した質問は、まず一般的なクエリに変換されます。この変換は、LLMが行います。過去の対話履歴などの追加の文脈を考慮することもできます。

変換されたクエリから埋め込みが計算され、データベースから関連するドキュメントが検索されます。検索では、コサイン類似度などの類似度尺度を用いて、クエリとの意味的な近さが上位のドキュメントが抽出されます。

検索されたドキュメントは、回答が含まれる可能性が高いチャンクが上位にくるように並び替えられます。

次に、チャンクを処理するConsolidator（統合器）が登場します。LLMのトークン数制限やレート制限といった制約を考慮しながら、チャンクを処理します。

最後に、生成されたテキストから回答を抽出するReaderが登場します。Readerは、ノイズを除去し、フォーマットの指示に従い、クエリに対する最終的な出力を生成します。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69154_1-1024x366.jpg)

RAGシステムのインデックス処理とクエリ処理の概要

## 事例

本研究では、RAGシステムの実装における課題を明らかにするために、3つの事例研究が行われました。

以下、各事例を説明します。

### 事例1：Cognitive Reviewer

研究者が科学論文を分析するためのRAGシステムです。ユーザーは研究の目的や質問を指定し、関連する論文を提供します。システムは論文をランク付けし、研究者がレビューしやすいように提示します。また、研究者は論文に対して直接質問することもできます。

システムは実行時にインデックス処理を行います。アップロードされる文書の品質を事前に管理できないためです。また、文書のランク付けにも独自のアルゴリズムが使用されています。

### 事例2：AI Tutor

学生が授業内容について質問し、学習コンテンツから回答を得られるRAGシステムです。学生は、回答の根拠となった情報源にアクセスすることで、回答を検証することもできます。

システムとしては、まず大学の学習管理システムと連携し、PDF文書、動画、テキスト文書などの学習コンテンツをインデックス化します。動画については、音声を抽出し、テキストに変換する前処理が行われます。

なお2023年8月から11月にかけて開発され、同年10月30日から200人の学生を対象とした試験運用が行われています。システムの実装から得られた教訓を共有し、試験運用の結果が追って報告される予定です。

### 事例3：BioASQ

バイオメディカル分野の大規模なRAGシステムの事例です。質問、文書へのリンク、回答からなるBioASQデータセットを用いて、4,017件の公開文書と1,000件の質問に対するRAGシステムが構築されています。

生成された回答は、OpenAIの評価手法を用いて評価されました。この自動評価は、人手による評価よりも厳しい結果となる傾向がありました。なお評価者がドメインの専門家ではなかったことには注意が必要です。

## RAGシステムの失敗パターン

上記の事例研究を通じて、RAGシステムには以下の7つの失敗パターンが考えられると明らかになりました。

### 失敗パターン1: 情報の欠如

ユーザーの質問に対して、システムが利用可能な文書から回答を見つけられない場合です。RAGシステムは「わかりません」と答えるべきですが、関連する情報が不足しているにもかかわらず、回答を生成してしまうことがあります。

### 失敗パターン2: 上位のドキュメントを見逃す

ユーザーの質問に対する回答は文書に存在するものの、検索で上位にランク付けされず、ユーザーに提示されない場合です。理論的には、関連する全ての文書がランク付けされ、後続の処理に用いられるべきですが、実際には、パフォーマンスを考慮して上位K件のドキュメントのみが使用されることが多いです。

### 失敗パターン3: 文脈の欠如（統合の失敗）

検索で関連するドキュメントは見つかったものの、回答を生成するためのコンテキストとして使用されなかった場合です。多数のドキュメントが検索された際に統合する処理が適切でない場合に起こります。

### 失敗パターン4: 回答の抽出失敗

回答はコンテキストの中に存在しているものの、LLMがそれを正しく抽出できない場合です。コンテキストにノイズや矛盾する情報が多く含まれている場合などに発生します。要するに、プロンプトを正しく処理できないケースです。

### 失敗パターン5: 出力フォーマットの不一致

表や箇条書きなど、特定のフォーマットで情報を抽出するように求められた質問に対して、LLMがその指示を無視してしまう場合です。

コンテキストに含まれる情報と期待される出力形式が大きく異なり、変換のエラーが起きてしまうのだと考えられます。

### 失敗パターン6: 回答の詳細度の不適合

回答は生成されたものの、細かすぎる、または抽象的すぎる場合です。システムの設計者が特定の質問に対して期待する回答の詳細度の設計とユーザーの期待が一致しないときに起こります。また、ユーザーが質問の仕方を適切にできていないときにも発生します。

### 失敗パターン7: 不完全な回答

生成された回答が間違ってはいないものの、文脈中に存在する情報の一部が抜け落ちている場合です。例えば、「文書A、B、Cの要点は何ですか？」という質問に対して、これらの文書を個別に尋ねる方が良い結果が得られるかもしれません。

## 教訓

逆に、3つの事例研究から得られた主な教訓は以下の通りです。

1. 文脈のサイズを大きくすることで、回答の正確さが向上する傾向にある。
2. [セマンティック](https://ai-data-base.com/archives/26143 "セマンティック") キャッシュを活用することで、応答時間とコストを削減できる。
3. LLMの安全性検証は、RAGシステムにおいても重要である。
4. メタデータの追加により、検索性能が向上する。
5. オープンソースの埋め込みモデルは、小規模なテキストデータに対して有効である。
6. RAGシステムは継続的なキャリブレーションが必要である。
7. RAGシステムの設定は、パイプラインとして管理すべきである。
8. 個別のモジュールを組み合わせたRAGシステムは、エンドツーエンドの学習に比べて性能が劣る。
9. RAGシステムの性能評価は、運用時にしか行えない。

なお4におけるメタデータは、ファイル名やチャンク番号、ドキュメントタイプ、日時などの情報を指します。

## 今後の研究の方向性

事例研究から得られた知見をもとに、以下の3つの研究領域が提案されました。

### 1\. チャンク化と埋め込み

ドキュメントのチャンク化は一見単純な処理ですが、その品質が検索性能に大きく影響を与えます。チャンク化の方法には、ヒューリスティックベース（句読点や段落の終わりなどを利用）と、意味的なまとまりを考慮する方法があります。手法の長所と短所を体系的に評価することが求められています。

また、表、図、数式などを含むマルチモーダルなチャンクに対する埋め込み手法の研究も重要です。さらに、クエリの前処理も、RAGシステムの性能に大きな影響を与えます。否定表現や曖昧な表現をどのように扱うかは重要なテーマです。

### 2\. RAGとファインチューニングの比較

LLMをファインチューニングする方法と、RAGを用いる方法は、それぞれ長所と短所があります。ファインチューニングは、ドメイン固有のデータを用いてLLMを適応させますが、データの管理やプライバシーの問題があります。一方、RAGは即座に利用可能ですが、検索と統合の戦略が重要になります。

両者を、正確性、応答時間、運用コスト、堅牢性などの観点から体系的に比較する研究が求められています。

（編集部注：次の研究事例が参考になります。 [ファインチューニングとRAGを比較実験した結果　LLMに外部知識を取り入れる手法としての違い](https://ai-data-base.com/archives/63401) ）

### 3\. RAGシステムのテストとモニタリング

RAGシステムの品質保証に対しては、従来のソフトウェア工学の方法論だけでは不十分です。本来はドメイン固有の質問と回答のペアを用いたテストが必要ですが、そのようなデータは事前に用意されていないことが多いです。LLMを用いて質問と回答のペアを自動生成する研究は始まっていますが、現実的なデータを生成することは容易ではありません。

また、RAGシステムの性能を評価するための指標も必要です。LLMの性能は日々更新されるため、システムの継続的なモニタリングが不可欠です。

## まとめ

本記事では、Retrieval Augmented Generation（RAG）システムの実装における課題を明らかにした研究を紹介しました。

RAGシステムは、LLMと情報検索技術を組み合わせることで、質問応答の性能を向上させる手法です。その実装には、チャンク化、埋め込み、検索、統合など、各ステップで課題があります。

今回研究者らは、3つの事例研究を通じて、RAGシステムの実装における7つの失敗パターンを整理しました。失敗要因は情報検索とLLMに固有の課題に大別でき、さらに、事例研究から得られた教訓をもとに、今後の研究の方向性として、チャンク化と埋め込み、RAGとファインチューニングの比較、テストとモニタリングの3つの領域が提案されました。

LLMアプリケーションとして大きく注目されるRAG技術における知見を深める上で有用な研究報告だったかと思います。

- 参照論文URL： [https://arxiv.org/abs/2401.05856](https://arxiv.org/abs/2401.05856)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[ChatGPTの「初頭効果」について](https://ai-data-base.com/archives/69101)

[スタンフォード大学の研究者ら、GPT-4oとGemini1.5 Proで「マルチモーダルモデルにおける『Many-Shot』の効果」を検証](https://ai-data-base.com/archives/69211)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)