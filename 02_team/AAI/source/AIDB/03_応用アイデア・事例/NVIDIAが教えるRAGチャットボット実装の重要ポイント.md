---
title: "NVIDIAが教えるRAGチャットボット実装の重要ポイント"
source: "https://ai-data-base.com/archives/72680"
author:
  - "[[AIDB Research]]"
published: 2024-07-12
created: 2025-06-13
description: "本記事では、NVIDIAによるRAGベースのLLMチャットボット構築の調査研究を紹介します。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、NVIDIAによるRAGベースのLLMチャットボット構築の調査研究を紹介します。

研究者らは自社の開発事例に基づいて、RAGチャットボット構築においてコンテンツの鮮度・ [アーキテクチャ](https://ai-data-base.com/archives/26562 "アーキテクチャ") ・コスト・テスト・セキュリティの5つに着目し、それらをフレームワーク『FACTS』としてまとめています。

また、RAGパイプラインの15の制御ポイントと最適化技術、LLMの精度と応答時間のトレードオフに関する分析結果も整理されています。

企業のAIチャットボット導入における実践的なガイドラインとして提供されています。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_72680-1024x576.jpg)

**参照論文情報**

- タイトル：FACTS About Building Retrieval Augmented Generation-based Chatbots
- 著者：Rama Akkiraju, Anbang Xu, Deepak Bora, Tan Yu, Lu An, Vishal Seth, Aaditya Shukla, Pritam Gundecha, Hridhay Mehta, Ashwin Jha, Prithvi Raj, Abhinav Balasubramanian, Murali Maram, Guru Muthusamy, Shivakesh Reddy Annepally, Sidney Knowles, Min Du, Nick Burnett, Sean Javiya, Ashok Marannan, Mamta Kumari, Surbhi Jha, Ethan Dereszenski, Anupam Chakraborty, Subhash Ranjan, Amina Terfai, Anoop Surya, Tracey Mercer, Vinodh Kumar Thanigachalam, Tamar Bar, Sanjana Krishnan, Samy Kilaru, Jasmine Jaksic, Nave Algarici, Jacob Liberman, Joey Conway, Sonu Nayyar, Justin Boitano
- 所属：NVIDIA

## 背景

従来の企業向けチャットボットは、単に情報検索の延長線上にありました。それでも、人事関連の問い合わせや、ITサポート、営業に関する質問、エンジニアリングの課題など、幅広い分野で活用されてきました。とはいえ、2022年11月にOpenAIのChatGPTが登場するまでは、企業内で開発されたチャットボットは対話フローに基づくものが主流でした。

そのころの（つまり初期の）チャットボットには、下記のような課題があったといいます。

1. ユーザーメッセージの意図理解のために広範な学習が必要
2. 応答生成には綿密な調整が求められる
3. 限定的な回答しか提供できない
4. システムの脆弱で安定性に欠けている
5. 企業での広範な使用に必要な精度、堅牢性、信頼性が不足している

そしてChatGPTの登場は、チャットボットの世界に革命をもたらしました。以下の要素も深く関係しています。

- ベクトルデータベースの出現
- 検索拡張生成（RAG）の普及

つまり複数の技術の組み合わせがシステムの能力向上につながったと考えられています。  
LLMとRAGが結びついたことにより、以下のような変化が起きました。

1. 自然言語で意図が理解できるため、複雑な意図変数の学習が不要になった
2. 会話能力の向上によりコンテンツの一貫した合成が実現した
3. ユーザーからの質問に対して、一貫性があり、事実に基づいた論理的な応答を構築できるようになった
4. クトルデータベースを活用した情報検索により、最新のコンテンツを取り込むことが可能になった

また、LangChainやLlamaindexなどのツールが登場したことも大きいです。複雑なワークフローの調整、メモリ管理、エージェントの実装、プロンプトテンプレートの作成が容易になりました。

そうしてChatGPT以降の時代における生成AIチャットボットの基盤ができてきたのです。

そんな中、NVIDIAでは、従業員の生産性向上を目的として企業チャットボットの開発に着手してきました。そして、その過程で多くの壁に直面したようです。結局のところChatGPT以降の時代においても、優れた企業向けチャットボットの構築には様々な困難が伴うことが明らかになりました。

彼らが考える主な課題は以下の通りです。

1. RAGパイプラインの精密な設計
2. LLMの微調整
3. プロンプトエンジニアリング
4. 企業知識の関連性と正確性の確保
5. ドキュメントアクセス権限の遵守
6. 簡潔な応答
7. 適切な参照
8. 個人情報の保護

上記の課題に対処するには、慎重な設計と熟練した実装、そして徹底的な評価が必要であり、多大なる反復が求められます。速度とコスト効率を最適化しつつ、ユーザーエンゲージメントを維持することも重要です。

彼らは、「企業における会話型バーチャルアシスタントを適切に実現することは、完璧な交響曲を奏でるようなものだ」と言います。つまり、すべての要素が重要な意味を持っています。

以下でそんなNVIDIAの語るRAGチャットボット実装のコツに関する話を詳しく見ていきます。

## NVIDIAにおけるチャットボット開発事例

まずは彼らがRAGチャットボット開発においてどのような事例を持つのか、その背景から見ていきます。

### 企業コンテンツの多様性

NVIDIAの企業コンテンツには、権威のある知識と非権威的なコンテンツの両方があります。権威ある内容には以下が含まれます。

1. ITヘルプ記事
2. ServiceNowプラットフォーム上のHRリソース
3. Confluence、SharePoint、Google Drive上のプロジェクト文書
4. NVBugsやGitHubなどのエンジニアリングツール上の情報

また、従業員がSlackやMS Teams上に作成したコンテンツも、上記を補完するものとして位置付けられるそうです。

このように多様なコンテンツをカバーする必要があるのが、企業におけるチャットボット開発の特徴です。

### 開発された3つのチャットボット

今回の論文では、NVIDIAで開発された3つのチャットボットについて紹介されています。すべて、社内で構築されたNVBotプラットフォームと呼ばれる生成AI型チャットボットプラットフォーム上で開発されました。各チャットボットの情報を見てみましょう。

**NVInfo Bot**

- 目的
	- 企業コンテンツに関する質問への回答（イントラネット検索の補完）
- データ量
	- 約500万ドキュメント（7TB以上）
- 特徴
	- 多様なデータ形式の管理、ドキュメントアクセス制御の実施
- 技術スタック
	- LangChain（LLMオーケストレーションフレームワーク）
	- ベンダー提供のベクトルデータベース（検索とドキュメントアクセス制御用）
	- 複数のLLMモデルから選択可能
	- カスタムウェブUI

**NVHelp Bot**

- 焦点
	- ITヘルプとHR給付に関する質問
- データ量
	- 約2,000のマルチモーダルドキュメント（テキスト、表、画像、PDF、HTMLページを含む）
- 技術スタック
	- NVInfo Botと同様だが、扱うデータ量が少ない

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_72680_7-1.jpg)

**Scout Bot**

- 目的
	- 公開情報源からの財務業績に関する質問への対応
- データ
	- 構造化・非構造化データ（約4,000のマルチモーダルドキュメント）
- 技術スタック
	- オープンソースのベクトルデータベース
	- LangChain
	- Ragas評価フレームワーク
	- 選択可能なLLMモデル
	- カスタムウェブUI

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_72680_6.jpg)

下記の表には、上記3つのチャットボットの概要と、それぞれが回答できる質問の例が示されています。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_72680_1-1024x169.png)

例えば、以下のような質問が与えられる想定のようです。

- NVInfo Bot：「本社の駐車場に一晩中駐車できますか？」
- NVHelp Bot：「従業員株式購入プランにどのように登録すればいいですか？」
- Scout Bot：「過去3年間のNVIDIAの収益はいくらですか？」

さて、本研究では上記の3つのチャットボットを構築する過程で直面した課題と得られた知見が紹介されています。

そして、RAGベースのチャットボットを構築する際に考慮すべき5つの重要な側面を整理してFACTSフレームワークとしてまとめています。

1. F（Freshness）：企業データの新鮮さ
2. A（Architectures）： [アーキテクチャ](https://ai-data-base.com/archives/26562 "アーキテクチャ")
3. C（Cost economics）：LLMのコスト経済性
4. T（Testing）：テスト
5. S（Security）：セキュリティ

各側面についての詳細を以下で紹介します。

## F（Freshness）：企業データの新鮮さ

### 企業データの鮮度維持における課題

LLMを利用したチャットボットで企業データの鮮度を保つのは難しいです。いくつかポイントがあります。

（１）基盤モデルの限界  
どんなに強力な基盤モデルでも、特定の領域や企業固有の知識は不足しているものです。一度学習されたモデルは「凍結」とよばれる状態となり、学習していない企業コンテンツに対しては不正確な情報を生成する可能性があります。

（２）RAGパイプラインの複雑さ  
RAGパイプラインには多くの制御ポイントがあり、適切に調整されていないと、チャットボットの精度低下、幻覚、不適切な応答につながる可能性があります。

（３）ドキュメントアクセス制御の課題  
ドキュメントアクセス制御権限により、検索と取得プロセスが複雑化し、データのセキュリティと関連性の確保が困難になります。

（４）マルチモーダルコンテンツへの対応  
構造化、非構造化、準構造化データ（プレゼンテーション、図表、動画、会議録画など）を扱うには、マルチモーダル検索機能が必要とされます。

### RAGパイプラインの15の制御ポイント

著者らは、事例研究から15の制御ポイントを特定しました。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_72680_2-1024x672.jpg)

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_72680_5-1024x724.jpg)

15の制御ポイントを図から読み取ると以下のようになります。

1. データ取り込み
2. データパーサー（情報解析）
3. メタデータ強化
4. 埋め込みモデル
5. メタデータ抽出のためのLLM
6. チャンキング（分割）
7. 検索用ストレージ
8. クエリ言い換え
9. 検索
10. チャンク再ランク付け
11. チャンク統合と後処理
12. ガードレール
13. 回答生成
14. 回答後処理
15. RAGモニタリング

そして、制御ポイントについての洞察と学びが以下のように共有されています。

**（１）メタデータ強化、チャンキング、クエリの言い換え、クエリの再ランク付け  
**この4つのステップがチャットボットの応答品質に最も大きな影響を与えることが分かりました。LLMの応答生成品質は検索の関連性に大きく依存し、検索の関連性はドキュメントのメタデータ強化、チャンキング、クエリの言い換えに依存します。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_72680_3-1024x346.jpg)

複雑なクエリを処理するためのエージェント アーキテクチャ

**（２）ハイブリッド検索の有効性  
**ベクトルデータベースは固有名詞（人名、場所、会社名など）の照合に弱いことが判明しました。レキシカル検索（例：Elastic Search）とベクトル検索を組み合わせることで、検索の関連性と網羅性が向上しました。

**（３）エージェント [アーキテクチャ](https://ai-data-base.com/archives/26562 "アーキテクチャ") の必要性  
**複雑な質問に対応するには、クエリの分解と調整が可能な複雑なエージェントが必要です。なお上の図は、Scout botで実装されたメカニズムの一例を示しています。

**（４）LLMの微調整に関する考察  
**LLMの微調整については、基盤モデルの使用とドメイン特化のカスタマイズのバランスを取る必要があります。ケースによっては基盤モデルで十分な場合もありますが、カスタマイズが必要な場合もあります。

**（５）マルチモーダルデータの扱い  
**企業データはマルチモーダルであり、多様なデータ形式を扱う必要があります。文書の構造が一貫しており事前に把握できる場合、セクションレベルの分割が検索の関連性向上に有効です。

### RAGOps（RAG運用）の重要性

RAGパイプラインの効果的な監視は、デプロイ後に不可欠です。応答品質が低い場合、検索の関連性とLLMの応答生成のどちらに問題があるかを特定するための詳細な分析が必要です。RAGシステムをチャットボットに実装することは有望ですが、安全で正確なデータ取得を確保するには綿密な計画と継続的な評価が求められます。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_72680_4-1024x642.jpg)

NVHelpボットの異なるモデル間での回答品質と待機時間の指標比較

## A（Architectures）：アーキテクチャ

AI技術の進歩は、急流を航行するような速さで進んでいます。ベクトルデータベース、埋め込みモデル、LLM、エージェント [アーキテクチャ](https://ai-data-base.com/archives/26562 "アーキテクチャ") 、ローコード/ノーコードプラットフォーム、RAG評価フレームワーク、プロンプト技術など、あらゆる側面が急速に発展しています。同時に、企業内の各部門が独自のチャットボットやAIコパイロットを開発し、生成AIの可能性を探っています。

このようなダイナミックな環境下では、共通のプラットフォームの構築が不可欠です。

NVIDIAでは、チャットボットのエコシステムが大幅に拡大し、多くの企業と同じような傾向が見られます。初期の3つのチャットボット開発を通じて、セキュリティ、ガードレール、認証、プロンプト、ユーザーインターフェース、フィードバックメカニズム、使用状況レポート、モニタリング、評価などの面で重複した取り組みを避けるための共通プラットフォームの重要性が認識されました。

### NVBotプラットフォーム

上記の課題に対応するため、NVIDIAではNVBotプラットフォームが開発されました。

特徴は以下の通りです。

（１）モジュール式設計  
プラグ可能な [アーキテクチャ](https://ai-data-base.com/archives/26562 "アーキテクチャ") を採用

（２）柔軟な選択肢  
LLM、ベクトルデータベース、埋め込みモデル、エージェント、RAG評価フレームワークなどを用途に応じて選択可能

（３）共通コンポーネント  
セキュリティ、ガードレール、認証、認可、ユーザーエクスペリエンス、モニタリングなどの重要機能を提供

（４）市民開発のサポート  
複数のチームが検証済みのプロンプト、ワークフロー、ガードレール、微調整済みモデルを共同利用可能

### チャットボット戦略の選択

チャットボットのエコシステムが拡大するにつれ、重要な問題が浮上しました。それは、

「組織は多数のドメイン特化型ボットを構築すべきか、単一の企業全体ボットを採用すべきか、それともハイブリッドアプローチを取るべきか？」

という点です。

ドメイン特化型チャットボットは特定の環境に合わせて調整された優れたパフォーマンスを発揮します。一方で企業全体チャットボットはジェネラリストとして機能し、全従業員向けの一元化された知識ベースを提供します。

NVIDIAの経験からは、各選択肢は相互排他的ではないことが明らかになりました。要するに、ケースバイケースということです。

### 新しいアーキテクチャパターン

企業全体のチャットボットが「スイッチボード」として機能し、問い合わせをドメイン固有のデータで調整された専門ボットに振り分ける新しい [アーキテクチャ](https://ai-data-base.com/archives/26562 "アーキテクチャ") パターンが登場しています。このマルチボット [アーキテクチャ](https://ai-data-base.com/archives/26562 "アーキテクチャ") により、専門チャットボットの並行開発が可能になる一方で、ユーザーには統一されたインターフェースが提供されます。

NVBotプラットフォームは、企業内での複数チャットボットの共存と調整をサポートしています。単一ボットか複数の専門ボットかの議論は継続中ですが、将来的には以下の共存が予想されます。

1. ドメイン特化型ボット
2. 中央集中型情報ボット
3. コパイロット（プログラミングIDEやコラボレーションツールなどの職場環境に統合された生成AI機能）

NVIDIAでは、生成AIが職場の効率と情報アクセシビリティを再形成する中で、上記3つのバリエーションすべてを探求しています。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_72680_8-1024x640.jpg)

複数のチャットボットが構築されているNVBotプラットフォームの アーキテクチャ

## C（Cost economics）：LLMのコスト経済性

生成AI型チャットボットの導入コストを理解する上で、いくつか重要な要因があります。以下に、主な課題とその対策について解説します。

**課題1：大規模LLMの高コスト問題**

主要な商用LLMの高額な利用料金は、複数のユースケースにわたると持続不可能なレベルに達する可能性があります。さらに、特定のニーズに合わせて様々なLLMをテストする過程で、予期せぬ費用が積み重なることがあります。

**課題2：セキュリティ上の懸念**

商用LLMベンダーのAPIを使用する際、機密性の高い企業データを保護するためには、以下の対策が必要とされます。

1. センシティブなデータ漏洩を検出・防止するためのガードレールの設置
2. 監査や法的に許可された学習のためのゲートウェイの構築

**課題3：コストと待機時間のトレードオフ**

大規模なLLMは長いコンテキスト長を扱える一方で、応答時間が遅くなる傾向があり、全体的な効率に影響を与える可能性があります。

### 大規模モデルと小規模モデルの比較

大規模な商用LLMに代わる選択肢として、小規模なオープンソースLLMが多くのユースケースで実用的な選択肢となりつつあります。以下のメリットが挙げられます。

1. コスト効率の向上
2. 商用モデルに匹敵する精度
3. 一般的に大規模モデルよりも優れた待機時間性能

[GPU](https://ai-data-base.com/archives/26570 "GPU") による推論モデルの最適化により、処理速度をさらに向上させることが可能です。例えば、NVIDIAのTensor RT-LLM推論ライブラリで最適化されたオープンソースモデルは、最適化されていないモデルよりも高速なパフォーマンスを示しています。

### LLMゲートウェイの導入

ベンダーのLLM APIを使用する必要がある場合、社内にLLMゲートウェイを実装することが推奨されます。目的は以下の通りです。

1. 監査のための使用状況追跡
2. 全社的なサブスクリプション管理
3. コスト管理の一元化

NVIDIAでは、監査目的でLLMゲートウェイが実装されており、インバウンドとアウトバウンドのペイロードが記録されています。データはアクセス制御許可で保護されています。また、このゲートウェイはLLM APIの呼び出しに関するサブスクリプションとコストの管理も行っています。

### バランスの取れたLLM戦略

コスト面でバランスの取れたLLM戦略の開発においては、以下の方針が推奨されます。

1. 小規模かつカスタマイズされたLLMを使用して費用を管理
2. LLMゲートウェイを通じて大規模LLMの責任ある探索を許可
3. LLMのサブスクリプションとコストを追跡し、生成AI機能の使用状況と生産性向上を評価してROIを測定
4. クラウドベースのLLM使用における機密企業データの保護のため、データ漏洩を防ぐガードレールと監査・法的に許可された学習のためのLLMゲートウェイを実装
5. コスト、精度、待機時間のトレードオフを認識し、小規模LLMをカスタマイズして大規模モデルの精度に近づける努力を行う一方で、長いコンテキスト長を持つ大規模LLMは応答時間が長くなる傾向があることに注意

## T（Testing）：テスト

生成AI型ソリューションのテストには、人間による応答の検証が必要なため、長時間を要することがあります。そこで、LLMを「判定者」として活用する「LLM-as-a-judge」アプローチが増加しています。  
しかし、このアプローチには注意が必要です。LLMを人間の代理として使用すると、バイアスがもたらす不意の状況に陥る可能性があるためです。

**セキュリティテストの自動化**

開発速度を落とすことなく安全性を確保するためには、セキュリティテストの自動化が重要です。チャットボットの潜在的な脅威に対する耐性を確保するには、強力なセキュリティフレームワークと回帰テストデータセットが必要です。  
NVIDIAでは、社内のRED（リスク評価と対策）チームと協力して、チャットボットの大規模な更新ごとにテストできるデータセットの準備が進められています。

**プロンプト変更テスト**

生成AIモデルは、プロンプトの変更に非常に敏感です。精度を維持するためには、プロンプトが変更されるたびに完全な回帰テストが必要とされます。

**フィードバックループの重要性**

継続的な改善のために重要なのは、収集されたフィードバックを取り入れ、RLHFサイクル（人間のフィードバックによる [強化学習](https://ai-data-base.com/archives/26125 "強化学習") ）を実施することです。適切に実施すれば、LLMは時間とともにソリューションと言語モデルの両方を洗練させることが可能になります。

もし選択しているのがカスタマイズできないモデルである場合は、人間のフィードバックにモデルを適合させることが困難になります。

現在、NVIDIAではユーザーフィードバックの収集を開始していますが、RLHFを使用した継続的学習パイプラインはまだ構築されていません。このプロセスを自動化するツールの開発が、プロダクション後のライフサイクル管理においては重要となります。

### 教訓と推奨事項

上記から教訓をまとめると以下のようになります。テストプロセスを最適化して信頼できるシステムを作るための教訓です。

まず、RAGベースのチャットボットの効果的なテストには、長期的なテストサイクルが必要です。テストの自動化に焦点を当て、精度評価を強化することで、この重要な段階を効率化することができます。

また、ターゲットとするソリューションの強みを全面的に反映した包括的な [グラウンドトゥルース](https://ai-data-base.com/archives/26293 "グラウンドトゥルース") データセットを構築することが重要です。チャットボットが実際の使用場面で遭遇するシナリオに対してテストされることを保証するためです。

そして、LLMを評価者として活用することで、スケーラブルなテストオプションが提供されますが、人間による評価の質には及ばないことを念頭に置く必要があります。自動化ツールは、人間による監督を補完するものとして使用されるべきであり、それに取って代わるものではありません。

さらに、人間のフィードバックを取り入れ、体系的なエラー分析を行うメカニズムを確立することが推奨されます。改善の優先順位を決定し、チャットボットのパフォーマンスと適応性を継続的に向上させることが重要です。

## S（Security）：セキュリティ

### 信頼性の構築と重要性

生成AIチャットボットを導入する際は、信頼性の構築が最も重要です。リスクを軽減するために、以下の分野におけるガードレールが不可欠とされています。

1. 幻覚（現実にない情報の生成）
2. 有害性
3. 公平性
4. 透明性
5. セキュリティ

強力な基盤モデルは、もともと上記のガードレールの改善に向けて進歩を続けています。しかし、ジェイルブレイク（システムの制限を回避する行為）、敵対的攻撃、その他のセキュリティ問題の可能性は依然として存在します。

### 派生リスクへの対応

生成AI型チャットボットは、通常のセキュリティリスクに加えて、「派生リスク」と呼ばれる特有のリスクにも直面します。NVIDIAのチャットボットは全て社内向けであるため、企業コンテンツのセキュリティと機密データの保護に重点が置かれました。

以下に、RAGベースのチャットボットのセキュリティ確保に関する洞察と学びを紹介します。

### 学びと洞察

（１）企業コンテンツのアクセス制御

企業ドキュメントはアクセス制御によって保護されているため、RAGベースのチャットボットは応答生成時にアクセス制御リスト（ACL）を遵守する必要があります。

そこでNVIDIAでは、ドキュメントのACLを効果的に尊重する能力で知られる特定の情報検索（IR）製品が選択されました。

（２）生成AIに関連する派生リスク

チャットボットが元のデータソースのコンテキストを欠いた応答を生成し、誤解を招く可能性があります。また、高度な検索方法により、企業コンテンツが適切に保護されていない場合、機密データ露出のリスクが高まる可能性があります。

NVInfo botの開発過程では、機密データのガードレールが実装されました。さらに、使用されたベクトル検索ソリューションの機密データフィルタリングと分類機能を活用し、検索時に機密データを自動的にフィルタリングする仕組みが導入されました。

（３）データガバナンスとコンテンツセキュリティ

効率的な知識アクセスにより、機密データ漏洩のリスクが高まる可能性があります。

未承認のアクセスとデータ侵害から保護するため、導入前にデータガバナンスを優先することが重要です。

NVIDIAでは、ドキュメントの機密性分類と、チャットボットからの機密コンテンツの除外を目的とした企業コンテンツセキュリティイニシアチブが開始されました。

（４）企業向けガードレール

生成AI応答を特定の企業ポリシーやルールに適合させるガードレールの実装が必要です。

ガードレールは、チャットボットが生成するコンテンツが確立された規範と倫理的ガイドラインに従うようにすることで、潜在的な法的および評判上のダメージを軽減するのに役立ちます。

NVInfo botでは、当初LLMプロンプトに多くのガードレールが実装されました。しかし、すべてのLLMがこれらのプロンプトを一貫して遵守するわけではないことが後に判明しました。そのため、Nemo Guardrailsを使用して、クエリと応答の前処理と後処理の段階でこれらのガードレールが実装されました。

なおセキュリティは継続的なプロセスであり、新たな脅威や課題に応じて常に進化し続ける必要があります。

## まとめ

本記事では、NVIDIAの3つのチャットボット開発経験に基づく、効果的なRAGベースチャットボット構築の研究を紹介しました。

FACTSフレームワークを通じて、企業向けチャットボット構築の5つの重要側面が強調され、RAGパイプラインの15の制御ポイントと最適化技術が提示されました。

また、LLMの精度と待機時間のトレードオフに関する分析も共有されています。

実験的なガイドラインとしてぜひ折に触れて確認してみてください。

- 参照論文URL： [https://arxiv.org/abs/2407.07858](https://arxiv.org/abs/2407.07858)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[複数LLM協調アプローチ「マージング」「アンサンブル」「協力」について](https://ai-data-base.com/archives/72609)

[LLMの「頑固な知識」を変えることができるコンテキスト内編集手法（中国科学院大学Baolong Bi氏）](https://ai-data-base.com/archives/72359)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)