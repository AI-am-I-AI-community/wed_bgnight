---
title: "ChatGPTと実際に交わされた会話の世界最大規模データセット「WildChat」"
source: "https://ai-data-base.com/archives/67317"
author:
  - "[[AIDB Research]]"
published: 2024-04-10
created: 2025-06-13
description: "コーネル大学などの研究者らは、ChatGPTを使って実際のユーザー対話ログを収集し、「WildChat」と名付けたデータセットを構築しました。66言語に及ぶ100万件以上の会話ターンが含まれます。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

コーネル大学などの研究者らは、ChatGPTを使って実際のユーザー対話ログを収集し、「WildChat」と名付けたデータセットを構築しました。66言語に及ぶ100万件以上の会話ターンが含まれます。

他の同様のデータセットと比べ、ユーザーの入力文が最も多様で、リアル（センシティブ）な内容も豊富に含まれている特徴を持ちます。さらにユーザーの10%以上が、ChatGPTを指示に従って「脱獄」させようとしていたことも判明しました。

※脱獄：言語モデルに、本来制限されている内容を出力させること。

研究者らは、WildChatを一般公開しています。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_67317-1024x576.jpg)

**参照論文情報**

- タイトル：(InThe)WildChat: 570K ChatGPT Interaction Logs In The Wild
- 著者：Wenting Zhao, Xiang Ren, Jack Hessel, Claire Cardie, Yejin Choi, Yuntian Deng
- 所属：Cornell University, Allen Institute for Artificial Intelligence, University of Southern California, University of Washington

**本記事の関連研究** ：

- [大規模言語モデル（LLM）のこれまでとこれから③　-使用法・拡張法、データセット編-](https://ai-data-base.com/archives/64398)
- [あらゆるLLMを「使い心地」基準でバトルさせる便利なプラットフォーム『Chatbot Arena：チャットボットアリーナ』](https://ai-data-base.com/archives/61080)
- [外部からの攻撃で一度でも欺瞞を学んだLLMは現在の技術では完全回復が難しい](https://ai-data-base.com/archives/62695)
- [ChatGPTを心理療法にもとづいて実行し、高い共感力と思いやりある会話をさせる手法『Chain of Empathy』と実行プロンプト](https://ai-data-base.com/archives/58847)

## 背景

LLMを使ったチャットボットが普及していますが、その開発には以下3つの段階があります。

1. 言語モデルの事前学習
2. 「指示調整データセット」を使った微調整
3. 人間のフィードバックを使った [強化学習](https://ai-data-base.com/archives/26125 "強化学習") （※オプション）

このうち、指示調整データセットは、チャットボットの振る舞いを人間の好みに合わせるために不可欠です。上記のうち1と3は行わなくても2は実施するといったプロジェクトも多くなっています。

しかし、指示調整に活用できるデータは各機関の内部にあり、一般にはアクセスしにくいのが現状です。

ここで指示調整データには、大きく分けて2種類あります。

1. 自然な利用事例：実際のユーザーとチャットボットのやり取り
2. 専門家が作成したデータ：1回限りの会話が多い

ただし自然な利用事例は非公開のことが多く、専門家が作成したデータは実際の会話とは分布が異なる、といった課題があります。

そこで今回研究者らは、ChatGPTを使ったチャットボットを一般公開し、ユーザーの同意を得て会話ログを収集しました。こうして65万件以上の会話データからなる「WildChat」が誕生しました。チャットボットの利用実態の解明や、有害な利用法の研究、さらには言語モデルの追加学習にも役立つと期待されます。

以下で詳しく紹介します。

## データ収集方法

研究者らは、GPT-3.5-turboとGPT-4を使った2つのチャットボットをHugging Face Spaces上で公開しました。ユーザーはアカウント登録や個人情報の入力なしで利用できます。データは2023年4月10日から11月9日まで収集され、今後も会話データを追加していく予定とのことです。

なお、データ収集にあたっては、ユーザーのプライバシーと倫理的配慮が不可欠です。研究者らは、データ収集・利用・共有に関する同意文書をユーザーに提示しました。ユーザーは同意文書に同意し、追加の確認メッセージに応じた後、初めてチャット画面にアクセスできる仕組みになっていました。

収集された177万件の会話ログには、完全な会話と不完全な会話が混在していました。研究者らは、各会話ログが他の会話ログの先頭部分と一致するかをチェックし、重複を取り除くことで、69.7万件の会話を抽出しました。

さらに、個人情報の削除、ユーザーとアシスタントの連続した発話の除去、同意取得前の会話の削除などの前処理を行いました。最終的に、65.2万件の会話データが残りました。

## データセットの統計的特徴

WildChatは、65.2万件の完全な会話と164万件以上の会話ターン（ユーザーの発話とAIの返答を1セットとしたもの）から構成されています。IPアドレスから推定される利用者数は19万人以上に上ります。平均の会話の長さは2.52ターンで、43%以上の会話が複数ターンに及んでいます。

つまり、スレッドの数が65.2万件、実際に交わされた会話ターンの総数が164万件以上ということです。

なお、WildChatでは66の言語が検出されました。最も多いのは英語で全体の51%を占め、次いで中国語が18%、ロシア語が11%となっています。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_67317_2-1024x447.png)

(a)データセットに含まれる会話のターン数の分布 (b)10言語における分布

他の主要な会話データセット（Alpaca、Open Assistant、Dolly、ShareGPT）と比べると、WildChatは会話数で5倍以上、利用者数で11倍以上の規模となっています。また、ユーザーの入力文と会話AIの返答文の長さが最も長いのも特徴です。なお、Alpacaはモデル生成の入力文、Dollyは専門家による入力文、Open Assistantはクラウドソーシングによる入力文のデータセットです。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_67317_1-1024x203.png)

また、WildChatのユーザー入力文は、他のデータセットと比べて語彙の多様性が高いことがわかりました。英語のみの会話でも、全言語の会話でも同様の結果が得られています。下の表は、各データセットのユーザー入力文のユニグラム（単語）の多様性をエントロピーで比較したものです。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_67317_3-1024x144.png)

さらに他のデータセットと比べ、WildChatは英語以外の言語の割合が高いのが特徴です。特に中国語の割合が18%と突出しています。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_67317_4-1-1024x176.png)

さらに、Llama-2 7Bを使って、各データセットがどれだけ他のデータセットの内容を説明できるかを調べた結果も出ています。各データセットでLlama-2 7Bを追加学習し、他のデータセットの会話をどれだけ「likely（尤もらしい）」と判断するかを評価しました。この尤もらしさを表す指標が「負の対数尤度（NLL）」です。NLLが低いほど、そのデータセットの内容をよりよく説明できると解釈できます。

実験の結果、WildChatで学習したLlama-2 7Bは、Open AssistantとShareGPTの会話に対して最もNLLが低くなりました（ただし、直接学習したモデルは除く）。また、AlpacaとDollyに対してもNLLが比較的低い値を示しました。この結果は要するに、WildChatが他のデータセットの内容を幅広くカバーしていることを示唆しています。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_67317_5.png)

さらに、WildChatと他のデータセットのユーザー入力文を、機械学習の手法で抽象化した空間（埋め込み空間）に配置した下記の図を見ると、WildChatは他のデータセットと重なる部分も多いものの、他のデータセットではカバーされていない領域も含んでいることがわかります。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_67317_6-1024x744.jpg)

WildChatが他のデータセットと比べて、より広範囲の会話パターンを含んでいることを示しています。既存のデータセットの内容を網羅しつつ、さらに新しい会話パターンも含んでいるということです。

## 有害性の分析結果

研究者らは、WildChatに含まれる有害な会話の分析を行いました。2つの有害性判定ツール（OpenAI Moderation APIとDetoxify）を使って、ユーザーの入力文とアシスタントの返答文をチェックしたところ、ユーザーの入力文の10.8%、アシスタントの返答文の7.8%が有害だと判定されました。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_67317_7.png)

なお2つの判定ツールの間では、有害と判定された会話の一致率は高くありませんでした。DetoxifyとOpenAI Moderation APIのどちらか一方のみに引っかかった例を人間が確認したところ、どちらも正しく有害性を検出していることがわかりました。つまり、複数の判定ツールを使うことで、有害コンテンツの検出率を高められるということです。

また、他の主要な会話データセットと比べると、WildChatは有害コンテンツの割合が突出して高いことがわかりました。実際のユーザーとチャットボットの会話を集めたデータセットだからだと考えられます。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_67317_8.png)

有害コンテンツの割合を月ごとに追跡したところ、当初はアシスタントの返答文の方がユーザーの入力文よりも有害な割合が高かったものの、6月以降は逆転していることがわかりました。研究者らの推測によると、OpenAIが6月27日にモデルをアップデートした影響の可能性があります。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_67317_9-1024x393.png)

なお、WildChatでは、ユーザーの10%以上がオンライン上の指示に従ってChatGPTを「脱獄」させようとしていたことが明らかになりました。「脱獄」とは、ChatGPTに本来制限されている内容を出力させることを指します。そして、あるタイプの脱獄の成功率は70%を超えていました。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_67317_10.png)

このように、実際のユーザーによるリアルな会話を集めることで、他のデータセットにはない特徴が得られています。

## 指示調整データとして活用

研究者らは、WildChatを指示調整のためのデータセットとして活用できないかを検討しました。指示調整は前述の通り、モデルに追加の学習データを与え、出力を調整することです。チャットボットの返答を利用者の好みに合わせるための重要な手段としてよく行われています。

そこで、Llama-2 7Bモデルを2023年7月16日までのWildChatで学習させ、新しいモデル「WildLlama」を開発しました。学習には最新のオープンソースチャットボットであるVicunaと同じ設定を使い、3 [エポック](https://ai-data-base.com/archives/26594 "エポック") （データ全体を学習させる回数。1回=1 [エポック](https://ai-data-base.com/archives/26594 "エポック") ）学習させました。

WildLlamaをMT-benchというベンチマークで評価したところ、同サイズのオープンソースモデルの中で最高の性能を示しました。ただし、GPT-3.5やGPT-4などの非公開モデルには及ばない結果でした。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_67317_12.png)

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_67317_11.png)

なおWildLlamaとVicunaを直接比較したところ、WildLlamaがVicunaに負けるのはわずか20%のケースだけで、ほとんどの場合で同等以上の性能を示しました。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_67317_13.png)

一方で、商用モデルだけでなく、Llama-2 Chatにも及ばない結果となりました。Llama-2 Chatは人間からのフィードバックを使った強化学習を行っているのに対し、WildLlamaとVicunaは行っていないことが原因だと研究者らは考察しています。

以上のように、WildChatは指示調整データとして有用であることが示されましたが一方で、人間からのフィードバックを使った強化学習の重要性も示唆される結果となりました。

## まとめ

本記事では、世界最大規模の会話データ「WildChat」を構築しした研究を紹介しました。

WildChatは、実際のユーザーとChatGPTとの多言語での会話を集めた大規模データセットです。匿名化された65万件以上の完全な会話データが収集されました。

なお、利用者の偏りや有害コンテンツの選択バイアスなど、いくつかの課題も指摘されています。また、大規模なデータが常に必要かどうかについても議論の余地があります。

それでも、WildChatは現実世界のユーザーとチャットボットの会話を集めた貴重な事例であり、研究に大きく貢献すると期待されます。

参照論文URL： [https://wenting-zhao.github.io/papers/wildchat.pdf](https://wenting-zhao.github.io/papers/wildchat.pdf)

プロジェクト： [https://wildchat.allen.ai/](https://wildchat.allen.ai/)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[LLMは制御工学でどれほど能力があるか　Claude 3、GPT-4、Gemini Ultraでの実験結果](https://ai-data-base.com/archives/67267)

[時系列分析におけるLLMの可能性](https://ai-data-base.com/archives/67378)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)