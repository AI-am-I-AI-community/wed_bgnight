---
title: "上司役のLLMが部下LLMたちに的確に仕事を振り分ける『Magentic-One』マイクロソフトが開発"
source: "https://ai-data-base.com/archives/77850"
author:
  - "[[AIDB Research]]"
published: 2024-11-12
created: 2025-06-13
description: "本記事では、マイクロソフトが開発したマルチエージェントシステム「Magentic-One」を紹介します。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、マイクロソフトが開発したマルチエージェントシステム「Magentic-One」を紹介します。

最近では特定の分野に特化したLLMエージェントが次々と開発されていますが、より汎用的な能力を持つエージェントの実現が課題となっていました。この課題に対し、Magentic-Oneは「複数のエージェントによるチームワーク」という新しいアプローチで解決を試みています。

その設計思想や具体的な仕組みは、今後のLLMエージェント開発に大きな示唆を与えています。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_77850-1024x576.jpg)

**参照論文情報**

- タイトル：Magentic-One: A Generalist Multi-Agent System for Solving Complex Tasks
- 著者：Adam Fourney, Ga [gan](https://ai-data-base.com/archives/26269 "敵対的生成ネットワーク（GAN）") Bansal, Hussein Mozannar, Cheng Tan, Eduardo Salinas, Erkang (Eric) Zhu, Friederike Niedtner, Grace Proebsting, Griffin Bassman, Jack Gerrits, Jacob Alber, Peter Chang, Ricky Loynd, Robert West, Victor Dibia, Ahmed Awadallah, Ece Kamar, Rafah Hosn, Saleema Amershi.
- 所属：Microsoft Research AI Frontiers

**本記事の関連研究**

- [リアルなWindowsOS環境でのエージェント能力を評価する『WindowsAgentArena』およびエージェント『Navi（ナビ）』Microsoftが開発](https://ai-data-base.com/archives/75765)
- [ノーコードでLLMマルチエージェントを操る『AUTOGEN STUDIO』Microsoftが新開発](https://ai-data-base.com/archives/75716)
- [計画のステップが増えるほど、LLMは最初の目標を見失っていく傾向がある](https://ai-data-base.com/archives/77302)

## 背景

人の代わりに複雑な作業をこなせるLLMエージェントを作ることが可能になってきました。私たちの仕事を手助けしたり、面倒な作業を代わりにやってくれたりすることがLLMエージェントに期待されています。例えばインターネットでの情報収集、データの分析、プログラミングなどの分野です。しかし、今あるエージェントのほとんどは、一つの分野に特化したものばかりで、もっと幅広い仕事ができるエージェントが必要とされています。

そこで注目されているのは、複数のエージェントを組み合わせて使うというアイデアです。例えば、ウェブ検索が得意なエージェント、文書作成が得意なエージェントというように、それぞれ得意分野の違うエージェントたちが協力して仕事を進めるといった方法です。もしうまくいくなら、新しい機能を追加するときも、その部分を担当する新しいエージェントを加えるだけで済みます。

こうした考えをもとに、Magentic-Oneという新しいシステムが作られました。リーダー役のエージェントが全体の計画を立て、ウェブ検索係、ファイル処理係、プログラミング係といった専門エージェントたちに仕事を振り分けます。一人のエージェントでは難しかった複雑な仕事もこなせるようになります。

さらに、エージェントの評価も考え直されました。これまでは「正しい答えが出せるか」ということだけが重視されていましたが、実際の使用では、処理にかかる時間やコスト、使い勝手の良さなども大切であるためです。

以下でMagentic-Oneの詳細をわかりやすく紹介します。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_77850_figure1-1024x570.jpg)

GAIAベンチマークでの複雑なタスクをMagentic-Oneのマルチエージェントチームが完了する様子

## 「複雑なタスク」の定義

今回開発されたMagentic-Oneの使命は、LLMエージェントたちに「複雑なタスク」を行わせることです。

複雑なタスクとは、計画を立て、実行し、結果を観察し、その結果について考察するというプロセスを必要とする作業を指します。単に文章を生成するだけでなく、コードを実行したり、ツールを使用したり、様々な環境で作業を行ったりすることです。また、作業を進める中で「それまで分からなかった新しい情報が得られる」ことも特徴です。

### タスクの構成要素

タスクは以下のような要素から構成されてるものとして捉えられます。

1. まず、入力として、具体的な文章による説明が与えられます。また、画像やデータセット、音声ファイルなどの添付ファイルが含まれる場合もあります。たとえば「添付PDFに記載された各主張について、正しいか誤りかを確認してください」といったタスクが考えられます。
2. 次に、期待される出力があります。文章による回答である場合もあれば、何らかの状態に達することが求められる場合もあります。先ほどの例では「主張1: 正しい、主張2: 誤り…」といった形式の回答が期待されます。

### システムに求められること

システムには、タスクの説明と関連する添付ファイルが与えられ、制限時間（例：25分）内にタスクを完了することが求められます。Pythonコードの実行やウェブブラウザの操作、ファイルのダウンロードなど、様々な操作が許可されています。様々な行動を取れるという特徴から、システムはLLMエージェントと呼ばれます。

システムは環境の状態を完全には把握できない中で、与えられた情報を基に最適な行動を選択していく必要があります。このような性質を「部分的な観察可能性を持つマルコフ決定過程」と呼びます。

## Magentic-Oneの基本概念

Magentic-Oneでは、「Orchestrator（オーケストレーター）」と呼ばれる中心的なLLMエージェントによって作業が調整されます。このエージェントにはタスクの分解や計画立案、他のエージェントへの指示、全体の進捗管理、必要に応じた修正作業などが任されます。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_77850_figure2.png)

Magentic-Oneはオーケストレーターが2つのループ（外部ループと内部ループ）を実装。外部ループはタスク台帳を、内部ループは進捗台帳を管理している

### チーム構成とその役割

Orchestrator以外にも専門的な能力を持つエージェントが配置されています。ウェブの閲覧やウェブアプリケーションの操作、ファイルの処理、Pythonコードの作成と実行など、特定の作業に特化した能力をそれぞれ備えます。

### 実際の作業例

具体例として、「先月発表されたAIの安全性に関する論文の調査と、その内容をまとめたスライド作成」というタスクが与えられた場合を見てみましょう。

まず、Orchestratorによってタスクが以下のような小さな作業に分解されます。

- 論文の要約を探す
- 関連論文のダウンロード
- 論文の読み込みと要約
- 発見した内容のプレゼンテーション作成

この初期計画は、厳密な手順書というよりも、作業を進めるための大まかな指針として機能します。計画が立てられると、Orchestratorは適切なエージェントを選んで作業を割り当てていきます。

たとえば、WebSurferエージェントはAI安全性に関する論文の検索とダウンロードを担当し、FileSurferエージェントはダウンロードされたPDFファイルを開いて必要な情報を抽出します。Coderエージェントは様々なファイルを操作するPythonコードを作成してプレゼンテーションを作り、ComputerTerminalエージェントはそのコードを実行します。

作業が進められる中で、Orchestrator自身は以下のような役割を果たします。

- 各エージェントの作業の調整
- 進捗状況の監視
- タスクの完了判定

そして複数のエージェントが協力し合いながら、人間が依頼したタスクが完了されていきます。

## 実験

### 評価の難しさ

具体的な実験の紹介に移る前に、LLMエージェントにおける評価上の課題を説明します。例えば、あるタスクでPythonライブラリのインストールが必要な場合を考えてみましょう。最初に評価されるシステムは不利な立場に置かれることになります。なぜなら、そのシステムは以下のような手順を踏まなければならないからです。

1. まずPythonコードを書いて実行し、失敗を経験する
2. 問題を特定してデバッグを行う
3. 必要なライブラリをインストールする
4. 再度コードを実行する

一方、後から評価される他のシステムは、既にインストールされているライブラリを利用できるため、見かけ上より良い性能を示す可能性があります。

逆に、誤った操作を行うエージェントが重要なファイルを削除したり、システムを使用不能な状態にしたりすると、後続のすべての評価に悪影響が及ぶ可能性もあります。

そこで上記に対処するため、「AutoGenBench」というツールが開発されました。このツールは、各タスクを独立して評価し、エージェントの危険な操作からシステムを保護する機能を備えています。

### AutoGenBenchの特徴

AutoGenBenchは、与えられたベンチマーク（評価用のタスク集）に対して、以下のような環境を提供します。

- 各タスクは完全に独立した環境（Dockerコンテナ）で実行される
- 毎回クリーンな初期状態から開始される
- 評価結果は安全な場所（ホストマシン）に保存される
- 複数のタスクを並行して実行することが可能
- 同じタスクを複数回実行して、結果のばらつきを確認することもできる

### 実験結果

今回実験では、GAIA、AssistantBench、WebArenaという3つの主要なベンチマークに対するMagentic-Oneの性能が、他のシステムと比較されています。GAIAとAssistantBenchについては、テストセットでの結果のみが報告されています。一方、WebArenaには共通のテストセットが存在しないため、全812タスクに対する結果が示されています。

Magentic-Oneは2つのバージョンで評価されました。

1. すべてのエージェントでGPT-4oを使用したバージョン
2. GPT-4oとo1-previewを組み合わせて使用したバージョン

実験結果は、下記の表にまとめられています。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_77850_1-1024x457.png)

Magentic-One（GPT-4o、o1-preview）は、GAIAとAssistantBenchの両方で、最高性能のシステムと統計的に同等の性能を示しました。WebArenaでは、GPT-4oのみのバージョンが評価され、WebPilotとJace.AIを除く最高性能システムと同等の性能が確認されました。

なおWebArenaには隠されたテストセットが存在しないため、評価に特別な課題が生じました。そこで独自の検証用/テスト用データ分割が作成されました。その結果、検証セットでは35.1%（422タスク中148タスク）の [正解率](https://ai-data-base.com/archives/25930 "正解率") が達成され、テストセットでは30.5%（390タスク中119タスク）の正解率が記録されました。

Magentic-Oneの2つのバージョンを比較すると、特にGAIAベンチマークで大きな改善が見られました。GAIAが論理的推論やパズル解決のようなタスクを多く含んでおり、これらがo1モデルの得意分野であることが理由として考えられています。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_77850_tabel2-1024x457.png)

各ベンチマークのテストセットにおける、カテゴリー別のMagentic-Oneと最高性能ベースラインの比較

これらの結果から、Magentic-Oneはウェブベースやファイルベースの複雑なタスクを処理する上で、高い性能を持つシステムであることが示されています。

特筆すべき点として、3つのベンチマークすべてで高い性能が確認されたことが挙げられます。これは、システムの汎用性の高さを示す重要な指標となっています。現在、他のシステムではこれら3つのベンチマークすべてで評価を行っているものはほとんど存在していません。

### 各エージェントや機能がシステム全体の性能にどう影響するか

GAIAのベンチマークの検証用データセットを用いて、段階的に機能を除去する実験が実施されました。まず、Magentic-Oneの中核となるOrchestratorの影響を調べるため、より単純な制御メカニズムに置き換えられました。タスクの実行中にどのエージェントが次に発言すべきかを決定するだけの機能に限定されたものです。

次に、個々のエージェントの重要性を評価するため、チームから一つずつエージェントを取り除いた実験が行われました。

そして実験結果は、タスクの難易度レベルや必要とされる機能の種類に基づいて分析されました。下のグラフは、GAIAの検証用データセットにおける、異なる機能除去実験の結果が難易度レベル別に示されています。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_77850_figure3-1024x754.png)

Orchestratorの管理機能は非常に重要であり、これを単純化すると性能が31%低下することが確認されました。また、すべての作業用エージェントが重要な役割を果たしており、どれか1つを除去しただけでも21%から39%の性能低下が観測されました。

注目すべき点として、FileSurferの除去は最も大きな影響を与え、特にレベル2のタスク（多くのファイル添付を含むカテゴリ）で顕著な性能低下が見られました。一方、WebSurferはレベル1のタスクにおいて特に重要であることが示されています。

興味深い発見として、エージェントたちは失われた機能を工夫して補おうとする傾向が観察されました。たとえば、CoderとComputerTerminalが利用できない場合、残りのエージェントがコードを読み解いて結果を予測するという対応が取られました。また、FileSurferが使えない場合、他のエージェントがオンラインのPDFビューアーを探して代替手段を見つけ出そうとしました。

### エラー分析

Magentic-Oneの動作中に発生する問題はどんなものがあるでしょうか。

本システムは作業中に非常に詳細なログを生成します。ログを手作業で確認すると、エージェントが犯したミス、見過ごした機会、行き詰まり、実行時エラーなどが見つけられます。問題の多くには一定のパターンが見られ、システムの改善につながる重要な示唆が含まれています。

しかし、これらの長大なログを人手で確認するのは時間と労力がかかる作業です。そこでLLMを活用した自動分析手法が採用されました。

まず、GPT-4oによって各事後分析文書に説明的なコード（ラベル）が付与されました。初期段階では、文書間でコードの種類が多様でしたが、その後GPT-4oによってコードのグループ化が行われ、類似したコードが統合されました。このプロセスは、コードが安定するか、最大反復回数に達するまで繰り返されました。

下の図には、すべてのベンチマークの検証例におけるMagentic-Oneの行動から自動的に発見されたエラーコードの分布が示されています。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_77850_figure4-1024x630.png)

最も頻繁に発生した問題は、エージェントが失敗を経験しているにもかかわらず、同じ非効率的な行動を繰り返すというものでした。

二番目に多かった問題は、データの十分な検証なしにタスクを完了としてしまうケースでした。

三番目に多かった問題は、非効率的なナビゲーション試行に関するものでした。エージェントがインターフェースのレイアウトを誤って解釈し、不要なタブの切り替えやメニューの探索を繰り返すような状況が観察されました。

なお下の図には各ベンチマークとMagentic-Oneのバージョンごとに、これらのエラーコードの出現頻度がヒートマップとして示されています。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_77850_figure4_2-2-1024x732.png)

## マルチエージェントシステムシステムの現状と課題

Magentic-Oneの最も大きな特徴は、そのマルチエージェント設計にあります。この設計方針が、高い性能を実現する主な要因として認識されています。実際、最高性能を示す他のシステムの多くも、同様のマルチエージェント設計を採用しています。

マルチエージェント方式には、性能面以外にも多くのメリットがあります。たとえば、開発のしやすさやコスト面での優位性が挙げられます。各エージェントの役割が明確に分かれているため、オブジェクト指向プログラミングと同様に、開発が単純化されます。また、各エージェントのプロンプト設計や他のパラメータを、特定のタスクに最適化しやすいという特徴も備えています。

しかし、いくつかの重要な懸念があります。

まず、評価方法が最終的な正確さのみに焦点を当てており、コストや応答時間、ユーザーにとっての価値といった重要な要素が考慮されていません。また、システムの実行には多くのLLM呼び出しが必要とされ、時間とコストがかかる点も課題となっています。

さらに、システムが処理できる情報の種類にも制限があります。たとえば、WebSurferはオンライン動画を視聴することができず、FileSurferは文書の視覚的な要素や配置に関する質問に答えることができません。音声ファイルも音声認識モデルを通じてテキストに変換されるため、音楽や非音声コンテンツに関する質問には対応できません。

### リスクと対策

コンピュータを自律的に操作するエージェントには、本質的なリスクが伴います。これに対処するため、以下のような対策が講じられています。

まず、すべてのタスクはコンテナ内で実行され、WebArenaのような合成環境が活用されています。また、強力な制御機能を持つモデルが選択され、生成前後でのフィルタリングが実施されています。さらに、実行中および実行後のログが緊密に監視されています。

### 今後の展望

とはいえ、より広範なリスクも予想されます。たとえば、エージェントがフィッシングやソーシャルエンジニアリング、誤情報の影響を受ける可能性があります。このようなリスクに対しては、人間による監視の強化や、外部情報を検証するためのツールの提供などが対策として検討されています。

さらに長期的な社会的影響としては、労働者のスキル低下や仕事の置き換えによる経済的混乱の可能性も指摘されています。そのため、今後は人間とエージェントが効果的に協力できるシステムの設計が重要視されます。

## まとめ

本記事では、マイクロソフトの研究チームが開発したマルチエージェントシステム「Magentic-One」の研究を紹介しました。オーケストレーター（指揮者役）のもと、ウェブ閲覧、ファイル処理、コーディングなどを担当する4つの専門エージェントが協力して作業を進める設計となっています。3つの異なるベンチマークテストでの評価では、他の最新システムと同等以上の成績を収めており、特に複雑な多段階のタスクで高い性能を発揮しました。

ただし、処理時間やコストの面では課題も残されています。また、音声や動画の処理には制限があり、作業履歴を次回に活かすような学習機能も現時点では備わっていません。

今後は、より小規模なモデルの活用によるコスト削減や、マルチメディア処理能力の向上、そして作業の経験を蓄積・活用できる仕組みの実装が期待されています。

- 参照論文URL： [https://www.microsoft.com/en-us/research/publication/magentic-one-a-generalist-multi-agent-system-for-solving-complex-tasks/](https://www.microsoft.com/en-us/research/publication/magentic-one-a-generalist-multi-agent-system-for-solving-complex-tasks/)
- GitHub： [https://aka.ms/magentic-one](https://aka.ms/magentic-one)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[「HTMLをそのままLLMに入力してはどうか」という新しいアプローチ](https://ai-data-base.com/archives/78254)

[LLMにおける長文処理能力の進化を調査 Claude 3.5は情報の流れを追跡するスキルに長ける](https://ai-data-base.com/archives/78379)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)