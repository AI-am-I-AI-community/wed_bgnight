---
title: "LLMによるText to SQL（SQLクエリ生成）の現状まとめ"
source: "https://ai-data-base.com/archives/73368"
author:
  - "[[AIDB Research]]"
published: 2024-07-25
created: 2025-06-13
description: "本記事では、LLMを活用したText-to-SQLタスクに関する調査研究を紹介します。自然言語をSQL文に変換する技術の最新動向と将来の方向性を探った取り組みです。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、LLMを活用したText-to-SQLタスクに関する調査研究を紹介します。自然言語をSQL文に変換する技術の最新動向と将来の方向性を探った取り組みです。プロンプトエンジニアリングとファインチューニングの2つの主要アプローチが分析され、新しいベンチマークデータセットや今後の課題についてもカバーされています。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_73368-1024x576.jpg)

**参照論文情報**

- タイトル：A Survey on Employing Large Language Models for Text-to-SQL Tasks
- 著者：Liang Shi, Zhengju Tang, Zhi Yang
- 所属：Peking University

## 背景

リレーショナルデータベースの活用はさまざまな分野で促進され、効率的に検索・活用する手法を発展させる必要性が高まっています。しかしデータベースへのアクセスにはSQL言語の知識が必要であり、専門知識を持たないユーザーにとっては大きな障壁となっています。

そんな中、自然言語をSQLクエリに変換する「Text-to-SQL」と呼ばれる技術が注目されています。誰でも日常的な言葉でデータベースにアクセスできるようにすることを目的とした技術です。そしてText-to-SQLはLLMの登場によってさらに強化されることが期待されています。

LLMによるText-to-SQLの重要アプローチは二つあります。1つ目はプロンプトエンジニアリング（LLMに適切な指示や例を与えること）でText-to-SQLタスクを実行させる手法です。2つ目はファインチューニング（Text-to-SQL専用のデータセットでLLMを追加学習させること）です。

今回、研究者らは上記のアプローチに加えてText-to-SQLにおける重要なベンチマークデータセット、そして今後の研究の方向性について詳細にまとめました。

以下で内容を紹介します。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_73368_1.png)

Text-to-SQLアプローチの時間経過による進化

## ベンチマーク

Text-to-SQLタスクの評価において、重要な役割を果たすのはまず高品質なデータセットです。

これまで様々なText-to-SQLデータセットが作成されてきましたが、ChatGPTやGPT-4の登場により、多くのスコアが格段に良くなりました。例えば、Spiderデータセットの実行精度は約73%から91.2%にまで向上しました。これは手放しに喜ばしいだけでなく、LLMの能力をより厳密に評価できる、より難しく現実的なベンチマークデータセットが求められていることを意味します。

そこで、いくつかのベンチマークデータセットが開発されてきました。以下では代表的な例を挙げます。

### BIRDデータセット

現実世界のアプリケーションにより近い環境を模倣するためにBIRDというデータセットが作成されました。以下の特徴があります。

1. 12,751のtext-to-SQLペアと95のデータベースを含み、総サイズは33.4 [GB](https://ai-data-base.com/archives/26343 "勾配ブースティング") に及ぶ
2. 37の専門分野をカバーする
3. 新たな課題を持つ
	- データベース値が不完全でノイズを持つ
	- 自然言語質問とデータベース値の間に外部知識が必要である
	- 大規模データベースのためSQL効率が重要

BIRDデータセットの難しさは、最も効果的なText-to-SQLモデルであるGPT-4でさえ、実行精度が54.89%にとどまっていることからも明らかになっています。人間の結果である92.96%と比べるとまだ大きな差があります。

### Dr.Spiderデータセット

さらに、Text-to-SQLモデルの [ロバスト](https://ai-data-base.com/archives/26590 "ロバスト") 性（頑健性）を評価するためにDr.Spiderというデータセットが作成されました。主な特徴は以下の通りです。

1. Text-to-SQLタスクの従来ベンチマーク [Spiderデータセット](https://yale-lily.github.io/spider) をベースにしている
2. データベース、自然言語質問、SQLクエリに対して17種類の摂動（perturbation）が設計されている※
3. 自然な摂動を生成する際にはfew-shot学習が利用された

※「摂動」とは、元のデータに意図的に小さな変化や乱れを加えることを指します。つまり、小さな変化に対してモデルがどれだけ安定した性能を維持できるかを評価するためのものです。

Dr.Spiderデータセットは、最も [ロバスト](https://ai-data-base.com/archives/26590 "ロバスト") なモデルでさえ全体的なパフォーマンスが14.0%低下し、最も困難な攪乱に対しては50.7%もパフォーマンスが低下することからその難しさが明らかにされています。

まとめると、BIRDデータセットは実世界のシナリオに近い環境を提供し、Dr.Spiderデータセットはモデルの [ロバスト](https://ai-data-base.com/archives/26590 "ロバスト") 性を多角的に評価することを可能にするベンチマークです。

## プロンプトエンジニアリング

LLMによるText-to-SQLタスクにおいてはプロンプトエンジニアリングも工夫する必要があります。

主に以下の5つの形式がText-to-SQLタスクにおける基本構造とされています。

1. 自然言語の問題文だけを含むシンプルな形式
2. SQLiteのコメント記号で始まる各行に、テーブル名とカラム名が記述される
3. 「SELECT \* From Table LIMIT X」というSQL文とその実行結果が含まれる
4. テーブル作成文を使用する。各カラムのデータ型や主キー、外部キーの関係は明示される
5. 上記の組み合わせや、独自の形式

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_73368_2-1.png)

Text-to-SQLにおけるプロンプトエンジニアリングの分類

### 補足知識の活用について

プロンプトに以下のような補足的な知識を追加することで、Text-to-SQLタスクにおけるLLMの性能向上が期待できます。

1. **スキーマ知識  
	**問題に関連するテーブルやカラムの情報を優先的に提供する
2. **SQL知識  
	**SQL構文やクエリ最適化のルールを含める
3. **その他の言語知識  
	**BINDER-SQLなど、独自の中間言語を使用する手法もある
4. **タスク関連知識  
	**特定のドメインに関する計算方法などを追加する
5. **メモリ知識  
	**複雑な多段階推論のための記憶機能を実装する
6. **質問知識  
	**類似問題の経験を活用する

### 例示を含めるか含めないか

プロンプトに例示を含めることで性能を上げることができるのはよく知られた知見です。しかし、ゼロショット（例示を含めない）手法もテーブル構造の説明や問題の分割に注力することができるため選択肢に入ります。  
一方でフューショット（いくつかのText-to-SQL例を含める）手法もやはり有効で、データベーススキーマ、テキストクエリ、SQL文の組み合わせや、推論過程を含む例示など、様々な形式が試みられています。

### 推論手法

下記のような、LLMに段階的な思考を促す推論手法も有効と考えられています。

1. **Chain of Thought (CoT)  
	**「一歩ずつ考えましょう」などの指示を加え、LLMに段階的な思考を促す
2. **Least-to-Most  
	**複雑な問題を一連のより単純なサブ問題に分解し、順次解決する
3. **Self-Consistency  
	**同じ質問に対して複数の回答を生成し、最も頻出する回答を最終的な解とする
4. **Self-Correction  
	**生成されたSQLの正確性をLLM自身にチェックさせ、必要に応じて修正を行う

## ファインチューニング

Text-to-SQLタスクにおいてもファインチューニングは効果的であると考えられています。以下はText-to-SQLにおけるファインチューニングの分類です。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_73368_3.png)

Text-to-SQLにおけるファインチューニングの分類

### 学習データの用意

ファインチューニングの成功は高品質な学習データに大きく依存します。学習データの準備方法は、主に下記2つのアプローチがよしとされています。

#### （１）既存データセットの統合

一般的なText-to-SQLモデルの訓練には、Spider、Spider-SYN、ADVETA、SParCなど、様々な既存データセットが利用されており、多様な課題（多言語対応、対話型タスク、ノイズへの耐性など）を網羅しています。

ただし、複数のデータセットを組み合わせることで必ずしも汎化性能が向上するとは限らないことが指摘されている点に注意です。

#### （２）新規データセットの構築

従来は人手による作成が一般的でしたが、最近はLLMを活用した半自動・全自動の構築方法が開発されています。例えば、LLMを用いてデータベーススキーマからSQLクエリを生成し、実行ベースの検証を行う手法が提案されています。また、既存のデータを基に、LLMを使って段階的に複雑で多様なデータを生成する手法も研究されています。

### 事前学習モデルの選択について

ファインチューニングにおいては、最適な事前学習モデルを選択することも重要です。以下の点が考慮されます。

- **モデルの能力  
	**より広範な事前学習 [コーパス](https://ai-data-base.com/archives/26324 "コーパス") を持つモデルが有利とされる
- **パラメータ規模  
	**同じ量の訓練データでは、より大規模なモデルの方が優れた性能を示す傾向がある
- **特化型モデル  
	**コーディング特化型のモデルがText-to-SQLタスクで効果を発揮するという報告もある

### モデルのトレーニングについて

Text-to-SQLタスクにおけるモデルトレーニングには、主に2つの手法が採用されています。

（１）完全なファインチューニング

モデル全体のパラメータを調整します。高い性能が期待できますが、計算コストが高くなります。

（２）パラメータ効率的ファインチューニング

モデルの一部のパラメータのみを調整する手法です。LoRAやQLoRAなどが開発されています。訓練効率が高く、破局的忘却（学習済みの知識を失う現象）のリスクが低いとされています。

### モデルの評価方法

ファインチューニング後のモデル評価には、以下の3つのアプローチが提案されています。そしてアプローチを組み合わせることで、ファインチューニングされたモデルの性能を多角的に分析することが可能になります。

（１）メトリクス分析評価

- **Exact Set Match Accuracy (EM)  
	**生成されたSQLと正解SQLの文字列を比較する
- **Execution Accuracy (EX)  
	**SQLの実行結果を比較する
- **Test-suite Accuracy (TS)  
	**小規模なテストスイートを用いて意味的な正確性を評価する
- **Valid Efficiency Score (VES)  
	**SQL実行の効率性も考慮に入れた評価指標

（２）カテゴリ分析評価

- **データセット特性による分類  
	**ゼロショットシナリオ、多言語シナリオなど
- **プロンプト手法による分類  
	**異なるプロンプトフォーマットや例示選択方法の効果を評価する
- **質問難易度による分類  
	**簡単、中程度、難しい、非常に難しいの4段階で評価
- **エラータイプによる分類  
	**システムエラーと結果エラーに大別し、さらに詳細に分類

（３）LLMベースの分析評価

LLMの [自然言語処理](https://ai-data-base.com/archives/26319 "自然言語処理（NLP）") 能力を活用して、モデル間の差異を「いつ、なぜ、どのように」の観点から分析します。

## 今後の課題

Text-to-SQLタスクにおけるLLMの応用は大きな進展を見せていますが、まだ多くの課題が残されています。以下の方向性で取り組むことで、Text-to-SQLシステムの実用性と性能が大幅に向上することが期待されるとのことです。

### （１）プライバシーへの懸念

ChatGPTやGPT-4などの（強力な）LLMは、APIを通じて利用されることが多いですが、プライバシーの問題が伴います。企業の機密情報や重要な指標がLLMのプロバイダーに送信されるという懸念がなくならないからです。

解決策として、プロバイダーに頼らずにLLMを開発するアプローチが挙げられます。しかし、オープンソースモデルとChatGPTやGPT-4との間には能力差があります。十分なデータがある場合はファインチューニングが選択肢として挙げられますが、ファインチューニングにはモデルの他の能力が低下したり、破局的忘却が起こる恐れがあります。

### （２）自律エージェント

LLMを「脳」として使用し、環境や人間、他のエージェントと対話しながらタスクを自動的に完了する自律エージェントの開発が期待されています。

利点として、柔軟性と探索性が高く、パイプラインシステムよりも優れることが挙げられます。人間のSQLライティングプロセスにより近い動作が可能です。また結果の観察や正確性の自律的な判断ができます。

ただし現状では、Text-to-SQLタスクにおける自律エージェントの応用はまだ見られていません。エージェントフレームワーク（ [MAC-SQL](https://arxiv.org/abs/2312.11242) など）は提案されていますが、完全に自律的ではありません。

### （３）複雑なスキーマへの対応

実世界のText-to-SQLタスクでは、非常に複雑なテーブルスキーマが使用されることがあります。しかし課題として、大量のトークンはLLMの注意を分散させ、正確なSQL生成を困難にします。また、推論時間が長くなります。

そこで解決策として、スキーマリンキング技術の改善が提案されています。自然言語クエリに関連するテーブルとカラムのみを選択することで、精度の向上が期待されています。

### （４）ベンチマークの改善

現在のベンチマークデータセットは、実世界のシナリオと比較してまだ単純すぎる傾向があります。

そのため、より複雑で大規模なテーブルスキーマを含むデータセットの開発が求められています。実際の企業データベースに近い規模と複雑さを持つベンチマークの作成が望まれます。

### （５）ドメイン知識の統合

産業応用では、タスク関連のドメイン知識がLLMに要求されます。

その課題としては、関連するドメイン知識がないと、LLMは質問の理解や回答に深刻なバイアスを持つ可能性がある点が挙げられます。

そこで解決策として、プロンプトエンジニアリングとファインチューニングの2つのアプローチがあります。ここでのプロンプトエンジニアリングとはつまりRAGです。ただし、知識ベースの構築と適切な知識の検索が難しい場合があります。  
またファインチューニングにおいては学習された知識の修正が困難という課題もあります。

## まとめ

本記事では、Text-to-SQLタスクにおけるLLMの活用に関する調査研究を紹介しました。

手法としては、プロンプトエンジニアリングとファインチューニングの2つの主要アプローチが挙げられています。プロンプトの構造や知識の追加方法、ファインチューニングのプロセスなどが調査されました。

また、BIRDやDr.Spiderなど、新しいベンチマークデータセットについても言及されました。  
最後に、今後の課題として、プライバシー、複雑なスキーマへの対応、ドメイン知識の統合などが挙げられています。

LLMによるText-to-SQLタスクは完全に実用的とはまだ言えないものの、今後の発展に期待されています。

- 参照論文URL： [https://arxiv.org/abs/2407.15186](https://arxiv.org/abs/2407.15186)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[キャラが自律的に対話しながら物語の台本を生成するLLMベースのシステム『IBSEN』](https://ai-data-base.com/archives/73294)

[Among UsのようなゲームでLLMエージェントはどれほど活躍できるか](https://ai-data-base.com/archives/71915)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)