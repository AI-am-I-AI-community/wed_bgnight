---
title: "100万体のLLMエージェントによるシミュレーションを実験できる環境が登場"
source: "https://ai-data-base.com/archives/76640"
author:
  - "[[AIDB Research]]"
published: 2024-10-07
created: 2025-06-13
description: "本記事では、LLMを活用した大規模マルチエージェントシミュレーションの研究を紹介します。Alibabaなどの研究チームは、多数のエージェントの効率的な並列処理、多様な背景設定の簡易化、大量エージェントの一括管理を実現しました。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、LLMを活用した大規模マルチエージェントシミュレーションの研究を紹介します。

Alibabaなどの研究チームは、多数のエージェントの効率的な並列処理、多様な背景設定の簡易化、大量エージェントの一括管理を実現しました。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_76640-1024x576.jpg)

**参照論文情報**

- タイトル：Very Large-Scale Multi-Agent Simulation in AgentScope
- 著者：Xuchen Pan, Dawei Gao, Yuexiang Xie, Zhewei Wei, Yaliang Li, Bolin Ding, Ji-Rong Wen, Jingren Zhou
- 研究機関：Alibaba Group, Renmin University of China

**本記事の関連研究**

- [リアルなWindowsOS環境でのエージェント能力を評価する『WindowsAgentArena』およびエージェント『Navi（ナビ）』Microsoftが開発](https://ai-data-base.com/archives/75765)
- [ノーコードでLLMマルチエージェントを操る『AUTOGEN STUDIO』Microsoftが新開発](https://ai-data-base.com/archives/75716)
- [100人以上の研究者が実験参加　LLMは人間より優れた研究アイデアを思いつくのか？](https://ai-data-base.com/archives/75562)
- [Appleが「LLMエージェントの評価」に特化したベンチマーク『MMAU』を開発　5領域5能力で測る](https://ai-data-base.com/archives/73656)

## 背景

LLMエージェントの開発が進み、様々な実用的なタスクが解決できるようになってきています。

そんな中、LLMエージェントを使って現実世界のシミュレーションを行う取り組みも始まっています。従来のシミュレーションは、あらかじめ決められたルールに基づいて行われていましたが、LLMを使ったエージェントでは現実的なシミュレーションが可能になると期待されています。

しかし、大規模なマルチエージェントシミュレーションを行うには、いくつか課題があります。

1. 多数のエージェントを効率よく動かすのが難しい
2. 多様な背景を持つエージェントを適切に設定するのが大変
3. 大量のエージェントを管理・監視するのは複雑な作業である

そこで今回、Alibabaなどの研究チームはマルチエージェントプラットフォーム「AgentScope」を基に、多数のエージェントを並列で効率よく動かせる仕組み、エージェントに多様な背景を簡単に設定できるツール、大量のエージェントを一括管理できるインターフェースを開発しました。

以下で紹介します。

## 基盤づくり

研究者らは大規模なマルチエージェントシミュレーションを可能にするために、 [AgentScope](https://github.com/modelscope/agentscope) というプラットフォームに以下の機能を追加しました。

**自動並列実行**

- エージェント同士のやりとりを「通信グラフ」として表現する
- 互いに依存関係のないエージェントを同時に動かすことで、処理を速くする

**中央集中型のワークフロー管理**

- シミュレーション全体を1つの中心プロセスで管理する
- 「プレースホルダー」という仕組みを使って、エージェントの処理が終わるのを待たずに次の処理に進めるようにする

### エージェントと環境のやりとり

また、エージェントが環境と相互作用する仕組みも、以下のように実装しました。

**（１）高頻度のアクセスに対応**

環境情報の登録、照会、更新、削除、監視といった操作を素早く行えるようにしました。

**（２）タイムラインと位置の2つの次元**

エージェントが時間や場所に応じて行動を変えられるようにしました。

****（３）** 分散 [ノード](https://ai-data-base.com/archives/26470 "ノード") としての実装**

多数のエージェントが同時に環境にアクセスしても対応できるようにしました。

****（４）** 多層環境構造**

グループごとに異なる環境を設定できるようにし、グループ内での協力や、グループ間での情報の違いを表現できるようにしました。

### エージェントに多様な背景設定を与える

研究者らは、シミュレーションに参加するエージェントに多様な背景設定を与える方法も準備しました。

**（１）設定ツール**

- ユーザーが簡単にエージェントの特性（年齢、性別、職業、国籍、教育など）の分布を指定できるツールを提供する
- 例えば、「教育レベルの分布を、小学校卒20%、高校卒20%、大学卒20%…」といった具合に設定できる

****（２）** 自動背景生成**

- 設定された分布に基づいて、各エージェントの詳細な背景設定を自動生成できる  
	（要するに自分で設定しなくてもさまざまなエージェントを用意できる）
- 多数のエージェントに対して、多様でありながら一貫性のある背景を効率的に作成できる

### 大規模エージェントの管理

また、多数のエージェントを効率的に管理するための機能も備えました。

**（１）分散サーバー**

複数のデバイスにサーバーを立ち上げ、エージェントの作成、監視、停止などを遠隔で行えるようにしています。

**（２）ウェブベースの視覚的インターフェース**

- すべてのサーバーとエージェントの状況を一目で確認できる画面を提供
- サーバーのIP、稼働状態、リソース使用状況などが表示される

**（３）複数シミュレーションの管理**

- サーバーは再利用可能なので、異なるシミュレーション間でも効率的に管理できる
- シミュレーションの設定、開始、終了などを簡単に行える

**（４）サーバー中心の管理**

個々のエージェントではなく、サーバー単位で管理することで、大規模なシステムでも効率的な運用が可能です。

## 実験

研究者らは、今回のAgentScopeの新機能を試すために一連の実験を行いました。

### 実験の設定

実験は、「3分の2の平均を当てるゲーム」という古典的なゲームが使用されました。ゲームのルールは以下の通りです。

1. 各プレイヤー（エージェント）は0から100の間の数字を報告する
2. 全プレイヤーが報告した数字の平均の3分の2に最も近い数字を報告したプレイヤーが勝者となる

このゲームには以下のような特徴があります。

- 理論的には、全員が0を報告するのが最適戦略（ナッシュ均衡）
- しかし、実際のプレイヤーは必ずしも完全に合理的ではないため、結果は0に収束しないことがある
- プレイヤーは他のプレイヤーの行動を予測しながら自分の戦略を決める必要がある

実験では、複数の高性能なコンピューターと6種類のLLMを使用しました。また、エージェントには以下2種類の基本的な指示（プロンプト）が与えられました。

1. 単純にゲームのルールを説明するもの
2. ステップバイステップで考えるよう促すもの

※実験で使用されたコンピューター環境とLLMを以下に捕捉します。

コンピューター環境

- 各デバイスに8台のA100-80G [GPU](https://ai-data-base.com/archives/26570 "GPU") が搭載
- 64コアのCPU
- 1TBのメモリ

LLM

- Llama3-8B
- Llama3-70B
- Qwen2-7B
- Qwen2-72B
- MistralAI-8x7B
- MistralAI-8x22B

### 拡張性と効率性

AgentScopeがどれだけ多くのエージェントを効率的に扱えるかの実験が行われました。

主な発見は以下の通りです。

4台のデバイスを使用して、100万のエージェントによるシミュレーションを12分で完了させることができました。ただし、エージェントに与える指示の複雑さによって所要時間は大きく変わります。例えば、より詳細な思考を促す指示を与えると、85分かかりました。

また、従来の方法と比較して、AgentScopeの新しい仕組みは大幅に効率が良いことがわかりました。例えば、100万エージェントのシミュレーションを40秒で完了させられました（従来の方法では12日以上かかっていました）。

さらに、デバイスの数を増やすと、それに比例してシミュレーションの実行時間を短縮できることがわかりました。例えば、デバイス数を1台から4台に増やすと、実行時間を4分の1に短縮できました。

### シミュレーション結果と分析

プロンプトを変更した際にシミュレーション結果はどう変わったかを以下にまとめます。

**基本的な指示（単純にゲームのルールを説明するもの）の場合**

- ほとんどのLLMで、エージェントは50前後の数字を報告する傾向があった
- ただし、MistralAIのモデルは他より低い数字（平均36.63と31.69）を報告した

**思考プロセスを促す指示（ステップバイステップで考えるよう促すもの）の場合**

- エージェントの報告する数字は全体的に0に近づいた
- MistralAI-8×22Bを使用したエージェントの30%以上が0付近の数字を報告し、ゲームの理論的な最適解（ナッシュ均衡）に近づいた

つまり、合理的な回答を行うように変化したという結果です。

**複数ラウンドのゲームではどうだったか**

ラウンドを重ねるごとに、エージェントの報告する数字は0に近づいていきました。エージェントがゲームを理解し、他のエージェントの行動を考慮して合理的な決定を下せることを示しています。さらに、思考プロセスを促す指示を使うと、より早くナッシュ均衡に近づきました。

### システムプロンプトにおける詳細な指示

研究者らはエージェントの行動をより細かく制御するために、より詳細な指示をシステムプロンプトに追加した実験も行いました。

新しく追加された指示は次のとおりです。

- 追加指示A：全てのプレイヤーが合理的であることを強調
- 追加指示B：全てのプレイヤーが他のプレイヤーの戦略を予測して自分の戦略を調整しようとすることを強調

その結果、次のことが明らかにされました。

これらの追加指示を使用した場合、エージェントの報告する数字は全体的に0に近づきました。「ステップバイステップで考えよ」といった一般的な指示よりも、具体的な指示の方が効果的だったということです。

また複数ラウンドのゲームを行った結果、詳細な指示を与えられたエージェントは、より早くナッシュ均衡に収束しました。  
例えばQwen2-72Bを使用した場合、5ラウンド目の平均報告数字は、Prompt 1で25.16、Prompt 2で2.02、Prompt 3で0.14、Prompt 4で0.15でした。

**LLMごとの違い**

詳細な指示の効果は、使用するLLMによって異なりました。

例えばQwen-72Bでは報告される最大値が大幅に低下しましたが、Mistral-8×22Bではあまり変化がありませんでした。

**応答の長さへの影響**

詳細な指示を与えると、エージェントの応答が長くなる傾向がありました。

エージェントがより多くの側面を考慮してから答えを出すようになったためと考えられます。

### 多様な背景設定

次に研究者らは、エージェントに対して以下のように異なる背景設定を与えた実験を行いました。

**教育レベルによる違い**

小学校卒から博士号取得者まで、5段階の教育レベルを設定しました。

その結果、一般的に、教育レベルが高いエージェントほど低い数字を報告する傾向がありました。

例えばQwen2-72Bを使用した場合、博士号取得者は小学校卒業者よりも明らかに低い数字を報告しました。

**職業による違い**

ゲーム理論の教授、経済学者、心理学者、アスリート、アーティスト、作家の6つの職業を設定しました。

すると、ゲーム理論の教授と経済学者は、他の職業よりも低い数字を報告する傾向がありました。

職業によって合理性が変わってくるということです。

個々のエージェントの行動を見ると、エージェントは与えられた役割に応じて、適切な思考プロセスと決定を示しました。

なお、ゲーム理論の教授は他のプレイヤーが完全に合理的ではないと仮定して行動を調整しました。

### LLMの混合

このセクションでは、異なるLLMを使用したエージェントを混ぜて行った実験について説明しています。マージではなくアンサンブルまたは協調に該当する実験です。

**個人レベルのシミュレーション**

各LLM（Llama3-70B、MistraAI-8×22B、Qwen2-72B）を使用するエージェントを500ずつ設定しました。

その結果、初回のラウンドでは、LLMごとに異なる傾向が見られました（例えばMistralAI-8×22Bは0を報告する傾向）。

そしてラウンドを重ねるにつれて、エージェントは前回の勝者の数字を参考に戦略を調整しました。

**グループレベルのシミュレーション**

同じLLMを使用するエージェントをグループ化した実験も行われました。

すると、グループ内のエージェントは素早く類似した行動を取るようになりました。また、エージェントは他のグループの行動を考慮しつつ、自分のグループに有利になるよう戦略的に数字を選びました。

### さらなる議論

追加の実験をもとに得られた洞察や注意点をまとめていきます。

**LLMの事前知識の影響**

ゲームのルールを少し変更（2/3を1/2や51/100に）して実験を行ったところ、LLMがゲームについての事前知識を持っている可能性があり、それが結果に影響を与える可能性があることがわかりました。

**ナッシュ均衡が0でない場合**

さらに、ゲームのルールを変更して、理論的な最適解（ナッシュ均衡）が10になるようにしました。

この場合は、多くのエージェントが正しく推論を行い、数ラウンド後には10に近い数字を報告するようになりました。

**生成温度の影響**

LLMの生成温度（ランダム性を制御するパラメータ）を変えて実験を行いました。その結果、温度が高いほど、報告される数字のばらつきが大きくなりましたが、平均値はあまり変わりませんでした。

**極端な役割の限界**

7歳の子供の役割を与えると、エージェントの行動が実際の7歳児とは一致しないことがありました。LLMに特定の役割を演じさせる際には限界があるということですね。

## まとめ

本記事では、エージェントベースの大規模シミュレーションを可能にする新たな技術開発に関する研究を紹介しました。

研究チームは、マルチエージェントプラットフォーム「AgentScope」に複数の新機能を追加し、アクターベースの分散メカニズム、柔軟な環境サポート、異種設定、そしてグラフィカルユーザーインターフェースを実装しました。

さたに、これらの新機能を活用して一連のシミュレーション実験が実施され、エージェントの多様な行動が観察されました。

このシミュレーション環境をどのように活用するかはユーザーに委ねられています。

- 参照論文URL： [https://arxiv.org/abs/2407.17789](https://arxiv.org/abs/2407.17789)
- コード： [https://github.com/modelscope/agentscope](https://github.com/modelscope/agentscope)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[「o1-preview」は従来のモデルとは明確に異なり「珍しいタイプの問題」にも強い](https://ai-data-base.com/archives/76609)

[ハーバード大学とGoogleの研究者ら、LLMチャットボットを総合的に評価するデータセットの作り方を報告（作成されたデータセットも公開）](https://ai-data-base.com/archives/76713)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)