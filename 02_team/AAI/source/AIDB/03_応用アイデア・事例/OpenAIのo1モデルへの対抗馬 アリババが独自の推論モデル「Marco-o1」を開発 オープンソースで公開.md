---
title: "OpenAIのo1モデルへの対抗馬 アリババが独自の推論モデル「Marco-o1」を開発 オープンソースで公開"
source: "https://ai-data-base.com/archives/79273"
author:
  - "[[AIDB Research]]"
published: 2024-11-27
created: 2025-06-13
description: "本記事では、OpenAIが発表した大規模推論モデル「o1」を超える性能を目指して開発された、アリババの新しいモデル「Marco-o1」を紹介します。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、OpenAIが発表した大規模推論モデル「o1」を超える性能を目指して開発された、アリババの新しいモデル「Marco-o1」を紹介します。

OpenAIのo1モデルは数学やコーディングなど明確に正解がある分野に主眼を置いていますが、Marco-o1は明確な基準のない現実世界の課題にも対応できる汎用的な推論能力の獲得に挑戦しています。

Chain-of-Thought（CoT）ファインチューニングやモンテカルロ木探索（MCTS）など、最新の技術を組み合わせることで、より幅広い問題解決能力の実現を目指した点が特徴的です。実際にケーススタディではその汎用的な能力がデモ的に示されています。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_79273-1024x576.jpg)

**参照論文情報**

- タイトル：Marco-o1: Towards Open Reasoning Models for Open-Ended Solutions
- 著者：Yu Zhao, Huifeng Yin, Bo Zeng, Hao Wang, Tianqi Shi, Chenyang Lyu, Longyue Wang, Weihua Luo, Kaifu Zhang
- 所属：MarcoPolo Team, Alibaba International Digital Commerce

**「o1」の関連研究**

- [Gemini-1.5-proやGPT-4o-miniなどの性能を上回るLLaVA-o1（11Bパラメータ）](https://ai-data-base.com/archives/79215)
- [o1モデルが人間のように6つの思考パターンを使い分けているとの実験結果](https://ai-data-base.com/archives/77445)
- [「o1-preview」は自己評価メカニズムを持つ　計画立案中に自分の行動をチェックして修正](https://ai-data-base.com/archives/77179)
- [OpenAIのo1-previewモデル、Kaggleのグランドマスター基準を上回るデータ分析性能を発揮](https://ai-data-base.com/archives/77077)
- [「o1」は従来のモデルとは明確に異なり「珍しいタイプの問題」にも強い](https://ai-data-base.com/archives/76609)
- [OpenAIの新しいモデルo1、従来のLLMと比べて「計画能力」で圧倒的な性能向上](https://ai-data-base.com/archives/76177)

## 背景

OpenAIによって発表されたo1モデルは、卓越した推論能力で注目を集めています。OpenAIはo1を単なる大規模言語モデルではなく大規模”推論（すいろん）”モデルとして世に知らしめています。

この成功に触発され、今回Alibabaの研究チームは新しく推論モデルの開発に取り組むことにしました。さらに「o1モデルをさらに幅広い領域に一般化できるか」というチャレンジをすることにしました。

そこで、Chain-of-Thoughtファインチューニング、モンテカルロ木探索、リフレクションメカニズムといった高度な技術を組み合わせることでモデルの開発が進められました。詳細は後述します。

また、その過程で研究チームはデータセットの整備にも取り組みました。Open-O1 CoTデータセット（フィルタリング済み）、Marco-o1 CoTデータセット（合成）、Marco指示データセットを組み合わせることで、モデルの推論能力とタスク遂行能力の向上が図られました。

その結果、出来上がったモデルは、予想を上回る性能を獲得することとなりました。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_79273_1.png)

Marco-o1の推論例。”strawberry”という単語に含まれる’r’の数を数えている。

## 開発用データセットについて

Marco-o1モデルの推論能力を向上させる上では、教師あり微調整（SFT：Supervised Fine-Tuning）という手法が採用されました。その上では、以下の3種類のデータセットが使用されました。

### 1\. Open-O1 CoTデータセット（フィルタリング済み）

[Open-O1プロジェクト](https://github.com/Open-Source-O1/Open-O1) から提供されたCoT（思考の連鎖）データセットに含まれるデータが、品質向上のために厳選されました。ヒューリスティック（経験則に基づく）な方法や品質基準によってフィルタリングが行われています。構造化された推論パターンをモデルが効果的に学習できるようにするのがこのデータセットの目的です。

### 2\. Marco-o1 CoTデータセット（合成）

モンテカルロ木探索（MCTS）という探索アルゴリズムを活用して、Marco-o1 CoTデータセットが生成されました。複雑な推論の過程が含まれており、モデルの推論能力をさらに強化するためのものです。

なおMCTSとは、将棋やチェスのようなゲームでよく使われる手法です。あらゆる可能性を調べるのではなく、有望そうな推論の道筋を重点的に探索することで、効率的に最適な解答にたどり着くことを目指すためのものです。  
このアルゴリズムを、Qwen2-7B-Instructというベースモデルと組み合わせることで、質の高い学習データを1万件生成しました。モデルが問題を解く過程で「次にどのように考えるべきか」という選択肢を生成し、その中から最も確信度の高い推論の道筋が選ばれていくといった流れです。

### 3\. Marco指示データセット

複雑なタスクを実行する際には、指示に正確に従う能力が重要です。そのため、アリババの研究チームは5,141件の指示データを独自に作成し、モデルに組み込みました。

### データセットの内訳

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_79273_2.png)

- オープンO1 CoTデータセット（フィルター済み）：45,125サンプル
- Marco-o1 CoTデータセット（人工生成）：10,000サンプル
- Marco指示データセット：5,141サンプル  
	合計で60,266サンプルが使用されました。

なお、データセットの一部は一般公開されており、ダウンロードが可能となっています。

[https://github.com/AIDC-AI/Marco-o1/blob/main/data/CoT\_demo.json](https://github.com/AIDC-AI/Marco-o1/blob/main/data/CoT_demo.json)

## Marco-o1における推論の戦略

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_79273_3.png)

Marco-o1システムの全体像を示す概要図

### 推論における「行動」

推論プロセスは、問題を解決するために一連の”思考のステップ”を進めていく過程です。次の推論ステップを選択することを「行動」と呼びます。たとえば、数学の問題を解く際の「式を立てる」「計算する」「結果を確認する」といった各ステップが行動に相当します。

### ”粒度”の重要性

推論の過程をどの程度の細かさで区切るかという「粒度」は、システムの性能に大きな影響を与えます。大きな単位で考えると効率的ですが、詳細な検討が不足する可能性があります。逆に細かすぎると計算量が膨大になるというトレードオフがあります。このバランスをどう取るかが、推論戦略の重要な要素となっています。

これらの前提を踏まえた上で、Marco-o1システムではどのように具体的な推論戦略が実装されているのかを見ていきましょう。

### 行動の選択

今回、重要な役割を果たすMCTSアルゴリズムによる探索においては、行動を単位とする方法では粒度が粗すぎるという問題があると考えられました。複雑な問題を解くためには、きめ細かな推論の道筋が必要とされます。

そのためMCTSの探索における粒度のレベルが見直されることになりました。

当初は前述したように「ステップ」が探索の単位として使用されましたが、モデルの探索範囲を広げ、問題解決能力を向上させるため、64トークンや32トークンという小さな単位（「ミニステップ」と呼ばれる）に分割する実験が行われました。トークンとは、言語モデルが出力するデータの単位です。

理論的には、1トークンレベルでの探索が最大の柔軟性と粒度を提供できますが、現時点では膨大な計算リソースが必要となること、報酬モデルの設計が困難であることから、まだ現実的ではありません。

### 内省機能の実装

思考プロセスの最後に「待って！私は間違いを犯したかもしれない！最初から考え直す必要がある」といったフレーズによってモデルに自身の推論ステップを再評価させるように実装されました。（実際には”Wait! Maybe I made some mistakes! I need to rethink from scratch.”というフレーズが使用されます）

この「振り返り」の実装は、モデルが誤って解答してしまいがちだった難しい問題において、顕著な改善をもたらしました。なんと当初間違えた問題の約半数が正しく解答されるようになりました。なお、内部フィードバックループとして機能します。

## 実験

### 基本設定

Qwen2-7B-Instructをいくつかのアプローチで改良することで推論モデルの作成が進められました。

まず、教師あり微調整（SFT）を用いてMarco-o1-CoTが作成されました。さらに、このMarco-o1-CoTにMCTS（モンテカルロ木探索）を組み合わせた実験が行われました。この際に行動の単位を変えた3つの異なるバージョンが作られました。

- Marco-o1-MCTS（ステップ）：推論の各ステップを1つの行動として扱うもの
- Marco-o1-MCTS（64トークンのミニステップ）：64トークンごとに区切って行動とするもの
- Marco-o1-MCTS（32トークンのミニステップ）：32トークンごとに区切って行動とするもの

ステップやトークンの意味合いは前述したとおりです。

実験の際には、すべてのモデルでCoT（思考の連鎖）プロンプトが使用され、推論プロセスの一貫性が保たれました。論文中には具体的なCoTプロンプトの内容は記載されていませんでしたが、おそらく”let’s think step by step”のようなテキストと推測されます。

### 実験結果

[MGSMデータセット](https://github.com/google-research/url-nlp/tree/main/mgsm) （英語版と中国語版）で評価が進められました。このデータセットは、多言語での数学的推論能力を評価するためのテストセットで、様々な数学の文章題が含まれています。

実験結果から、興味深い発見がいくつか得られました。

英語版MGSMでは、Marco-o1-CoTはQwen2-7B-Instructよりも良い成績を示しました。英語のCoTデータで微調整を行った効果が順当に出ていると考えられます。

一方で、中国語版MGSMでは逆にMarco-o1-CoTの性能が低下しました。微調整に使用されたCoTデータが英語のみだったことが原因と考えられています。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_79273_4.png)

各モデルのMGSM英語版と中国語版での精度の比較結果

そして次に、MCTSアルゴリズムを組み込んだ3つのモデルは、いずれもMarco-o1-CoTよりも性能が向上しました。MCTSによって解の探索範囲が広がり、正解にたどり着く確率が高まったためと解釈されています。ただし、信頼度スコアを報酬として使用しているため、木探索の結果にはかなりのランダム性が含まれていると指摘されています。

英語版MGSMでは「ステップを行動とする」戦略が最も高い性能を示し、中国語版MGSMでは「32トークンのミニステップを行動とする」戦略が最高の正確性を達成しました。現時点ではどの行動戦略が最も優れているかについて、結論を下すことは困難とのことです。しかし報酬の精度が向上すれば、MCTSが提供するより大きな解探索空間の潜在能力がより明確になると予測されています。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_79273_5.png)

各モデルのMGSM英語版と中国語版での精度（Accuracy）の比較結果

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_79273_6-1024x802.jpg)

Marco-o1-CoTとMarco-o1-MCTS(step)のMGSMデータセットでの比較

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_79273_7-1024x787.jpg)

Marco-o1-MCTS(step)とMarco-o1-MCTS(mini-step of 32 tokens)の比較

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_79273_8-1024x761.jpg)

Marco-o1-MCTS(mini-step of 64 tokens)とMarco-o1-MCTS(step)の比較

ただし実験結果全体を通して言えることは、様々な言語や設定においてこのアプローチが推論能力の向上に効果的である可能性が高いということです。

※なお、ベースモデルであるQwen2が日本語に対応しているため、Marco-o1にも日本語能力が備わっています。詳しくは、 [HuggingFaceで実際にモデルをダウンロード](https://huggingface.co/AIDC-AI/Marco-o1) するか、 [AnyChat](https://huggingface.co/spaces/akhaliq/anychat) で試すことで確認できます。

## 翻訳タスクによるケーススタディ

Marco-o1モデルの能力を実証するため、例として口語表現やスラングの翻訳を行うケーススタディが実施されました。今回はGoogle翻訳との比較が行われ、文脈理解とニュアンスの把握における性能が評価されました。

### 具体的な事例

3つの実験が行われました。

1つ目は、「この靴は履き心地が良く、購入がお勧めです」といった表現の翻訳が検証されました。日常的な商品レビューにおける自然な言い回しの翻訳能力が試されました。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_79273_9.jpg)

「履き心地の良い靴」に関する口語表現の翻訳デモ

2つ目は、「とても美しく魅力的で、上部は韓国風のスタイルが際立ち、柔らかくふんわりとした素材は完璧な厚みで、ベース層と組み合わさって、ユニークな普段着のアウトフィットを作り出しています」といった、より複雑な表現が扱われました。ファッションに関する詳細な描写と文化的な要素を含む表現の翻訳精度が評価されました。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_79273_10-edited.jpg)

3つ目は、感情をこめて商品をお勧めしている文の翻訳です。「とても美しい！そして、とても安く、超まっすぐでカールしません。買いましょう、買いましょう！（おそらくウィッグのようなものを宣伝しています）」といった感情的な表現を含む文章が取り上げられました。感嘆文や繰り返しを含む口語的な表現の翻訳が検証されました。

![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_79273_11-edited.jpg)

全体的に、Marco-o1が口語表現やスラングの翻訳において、標準的な翻訳ツールを上回る性能を示したことが報告されています。文化的な文脈やニュアンス、感情表現の理解において優れた能力を発揮しているようです。

ケーススタディをまとめると、モデルは以下の点で優れた性能を示しました。

- 文化的な背景を考慮した適切な表現の選択
- 感情的なニュアンスの保持
- 自然な口語表現への変換
- 商品レビューなどの実用的な文脈における適切な表現の選択

Marco-o1が単なる逐語訳を超えて、より深い言語理解と文脈に応じた適切な表現の選択が可能であることを示唆しています。

翻訳以外のタスクでの性能に関しては今後の報告が待たれます。

## まとめ

本記事では、Chain-of-Thought（CoT）ファインチューニング、モンテカルロ木探索（MCTS）、および新しい推論戦略を統合することで、推論能力の向上を目指したMarco-o1プロジェクトを紹介しました。

MCTSの導入により解の探索空間が拡大され、ステップやミニステップという異なる粒度での探索実験を通じて、より細かな探索がモデルの精度向上に寄与する可能性が示されました。

研究チームは今後、MCTSの報酬シグナルの改善や [強化学習](https://ai-data-base.com/archives/26125 "強化学習") 技術の活用を通じて、さらなる性能向上を目指すとしています。

モデルは公開されているのでぜひ試してみてください。

- 参照論文URL： [https://arxiv.org/abs/2411.14405](https://arxiv.org/abs/2411.14405)
- GitHub： [https://github.com/AIDC-AI/Marco-o1](https://github.com/AIDC-AI/Marco-o1)
- モデル： [https://huggingface.co/AIDC-AI/Marco-o1](https://huggingface.co/AIDC-AI/Marco-o1)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[Gemini-1.5-proやGPT-4o-miniなどの性能を上回るLLaVA-o1（11Bパラメータ）](https://ai-data-base.com/archives/79215)

[LLMを「評価者」として活用する『LLM-as-a-judge』の基本](https://ai-data-base.com/archives/79428)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)