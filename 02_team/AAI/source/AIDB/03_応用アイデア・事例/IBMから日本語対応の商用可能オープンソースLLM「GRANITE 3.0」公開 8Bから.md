---
title: "IBMから日本語対応の商用可能オープンソースLLM「GRANITE 3.0」公開 8Bから"
source: "https://ai-data-base.com/archives/77349"
author:
  - "[[AIDB Research]]"
published: 2024-10-23
created: 2025-06-13
description: "本記事では、IBMが新たに開発した軽量なLLM「Granite」について紹介します。近年、企業が自社サーバーで安全にLLMを運用したいというニーズが高まっていますが、データの透明性やライセンスの制約など、多くの課題が存在していました。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、IBMが新たに開発した軽量なLLM「Granite」について紹介します。近年、企業が自社サーバーで安全にLLMを運用したいというニーズが高まっていますが、データの透明性やライセンスの制約など、多くの課題が存在していました。Graniteは、これらの課題を解決しつつ、限られたコンピューターリソースでも動作する実用的なモデルとして注目を集める可能性が高いです。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77349-1024x576.jpg)

**参照論文情報**

- タイトル：GRANITE 3.0 LANGUAGE MODELS
- 著者：Granite Team
- 所属：IBM

## 背景

LLMは様々な用途で急速に普及しています。LLMの使い方としてはウェブサイトやAPIを通じて利用するのが最も一般的ですが、企業によっては自社のサーバー内で動かしたいというニーズがあります。

しかし、LLMを企業で利用するには大きく3つの課題があります。まず、小規模なハードウェアでも動作する軽量なモデルが必要です。

次に、企業利用の場合、学習に使用したデータの出所や処理方法が明確である必要があります。法的・コンプライアンス上の問題を避けるために重要な要素です。また、既存のモデルには特定の用途に使用できないなどのライセンス制約があることがあり、企業のユースケースによっては使用できない場合があります。

そこで、IBMはGraniteを開発しました。Graniteは複数の言語に対応し、優れたプログラミング能力や推論能力を持ちます。さらに、限られたコンピューターリソースでも動作するように設計されています。

また、すべてのモデルはApache 2.0ライセンスで公開されており、研究目的でも商用目的でも利用可能です。企業での利用を想定して、データのキュレーションや学習プロセスにも十分な配慮がなされています。

以下で詳しく紹介します。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77349_1.png)

6つのドメインにまたがる19のタスクにおける各ベースモデルの平均性能比較

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77349_2.png)

8つのドメインにまたがる23のタスクにおける各instructモデルの平均性能比較

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77349_3-1024x443.png)

異なるドメインにおけるGranite-3.0-8Bとベースラインモデルの相対的な性能比較

## モデルのアーキテクチャについて

まずはGraniteモデルの [アーキテクチャ](https://ai-data-base.com/archives/26562 "アーキテクチャ") について、基本的な構造から説明していきます。

### 2つの基本構造

Granite 3.0のモデル群は、以下の2つの基本構造タイプを持っています。

1. 通常(Dense)モデル

シンプルな構造で、すべてのパラメータを常に使用します。2Bと8Bの2つのサイズが用意されています（※B(Billion)は10億を表し、パラメータ数を示しています）。

1. Mixture-of-Expert (MoE)モデル

より効率的な構造で、状況に応じて必要な部分のみを使用するタイプです。1Bと3Bの2つのサイズが用意されており、実際に使用されるパラメータは400Mと800M程度に抑えられています（※M(Million)は100万を表します）。

### 主な特徴

本モデルファミリーにはいくつかの工夫が施されています。

まず、Grouped Query Attention (GQA)という仕組みが導入され、メモリ効率と性能のバランスが改善されました。またRotary Position Embedding (RoPE)により、文章中の単語の位置関係をより正確に理解できるようになりました。さらにSwiGLUという [活性化関数](https://ai-data-base.com/archives/27011 "活性化関数") が採用され、より柔軟な学習が可能になりました。そして、RMSNormという層 [正規化](https://ai-data-base.com/archives/26401 "正規化") 手法により、計算の安定性が向上しています。

中でもMoEモデルでは、Dropless Token Routingといって処理の安定性を高めるためのデータの欠落を防ぐ仕組みが導入されました。またより細かな専門化（Fine-grained Experts）により、モデルの性能が向上しました。最後に、計算リソースを効率的に分散させる仕組み（Load Balancing Loss）が組み込まれています。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77349_4.png)

Granite 3.0モデルのハイパーパラメータ一覧

## 学習データについて

次にGranite 3.0の学習データについて、重要なポイントを分かりやすく説明します。

### データの基本方針

学習データの収集には3つの重要な基準が設けられました。

基準１：法的な観点

IBMは厳格なデータ審査プロセスを設けており、すべてのデータはこれを通過することが求められます。また、適切なライセンスを持つデータのみを使用し、プライバシーへの配慮も徹底した情報管理を行っています。

基準２：多言語対応

英語を中心としながら、合計12の言語をサポートしています。具体的には英語をはじめ、ドイツ語、スペイン語、フランス語、日本語、ポルトガル語、アラビア語、チェコ語、イタリア語、韓国語、オランダ語、中国語に対応しており、幅広い言語での利用が可能となっています。

基準３：データの品質管理

重複を効果的に排除し、有害なコンテンツを除去しながら、高品質なデータの選別を徹底して行っています。

### データ処理の主なステップ

1. Webページなどから必要な情報を取り出し、その後言語を自動判定して適切に分類する
2. 完全な重複を削除するとともに、類似度の高いコンテンツも検出して適切に整理する
3. 攻撃的な表現の検出と除去を行い、さらにマルウェアなどの有害なコードについても徹底的に除去する
4. 文章の質を総合的に評価し、基準に満たない低品質なコンテンツは除外する

### 人工的なデータの生成

モデルの特定の能力を強化するため、以下のような分野で人工的なデータも作成されました。

（１）プログラミング関連  
コード生成やバグ修正、さらにコードの説明文作成など、プログラミングに関連する様々なタスクに対応したデータ

（２）論理的思考  
数学的問題解決の能力や推論能力の向上を目指し、知識ベースを活用した学習データ

（３）情報検索と生成  
文書からの情報抽出能力や質問応答、自然な会話の生成など、情報処理に関する幅広いデータ

（４）サイバーセキュリティ  
セキュリティに関する基本的な知識から、脅威の検出と対応、さらにセキュリティルールの理解まで、包括的なセキュリティ関連データ

（５）多言語対応  
高品質な翻訳データの作成と、多言語での自然な会話能力の向上を目指したデータ

（６）安全性への配慮  
不適切な使用の防止や倫理的な判断の学習、さらにリスク回避の訓練など、安全性に関する総合的なデータ

## 事前学習について

次に、Granite 3.0の事前学習プロセスについて、基本的な内容から説明していきます。

### データの組み合わせ方

事前学習は2段階に分けて行われ、それぞれで異なるデータの組み合わせを使用しています。

**第1段階：一般的な知識を幅広く学習させる段階**

Webから収集したデータが約69.5%を占め、次いでコードが19.0%、その他に専門分野のデータ、学術データ、数学データ、技術文書などが含まれています。

**第2段階：より高品質なデータを用いて性能を高める段階**

Webデータが45%、専門分野とコードがそれぞれ10%、数学が10%、指示データが10%、多言語データが5%、学術データが5%、技術文書が4%という構成になっています。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77349_5-1024x440.png)

(a) 第1段階の事前学習データの混合比率 (b) 第2段階の事前学習データの混合比率 を円グラフで表示

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77349_6-1024x313.png)

自然言語、コード、数学の各ドメインにおける予測精度と実際の精度の散布図

### 学習の最適化

効率的な学習のため、以下のような工夫が取り入れられました。

（１）μP（ミューピー）手法

小規模なモデルで見つけた最適な設定を、大規模なモデルにも適用できるようにする技術です。効率的な学習が可能にします。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77349_7-1024x361.png)

μPを使用する際に適用される変更点のリスト

（２）パワースケジューラーの導入

学習の進め方を制御する新しい方式で、学習の初期段階で徐々に学習率を上げていき、その後はゆっくりと学習率を下げていく方法です。また、最後は急速に学習率を下げて調整を行います。異なる規模のデータセットでも効率的な学習が可能にすると考えられています。

### 並列処理による効率化

大規模なモデルを効率的に学習させるため、3種類の並列処理が組み合わせられています。

1. テンソル並列処理（計算を複数の [GPU](https://ai-data-base.com/archives/26570 "GPU") に分散させる方式）
2. パイプライン並列処理（モデルの層を複数の [GPU](https://ai-data-base.com/archives/26570 "GPU") に分割して処理する方式）
3. データ並列処理（データを分割して複数の [GPU](https://ai-data-base.com/archives/26570 "GPU") で同時に処理する方式）

例えば、2Bモデルは256個の [GPU](https://ai-data-base.com/archives/26570 "GPU") 、8Bモデルは768個の [GPU](https://ai-data-base.com/archives/26570 "GPU") を使用して学習が行われました。また、MoEモデルは128個から256個の [GPU](https://ai-data-base.com/archives/26570 "GPU") を使用しています。

## 事後学習について

モデルをより実用的にするための追加学習（事後学習）についても説明します。

### チャット形式の構造化

人間との会話をスムーズに行えるよう、まるでチャットアプリのような構造で設計されました。会話における異なる役割を認識するように作られました。

まず、人間が質問や指示を入力する場合、それは「ユーザーの役割」として認識されます。例えば「今日の天気を教えて」という質問が入力されると、それを「ユーザーからの問いかけ」として理解します。

次に、Granite 3.0自身は「アシスタントの役割」として応答します。先ほどの天気の質問に対して、適切な情報を集めて回答を生成する部分です。

その裏では、「システムの役割」が働いています。これは例えるなら、店員さんが接客する際の基本マニュアルのようなものです。「丁寧に応答すること」「不適切な発言は控えること」といった基本ルールを管理します。

さらに、実際の情報を取得するために「ツールの役割」が活躍します。天気の例で言えば、天気情報を取得するためのプログラムと連携して、正確な情報を得る役割を担います。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77349_8-1024x233.png)

会話タスクのためのチャットテンプレート例。基本的な1ターンのユーザーとアシスタントの対話、およびツール使用を含む対話例を提示

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77349_9-1024x154.png)

ユーザーとアシスタントの対話に使用される制御トークンの一覧と説明

### 教師あり微調整

モデルの性能をさらに向上させるため、以下のような方法で追加学習が行われました。

まずデータの構成としては一般的な英語が68%、プログラミング関連が13%、ツールの使用が8%、数学が6%、多言語対応が4%、安全性関連が1%という割合で学習データを用意しました。

また学習の進め方に関しては、まず基本的な能力を学習し、その後により高度な推論能力や対話能力の向上に焦点を当てた学習を行いました。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77349_10-1024x260.png)

6つの主要カテゴリー（一般英語、コード、ツール、数学、多言語、安全性）におけるデータの統計情報

### モデルの調整

モデルをより安全で有用なものにするため、以下の3つの手法を組み合わせて調整を行いました。

1. PPO（近位方策最適化）：モデルの行動方針を徐々に改善していく手法
2. BRAIn：モデルの応答をより適切なものに調整する手法
3. Best-of-N [サンプリング](https://ai-data-base.com/archives/26518 "サンプリング") ：複数の候補から最適な応答を選択する手法

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77349_11-1024x183.png)

アライメントに使用されるデータセットの混合比率とその出典

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77349_12-1024x330.png)

サンプリング 、スコアリング、重み付けクロスエントロピー更新を含むモデルアライメントの流れ図

### 報酬モデルによる評価

モデルの応答評価には、3種類の異なる方法が採用されました。

（１）多面的な評価  
有用性や正確性、一貫性などの様々な観点から応答を評価する

（２）選好度による評価  
2つの応答を比較して、より適切な方を選択する

（３）対照的な評価  
異なるモデルの応答を比較する

### モデルの統合

それぞれの分野に特化した複数のモデルを学習させ、それらを最終的に1つのモデルに統合することで、総合的な性能の向上を図りました。

## モデルの性能

Granite 3.0の性能を公平に評価するため、同じような規模の他のオープンソースモデル（Llama 3.1/3.2、Gemma-2、Mistral、SmolLMなど）と比較評価が行われました。

### 基本モデルの評価

様々な分野で性能が測定されました。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77349_14.png)

Granite-3.0の密なモデルとベースラインモデルの事前学習性能比較（人間の試験、常識、読解力など）

まず人間が受けるような試験問題を解く能力や、常識的な判断力、文章の読解力、論理的な推論能力などが評価されました。結果として、Granite 3.0は比較対象のモデルを多くの項目で上回る性能を示しました。

次にコードの生成や理解に関する能力が評価されました。この分野では特に、他のモデルを大きく上回る結果となりました。

また、数学の問題解決能力も評価されました。この分野でもGranite 3.0は優れた性能を発揮しました。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77349_15.png)

Granite-3.0のMoEモデルとベースラインモデルの事前学習性能比較

### 会話モデルの性能

会話用にチューニングされたモデルについては、まず外部のプログラムやAPIを適切に利用する能力が評価されました。Granite 3.0は、特に2Bと8Bのモデルで高い性能が示されました。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77349_16.png)

Granite-3.0の密なInstructモデルとベースラインモデルの指示追従性能比較

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77349_17-855x1024.jpg)

Granite-3.0のMoE Instructモデルとベースラインモデルの指示追従性能比較

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77349_18-1024x315.png)

密なモデルの関数呼び出しベンチマーク性能比較

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77349_19-1024x316.png)

MoEモデルの関数呼び出しベンチマーク性能比較

また、与えられた文書から適切な情報が見つけ出され、的確な回答が生成される能力が評価されました。多くのケースで他のモデルを上回る性能が達成されました。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77349_22-1024x405.png)

RAGベンチマークにおける各モデルの性能比較（忠実性と正確性の評価）

そしてサイバーセキュリティに関しては、セキュリティに関する知識や判断能力が評価されました。企業での実用を想定した評価でも良好な結果が得られました。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77349_20-1024x179.png)

密なモデルのサイバーセキュリティベンチマーク性能比較

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77349_21-1024x229.png)

MoEモデルのサイバーセキュリティベンチマーク性能比較

最後に不適切な内容の生成を避け、安全な応答を行う能力が評価されました。他のモデルと同等以上の安全性が確保されています。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77349_23-1024x164.png)

安全性ベンチマークにおけるGranite-3.0-8B-Instructと同規模モデルの性能比較

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77349_24-1024x852.jpg)

(a) 8Bパラメータモデルの比較 (b) 2B-3Bパラメータモデルの比較 (c) MoEモデルの比較 を、7つの有害性カテゴリーについてレーダーチャートで表示

### 小規模モデルの実力

なお特筆すべき点として、Granite 3.0の小規模モデル（MoEモデル）も優れた性能を示しました。400Mパラメータのモデルは、より大きな1Bモデルと同等の性能を達成し、800Mパラメータのモデルは、2B〜3Bクラスのモデルに匹敵する性能を発揮しています。

## 社会的・技術的な危害とリスクについて

LLMの使用においては、誤った情報の拡散、事実と異なる内容の生成、個人情報の漏洩、著作権侵害、差別的な発言や有害な内容の生成、いじめやガスライティングなどの対人関係の問題、悪意のある使用、敵対的な攻撃といった様々な懸念が指摘されています。

これらのリスクに対し、IBMではAI倫理委員会の指針に基づいた対策が講じられています。学習データは厳密な審査プロセスを経て選別され、ブロックリストによる制御や有害なコンテンツのフィルタリングが実施されています。また、社会的に望ましい行動パターンが学習され、有害な使用を防ぐための調整が行われています。

さらに、Granite Guardian（保護モデル）という新しい仕組みが導入され、あらゆるLLMの入出力が監視・管理されています。開発者向けには責任あるAI開発のためのガイドが公開され、安全なAIの実装が支援されています。

完全なリスク回避は困難とされていますが、モデルの能力向上に応じた新たなリスク評価が実施され、段階的なリリースによるリスクの最小化が図られています。

各企業の規制や基準に合わせたカスタマイズが支援され、ユーザーが自身の価値観に基づいてモデルを調整できる機能が提供されています。Granite 3.0では技術の発展と安全性のバランスが重視され、潜在的なリスクを認識しつつ、それらを最小限に抑えるための様々な対策が実施されています。

## まとめ

本記事では、IBMが開発した新しい言語モデル「Granite 3.0」の研究を紹介しました。このモデルは、通常型とMoE型の2つの [アーキテクチャ](https://ai-data-base.com/archives/26562 "アーキテクチャ") で4つのサイズが用意され、それぞれに基本モデルと会話用モデルが提供されています。

IBMは開発過程の透明性を重視し、トレーニングデータから評価方法まで詳細な情報を公開しています。言語理解、推論、コーディングなどの基本性能に加え、企業での実用に重要なRAGやサイバーセキュリティでも高い能力を示しました。

なお、本モデル群はApache 2.0ライセンスで公開され、研究・商用の両用途で利用可能です。多言語対応や長文脈モデルなど、今後も継続的な改善が予定されています。

- 参照論文URL： [https://github.com/ibm-granite/granite-3.0-language-models/blob/main/paper.pdf](https://github.com/ibm-granite/granite-3.0-language-models/blob/main/paper.pdf)
- プロジェクトページ： [https://github.com/ibm-granite/granite-3.0-language-models/tree/main](https://github.com/ibm-granite/granite-3.0-language-models/tree/main)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[計画のステップが増えるほど、LLMは最初の目標を見失っていく傾向がある](https://ai-data-base.com/archives/77302)

[o1-previewが人間のように6つの思考パターンを使い分けているとの実験結果](https://ai-data-base.com/archives/77445)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)