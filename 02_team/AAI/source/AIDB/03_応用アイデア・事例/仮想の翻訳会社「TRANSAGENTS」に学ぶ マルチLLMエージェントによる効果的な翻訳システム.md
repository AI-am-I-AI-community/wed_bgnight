---
title: "仮想の翻訳会社「TRANSAGENTS」に学ぶ マルチLLMエージェントによる効果的な翻訳システム"
source: "https://ai-data-base.com/archives/70529"
author:
  - "[[AIDB Research]]"
published: 2024-06-07
created: 2025-06-13
description: "本記事では、LLMを活用した新しいマルチエージェントフレームワーク「TRANSAGENTS」を紹介します。従来の翻訳出版プロセスを模倣して、複数のエージェントの協力によって翻訳を行うものです。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、LLMを活用した新しいマルチエージェントフレームワーク「TRANSAGENTS」を紹介します。従来の翻訳出版プロセスを模倣して、複数のエージェントの協力によって翻訳を行うものです。機械翻訳（MT）の進歩が様々な分野で翻訳の質を大きく向上させたにもかかわらず、翻訳にはまだ多くの課題があり、複雑な言語表現や文化的なニュアンスが多いため翻訳が難しいという現状を背景にしています。

![](https://ai-data-base.com/wp-content/uploads/2024/06/AIDB_70529-1024x576.jpg)

**参照論文情報**

- タイトル：(Perhaps) Beyond Human Translation: Harnessing Multi-Agent Collaboration for Translating Ultra-Long Literary Texts
- 著者：Minghao Wu, Yulin Yuan, Gholamreza Haffari, Longyue Wang
- 所属：Monash University, University of Macau, Tencent

## 背景

機械翻訳の性能は目覚ましく向上していますがまだ課題も多く、とりわけ文学作品の翻訳においては大きな課題が残されています。文学作品には複雑な言葉の表現や言葉遊び、比喩などが使用されており、適切に翻訳するためには言語を理解するだけでなく、創造性や解釈力が必要とされるためです。

そこで、LLMによる翻訳能力を活かしたシステムの構築に焦点が当たっています。LLMは知識や文脈の解釈に基づいた翻訳を行うこともある程度可能であるため、従来の限界を超えた翻訳が期待されています。  
しかし、単一のモデルで翻訳を行うことは、その性質上、あまり効率的ではありません。実際の会社現場における高品質な翻訳におけるあらゆる役割（編集長の仕事や、その下の編集者の仕事など）を反映させるのに手間がかかってしまうためです。

そんな中、複数のエージェントが協力して問題解決にあたる「マルチエージェントシステム」が有望な手段として台頭します。LLMのマルチエージェントシステムはかなり研究が進んでおり、一つのモデルだけでは難しい複雑な問題について優れた性能を発揮することがわかってきました。  
翻訳というケースにおいても、さまざまなペルソナを与えたエージェントたちが協力し、優れた性能を見せるかもしれません。

今回研究者らは、文学翻訳という難題にマルチエージェントシステムを活用する具体的なアプローチを提案しています。仮想の翻訳会社「TRANSAGENTS」を設立し、その中の複数のエージェントが協力して翻訳作業を行います。出版社の翻訳プロセスを模倣しており、文学作品の複雑さに対応することを目指しているものです。

![](https://ai-data-base.com/wp-content/uploads/2024/06/AIDB_70529_1-1024x513.jpg)

従来の機械翻訳と本手法の違いをイメージにした図

## TRANSAGENTS（文学翻訳のための仮想マルチエージェント翻訳会社）

### 会社の構成

CEO（最高経営責任者）をはじめ、シニアエディター、ジュニアエディター、翻訳者、文化適応のスペシャリスト、校正者など、多様な役割を持つエージェントを設計します。

![](https://ai-data-base.com/wp-content/uploads/2024/06/AIDB_70529_2-1024x874.jpg)

TRANSAGENTSのイメージ図

それぞれのエージェントには、言語スキルだけでなく、性別や国籍、専門分野など、詳細なプロフィールを与え、現実世界の翻訳チームの多様性を再現します。例えばシニアエディターは以下のようにペルソナが設計されています。

![](https://ai-data-base.com/wp-content/uploads/2024/06/AIDB_70529_3-1024x564.png)

シニアエディターの仮想エージェントプロファイルの例。

```js
名前: Sofia Chang
言語: 英語、中国語（マンダリン）、スペイン語、フランス語
国籍: カナダ
性別: 女性
年齢: 47
学歴: 比較文学の博士号
性格: 几帳面、内向的、
　　　完璧主義者、批判的、思慮深い
趣味: ガーデニング、チェス、水彩画
単語ごとの料金: 0.12ドル
勤務年数: 22年
職業: シニアエディター
役割のプロンプト: あなたはSofia Changです。高く評価されている
シニアエディター [途中省略]
```

エージェントの役割一覧は以下のとおりです。

1. CEO（最高経営責任者）: プロジェクトの要件に基づいてシニアエディターを選出し、全体の監督を行う。
2. シニアエディター: 編集基準を設定し、ジュニアエディターを指導し、コンテンツが会社の目標に沿っていることを確認する。
3. ジュニアエディター: シニアエディターの指導の下、日々の編集作業を管理し、コンテンツの編集を行う。他の役割との連絡も担当する。
4. 翻訳者: 原文の調子、スタイル、文脈を保ちながら、ある言語から別の言語へ書かれた文章を変換する。
5. ローカリゼーション専門家: 単なる翻訳だけでなく、特定の地域や市場向けにコンテンツを適応させる。
6. 校正者: 文法、スペル、句読点、書式のエラーについて最終チェックを行う。

### エージェント間の協力方法

エージェント同士の協力には、二つの戦略が提案されています。

**「Addition-by-Subtraction Collaboration」戦略**

一方のエージェントが関連情報をできるだけ多く集め（Addition）、もう一方のエージェントが不要な情報を取り除いてフィードバックを行います（Subtraction）。下記のアルゴリズムで示されています。

![](https://ai-data-base.com/wp-content/uploads/2024/06/AIDB_70529_4-1024x482.png)

内容：

```js
入力: コンテキスト C、指示 I、最大反復回数 M、追加エージェント A、削除エージェント S
出力: 両方のエージェントが合意した最終応答 R

会話履歴 H を [C と I] で初期化します。
応答 R を空の状態で初期化します。
現在のラウンド m を 0 で初期化します。
m が M 以下の間、以下を繰り返します：
m を 1 増やします。
追加エージェント A が会話履歴 H に基づいて詳細な応答 R' を生成します。
削除エージェント S が会話履歴 H と応答 R' に基づいて冗長な情報を削除し、フィードバック F を行います。
会話履歴 H に応答 R' とフィードバック F を追加します。
もし R が R' と等しい場合、反復を停止します。
最終応答 R を返します。
```

**「Trilateral Collaboration」戦略**

「Action」「Critique」「Judgment」の三つの役割を設定します。Actionは指示に従ってタスクを実行し、Critiqueは結果をレビューしてフィードバックを提供し、Judgmentは最終的な判断を下します。こちらも下記のようにアルゴリズムで示されています。

![](https://ai-data-base.com/wp-content/uploads/2024/06/AIDB_70529_5-1024x529.jpg)

内容：

```js
入力: コンテキスト C、指示 I、最大反復回数 M、アクションエージェント P、批評エージェント Q、判断エージェント J
出力: 判断エージェント J によって承認された最終応答 R

会話履歴 H を [C と I] で初期化します。
現在のラウンド m を 0 で初期化します。
m が M 以下の間、以下を繰り返します：
m を 1 増やします。
アクションエージェント P が会話履歴 H に基づいて応答 R を生成します。
批評エージェント Q が会話履歴 H と応答 R に基づいて批評 F を生成します。
会話履歴 H に応答 R と批評 F を追加します。
もし m が 1 より大きい場合、判断エージェント J がコンテキスト C と指示 I、応答 R の質を評価します。
もし評価結果 D が TRUE ならば、反復を停止します。
最終応答 R を返します。
```

### 翻訳の流れ

翻訳作業は、準備段階と実行段階の二つに分けられます。

**準備段階**

1. プロジェクトメンバーの選定と翻訳ガイドラインの作成が行われます。
2. CEOがシニアエディターを選びます。
3. シニアエディターがチームを編成します。
4. 翻訳で使う用語集や、翻訳文の文体、対象読者などを決めるガイドラインが作られます。

**実行段階**

下記の四つのステップに分けて作業が進められます。

1. 翻訳
2. 文化適応
3. 校正
4. 最終チェック

各ステップでは「Trilateral Collaboration」戦略が使われ、翻訳者、文化適応のスペシャリスト、校正者がActionの役割を、ジュニアエディターとシニアエディターがそれぞれCritiqueとJudgmentの役割を担います。最後に、シニアエディターが最終チェックを行って翻訳が完成します。

（まさに、人間の翻訳会社が行なっている手順のようですね）

## 実験の目的と方法

### 比較対象となる翻訳システム

TRANSAGENTSの性能を評価するために、いくつかの他の翻訳システムが比較対象として選ばれました。

1. LLAMA-MT: LLAMA-7Bという言語モデルを文学翻訳用に調整したシステムです。
2. GPT-4: GPT-4-0613とGPT-4-1106-PREVIEWというモデルを使って、章ごとに翻訳を行うシステムです。
3. GOOGLE: Googleの翻訳システムを使って、文ごとに翻訳を行うシステムです。
4. DUT: 大規模言語モデルの性能を向上させるためのいくつかの技術を試したシステムです。
5. HW-TSC: 文レベルの翻訳モデルをベースに、分野適応や文脈のモデリングなどの手法を用いて性能を上げたシステムです。

### 使用されたデータセット

新しいモデルを訓練する必要がなかったため、WMT2023のDLLTタスクの公式テストセットだけが使われました。20のWeb小説から集められたもので、各小説は20の連続した章で構成されています。合計で240章が含まれています。また、このテストセットには二つの参照訳が用意されています。一つは人間の翻訳者が翻訳したもの（REFERENCE 1）、もう一つはWebページ上の二言語のテキストを手動で対応付けることで作られたものです（REFERENCE 2）。

### 評価の方法

文学作品の翻訳を評価するには、ニュース記事などの一般的な機械翻訳とは異なるアプローチが必要です。今回は二つの評価方法が採用されました。

1. 標準的な評価: d-BLEU（文書レベルのBLEUスコア）を使って、翻訳の品質を評価します。
2. 選好度評価: 文学作品には唯一の正解となる翻訳がないことを考慮し、人間の評価者や大規模言語モデルに、参照訳を見せずに翻訳の選好度を判断してもらう新しい評価方法

## 標準的な評価による実験結果

研究チームは、まず標準的な機械翻訳の評価尺度であるd-BLEUスコアを使って、TRANSAGENTSの性能を評価しました。d-BLEUスコアは、翻訳結果と参照訳がどれだけ一致しているかを測る指標です。スコアが高いほど、翻訳の品質が高いと考えられています。

しかし、結果はチームの予想に反するものでした。TRANSAGENTSのd-BLEUスコアは、比較対象の中で最も低い値を示したのです。これは一見、TRANSAGENTSの性能が悪いように見えます。

### d-BLEUスコアの限界

ただし、d-BLEUスコアにはいくつかの限界があることが指摘されています。d-BLEUは、翻訳結果と参照訳の表面的な一致度を測るだけで、翻訳の品質や流暢さを十分に捉えられないことがあるのです。

さらにd-BLEUの計算に使われる参照訳は、多様性に乏しく、翻訳調の言葉遣いに偏りがちだと言われています。つまり、d-BLEUスコアが低くても、必ずしもTRANSAGENTSの性能が悪いとは限らないのです。

![](https://ai-data-base.com/wp-content/uploads/2024/06/AIDB_70529_6-1024x530.png)

### 文学翻訳の特殊性

これは、文学翻訳の特殊性とも関係しています。先行研究によると、自動評価尺度は文学翻訳において人間の好みを正確に反映できないことが示唆されています。  
つまり、例えばマニュアルドキュメントなどの翻訳よりも文学作品の翻訳では人間の好みがより重要にも関わらず、評価する手法が不十分ということです

また、一般的な機械翻訳の評価では、翻訳の品質を多面的に評価する「Multidimensional Quality Metrics (MQM)」というフレームワークがよく使われます。しかし、このフレームワークも文学翻訳の品質評価には適していないかもしれません。

文学作品は、独特の表現や創造的な要素を含んでいるため、標準的な自動評価尺度やMQMに基づく人手評価では捉えきれない側面があるのです。

## 文学翻訳の評価における新しい方法

文学作品の翻訳は、ニュース記事などの一般的な機械翻訳とは異なる特徴があります。文学翻訳では、意味が正確に伝わるだけでなく、表現の豊かさや文化的なニュアンスを伝えることが求められます。そのため、参照訳と直接比較するだけの従来の評価方法では、文学翻訳の品質を適切に評価することが難しいのです。

### 選好度に基づく評価の提案

研究者らはLLMを活用して翻訳の選好度に基づき評価を行う新しい方法を提案しています。次の二つの方法です。

**Monolingual Human Preference (MHP)**

MHPは、翻訳された文章を読む人の視点から評価を行う方法です。対象言語のみを理解する人間の評価者が、原文を見ずに翻訳の選好度を判断します。

翻訳された文学作品を実際に読む状況を模倣しているものです。

インタフェースは以下のように二つのパターンを並べて選択させるようになっています。

![](https://ai-data-base.com/wp-content/uploads/2024/06/AIDB_70529_7-1024x408.png)

Monolingual Human Preference (MHP) の評価インターフェース。

```js
Q: 次のうち、どの文体がお好みですか？

[x] 第455章: 転換3 「形のない波動の感知をお見せします。これは非常に簡単です」と、別の魔術師が微笑を浮かべて言った。「ご協力感謝します」とリン・シェンは感謝の意を込めてうなずいた。彼は残りの破片を見つけることが時間の要であると感じていた。彼はもともと多くの大悪霊を征服し、純粋な魂の力を大量に蓄える計画を立てていた。しかし、今の状況では迅速かつ決定的な取得が求められた。すぐに魔術師のリーダーはリン・シェンを恐ろしい悪霊の門に連れて行った。二人は手を差し出し、門の神秘的な枠に触れ、目を閉じた。リーダーは迅速に彼の特別な能力を用いて空間基盤を確立し、座標コードを設定した。

[ ] 第455章: 反転3 「これはオーラの変動を感じさせるためです。本当に簡単です」と別のウォーロックが微笑を浮かべながら口を挟んだ。「お手数をおかけします」とリン・シェンはうなずいた。彼はできるだけ早く他の破片を見つけ、より多くの純粋な魂の力を得る必要があった。しかし、このような機会に出くわした今、最も重要なのはできるだけ早くそれを手に入れることだった。すぐにウォーロック司令官はリン・シェンを悪霊の門に導いた。二人は手を差し出し、同時に悪霊の門の枠に触れ、目を閉じた。ウォーロック司令官は迅速に彼の能力を用いて空間基盤を座標として確立した。

[ ] どちらも好まない
```

**Bilingual LLM Preference (BLP)**

BLPは、高度な言語モデルを使って、翻訳文を原文と直接比較する方法です。この方法では、GPT-4-0125-PREVIEWというモデルが、参照訳を使わずに翻訳の品質を評価します。参照訳の不完全さの影響を減らしつつ、言語モデルの優れた翻訳能力を活用することが期待されます。

![](https://ai-data-base.com/wp-content/uploads/2024/06/AIDB_70529_8-1024x547.png)

Bilingual LLM Preference の評価に使用するプロンプトの例。

```js
[原文の開始]
[$src_lang]: $src
[原文の終了]

[アシスタント1の翻訳の開始]
[$tgt_lang]: $asst1
[アシスタント1の翻訳の終了]

[アシスタント2の翻訳の開始]
[$tgt_lang]: $asst2
[アシスタント2の翻訳の終了]

ご意見をお聞かせいただければ幸いです [途中省略]
```

### 評価実験の設定

選好度に基づく評価の有効性を検証するために、次のような設定で評価実験が行われました。

- TRANSAGENTSと、REFERENCE 1（人間の翻訳者による参照訳）、GPT-4-1106-PREVIEWモデルの比較
- テストセットに含まれる各小説の最初の2章を使用
- MHPとBLPの両方の評価方法を適用

### 評価実験の結果

評価実験の結果、次のようなことがわかりました。

- MHPでは、TRANSAGENTSの翻訳は、REFERENCE 1やGPT-4-1106-PREVIEWよりも人間の評価者に好まれる傾向があった。
- BLPでも、TRANSAGENTSの翻訳は、他のモデルよりもGPT-4-0125-PREVIEWに選好される傾向が見られた。
- GPT-4-0125-PREVIEWは、文学翻訳の評価において、多様で生き生きとした表現を重視する傾向があることが示唆された。

![](https://ai-data-base.com/wp-content/uploads/2024/06/AIDB_70529_9-1024x529.png)

Monolingual Human Preference 評価の結果。TRANSAGENTSの翻訳が他のモデルよりも人間の評価者に好まれる傾向がある。

![](https://ai-data-base.com/wp-content/uploads/2024/06/AIDB_70529_10-1024x529.png)

Bilingual LLM Preference 評価の結果。TRANSAGENTSの翻訳が他のモデルよりもGPT-4-0125-PREVIEWに選好される傾向がある。

上記の結果から、選好度に基づく評価が文学翻訳の品質を評価する上で有効であることが示されました。

また、TRANSAGENTSが生成する翻訳が、人間の評価者やLLMから高く評価される傾向があることが明らかになりました。

## 詳細な分析（考察）

### なぜTRANSAGENTSはd-BLEUスコアが低かったのか

標準的な評価指標であるd-BLEUスコアでは、TRANSAGENTSは他の手法と比べて最も低い結果となりました。この原因を探るために、研究チームはTRANSAGENTSの翻訳プロセスの各段階における出力を評価しました。その結果、翻訳ガイドラインが最終的な翻訳の品質に大きな影響を与えていることがわかりました。また、文化適応の段階でd-BLEUスコアがさらに低下し、校正の段階ではほとんど変化がないことも明らかになりました。

つまり、人間の好みに合うように内容を調整する段階で、伝統的な指標で測る「正確性」は表面的には下がってしまうということですね。

![](https://ai-data-base.com/wp-content/uploads/2024/06/AIDB_70529_11-1024x259.png)

TRANSAGENTSのワークフローの各段階におけるd-BLEUスコア。翻訳ガイドラインが最終的な翻訳品質に大きく影響していることを示唆。

![](https://ai-data-base.com/wp-content/uploads/2024/06/AIDB_70529_12.png)

TRANSAGENTSのGPT-4-1106-PREVIEWとREFERENCE 1に対する勝率の内訳。ジャンルごとの性能の違いを示している。

### TRANSAGENTSの長所と短所

研究チームは、テストセットに含まれるさまざまなジャンルごとにTRANSAGENTSの性能を詳しく分析しました。その結果、歴史的な背景や文化的なニュアンスなど、専門的な知識を必要とする分野では優れた性能を発揮することがわかりました。一方で、現代を舞台にした作品では、やや苦手とする傾向が見られました。

### 言語の多様性

文学作品では、”言葉の多様性”（要するに表現の豊かさ）が読者の体験を豊かにする重要な要素です。TRANSAGENTSが生成する翻訳の言語的な多様性を定量的に評価するために、MATTR（Moving-Average Type-Token Ratio）とMTLD（Measure of Textual Lexical Diversity）という二つの指標が用いられました。

その結果、TRANSAGENTSの初期翻訳は、翻訳ガイドラインのおかげで、原文よりも言語的な多様性が大幅に向上していることがわかりました。さらに、文化適応の段階でも多様性が向上し、校正の段階では影響がないことも明らかになりました。

![](https://ai-data-base.com/wp-content/uploads/2024/06/AIDB_70529_13-1024x480.png)

MATTR (Moving-Average Type-Token Ratio) とMTLD (Measure of Textual Lexical Diversity) による言語的多様性の評価。TRANSAGENTSの翻訳が高い言語的多様性を示している。

![](https://ai-data-base.com/wp-content/uploads/2024/06/AIDB_70529_14-1024x246.png)

文化的適応のケーススタディ。TRANSAGENTSのみが文化的文脈を正確に反映できている。

### コスト分析

プロの人間翻訳者を雇う場合と比べて、TRANSAGENTSを使うことで翻訳コストを80倍も削減できる可能性が示されました。

## その他の分析

### 文化的な適応

中国語では、役職は通常、人名の前に置かれますが、英語では人名の後に置かれるのが一般的です。TRANSAGENTSは、この文化的な違いを翻訳に正しく反映することができた唯一のシステムでした。一方、REFERENCE 1（人間の翻訳者による参照訳）とGPT-4-1106-PREVIEWは、名前と役職の順番を適切に調整できませんでした。

（今回の実験では、中国語↔️英語間の翻訳がテストされています）

### 全体的な一貫性

章のタイトルは、番号以外は一貫性が保たれていました。REFERENCE 1とTRANSAGENTSは、一貫した翻訳を生成することに成功しましたが、GPT-4-1106-PREVIEWは異なる章の間で一貫性を維持するのに苦労していました。

![](https://ai-data-base.com/wp-content/uploads/2024/06/AIDB_70529_15-1024x149.png)

全体的な一貫性のケーススタディ。TRANSAGENTSとREFERENCE 1は一貫した翻訳を生成できているが、GPT-4-1106-PREVIEWは章間で一貫性を維持するのに苦労している。

### 内容の欠落

人間の評価者やLLMによる評価では、TRANSAGENTSの翻訳はREFERENCE 1やGPT-4-1106-PREVIEWよりも好まれる傾向がありました。しかし、翻訳された章を小さな部分に分けて詳しく分析したところ、GPT-4-1106-PREVIEWとTRANSAGENTSの両方で、内容の欠落が大きな問題となっていることがわかりました。ストーリーの展開には影響しないように見えますが、登場人物の描写や感情の描写を損なう可能性があります。

今回は文学作品なので読み味が重視される場合は大きな問題にはなりませんが、情報の綿密性や網羅性に重きをおく別のファイルを扱う際には注意したほうがいいのかもしれません。

![](https://ai-data-base.com/wp-content/uploads/2024/06/AIDB_70529_16-1024x728.png)

内容の欠落のケーススタディ。GPT-4-1106-PREVIEWとTRANSAGENTSの両方で内容の欠落が見られる。

### プロの翻訳者の意見

研究チームは、TRANSAGENTSとREFERENCE 1、GPT-4-1106-PREVIEWの翻訳を匿名化して、2人のベテラン翻訳者に品質を評価してもらいました。

その結果、TRANSAGENTSの翻訳は小説のような表現力豊かなスタイルだと評価されました。一方、REFERENCE 1とGPT-4-1106-PREVIEWは原文に忠実ではあるものの、伝統的なスタイルにとどまっていると指摘されました。

![](https://ai-data-base.com/wp-content/uploads/2024/06/AIDB_70529_17-1024x290.png)

2人のベテラン翻訳者によるTRANSAGENTS、REFERENCE 1、GPT-4-1106-PREVIEWの翻訳に対するコメント。TRANSAGENTSの翻訳が最も表現力豊かで洗練されていると評価されている。

## まとめ

本記事では、文学翻訳のための仮想のマルチエージェント翻訳会社「TRANSAGENTS」を提案した研究を紹介しました。

LLMを用いたマルチエージェントシステムと新たな評価手法を組み合わせたアプローチを採用し、人間の評価者や言語モデルから高い評価を得ています。一方で、評価手法の制約や内容の欠落などの課題も指摘されています。

本研究は文学翻訳という難しいタスクに対する新しいアプローチであり、今後の展開に期待です。システムが実用化されれば、翻訳コストの削減と翻訳プロセスの効率化によって、より多くの文学作品が世界中の読者に届けられるかもしれません。

- 参照論文URL： [https://arxiv.org/abs/2405.11804](https://arxiv.org/abs/2405.11804)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[LLMの出力が信頼できるかを判定する手法　Google DeepMindが新しく考案](https://ai-data-base.com/archives/70453)

[難しいベンチマークで高性能なLLMでも単純な問題で間違えてしまう現象について「不思議の国のアリス問題」とGPT-4o、Claude-3、Llama 3などで分析](https://ai-data-base.com/archives/70613)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)