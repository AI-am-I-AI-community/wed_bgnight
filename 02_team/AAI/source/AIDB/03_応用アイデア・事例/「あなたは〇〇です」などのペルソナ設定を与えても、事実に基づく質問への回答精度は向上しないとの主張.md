---
title: "「あなたは〇〇です」などのペルソナ設定を与えても、事実に基づく質問への回答精度は向上しないとの主張"
source: "https://ai-data-base.com/archives/76905"
author:
  - "[[AIDB Research]]"
published: 2024-10-11
created: 2025-06-13
description: "本記事では、LLMのシステムプロンプトにペルソナ設定を追加することの効果に関する研究を紹介します。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、LLMのシステムプロンプトにペルソナ設定を追加することの効果に関する研究を紹介します。

カーネギーメロン大学やスタンフォード大学などの研究者らは、162の異なる役割設定、4種類のLLM、2,410の事実に基づく質問を用いて、ペルソナがモデルの性能に与える影響を体系的に評価しています。

従来の常識とは異なる興味深い発見がありました。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_76905-1024x576.jpg)

**参照論文情報**

- タイトル：When “A Helpful Assistant” Is Not Really Helpful: Personas in System Prompts Do Not Improve Performances of Large Language Models
- 著者：Mingqian Zheng, Jiaxin Pei, Lajanugen Logeswaran, Moontae Lee, David Jurgens
- 研究機関：Carnegie Mellon University, Stanford University, LG AI Research, University of Illinois Chicago, University of Michi [gan](https://ai-data-base.com/archives/26269 "敵対的生成ネットワーク（GAN）")

**本記事の関連研究**

- [GPT-4oに”嘘をつく理由”を与えると正直さが約32.5%減少　LLMは役割に応じて”正直さ”が変化する](https://ai-data-base.com/archives/75881)
- [LLMは与えられたペルソナ（役割）に応じてバイアスが変化することが明らかに](https://ai-data-base.com/archives/70696)
- [タスクに応じてロールプレイさせるとChatGPTなどLLMの推論能力は普遍的に向上する](https://ai-data-base.com/archives/54536)

## 背景

LLMと人間のやり取りにおいて、プロンプトが重要な役割を果たしています。多くのシステムでは、システムプロンプトにLLMの役割を定義することが一般的です。例えば、ChatGPTは「あなたは役に立つアシスタントです」という設定をデフォルトのシステムプロンプトに含めています。

しかし、このようなペルソナ（役割設定）をシステムプロンプトに追加することが、モデルの性能にどのような影響を与えるのかは、これまで詳しくは明らかにされてきませんでした。特に、客観的な事実が求められるタスクにおいては。

そこで研究者らは、ペルソナがLLMの性能に与える影響を体系的に評価することにしました。そして以下のような取り組みを行いました。

1. 6種類の対人関係と8つの専門分野をカバーする162の役割のリストを作成
2. 4つの人気のあるオープンソースLLMファミリーを使用
3. 2,410の事実に基づく質問を用意

このようにして、ペルソナを追加することがモデルの性能にどのような影響を与えるのかを詳細に分析しました。また、ペルソナの性別、種類、専門分野が予測精度にどのように影響するかも調査しました。

さらに、各質問に最適なペルソナを自動的に特定することが可能かどうかを探るため、いくつかのペルソナ検索戦略も試してみました。

以下で実験内容や実験結果を紹介します。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_76905_1.png)

## 実験内容

### データセット

実験には、MMLU（Massive Multitask Language Understanding）という広く使われているデータセットの一部が使用されました。

MMLUの特徴を以下におさらいします。

1. 多様な分野にわたる複数選択式の問題が含まれている
2. LLMの性能を評価するのによく使われている
3. 異なる分野の問題が似たような形式で書かれているため、比較がしやすくなっている

研究チームは、MMLUのうち26の科目から2,410問を選び、それらを8つの主要カテゴリー（法律、医学、コンピューター科学、数学、政治、心理学、自然科学、経済学）に分類しました。

### プロンプト

人格をプロンプトに組み込む方法として、2種類のプロンプトが設計されました

1. LLMに役割を割り当てるもの（例：「あなたは弁護士です」）
2. 会話の相手を指定するもの（例：「あなたは消防士と話しています」）

比較のため、質問のみを含む通常のプロンプトも使用されました。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_76905_2.png)

ペルソナを含むプロンプトの種類と例を示す表

### ペルソナ

研究では162のペルソナが使用されました。162のペルソナは以下のように分類されています。

- 対人関係の役割（家族、友人、恋愛関係、仕事関係、学校関係など）50種類
- 職業的役割112種類

ペルソナには日常生活でよく使われるものが幅広く選ばれています。

例えば家族関係では母親、父親、姉妹、兄弟、祖父母など。また職業的役割は医師、弁護士、教師、エンジニアなどです。

### モデル

実験には、4つのモデルファミリーから9つのオープンソースのLLMが使用されました。

1. FLAN-T5-XXL (11B)
2. Llama-3-Instruct (8Bと70B)
3. Mistral-7B-Instruct-v0.2
4. Qwen2.5-Instruct (3Bから72B)

指示に従うようにすでに微調整されており、システムプロンプトとユーザープロンプトの両方を含むチャットテンプレートを使用できます（FLAN-T5を除く）。

オープンソースのモデルを選んだ主な理由は、計算コストの制約もありますが、他の研究者が結果を再現しやすくするためです。また、異なるサイズのモデルを使用することで、モデルサイズによる影響も調べることができます。

## ペルソナを用いたプロンプトはLLMの性能を向上させるのか？実験結果

### 主な発見

全体的な傾向として、ペルソナを追加しても、LLMの性能は一般的に向上しませんでした。むしろ、いくつかのペルソナでは性能が低下する傾向が見られました。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_76905_3.png)

各ペルソナがモデルの性能に与える影響を示すグラフ

モデルごとの違いとしては、Llama3-70Bでは、多くのペルソナが性能にマイナスの影響を与えた一方、Qwen2.5-7BとQwen2.5-72Bは、162のペルソナのどれにも影響を受けませんでした。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_76905_5.png)

モデル別のペルソナの効果（影響なし、負の影響、正の影響）を示すグラフ

また、ペルソナの効果はモデルサイズにほとんど関係がないことが分かりました。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_76905_6.png)

Qwen2.5の異なるサイズでのペルソナの効果を示すグラフ

### プロンプトの表現方法の影響

研究チームは、プロンプトの表現方法が性能に影響を与えるかどうかも調べました。

その結果、「あなたは〇〇と話しています」のように聞き手を指定する方法の方が、「あなたは〇〇です」のように役割を指定する方法よりも若干良い性能を示しました。

しかし、その差はごくわずかでした。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_76905_4.png)

異なるプロンプト形式の効果を比較するグラフ

### ペルソナがLLMの性能を向上させるかどうかの結論

以上の分析から、以下のことが示唆されています。

1. ペルソナをプロンプトに追加しても、LLMの性能は一般的に向上しない
2. 場合によっては、ペルソナの追加が性能を低下させる可能性がある
3. 多様な質問に対して一貫して性能を向上させる万能なペルソナは、存在しない可能性が高い

これらの結果は、LLMを使用する際のプロンプト設計に対して重要な示唆を与えるものであり、これまで考えられてきた常識の一部を覆しているかもしれません。

ただし、この研究は特定のデータセットと条件下で行われたものであり、他の状況でも同じ結果が得られるかどうかを知るには、さらなる研究が必要です。

## 特定のペルソナは他よりも優れているのか？

続いて研究者らは、ペルソナの違いがLLMにもたらす影響を調査しました。

### 性別の影響

ペルソナの性別が性能に影響を与えるかが調べられました。

その結果、性別中立的な役割が最も良い性能を示しました。また、男性的な役割は女性的な役割よりもわずかに良い性能を示しました。

しかし、差はごくわずかで、性別が性能に大きな影響を与えるとは言えませんでした。

なお、職業的役割においては性別による有意な差は見られませんでした。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_76905_7.png)

中性、男性、女性のペルソナの効果を比較するグラフ

### 役割のカテゴリーの影響

162の役割を7つのグループ（仕事、学校、社会、家族、恋愛、職業、AI）に分類し、分析が行われました。

結果、仕事や学校に関連する役割が、他の種類の役割よりも若干良い性能を示しました。特に、AIや職業的な役割と比べて良い結果となりました。

ただし、ここでも効果の大きさは小さく、役割のカテゴリーが性能に大きな影響を与えるとは言えませんでした。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_76905_8.png)

異なる役割カテゴリーのペルソナの効果を比較するグラフ

### 分野の一致度の影響

「質問の分野」とペルソナの専門分野が一致している場合（例：法律の質問に対する弁護士の役割）、性能が向上するかを調べました。

結果、分野が一致している場合、わずかに性能が向上しました。

しかし、この効果も非常に小さいものでした。

### ペルソナの違いがLLMにもたらす影響の結論

1. 性別中立的な役割が最も良い性能を示す傾向があるが、その差はわずかであった
2. 仕事や学校に関連する役割が、他の役割よりもやや良い性能を示した
3. 質問の分野と人格の専門分野が一致している場合、わずかに性能が向上した

しかし、違いが生じた場合もいずれも小さく、特定の種類の人格が他よりも大幅に優れているとは言えませんでした。つまり、人格の種類による性能の違いは、実用上はあまり重要ではない可能性が高いことが示唆されています。

この結果は、LLMを使用する際のプロンプト設計において、特定の種類の人格を選ぶことにあまり注力する必要がないかもしれないことを示唆しています。

ただし、繰り返しになりますが今回の実験結果は特定の条件下での実験に基づいているため注意が必要です。

## とはいえ、なぜ特定のペルソナがより高い精度につながるのか？

### ペルソナの単語の頻度

研究チームはこの謎を解き明かすために、まず、各ペルソナを表す単語がどれくらい一般的に使われているかを調べました。

結果、頻繁に使用される単語で表されるペルソナは、やや良い性能を示す傾向がありました。

しかし、この関係性は弱く、モデルによって異なりました。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_76905_9-1024x346.jpg)

単語頻度、プロンプト-質問の類似性、パープレキシティと精度の関係を示すグラフ

### プロンプトと質問の類似性

プロンプト（ペルソナを含む文）と質問文がどれくらい似ているかを分析しました。その結果、プロンプトと質問の類似性は、性能と弱いつながりがありました。そして効果は異なるモデルに対して一貫していませんでした。

### プロンプトの複雑さ

プロンプトの文がどれくらい複雑か（パープレキシティという指標で測定）も調べられました。その結果、プロンプトの複雑さと性能の関係は、モデルによって異なりました。つまり一部のモデルでは複雑さが低いほど性能が良く、他のモデルでは逆の傾向が見られました。

### 総合的な分析

これらの要因を全て考慮した分析を行った結果、単語の頻度が高く、質問との類似性が高く、複雑さが低いプロンプトが、やや良い性能につながる傾向がありました。

しかし、これらの効果はやはり小さく、一貫性がありませんでした。

### なぜ特定のペルソナがより高い精度につながるのか？の結論

1. 特定のペルソナが良い性能を示す理由を完全に説明することは難しい
2. 単語の頻度、質問との類似性、プロンプトの複雑さなどの要因が若干の影響を与えているが、その効果は小さく、モデルによって異なる
3. ペルソナが性能に与える影響を十分に説明できない

ペルソナがLLMの性能に与える影響は無いというよりはむしろ複雑で、単純な要因だけでは説明できないということです。また、効果がモデルによって異なることから、モデルの設計や訓練方法が重要な役割を果たしている可能性が示唆されています。

## 質問に効果的なペルソナを自動選択する方法はある？

前のセクションでは、全ての質問に対して一貫して性能を向上させるペルソナはないと分かりました。しかし、質問ごとに適切なペルソナを選べば、全体的な性能が向上する可能性があります。

そこで研究者らは、最適なペルソナを選ぶ方法を探る実験を行いました。

下記の方法が比較されました。もっとも優れた方法はどれだったでしょうか？

1. ランダムにペルソナを選ぶ方法
2. 訓練データセットで最も性能の良かった、質問と同じ分野のペルソナ
3. 訓練データセットで最も性能の良かったペルソナ
4. テストデータで各質問に最適なペルソナを選ぶ（理想的な上限値）
5. 質問と最も類似性の高いペルソナ
6. 質問の分野を予測し、その分野で最適なペルソナを選ぶ
7. 各質問に対して最適なペルソナを直接予測する

### 結果

質問ごとに最適なペルソナを選ぶと、大幅な性能向上が見られました。各質問には確かに役立つペルソナが存在することを示しています。

しかし、ほとんどの自動選択方法は、ランダム選択とほぼ同じ程度の性能しか示しませんでした。一部のモデル（Qwenなど）では、自動選択方法がランダム選択よりも悪い結果となりました。

![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_76905_10-1024x435.png)

異なるペルソナ選択戦略の性能比較を示すグラフ

### 質問ごとにペルソナを変える方法に関する結論

1. 各質問には確かに役立つペルソナが存在するものの、それを自動的に特定することは非常に難しい
2. ペルソナが大規模言語モデルの性能に与える影響は、予測困難で不規則な性質を持っている可能性がある
3. 基本的にはランダム選択以上の性能向上は期待できない

身も蓋も無い話ですが、ペルソナよりも質問の明確さや具体性などに注力した方が効果的である可能性があります。

## まとめ

本記事では、LLMのプロンプトにペルソナを組み込む効果を分析した研究を紹介しました。

162のペルソナを評価した結果、ペルソナの追加は必ずしもLLMの性能を向上させず、場合によっては悪化させる可能性が示されました。

最適なペルソナ選択は性能向上に繋がりますが、自動的な特定は困難です。

今後のプロンプト設計において参考にできる可能性のある知見が得られたかと思います。

- 参照論文URL： [https://arxiv.org/abs/2311.10054](https://arxiv.org/abs/2311.10054)
- コードとデータ： [https://github.com/Jiaxin-Pei/Prompting-with-Social-Roles](https://github.com/Jiaxin-Pei/Prompting-with-Social-Roles)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[複雑なプログラミングタスクに特化したベンチマーク『BigCodeBench』登場　最新モデルでも60%](https://ai-data-base.com/archives/76844)

[LLMの推論能力は単純に文脈を繰り返すだけでも大幅に向上　最大で30%改善](https://ai-data-base.com/archives/76967)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)