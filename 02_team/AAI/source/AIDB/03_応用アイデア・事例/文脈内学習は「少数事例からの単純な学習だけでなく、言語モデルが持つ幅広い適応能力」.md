---
title: "文脈内学習は「少数事例からの単純な学習だけでなく、言語モデルが持つ幅広い適応能力」"
source: "https://ai-data-base.com/archives/80765"
author:
  - "[[AIDB Research]]"
published: 2024-12-17
created: 2025-06-13
description: "本記事では、言語モデルの文脈内学習について、DeepMindの研究者たちが提案する新しい理論的枠組みを紹介します。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、言語モデルの文脈内学習について、DeepMindの研究者たちが提案する新しい理論的枠組みを紹介します。

これまで、文脈内学習は主に「少数の例から学習する能力」として議論されてきましたが、実際には指示に従う能力や役割演技、時系列データの予測など、より幅広い現象を含んでいます。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80765-1024x576.jpg)

**発表者情報**

- 研究者：Andrew Kyle Lampinen et al.
- 研究機関：Google DeepMind

## 背景

LLMが持つ「文脈から学習する能力」に大きな注目が集まっています。これはどういうものかと言うと、「新しいことを学ぶ方法を学ぶ」能力です。

もともとAIの分野では、研究者らは言語モデルのメモリや情報処理の仕組みを工夫することで、新しい課題への対応力を高めようとしてきました。そして [Transformer](https://ai-data-base.com/archives/26535 "Transformer") ベースのモデルでは、少数の例を見ただけで新しい課題に取り組めるようになり、まるで「少しヒントを与えるだけで自分で考えて解決できる」ような能力を示すようになりました。

この能力の源泉として、学習データに含まれる特徴的なパターン、例えばデータの突発的な集中や繰り返し現れる類似構造などが重要な役割を果たしていると考えられています。しかし、これまでの研究は主に「少数の例から正解を教わりながら学習する」という限定的な枠組みに焦点が当てられてきました。

実際には言語モデルは、指示に従って行動を変えたり、特定の役割を演じたり、時系列データを予測したりするなど、より幅広い学習能力を持っています。これらの能力が互いに独立したものなのか、それとも統一的な学習の枠組みで説明できるのかは、まだ明らかになっていません。

そこでGoogle DeepMindの研究者らは、言語モデルの文脈学習能力を包括的に理解するため、学習の内容、方法、応用という複数の観点から検討を行いました。本稿では、言語モデルが示す多様な学習能力の本質に迫ります。

## 広い視点から「文脈内学習」を捉える

文脈内学習（ICL）は、これまで「少数の例から学ぶ能力」として考えられてきましたが、実はもっと広い意味を持つことが分かってきました。文脈から学ぶ能力とはすなわち、過去に見たことが後の判断に役立つという基本的な性質とも言えます。この視点に立つと、例からの学習、指示に従う能力、そして言語モデルの基本的な能力は、すべてつながりがあることが見えてきます。

### 文脈内学習の基本的な仕組み

文脈内学習とは、過去に見たことを手がかりにして、次の予測や判断を行う能力です。この能力は、様々なパターンのデータに触れることで育ちます。

例えば、私たちが文章を読むとき、前の文の内容が次の文の理解に役立ちます。また、会話をするときも、それまでの話の流れが次の発言の理解を助けます。このように、前後のつながりを理解して適切に対応する能力が、文脈内学習の本質です。

### どんな場合に文脈が重要か

文脈が特に重要になるのは、過去の情報を知らないと適切な判断ができない場合です。例えば、「彼」という言葉が誰を指しているかを理解するには、前の文で誰について話していたかを覚えておく必要があります。（後のセクションでもこの話が登場します）

過去の情報を使える場合と使えない場合で結果に大きな違いが出るような状況では、文脈内学習が重要な役割を果たします。

### 単純な例から複雑な学習へ

最も単純な例として、「記憶」の課題があります。最初に見た情報を後で思い出すという課題は、一見とても簡単に見えます。しかし、モデルが訓練時に見たことのない新しい情報でも正しく覚えて再現できるという点で、これも文脈内学習の一種と言えます。

こうした単純な能力を基礎として、より複雑な学習が積み重なっていきます。例えば、いくつかの例から規則を学んで新しい問題を解く、指示文を理解して適切に行動する、会話の流れに沿って適切に応答するなど、様々な能力につながっていくのです。

このように考えると、これまで研究されてきた「例からの学習」は、文脈内学習のほんの一部に過ぎないことが分かります。文脈内学習の全体像は、単純な記憶から複雑な状況への適応まで、幅広い能力を含む概念として理解できます。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80765_1.png)

本研究の全体像

## 「例から学ぶ」文脈内学習

文脈内学習には様々な形がありますが、ここでは最も基本的な「例から学ぶ」形式について説明します。これは、いくつかの例を見せてから新しい問題を解かせる方法です。

### 例を使って学習する仕組み

典型的な例として、次のような翻訳の問題を考えてみましょう。

```js
hello->bonjour
thank you->merci
goodbye->
```

この形式では、最初に「入力→出力」の対応関係をいくつか示し、その後で新しい単語の翻訳を求めます。モデルは示された例から規則性を見つけ出し、その規則性を使って新しい問題を解きます。

つまり、関数f(x)=yのように、入力xから出力yを生み出す規則を、例から学習しているのです。文脈内学習では、示された例から共通のルールを見つけ、それを新しい入力に適用します。

### ルールの種類と応用

このルールには様々な種類があります。例えば、

単純な対応付けでは、「犬」は1、「猫」は2というように、それぞれに決まった値を割り当てます。

一方で一貫した関係としては、「国名」から「その国の首都」を答えるように、同じ関係性を使います。

ルールの種類や入力の性質によって、必要な推論の方法や、どこまで一般化できるかが変わってきます。しかし、基本的には「例から規則を見つけ、新しい場面に応用する」という考え方は同じです。

#### パズルのような推論

パズルに似た学習方法もあります。例えば、

「パリ：フランス：：ロンドン：？」

このパズルでは、

1. 最初に「パリ」と「フランス」の関係を理解する（パリはフランスの首都）
2. 同じ関係を「ロンドン」に当てはめる
3. 答え（イギリス）を導き出す

といった手順が求められます。

例から学ぶ文脈内学習も、同じような手順で行われます。

1. 示された例から関係性を理解する
2. その関係性を新しい問題に当てはめる
3. 答えを導き出す

### より広い可能性

ただし、必ずしも以上のような明確な対応関係だけが重要なわけではありません。文脈からの学習には、もっと多様な方法があります。状況や課題に応じて、様々な形で文脈の情報を活用できるのです。

## 文脈内学習の多様な実例

言語モデルは、少数の例から学ぶだけでなく、より広い範囲で文脈から学習できることが分かってきました。タスクの説明を理解する、専門家の役割を演じる、説明付きの回答から学ぶ、例なしでも学習する、時系列データを予測する、さらには学習の仕方自体を学ぶなど、様々な能力が報告されています。

### 例１：説明文を理解して対応する

言語モデルは、例を示さなくても、タスクの説明だけから学習して対応することができます。特別な調整を受けていない基本的な言語モデルでも、与えられた指示に従って適切に動作することが可能です。

例えば「英語をフランス語に翻訳する」というような指示だけでも翻訳ができ、この手法は多くの研究で使われてきました。時には、説明だけで例を示す場合と同じくらいの性能を発揮することもあります。さらに、説明と例を組み合わせることで、より良い結果が得られることも分かっています。

このような説明文による指示への対応は基本的な能力として重要視されており、最近の言語モデルでは特に注目されている機能です。

### 例２：専門家の役になりきって回答する

言語モデルの性能を引き出す効果的な方法として、専門家からの回答という形で質問を設定する手法が知られています。

例えば、フランス語から英語への翻訳では、「フランス語の翻訳者が、このフレーズを完璧に英語に翻訳します」というように設定すると、単純に例を示すよりも良い結果が得られることが分かっています。

これは、説明や指示を理解するだけでなく、特定の役割を演じることで、より適切な回答ができるようになることを示唆しています。

### 例３：説明付きの回答で学習を深める

回答に説明を付け加えることで、モデルの性能が向上することが分かっています。これは、単に指示を与えたり、他の方法で制御したりするよりも効果的です。

難しい問題や曖昧な問題では、説明を加えることでモデルの推論の方向性が明確になり、結果として良い回答が得られます。説明が理解を深め、性能向上につながるという点が重要です。

### 例４：例なしでも学習できる

興味深い発見の一つが「教師なし文脈内学習」です。問題だけを示して解答例を示さなくても、モデルの性能が大きく向上することがある現象です。

例えば数学の問題集のように、一般的によく知られたタスクであれば、解答がなくても関連する情報があるだけで性能が向上する可能性があります。さらに、そのタスクが新しいものであっても、学習データが十分に構造化されていれば、例なしでの学習が機能する可能性があります。

また、興味深いことに、プロンプトにランダムな答えを含めても正確な結果が得られることがあります。この場合、モデルは新しい学習をしているというより、すでに学習済みのタスクを思い出している可能性が高いと考えられています。

### 例５：時系列データを予測する

言語モデルは、時間とともに変化するデータの予測でも、その分野に特化したモデルに匹敵する能力を示すことがあります。

例えば、徐々に増加する傾向と季節による変動が組み合わさったような複雑なデータでも、モデルは各要素を正確に理解して予測できます。このことは、入力と出力の区別が明確でない状況でも、言語モデルが複雑なデータのパターンを学習できることを示しています。

### 例６：学習の仕方を学ぶ

言語モデルが複数の似たタスクを連続して処理すると、興味深い現象が観察されます。後半のタスクほど、前半のタスクよりも早く学習できるのです。これは文脈の中にもう一段階上のタスクのループが含まれており、モデルが両方のレベルで学習と適応を行っている状況だと考えられます。

上記は通常の学習を超えて、「学習の仕方」自体を学んでいることを示す重要な例です。モデルが与えられた課題を解くだけでなく、より効率的な学習方法も同時に身につけていることを示唆しています。

## 文脈内学習から生まれる能力

言語モデルは文脈から学習する優れた能力を持っています。この能力は、言語データに含まれる様々なパターンや特徴的な情報の分布を理解することから生まれています。

以下では、言語の特徴と文脈内学習の関係を具体例で見ていきます。単純な記憶から、言葉のつながりの理解、例からの学習、そして複雑な状況への適応まで幅広く及びます。

### 例１：文章中の「それ」や「彼」が指すものを理解する

言語モデルにとって、文中の指示語が何を指しているかを理解することは重要な課題でした。この能力は図1dでも示されているように、少数の例から学習する能力と深く関係しています。

興味深い例として、次のような問題があります。

「トロフィーは茶色のスーツケースに入らない。なぜなら、大きすぎるからだ。何が大きすぎるのか？」

「トロフィーは茶色のスーツケースに入らない。なぜなら、小さすぎるからだ。何が小さすぎるのか？」

この二つの文はとても似ていますが、答えは異なります。最初の文では「トロフィー」が大きすぎ、次の文では「スーツケース」が小さすぎると理解しなければなりません。これには文章全体の意味をつなぎ合わせ、常識的な判断も必要です。

このように、言葉の指す対象を正しく理解し、それを新しい質問に活用できる能力は、高度な文脈学習の一例と言えます。最近の言語モデルはこのような複雑な理解が得意になっており、単純な言葉の結びつきを超えて、より深い文脈理解ができるようになっています。

### 例２：似た形の文章から学ぶ

「アレックスはペットの蛇を飼っている。ブレイクはペットのハムスターを飼っている。」という文では、同じような文の形が繰り返されています。このような「並列構造」は、情報を分かりやすく伝えたり、自然な会話の流れを作ったりする上で重要です。

言語データには、このような並列構造が自然に含まれています。言語モデルはこれらのパターンから、例を見て学習する基本的な能力を身につけていると考えられます。

### 例３：文脈に合わせて単語の意味を理解する

「bank」という単語が「銀行」を意味するのか「川岸」を意味するのかは、その単語が使われている状況から判断する必要があります。最近の言語モデルは、このような単語の意味の使い分けが上手になっています。

これは限られた数の意味の中から選ぶ作業ですが、訓練の際に様々な組み合わせで繰り返し学習することで、新しい状況でも適切な意味を選べるようになります。これは文脈から学習する能力の基本的な形と言えます。

### 例４：主語と動詞の関係を理解する

初期の単純な言語モデルでも、文の主語が単数か複数かによって、動詞の形を正しく変えることができました。例えば「フレッドが追いかける少年たちは猫に餌をやる」という文では、「少年たち」が複数なので、それに合わせて動詞も複数形にする必要があります。

これは学んだルールを新しい文脈で使える例です。複雑な文章構造でも、主語と動詞の関係を正しく理解し、適切な形を選べることを示しています。

### 例５：文章の話題の流れを読み取る

言語モデルは、文章の大きな流れも理解します。例えば、先史時代の芸術について書かれた文章が続くと、次の段落も同じような話題だろうと予測できます。

これは主語と動詞の関係のような明確なルールではなく、文章全体から話題を感じ取る能力です。単語と話題の緩やかなつながりを理解することで、文脈に応じた適切な予測ができます。このように、文脈内学習は単純なパターンの理解から、より豊かな文脈理解へと広がっています。

## 汎化能力についての最近の研究動向

文脈内学習は、単語の意味理解から画像のラベル付け、指示に従う能力まで、幅広い学習を含みます。中でも重要なのは「汎化」、つまり学習した内容を新しい場面で使える力です。

文脈から学ぶ能力は、モデルによって大きく違います。単語の意味を理解する程度の簡単なことはできても、もっと複雑な学習には対応できないモデルもあります。少数の例から学習できる言語モデルでも、学習時と大きく違う状況では上手く働かないことがあります。そのため、文脈内学習の本質を理解するには、学んだことをどこまで応用できるのかを調べる必要があります。

文脈内学習の汎化には3つの側面があります。「何を学べるか」「どう学ぶか」「学んだことをどう使うか」です。これらは互いに関係していますが、それぞれ違う方法で評価できるので、分けて考えると理解しやすくなります。

![](https://ai-data-base.com/wp-content/uploads/2024/12/AIDB_80765_2.png)

例から学ぶ様子のワンシーン

### 新しい情報の学習

モデルは本当に新しいことを学べるのでしょうか。ただ覚えていることを思い出すのではなく、新しい課題を文脈から学習できるかが大切です。研究者たちはこの能力を様々な角度から検証しています。

例えば、データの種類が変わった時にどう対応するか、新しい分類の仕方を学べるか、数学的な関係をどこまで理解できるかなどが調べられています(Xie et al., 2022; Chan et al., 2022a; Zhang et al., 2024)。最近は、言葉での説明から複雑な機能を理解する能力まで研究されています(Ramesh et al., 2024)。

### 多様な形式での学習

言語モデルは同じ課題でも、様々な方法で学習できます。例の見せ方や順番を少し変えただけでも、学習の成果が変わることが分かっています(Lu et al., 2022; Sclar et al., 2023)。まだ研究が足りない分野もたくさんあります。異なる学び方を組み合わせたり、画像と言葉を一緒に使ったりする学習方法は、これからもっと調べる価値があります。

### 学習内容の柔軟な適用

学んだことを色々な場面で使えることも大切です。例えば、数字で学んだルールを文字に使ってみたり、地下鉄の路線図や大統領の順番といった全く違う場面で応用したり、プログラムや説明文として表現したりできるかが問題です。

この分野では、例から指示を作り出したり(Honovich et al., 2023; Liu et al., 2024)、答えの理由を説明したり(Marasović et al., 2022)する研究が始まっていますが、まだまだ解明すべきことがたくさんあります。

学んだことを柔軟に使い、抽象的に理解する能力については、理論から実践まで、もっと研究が必要です。具体例から学んだことを指示として使う場合など、異なる学習の仕組みがどう影響し合うのかを理解することが重要です。こうした研究を通じて、文脈内学習の可能性と限界がより明確になっていくでしょう。

## より広い視点での文脈内学習に向けて考察

文脈内学習は、その時々の状況に応じて行動を変える幅広い能力を含んでいます。そのため、少数の例から学ぶ教師あり学習だけでなく、もっと広い範囲で研究を進める必要があります。

### 課題１：広い視野で文脈内学習を捉える必要性

今日のモデルは主に指示に従って動作することが求められています。そのため、単に少数の例から学ぶだけでなく、様々な形の文脈内学習とそれらの関係を理解することが大切です。モデルは指示や例示など、異なる形で示された課題にも対応できる必要があります。

### 課題２：学習の仕組みの共有と発展

文脈内学習には様々な形があり、それらの仕組みは互いに関係している可能性があります。例えば、例から学んでも指示から学んでも、その知識を使う時は同じような仕組みが働くかもしれません。単純な言葉の関係を学ぶ能力が、より複雑な問題を解く力につながることもあります。

### 課題３：学習の妨げ合いと形式の影響

時として、モデルは意図した通りに学習できないことがあります。これは異なる種類の学習が互いに影響し合うためかもしれません。また、情報の示し方や順序によって学習効果が変わることもあります。

### 課題４：汎化能力は自然には身につかない

シーケンスを学習できるからといって、必ずしも広く応用できる力が身につくわけではありません。モデルの特性や学習データの性質によって、どこまで一般化できるかが決まってきます。単純な言語モデルは基本的な文脈理解はできても、本当の意味での応用は難しいものです。

### 課題５：文脈内学習の本質

文脈に応じた振る舞いの変化を「学習」と呼べるのかという疑問もあります。しかし、これはメタ学習の一種として理解できます。つまり、その場その場の情報を活かして適応する能力と考えられます。

### 課題６：他の学習との関係

現在のモデルでは、学習をいくつかの時間スケールに分けて考えています。しかし、実際には連続的な学習の流れの一部かもしれません。最近では、異なる種類の学習の境界があいまいになってきています。

### 課題７：自然な知能との共通点

人間も文脈から学ぶ能力を持っています。文脈を理解し、それに応じて行動を変える能力は、自然な知能の重要な特徴の一つかもしれません。

今後は、以上のような課題が取り組まれていくことが期待されています。

## まとめ

この記事では、Google DeepMindの研究者たちが提案する文脈内学習の新しい見方を紹介しました。彼らは文脈内学習を、少数事例からの単純な学習だけでなく、言語モデルが持つ幅広い適応能力として捉え直しています。

著者たちは、この広い視点から文脈内学習を研究することで、モデルの能力をより深く理解し、より優れたシステムの開発につながる可能性を示唆しています。また、人工的な学習と自然な知能の関係についても、新しい洞察が得られるかもしれないと論じています。

この研究は、急速に発展する言語モデルの能力を体系的に理解しようとする重要な一歩といえるでしょう。

**参照文献情報**

- タイトル：The broader spectrum of in-context learning
- URL： [https://arxiv.org/abs/2412.03782](https://arxiv.org/abs/2412.03782)
- 著者：Andrew Kyle Lampinen, Stephanie C. Y. Chan, Aaditya K. Singh, Murray Shanahan
- 所属：Google DeepMind

## 理解度クイズ（β版）

Q1. 文脈内学習はこれまでどのように捉えられていたか？

文脈内学習はこれまで主に「少数の例から学習する能力」として議論されてきたと述べています。

解説を見る

Q2. 文脈内学習において、言語モデルが示す能力として挙げられていないものはどれか？

指示に従う能力、役割演技、時系列データ予測を文脈内学習の例として挙げていますが、外部データベースへのアクセスについては言及していません。

解説を見る

Q3. 「教師なし文脈内学習」について述べられているが、これはどのような学習方法か？

教師なし文脈内学習は「問題だけを示して解答例を示さなくても、モデルの性能が大きく向上する現象」と説明しています。

解説を見る

Q4. 文脈内学習の汎化能力に関する説明で、次のうち誤っているものはどれか？

文脈内学習の汎化能力について、モデルによって能力に差があり、学習時と大きく違う状況では上手く働かない場合もあると述べています。選択肢c)は誤りです。

解説を見る

Q5. 文脈内学習の課題として適切でないものはどれか？

学習データが多いからといって必ずしも汎化能力が高いとは限らないと指摘しています。選択肢c)は誤りです。

解説を見る

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[LLM同士による人工言語コミュニケーションで発見された「言語構造の創発」](https://ai-data-base.com/archives/80658)

[LLMエージェントに人間のような欲求を持たせてシミュレーションする手法](https://ai-data-base.com/archives/80804)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)