---
title: "自然言語プログラミングを可能にするシステム『CoRE』"
source: "https://ai-data-base.com/archives/69789"
author:
  - "[[AIDB Research]]"
published: 2024-05-27
created: 2025-06-13
description: "自然言語プログラミング、疑似コードプログラミング、フロープログラミングを統一し、LLMをインタープリターとして自然言語プログラムを解釈し実行するシステム『CoRE』が開発されています。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

自然言語プログラミング、疑似コードプログラミング、フロープログラミングを統一し、LLMをインタープリターとして自然言語プログラムを解釈し実行するシステム『CoRE』が開発されています。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69789-1-1024x576.jpg)

**参照論文情報**

- タイトル：AIOS Compiler: LLM as Interpreter for Natural Language Programming and Flow Programming of AI Agents
- 著者：Shuyuan Xu, Zelong Li, Kai Mei, Yongfeng Zhang
- 所属：Rutgers University

**本記事の関連研究** ：

- [LLMによるプログラミング言語の変換　Go→Rustのケーススタディ](https://ai-data-base.com/archives/69610)
- [LLMに対して、「人間には意味が分からない滅茶苦茶な文」でプロンプトを送る手法『LM Babel』](https://ai-data-base.com/archives/68433)
- [LLMが「自然言語で記述されたアルゴリズムを実行する」能力で非常に高い性能を示す](https://ai-data-base.com/archives/65949)
- [LLMの記号推論タスク（化学式や絵文字の理解など）で記号を自然言語に変換することの有効性を確認](https://ai-data-base.com/archives/65784)

## 背景

プログラミング言語は、機械語から始まり、アセンブリ言語、高級言語へと進化してきました。プログラミング言語の可読性や使いやすさは向上し、プログラマーにとってより身近な存在となってきました。

この流れを受けて、自然言語（人間が話す言葉）をプログラミング言語として用いることで、プログラミングの敷居をさらに下げられる可能性が模索されています。ただし自然言語には曖昧さや冗長さがあることが問題となります。正確にプログラミングの論理を理解し、命令を実行するインタープリター（プログラムを逐次的に解釈し実行するプログラム）の開発が課題とされています。

そんな中、LLMは複雑な自然言語の解釈ができ、加えてプログラミングの知識も豊富です。ツールの使用や関数の呼び出し、環境との対話などの面でも優れた能力を示しています。

今回研究者らは、LLMをインタープリターとして用いる新しいシステムを提案しています。自然言語プログラミング、疑似コードプログラミング、フロープログラミング（プログラムの処理の流れを視覚的に表現するプログラミング手法）を統一的に表現できる「CoRE言語」を開発しました。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69789_1-1024x786.jpg)

CoRE言語は自然言語プログラミング、疑似コードプログラミング、フロープログラミングを統一的に表現する

## CoRE言語の特徴

自然言語による命令を論理的に構造化するために、各ステップが4つの要素で構成されています。

**（1）ステップ名 (Step Name)**

各ステップを一意に識別する名前で、プログラム内のナビゲーションや参照を行うためのものです。従来のプログラミング言語における関数識別子に相当します。

**（2）ステップタイプ (Step Type)**

ステップで実行される操作の性質を分類します。従来のプログラミングにおける制御構造に類似しています。

ステップタイプには以下の3種類があります。

- **Process**  
	従来のプログラミングにおける手続き型のステートメントに相当し、特定の操作を実行して次の指定されたステップに移行します。
- **Decision**  
	条件分岐（if-else文など）に対応し、評価された条件に基づいて複数の潜在的なパスに分岐します。
- **Terminal**  
	“end”や”return”ステートメントに類似し、プログラムの終了を示します。これ以上実行されるステップがないことを意味します。

**（3）ステップ命令 (Step Instruction)**

ステップで実行すべきタスクを明示します。従来のプログラミング言語のステートメントブロックに相当し、実行のための命令とコンテンツを提供します。自然言語で命令を下せる点が従来と異なる点です。

**（4）ステップ接続 (Step Connection)**

あるステップから次のステップへの進行方向を定義します。Processステップ（ステップタイプの一つ）では、単一の次ステップが指定されます。Decisionステップでは、条件に基づいて複数の経路が示されます。Terminalステップは、定義上、その先のステップにつながることはありません。

### CoRE言語の制御構造

プログラミング言語の3つの基本的な制御構造である順次実行（sequence）、選択（selection）、反復（iteration）が設計されています。

- **順次実行** （各ステップが次のステップにつながる線形の実行順序）“Step Connection”を次のステップに設定することで実現されます。Processステップを連続して使用します。
- **選択** （条件分岐により、特定の条件に基づいて異なるステップのシーケンスを実行）Decisionステップタイプを使用し、”Step Connection”部分で複数の潜在的なパスを明示的に示すことで実装されます。
- **反復** （ある条件が満たされるまで一連の操作を繰り返す）Decisionステップを使用してループ条件が満たされたかどうかを評価します。条件が満たされている場合は、Processステップで必要な操作を実行します。1回のループサイクルの終わりに、”Step Connection”を前のDecisionステップにポイントバックするように設定することで、ループを継続させます。

### CoREシステムにおけるLLMの役割

LLMインタープリターは、1ステップずつ以下の4つの手順で実行します。

1. 観察情報の取得 (Observation Retrieval from Memory)
2. 入力プロンプトの構築 (Input Prompt Construction)
3. 出力の分析 (Output Analysis)
4. 分岐の分析 (Branching Analysis)

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69789_2-1024x344.png)

CoREシステムが1つのステップを実行する例

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69789_3-1024x474.png)

LLMインタープリターシステムの概要

**1 観察情報の取得**

ステップ実行プロセス全体の基礎となります。システムのメモリには、プログラムに関連する過去の観察情報が格納されています。観察情報とは、検索結果などのツール実行の結果を指します。LLMインタープリターは、メモリをスキャンして、現在の命令に関連するレコードを特定します。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69789_4-1024x391.png)

システムが関連情報を取得する例

**2 入力プロンプトの構築**

プロンプトの構築は、LLMが理解し、効果的に応答できる包括的で一貫性のあるクエリを合成することです。CoREシステムでは、インタープリターが4つの要素を含む詳細なプロンプトを構築します。

1. **タスク記述 (Task Description)  
	**システム操作の主なインプットとして機能します。プログラム全体を定義するクエリ。
2. **現在の進捗 (Current Progress)  
	**何が行われたか、何が決定されたかを要約し、流れを維持するのに役立ちます。
3. **観察情報 (Observation)  
	**インタープリターがメモリから関連情報を取得した場合、ここに組み込まれます。
4. **現在の命令 (Current Instruction)  
	**現在のステップで実行すべき操作を自然言語で指定し、インタープリターに進行方法を指示します。

**3 出力の分析**

CoREシステムでは、インタープリターがLLMの初期応答とタスクの要求に基づいて、特殊なツールの使用を決定します。複雑なタスクでは、必要に応じてLLMの能力を拡張する必要があるためです。言語プロンプトを処理するだけでなく、能動的に問題を解決することが求められます。ツールの使用が必要な場合、システムは適切なツールを選択し、必要なパラメータを設定して実行し、出力を進行中のプロセスに統合します。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69789_5-1024x570.png)

CoREシステムがLLMインタープリターの出力を分析する例

**4 分岐の分析**

CoRE言語のインタープリターでは、Decisionステップが複数の分岐を示し、対応する条件が記されています。プログラムにおいて、次のステップを適切に決定することは重要です。異なる結果が異なる後続のアクションにつながる分岐シナリオでは、その重要性が高まります。

インタープリターはLLMを使用して、プロンプトが自然言語で記述された分岐条件を満たしているかどうかを判断し、次のステップを決定します。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69789_6-1024x443.png)

CoREシステムがフロー内の次のステップを決定する例

## 実験

CoREの実用性を検証する実験と結果を以下に記します。

### モデル

以下の2種類の大規模言語モデル（LLM）が使用されました。

1. GPT-4
2. Mixtral-8x7B  
	（467億のパラメータを持つ生成型のスパース混合エキスパートモデル（オープンソースモデル））

### プランニングスキーマ

以下の4つのエージェントプランニングスキーマが採用されました。

1. Zero-shot Learning (Zero)  
	クエリを直接LLMに入力
2. Chain-of-Thought (CoT)  
	クエリと回答をつなぐ中間的なステップを生成させる
3. Few-shot Learning (Few)  
	対象タスクと望ましい出力の例示をプロンプトに含める
4. CoRE (提案手法)  
	LLMをインタープリターとして使用する自然言語プログラミング手法

### ベンチマークデータセット

[OpenAGIベンチマークデータセット](https://github.com/agiresearch/OpenAGI) が使用されました。タスクは出力タイプとグランドトゥースのラベルタイプに基づいて分類され（Task 1, 2, 3）、タスクタイプに応じて以下の評価指標が用いられました。

- CLIP Score：テキストと画像の類似度を評価（Text-to-Imageタスク用）
- BERT Score：BERTを用いてテキスト生成を評価（データラベルと期待される出力がテキストの場合）
- ViT Score：画像ラベルと画像出力の類似度を評価

なお、論文中では具体的なタスクについて詳しく述べられていません。ただし上記評価指標から、テキストから画像を生成するタスク、テキストからテキストを生成するタスク（要約、翻訳、質問応答など）、画像から画像を生成するタスク（画像変換、画像生成など）が検証されたと推測されます。

### 実装

実験で使用されたフレームワークとベースラインはすべて [PyTorch](https://ai-data-base.com/archives/26256 "PyTorch") で実装されました。Zero-shotとFew-shot学習にはOpenAGIプラットフォームの実装設定が使用され、CoT戦略には [DSPyフレームワーク](https://github.com/stanfordnlp/dspy) が適用されました。

### 実験結果

OpenAGIベンチマークタスクの性能は以下のとおりです。

![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69789_7-1024x189.png)

実験結果から、以下のような知見が得られました。

- CoREプランニングスキーマは、MixtralとGPT-4のどちらをインタープリターとして使用した場合でも、平均性能でベースラインを上回った。
- Mixtralをインタープリターとして使用した場合、CoREはすべてのタスクタイプでZero-shotとCoTを上回り、Task 2と平均スコアではFew-shot学習よりも優れていた。
- GPT-4をインタープリターとして使用した場合、CoTとFew-shotはTask 1とTask 3で同様の性能を示したが、Task 2と平均スコアではCoREが最も優れていた。
- 同じCoREプログラムでも、インタープリターとして使用するLLMによって性能が異なる場合があり、これは自然言語プログラミングの性能がLLMインタープリターの自然言語理解能力に依存していることを示唆している。

提案されたCoREシステムは、複数のベンチマークタスクにおいて優れた性能を示し、LLMをインタープリターとして使用する自然言語プログラミングの有効性が実証されました。

## まとめ

本記事では、自然言語プログラミングを可能にするCoREシステムの研究を紹介しました。CoRE言語およびLLMインタープリターにより、自然言語プログラムの解釈と実行の有効性が実験で実証されました。今後、自然言語命令の自動生成や多言語サポート、デバッグ機能の実装などの課題が解決されれば、CoREシステムはより幅広いユーザーに利用されるようになり、プログラミングの敷居を下げる存在になるかもしれません。

実際に使用してみるには下記リポジトリをご覧ください。

- 参照論文URL： [https://arxiv.org/abs/2405.06907](https://arxiv.org/abs/2405.06907)
- Github： [https://github.com/agiresearch/CoRE](https://github.com/agiresearch/CoRE)

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[LLMでプログラミング言語間の翻訳を行うプロンプト手法　C、Go→Rustのケーススタディ結果](https://ai-data-base.com/archives/69610)

[時系列データの異常検知にLLMを使用する手法と実行プロンプト](https://ai-data-base.com/archives/69867)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)