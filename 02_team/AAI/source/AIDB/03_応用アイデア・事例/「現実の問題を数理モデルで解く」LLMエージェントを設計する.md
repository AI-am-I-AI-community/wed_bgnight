---
title: "「現実の問題を数理モデルで解く」LLMエージェントを設計する"
source: "https://ai-data-base.com/archives/90253"
author:
  - "[[AIDB Research]]"
published: 2025-06-03
created: 2025-06-13
description: "本記事では、LLMに現実の課題を数学的に解かせるためのエージェント設計に関する研究を紹介します。分析やレポート作成を含む複雑なプロセスを分担しながら進める構成が提案されています。"
tags:
  - "clippings"
---
**【お知らせ】** AIDB主催のビジネスマッチングイベントを7月25日(金)開催予定です！  
  

\---以下、記事本文---

本記事では、LLMに現実の課題を数学的に解かせるためのエージェント設計に関する研究を紹介します。

分析やレポート作成を含む複雑なプロセスを分担しながら進める構成が提案されています。評価には、実務でも参考になるような多面的な基準が取り入れられています。

業務でLLMを使った問題解決を検討している方にとって、具体的なヒントが得られる内容です。

![](https://ai-data-base.com/wp-content/uploads/2025/05/AIDB_90253-1024x576.png)

**本記事の関連研究**

- [LLMで複数のアイデアを組み合わせ、イノベーションを目指した新しいアイデアを作成する方法](https://ai-data-base.com/archives/87358)
- [LLMベンチマークは現場の実用性を捉えているか？モデルを選ぶ前に確認したい評価スコアの盲点](https://ai-data-base.com/archives/89851)

## 背景

AIがますます高度な仕事を担うようになってきた今、実世界の課題をどこまで解決できるのかが問われています。計算や検索といった狭い範囲を超えて、現実の複雑な状況を理解し、全体を見通したうえで最適な判断を下す。そうした「地に足のついた知性」は、多くの現場で求められているものです。

その力を測るうえで鍵になるアプローチの一つが「数理モデリング」です。

現実の問題を数式で表現し、分析やシミュレーションを通じて、意思決定の根拠を導く手法のことを指します。

数理モデリングは、政策立案から業務改善まで幅広く使われています。交通の最適化、疫病対策、資源の配分など、多くの分野で人間が頼ってきた手段です。

LLMの性能が進化する中で、記号処理や定理証明といった純粋数学の課題ではすでに高い正答率を記録しています。しかし、現実の課題に立ち向かう段になると話は変わります。多くのLLMは「文脈から問題を読み取り、自ら仮定を置き、必要なデータを探し、柔軟に道筋を考える」といった一連の推論にはまだ十分に対応できていません。

現在使われている多くのベンチマークも、こうした「実務的な知性」を測るには不十分です。実世界の問題では、抽象的な計算だけでなく、分野横断的な視点、戦略的なツールの使い方、解釈力や創造性が問われます。ところが従来の評価指標では、これらの力が測られていないことが多く、実践的な活用に向けた指針を与えてくれません。

このような課題に応えるかたちで、「どのようにすればLLMに実世界のモデリングをやらせられるか」という観点から設計を行いました。複数の役割に分かれたLLMエージェントを協調させ、モデリングの発想、データ収集、実装、報告といった一連のプロセスを段階的に進める仕組みを検討しています。

LLMがどこまで実用的な解決策を導けるのかを問いながら、その具体的な設計方針もあわせて示す試みとなっています。

以下で詳しく紹介します。

![](https://ai-data-base.com/wp-content/uploads/2025/05/AIDB_90253_1-1024x726.png)

数学で表現できる現実課題の具体例

## LLMを「実務で使える存在」に近づけるには

実社会の課題を解かせたいとき、LLMに必要なのは計算の速さや知識量だけではありません。状況を読み取り、情報を集め、全体を構造化しながら、妥当で納得感のある解決策を導けることが求められます。こうした力をどう育て、どう引き出せばよいのか。いくつかの視点から、その問いに向き合います。

### 「賢さ」を三つに分けて考える

LLMの知的なふるまいを測る際、よく参照されるのが「三つの知性」という考え方です。知性を「論理力」「現場対応力」「発想力」の三つに分けて捉えます。

まず、 **問題の構造を理解し、条件を整理して論理的に解いていく力** 。いわゆる分析的な知性にあたります。多くの数学系ベンチマークが測っているのは主にこの部分です。

次に、 **ツールを使ったり環境とやり取りしたりしながら、柔軟に目標を達成する力** 。たとえば、ウェブ検索で情報を探したり、Pythonでデータを処理したりといったふるまいが求められる場面では、こうした実用的な知性が試されます。

最後は、 **既存の方法にとらわれず、新しいアプローチを生み出す発想力** です。ありきたりな解法ではなく、複数の技法をうまく組み合わせて新たな道筋を提示する力のことです。

これら三つの知性を同時に測る方法が模索されています。

### 複数のLLMをどう連携させるか

もうひとつの重要な視点は「協調」です。ひとつのLLMにすべてを任せるのではなく、役割を分担させて複数のLLMを連携させるという考え方は、すでにいくつかの分野で実践されています。

たとえば、契約書のレビューでは法的判断を下すLLMと文書を整えるLLMを使い分けたり、コード生成では設計担当と実装担当を分けたりといった事例があります。ただし、こうした構成は比較的定型的な作業に向いている場合が多く、複雑なモデリング課題に応用するには、より繊細な設計が求められます。

そこで今回研究者らは、アイデアを出す役割、データを集める役割、数式に落とし込む役割、報告書をまとめる役割を分け、それぞれが段階的に連携する仕組みを設けています。さらに、それら全体を客観的に見直す「批評」役を導入することで、自己改善のサイクルも内蔵されています。

## モデリングでLLMの「地に足のついた力」を見極める

LLMがどこまで現実の問題に対応できるのか。それを真に評価するには、適切な題材と状況設定が欠かせません。今回の研究では、その題材として「数理モデリング」が選ばれています。

### なぜ数理モデリングなのか

数式と現実をつなぐ役割を果たすモデリングは、ただの計算力では太刀打ちできない奥深さがあります。扱うのは、病気の広がり、都市の交通、資源の配分といった実世界の問題です。そこでは、何を変数と見なすか、どう因果を定式化するか、どんな視点からアプローチするか。こうした一つひとつの判断に、知性の重みが乗ります。

最近のLLMは、記号代数や定理証明といった純粋数学では目覚ましい成果を上げています。しかし、実社会に根ざした課題では、状況を整理し、データを探し、仮定を立て、筋道を構築するといった過程において、まだ多くの壁が残っています。

たとえば、「感染症の拡大を、限られた資源下でどう抑えるか」「低コストで機能する交通ネットワークをどう設計するか」。こうした問いに向き合うには、数学の知識だけでなく、ツールの使い方、データの読み方、そして視点の切り替えが必要です。

このような力をLLMに問うための評価環境としてModelin [gB](https://ai-data-base.com/archives/26343 "勾配ブースティング") enchというベンチマークデータセットが設計されました。

![](https://ai-data-base.com/wp-content/uploads/2025/05/AIDB_90253_2-1024x447.png)

既存ベンチマークがカバーしている力の整理

### 問題はすべて、実社会からの出題

Modelin [gB](https://ai-data-base.com/archives/26343 "勾配ブースティング") enchで題材となったのは、国際的な数学モデリングコンテストの出題です。大学生向けのMCMやICM、高校生・中学生向けのHiMCMやMidMCM、さらには世界規模のIM²Cなど、いずれも現実の社会課題に取り組ませる内容で知られています。

これらの問題は、環境政策から感染症制御、都市設計に至るまで、幅広い分野をカバーしており、どれも専門家によるレビューを経て構成されています。

![](https://ai-data-base.com/wp-content/uploads/2025/05/AIDB_90253_3.png)

扱われている問題のジャンルと具体例

### 良問だけを残すためのフィルタリング

収集された問題の中から、実際にLLMに解かせるにふさわしいものだけを厳選するため、3つの観点から事前スクリーニングが行われました。

まず、必要なデータがオンラインで手に入るか、問題文に含まれているか。次に、LLMでも物理的行動を伴わずに対応可能か。そして、画像が含まれる場合でも、テキスト情報として取り出せるか。この三点を、GPT-4oの評価と人手によるチェックで確認しています。

その結果、最終的に100件以上の候補から68件が採用され、難易度別に整理されました。

![](https://ai-data-base.com/wp-content/uploads/2025/05/AIDB_90253_4-1024x337.png)

モデリングと評価をセットで行う全体構成の図

### 実践的なツール環境も用意

モデリングに取り組むうえで、データ収集や分析は欠かせません。実際のコンテストでは、参加者が自由にインターネットやプログラミングを駆使できるように、ツールの利用が認められています。

Modelin [gB](https://ai-data-base.com/archives/26343 "勾配ブースティング") enchでもそれに倣い、LLMが必要な操作を行えるよう、拡張サンドボックス環境が整備されています。ファイルの読み書き、ウェブ検索、コード実行、PDFや画像の解析など、さまざまな操作を通じて、情報の取得と分析が可能です。

LLMがこの環境内でどのように行動するかを通じて、「知識を与えられるだけの存在」ではなく、「状況を読み取り、選択し、組み立てていく存在」としての実力が問われる設計になっています。

![](https://ai-data-base.com/wp-content/uploads/2025/05/AIDB_90253_5-1024x561.png)

LLMが使えるツールの一覧

![](https://ai-data-base.com/wp-content/uploads/2025/05/AIDB_90253_6.png)

収集された問題の難易度や分野ごとの分布

## LLMを複数人チームのように動かす

複雑なモデリング課題に取り組むときは、構想、情報収集、実装、文書化といった作業を分担し、役割ごとに専門性を発揮できるようにします。LLMを一つの大きな頭脳としてではなく、複数の特化型エージェントに分けて扱うと、問題解決の流れが明確になり、思考の整理が進みます。各工程が互いに影響を与え合う循環をつくると、現実の課題に対してより確実で柔軟な対応が可能になります。

### 4つの役割に分けて進める

まず、次の4つの役割を用意します。

**構想を考えるエージェント**  
問題文を読んで、どのようなアプローチがあり得るかを考えます。タスクを分解し、どのような数式やモデルが使えそうかを見立てて、いくつかの方向性を提示します。構想には根拠を添えておきます。

**データを集めるエージェント**  
構想段階で想定された変数に対して、どこからデータが得られるかを探します。ウェブ検索やファイル操作などのツールを使って情報を集め、どのデータを採用するかを判断します。信頼性や形式も考慮します。

**モデルを組み立てるエージェント**  
提案された構想をもとに、具体的な数式に落とし込みます。定式化が終わったら、実際に計算を行ってシミュレーション結果を出力し、モデルの挙動を分析します。必要に応じて構想やデータ選定にフィードバックを返します。

**全体をまとめるエージェント**  
これまでの流れをひとつのレポートにまとめます。各エージェントの出力を読み取り、順序立てて説明し、読みやすい構成に整えます。構想・検証・結果の流れが自然に伝わるように調整します。

### 指摘と改善の循環を作る

各エージェントが単独で動くだけでは、質の高いアウトプットにはつながりません。すべての出力に対して、独立した批評エージェントがフィードバックを返すようにします。構想の妥当性、データの信頼性、定式化の整合性、文章の説得力など、それぞれの軸に応じた評価を行い、必要に応じてやり直します。

![](https://ai-data-base.com/wp-content/uploads/2025/05/AIDB_90253_7-1024x389.png)

エージェントの出力にフィードバックを返す流れ

このようにすることで、全体が一方向に進むだけでなく、常に見直しと修正の機会が組み込まれたプロセスになります。

### 情報は共有メモリで一元管理する

各エージェントのやり取りには、共有メモリを使います。構想の案、探索済みのデータ、数式、図表、考察などを順次記録し、誰がいつどの情報を扱ったかがわかるように整理しておきます。

記録はキー付きのメモ形式で行います。各エージェントは新しい情報を保存するたびに、固有のラベルをつけ、他のエージェントがそれを参照できるようにします。作業履歴が可視化され、後工程でのトレースも容易になります。

### 協調の進め方

進行の起点は構想です。構想エージェントが複数の案を提示し、それをメモリに記録します。次に、データ探索とモデル実装がそれぞれの案に基づいて動き出します。データの可用性や精度、モデリング上の整合性に応じて、構想側へ再提案を促すこともあります。報告書作成はプロセス全体の動きを俯瞰しながら、適切なタイミングで各エージェントの成果を統合し、全体像を整えていきます。

## モデリングをどう評価するか

評価体制を整えることで、オープンエンドなモデリング課題に対しても、LLMが生み出した成果の質を的確に見極めることができます。

基本的に、モデリングの成果を確認するときは、最終的に提出されたレポートを主な判断材料とします。計算の正確さやデータの品質だけでなく、課題の理解、構想の明快さ、手法の適切さ、結果の伝え方まで含めて評価します。途中の試行錯誤やコードそのものではなく、ひとまとまりの成果物としての完成度を見ます。

### 評価には異なる専門分野を組み合わせる

一つの視点では見落としがちなポイントを補うため、複数の専門性をもった評価者を組み合わせます。数理モデリングに詳しい人とデータ分析に精通した人を基本にしつつ、課題に応じた分野から2名の専門家を追加します。たとえば森林管理の問題であれば、生態学や環境政策に通じた専門家を加えることで、現実的な妥当性にも目を配ります。

### 評価の軸は三つに整理する

次の三つが評価軸です。

- 構成が論理的で読みやすいこと
- 課題に含まれるすべての要素に対応していること
- 内容に説得力と独自性があること

### 評価の偏りを抑える仕組み

構成の整理や要素の網羅といった部分は、単一の評価者でも比較的安定した判断が可能です。一方で、内容の価値や創造性には主観が入りやすいため、異なる専門性を持つ複数の評価者の判断を組み合わせて、バランスをとります。個人の好みによる偏りを防ぎながら、より実務に即した判断を導きます。

## LLMにモデリングを任せたとき、何ができて何ができないのか

### 比較対象を用意して検証する

LLMに複雑なモデリング課題を解かせたとき、どのような構成で最も良い成果が得られるかを確認するには、異なるアプローチでの比較が有効です。以下の2つの手法を基準として性能を測定します。

- LLMにツールを使わせず、プロンプトだけでモデリング報告書を一括生成する直接生成方式
- LLMにサンドボックスの全機能を解放し、プランナーを含めたツール使用を自律的に判断させるツールエージェント方式

それぞれ「ツールなしでどこまでできるか」「役割分担なしでどこまで工夫できるか」を測るためのベースラインになります。

### モデルと評価の設計

検証には、GPT-4oやQwen2.5-70B、Llama3.1-72Bなど、多様なLLMを含むモデル群を使用します。出力されたモデリング報告書を、前に紹介した評価フレームワークに従って採点します。

- 評価には構成の整合性、課題要件の網羅、内容の根拠性と創造性を含む
- 各スコアは、専門性の異なる評価者の視点から集計し、平均で算出
- 使用する全問題においてスコアを平均化し、安定した傾向を確認

小規模モデルは、複雑な指示に応じた出力が困難であるため除外しています。

### ModelingAgentの結果を見る

ModelingAgentを使った場合、2つのベースライン手法に比べて最大20%のスコア向上が見られました。とくに、アイデアの多様性や創造性を評価するスコアでは30%近い改善が観測され、構想段階から工夫できる構成が成果に大きく影響していると判断されます。

構造の明確さや根拠のある分析にもプラスの影響があり、報告書全体の品質向上につながっています。

![](https://ai-data-base.com/wp-content/uploads/2025/05/AIDB_90253_8-1024x658.png)

手法やモデルごとの評価スコアの比較

### 人間との比較で見えた課題

同じ課題を人間の受賞者チームが解いた過去の報告書と比較すると、まだ差があることが明らかになります。人間は課題の構成を正確に把握し、要素を漏れなく盛り込む力に優れています。

また、必要なデータの見極めや分析の柔軟性でも、人間の判断には依然として強みがあります。推論に特化した大規模モデルであっても、その点で人間を上回る結果は出ていませんでした。

### 革新性は依然として課題

ツールを使わせるだけでも一定の改善は得られますが、最も得点が低かった項目は創造性です。ModelingAgentを導入することでこのスコアは明確に向上しますが、それでも他の評価軸に比べて一貫して低いままです。

これは、LLMが人間のような新規性を持った発想を生み出すにはまだ限界があることを示しています。

ただしベースモデルが変われば結果は変わるため、あくまで一例として見ておくのがよいです。

### 批評と改善の効果を追跡する

ModelingAgent内で複数のエージェントが批評を繰り返す過程では、スコアが段階的に上昇する傾向が確認されています。アイデア提案、データ探索、モデル構築といった各工程で、繰り返しのやり取りを通じて改善されていきます。

![](https://ai-data-base.com/wp-content/uploads/2025/05/AIDB_90253_9-1024x263.png)

批評スコアがどう変化したかの推移グラフ

この変化は、LLMを一つのタスクで完結させるのではなく、ステップごとに見直す設計が有効であることを示しています。

![](https://ai-data-base.com/wp-content/uploads/2025/05/AIDB_90253_10-1024x687.png)

ある課題でのモデル改良の具体例

### よくある失敗の傾向

生成された出力を観察すると、以下の点でつまずく傾向が見られます。

- 仮定や定義があいまいで、数式に反映されていない
- 実データを取り扱う際の信頼性評価が甘い
- 分析が表面的で、仮定の影響を十分に検討できていない

これらは、タスクの理解やデータ解釈、分析設計の部分で人間にまだ及ばない部分といえます。

![](https://ai-data-base.com/wp-content/uploads/2025/05/AIDB_90253_11-1024x363.png)

よくある失敗パターンの分類まとめ

### 人間の目で見たときの印象

人間の評価者にもモデリング報告書を読んでもらい、他の出力と比較して順位づけを行う方式で主観評価を実施しました。その結果、QwQ-32Bを使ったModelingAgentの報告書が最も多く選ばれ、ベースライン手法よりも一貫して好まれる傾向がありました。

さらに、半数以上のケースで、人間チームの解答と区別がつかなかったと判断されています。これはLLMが現実の問題に対して、人間の出力に近い説得力を持つ報告書を作成できる可能性を示しています。

![](https://ai-data-base.com/wp-content/uploads/2025/05/AIDB_90253_12-537x1024.png)

人間による評価でのモデルや手法の順位

## まとめ

本記事では、LLMによるモデリング支援のためのエージェント設計と評価手法を紹介しました。

構想、実装、報告までを役割分担しながら進める設計が、出力の安定性や分析の根拠性を高める効果を見せています。創造性や応用の幅に課題は残るものの、定型的な課題には一定の再現性が確認されています。

人間の審査に近い評価軸を導入することで、出力の質をより正確に把握できるようになっています。

自社でLLMを使ってレポート生成や分析支援を行う際の構成や導入ステップを考える手がかりになれば幸いです。

**参照文献情報**

- タイトル：ModelingAgent: Bridging LLMs and Mathematical Modeling for Real-World Challenges
- URL： [https://doi.org/10.48550/arXiv.2505.15068](https://doi.org/10.48550/arXiv.2505.15068)
- 著者：Cheng Qian, Hongyi Du, Hongru Wang, Xiusi Chen, Yuji Zhang, Avirup Sil, Chengxiang Zhai, Kathleen McKeown, Heng Ji
- 所属：University of Illinois Urbana-Champaign, IBM Research AI, Columbia University

**■サポートのお願い  
**AIDBを便利だと思っていただけた方に、任意の金額でサポートしていただけますと幸いです。  

  

[ウェブからデータを構造的に自動収集するLLMエージェント手法](https://ai-data-base.com/archives/90371)

[「マルチエージェント」は必要か　精度とコストのバランスをとるLLMエージェント構成判断の考え方](https://ai-data-base.com/archives/90497)

 [![](https://ai-data-base.com/wp-content/themes/innovate_hack_tcd025/img/footer/return_top.png) PAGE TOP](https://ai-data-base.com/archives/#header_top)